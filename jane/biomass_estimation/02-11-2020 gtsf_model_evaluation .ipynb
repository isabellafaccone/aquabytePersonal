{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.data_loader import KeypointsDataset, NormalizeCentered2D, ToTensor, BODY_PARTS\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADIPOSE_FIN = 'ADIPOSE_FIN'\n",
    "ANAL_FIN = 'ANAL_FIN'\n",
    "DORSAL_FIN = 'DORSAL_FIN'\n",
    "EYE = 'EYE',\n",
    "PECTORAL_FIN = 'PECTORAL_FIN'\n",
    "PELVIC_FIN = 'PELVIC_FIN'\n",
    "TAIL_NOTCH = 'TAIL_NOTCH'\n",
    "UPPER_LIP ='UPPER_LIP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NormalizedStabilityTransform(object):\n",
    "    \"\"\"\n",
    "        Transforms world keypoints into a more stable coordinate system - this will lead to better\n",
    "        training / convergene\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        modified_kps, label, stereo_pair_id, cm = \\\n",
    "            sample['modified_kps'], sample['label'], sample['stereo_pair_id'], sample['cm']\n",
    "        modified_wkps = pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)\n",
    "        stabilized_coordinates = {}\n",
    "        for bp in BODY_PARTS:\n",
    "            wkp = modified_wkps[bp]\n",
    "            stabilized_kp_info = [0.5 * wkp[0]/wkp[1], 0.5 * wkp[2]/wkp[1], 0.5 * 0.1/wkp[1]]\n",
    "            stabilized_coordinates[bp] = stabilized_kp_info\n",
    "            \n",
    "        normalized_label = label * 1e-4 if label else None\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': stabilized_coordinates,\n",
    "            'label': normalized_label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gtsf data\n",
    "\n",
    "#rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints -> 'leftCrop' is not null\n",
    "    and b.keypoints -> 'rightCrop' is not null\n",
    "    and b.is_qa = false\n",
    "    order by b.captured_at\n",
    "\"\"\"\n",
    "\n",
    "results = prod_db_connection.execute(query)\n",
    "df_gtsf = pd.DataFrame(results.fetchall())\n",
    "df_gtsf.columns = results.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtsf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtsf['data_collection_type_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pre_trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amg = AccuracyMetricsGenerator()\n",
    "# amg.generate_accuracy_metrics(y_pred, df_gtsf['weight'], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_MPE(y_pred, df_gtsf['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_MAPE(y_pred, df_gtsf['weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MPE(y_predict, y_train):\n",
    "    # calculate mean percentage error\n",
    "    return np.mean((y_train - y_predict) / y_train)\n",
    "\n",
    "def get_MAPE(y_predict, y_train):\n",
    "    # calcuate mean absolute percentage error\n",
    "    return np.mean(np.absolute((y_train - y_predict) / y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_gtsf.iloc[13752]\n",
    "input_sample = {\n",
    "    'keypoints': row.keypoints,\n",
    "    'cm': row.camera_metadata,\n",
    "    'stereo_pair_id': row.id,\n",
    "    'single_point_inference': True\n",
    "}\n",
    "nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform.__call__(input_sample)\n",
    "\n",
    "normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "normalized_3D_kps = normalized_stability_kps['kp_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_3D_kps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_orientation(normalized_3D_kps):\n",
    "    # degree between tail to lip vector and \n",
    "    tail_lip = np.array(normalized_3D_kps[TAIL_NOTCH]) - np.array(normalized_3D_kps[UPPER_LIP])\n",
    "    x_hat = np.array([1, 0, 0])\n",
    "    tail_lip_xy_proj = tail_lip * np.array([1, 1, 0])\n",
    "    cos_phi = get_cos(x_hat, tail_lip_xy_proj)\n",
    "    return np.degrees(np.arccos(cos_phi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_orientation(normalized_3D_kps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curvature(normalized_3D_kps):\n",
    "    dorsal_lip = np.array(normalized_3D_kps[DORSAL_FIN]) - np.array(normalized_3D_kps[UPPER_LIP])\n",
    "    dorsal_tail = np.array(normalized_3D_kps[DORSAL_FIN]) - np.array(normalized_3D_kps[TAIL_NOTCH])\n",
    "\n",
    "    dorsal_lip_xy_proj = dorsal_lip * np.array([1, 1, 0])\n",
    "    dorsal_tail_xy_proj = dorsal_tail * np.array([1, 1, 0])\n",
    "\n",
    "    cos_alpha = get_cos(dorsal_lip_xy_proj, dorsal_tail_xy_proj)\n",
    "    return np.degrees(np.arccos(cos_alpha))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lean(normalized_3d_kps):\n",
    "    tail_lip = np.array(normalized_3D_kps[TAIL_NOTCH]) - np.array(normalized_3D_kps[UPPER_LIP])\n",
    "    tail_lip_xz_proj = tail_lip * np.array([1, 0, 1])\n",
    "    x_hat = np.array([1, 0, 0])\n",
    "    cos_beta = get_cos(tail_lip_xz_proj, x_hat )\n",
    "    return np.degrees(np.arccos(cos_beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(weight):\n",
    "    if weight < 2000:\n",
    "        return 'small'\n",
    "    if weight < 6000:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_centered_2D_transform = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"fish_id\"\n",
    "                           ,\"weight\"\n",
    "                           ,\"input_sample\"\n",
    "                           ,\"orientation\"\n",
    "                           ,\"curvature\"\n",
    "                           ,\"lean\"\n",
    "                           ,\"predicted_weight\"\n",
    "                           ,\"size\"\n",
    "                          ])\n",
    "y_pred = []\n",
    "\n",
    "for idx, row in df_gtsf.iterrows():\n",
    "    input_sample = {\n",
    "        'keypoints': row.keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps) \n",
    "    normalized_3D_kps = normalized_stability_kps['kp_input']\n",
    "    weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    ornt = get_orientation(normalized_3D_kps)\n",
    "    curv = get_curvature(normalized_3D_kps)\n",
    "    lean = get_lean(normalized_3D_kps)\n",
    "    df = df.append({'fish_id': row['fish_id']\n",
    "                  ,'input_sample':input_sample\n",
    "                  ,'weight': row['weight']\n",
    "                  ,\"orientation\":ornt\n",
    "                  ,\"curvature\":curv\n",
    "                  ,\"lean\":lean\n",
    "                  ,\"predicted_weight\":weight_prediction}, ignore_index=True)   \n",
    "\n",
    "    \n",
    "df['weight'] = df['weight'].astype(int)\n",
    "df['error'] = df['weight'] - df['predicted_weight']\n",
    "df['size'] = df['weight'].apply(get_size)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['size'] == 'small') / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['size'] == 'medium') / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['size'] == 'large') / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(df['weight'], bins=10)  # arguments are passed to np.histogram\n",
    "#_ = plt.hist(orientation, bins=20)\n",
    "plt.title(\"Histogram of GTSF weight\")\n",
    "plt.xlabel('weight (g)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('error plot')\n",
    "\n",
    "plt.axvline(x=2000, color='r', linestyle='--')\n",
    "plt.axvline(x=6000, color='r', linestyle='--')\n",
    "plt.scatter('weight', 'error', data = df, marker='.')\n",
    "plt.xlabel('ground truth weight (g)')\n",
    "plt.ylabel('error (g)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.error == df.error.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.error == df.error.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(10, 5))\n",
    "fig.suptitle('Error plots')\n",
    "ax1.plot('weight', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "ax2.plot('predicted_weight', 'weight', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3,figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('Error plots')\n",
    "\n",
    "axes[0].plot('orientation', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "axes[0].set(xlabel='orientation', ylabel='error')\n",
    "\n",
    "axes[1].plot('curvature', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "axes[1].set(xlabel='curvature')\n",
    "\n",
    "axes[2].plot('lean', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "axes[2].set(xlabel='lean')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot('orientation', 'error', \n",
    "         data=df.drop([np.argmin(df['orientation'])], axis = 0), linestyle='none', marker='.')\n",
    "plt.title('Orientation vs error')\n",
    "plt.xlabel('orientation (degree)')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot('curvature', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot('lean', 'error', \n",
    "         data=df, linestyle='none', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(df['curvature'], bins=10, range = (100, 180))  # arguments are passed to np.histogram\n",
    "#_ = plt.hist(orientation, bins=20)\n",
    "plt.title(\"Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True) # keypoints nan leads to orientation nan\n",
    "df = df.drop(df[df['orientation'] < 90].index)\n",
    "X = df[['size', 'orientation']]\n",
    "X['size'] = X['size'].astype('category')\n",
    "X = pd.get_dummies(X, columns=['size'], prefix = ['size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    df.error,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overpredict when more alined with the frame\n",
    "\n",
    "underpredict for large fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_MPE(df[df['size'] == 'small']['predicted_weight'],\n",
    "        df[df['size'] == 'small']['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_MPE(df[df['size'] == 'medium']['predicted_weight'],\n",
    "        df[df['size'] == 'medium']['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_MPE(df[df['size'] == 'large']['predicted_weight'],\n",
    "        df[df['size'] == 'large']['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['size'] == 'large'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['size'] == 'medium'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['size'] == 'small'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argmin(df[df['size'] == 'small']['error'])\n",
    "f_id = df[df['size'] == 'small'].iloc[ind]['fish_id']\n",
    "\n",
    "df.loc[df['fish_id'] == f_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gtsf.loc[df_gtsf['fish_id'] == f_id]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gtsf.loc[df_gtsf['id'] == 606388]['keypoints'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, cnt = np.unique(df['fish_id'], return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ids = val[cnt > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(cnt, bins=10)  # arguments are passed to np.histogram\n",
    "#_ = plt.hist(orientation, bins=300)\n",
    "plt.title(\"Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 20), sharex=True)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # axes.ylim(-500, 500)\n",
    "        f_id = f_ids[i * 3 + j]\n",
    "        temp = df.loc[df['fish_id'] == f_id]\n",
    "        axes[i, j].plot('orientation', 'error',\n",
    "                        data=temp, linestyle='none', marker='.')\n",
    "        axes[i, j].set_title('weight (g): {} '.format(temp['weight'].iloc[0]))\n",
    "\n",
    "        axes[i, j].set(ylabel='error')\n",
    "\n",
    "#plt.xlabel('orientation')        \n",
    "figure.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows for the fish that have most records\n",
    "f_id = val[np.argmax(cnt)]\n",
    "#f_id = '190710-ce6f49e0-eb12-4655-985b-0fdd82ab519a'\n",
    "#f_id = '190717-d2573589-6b5b-4f19-a0b9-4714432b5209'\n",
    "#f_id = '190725-56a4b6d5-edfb-4fc2-9f81-cb152901da40'\n",
    "\n",
    "temp = df.loc[df['fish_id'] == f_id]\n",
    "print('weight of the fish', temp['weight'].iloc[0])\n",
    "plt.ylim(-100, 600) \n",
    "plt.plot('orientation', 'error', \n",
    "         data=temp, linestyle='none', marker='.')\n",
    "plt.xlabel(\"orientation\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coff = []\n",
    "for f_id in f_ids:\n",
    "    temp = df.loc[(df['fish_id'] == f_id) & (np.absolute(df['error']) < 800)]\n",
    "    X = temp[['orientation']] \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, temp.error, test_size=0.2, random_state=0)\n",
    "    regressor = LinearRegression()  \n",
    "    regressor.fit(X_train, y_train)\n",
    "    coff.append(regressor.coef_)\n",
    "np.mean(coff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
