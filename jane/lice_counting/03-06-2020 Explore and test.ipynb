{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 33\n",
    "CROP_WIDTH = 512\n",
    "CROP_HEIGHT = 512\n",
    "\n",
    "\n",
    "LABEL_PATH = 'data/lice_crop_labels'\n",
    "IMAGE_PATH = 'data/lice_crop_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "\n",
    "def train_test_split(train_size, valid_size, random_state = None, shuffle = True):\n",
    "    image_files = [join(IMAGE_PATH, f) for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "    if shuffle: random.shuffle(image_files)\n",
    "    \n",
    "    train_file = open(\"data/train.txt\", \"w+\")\n",
    "    valid_file = open(\"data/valid.txt\", \"w+\")\n",
    "    test_file = open(\"data/test.txt\", \"w+\")\n",
    "    train_number,valid_number,test_number = 0, 0, 0\n",
    "    \n",
    "    for f in image_files:\n",
    "        u = random.uniform(0, 1)\n",
    "        f += '\\n'\n",
    "        if u < train_size:\n",
    "            train_file.write(f)\n",
    "            train_number += 1\n",
    "            continue\n",
    "        elif u < train_size + valid_size:\n",
    "            valid_file.write(f)\n",
    "            valid_number += 1\n",
    "            continue\n",
    "        test_file.write(f)\n",
    "        test_number += 1\n",
    "    print(\"train {}, valid {}, test {}\".format(train_number, valid_number, test_number))\n",
    "    train_file.close()\n",
    "    valid_file.close()\n",
    "    test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 94, valid 80, test 691\n"
     ]
    }
   ],
   "source": [
    "train_test_split(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-07 05:43:32.223955: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:32.224034: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:32.224046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Namespace(batch_size=4, checkpoint_interval=1, compute_map=False, data_config='config/lice.data', epochs=100, evaluation_interval=1, gradient_accumulations=2, img_size=512, model_def='config/yolov3-lice.cfg', multiscale_training=True, n_cpu=0, pretrained_weights=None)\n",
      "2020-03-07 05:43:33.335380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-03-07 05:43:33.355929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-03-07 05:43:33.357122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-03-07 05:43:33.358200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-03-07 05:43:33.361416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-03-07 05:43:33.361604: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361667: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361724: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361781: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361836: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361890: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361944: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-03-07 05:43:33.361954: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2020-03-07 05:43:33.362209: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-07 05:43:33.393119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3597595000 Hz\n",
      "2020-03-07 05:43:33.394316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb5ef021f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-07 05:43:33.394375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-07 05:43:33.947658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb5ef98930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-07 05:43:33.947689: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-03-07 05:43:33.947701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-03-07 05:43:33.947707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-03-07 05:43:33.947714: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-03-07 05:43:33.948233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-07 05:43:33.948249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      \n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 105, in <module>\n",
      "    loss, outputs = model(imgs, targets)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/jane/cv_research/jane/lice_counting/models.py\", line 252, in forward\n",
      "    x = module(x)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/activation.py\", line 544, in forward\n",
      "    return F.leaky_relu(input, self.negative_slope, self.inplace)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\", line 1018, in leaky_relu\n",
      "    result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 40.50 MiB (GPU 3; 10.91 GiB total capacity; 1.47 GiB already allocated; 35.44 MiB free; 730.50 KiB cached)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!pip install -r requirements.txt\n",
    "!python3 train.py --model_def config/yolov3-lice.cfg --data_config config/lice.data --n_cpu 0 --batch_size 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
