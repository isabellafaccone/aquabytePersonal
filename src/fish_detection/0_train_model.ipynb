{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_retinanet imports\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "# sys.path.append('/root/amol/product_detection/keras-retinanet/keras_retinanet/preprocessing/')\n",
    "# from csv_generator import CSVGenerator\n",
    "# from ..models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create annotations.csv\n",
    "# directory = '/root/data/blender_data/augmented_data0/training/validation_low_rez//'\n",
    "# labels = json.load(open(os.path.join(directory, 'labels.json')))\n",
    "# annotations = []\n",
    "# for label in labels:\n",
    "#     if not isinstance(label, list):\n",
    "#         for bbox in label['bboxes']:\n",
    "#             annotations.append([label['path'], bbox[0], bbox[1], bbox[2], bbox[3], 'fish'])\n",
    "\n",
    "# with open(os.path.join(directory, 'annotations.csv'), 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile, delimiter=',')\n",
    "#     for row in annotations:\n",
    "#         writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(annotations,classes,batch_size=1,val_annotations=''):\n",
    "    # create random transform generator for augmenting training data\n",
    "    transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_generator = CSVGenerator(\n",
    "        annotations,\n",
    "        classes,\n",
    "        transform_generator=transform_generator,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_annotations:\n",
    "        validation_generator = CSVGenerator(\n",
    "            val_annotations,\n",
    "            classes,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = None\n",
    "    \n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, backbone, num_classes, weights, multi_gpu=0, freeze_backbone=False):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, backbone=backbone, nms=False, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "\n",
    "        # append NMS for prediction only\n",
    "        classification   = model.outputs[1]\n",
    "        detections       = model.outputs[2]\n",
    "        boxes            = keras.layers.Lambda(lambda x: x[:, :, :4])(detections)\n",
    "        detections       = layers.NonMaximumSuppression(name='nms')([boxes, classification, detections])\n",
    "        prediction_model = keras.models.Model(inputs=model.inputs, outputs=model.outputs[:2] + [detections])\n",
    "    else:\n",
    "        model            = model_with_weights(backbone_retinanet(num_classes, backbone=backbone, nms=True, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model   = model\n",
    "        prediction_model = model\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/root/data/blender_data/augmented_data0/training/train_low_rez/annotations.csv'\n",
    "# annotations = '/root/thomas/mask/data/annotations.csv'\n",
    "classes = '/root/thomas/mask/data/classID.csv'\n",
    "batch_size = 8\n",
    "val_annotations = '/root/data/blender_data/augmented_data0/training/validation_low_rez/annotations.csv'\n",
    "val_annotations = annotations\n",
    "weights = download_imagenet('resnet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = create_generators(annotations, classes, batch_size, val_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Output \"nms\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"nms\" during training.\n"
     ]
    }
   ],
   "source": [
    "model, training_model, prediction_model = create_models(backbone_retinanet=retinanet,\n",
    "                                                        backbone='resnet50',\n",
    "                                                        num_classes=train_generator.num_classes(),\n",
    "                                                        weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-5\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/retinanet/', 'model_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 122s 976ms/step - loss: 4.6078 - regression_loss: 3.6457 - classification_loss: 0.9620 - val_loss: 3.1264 - val_regression_loss: 2.7296 - val_classification_loss: 0.3967\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 117s 939ms/step - loss: 2.5041 - regression_loss: 2.1994 - classification_loss: 0.3048 - val_loss: 1.9100 - val_regression_loss: 1.6538 - val_classification_loss: 0.2563\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 117s 939ms/step - loss: 1.6674 - regression_loss: 1.4311 - classification_loss: 0.2363 - val_loss: 1.4941 - val_regression_loss: 1.2773 - val_classification_loss: 0.2168\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 1.3559 - regression_loss: 1.1571 - classification_loss: 0.1988 - val_loss: 1.2612 - val_regression_loss: 1.0816 - val_classification_loss: 0.1796\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 1.1702 - regression_loss: 1.0102 - classification_loss: 0.1601 - val_loss: 1.0638 - val_regression_loss: 0.9247 - val_classification_loss: 0.1391\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 117s 939ms/step - loss: 1.0328 - regression_loss: 0.9038 - classification_loss: 0.1290 - val_loss: 0.9436 - val_regression_loss: 0.8281 - val_classification_loss: 0.1155\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.9282 - regression_loss: 0.8220 - classification_loss: 0.1063 - val_loss: 0.9201 - val_regression_loss: 0.8210 - val_classification_loss: 0.0992\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 0.8529 - regression_loss: 0.7615 - classification_loss: 0.0914 - val_loss: 0.7751 - val_regression_loss: 0.6929 - val_classification_loss: 0.0823\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 0.7917 - regression_loss: 0.7105 - classification_loss: 0.0812 - val_loss: 0.8065 - val_regression_loss: 0.7255 - val_classification_loss: 0.0810\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 117s 939ms/step - loss: 0.7335 - regression_loss: 0.6585 - classification_loss: 0.0750 - val_loss: 0.6980 - val_regression_loss: 0.6270 - val_classification_loss: 0.0710\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 118s 942ms/step - loss: 0.7012 - regression_loss: 0.6306 - classification_loss: 0.0706 - val_loss: 0.6892 - val_regression_loss: 0.6199 - val_classification_loss: 0.0692\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 118s 945ms/step - loss: 0.6784 - regression_loss: 0.6112 - classification_loss: 0.0673 - val_loss: 0.6841 - val_regression_loss: 0.6179 - val_classification_loss: 0.0662\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.6540 - regression_loss: 0.5897 - classification_loss: 0.0642 - val_loss: 0.6273 - val_regression_loss: 0.5654 - val_classification_loss: 0.0618\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 117s 937ms/step - loss: 0.6326 - regression_loss: 0.5713 - classification_loss: 0.0613 - val_loss: 0.6175 - val_regression_loss: 0.5534 - val_classification_loss: 0.0641\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 117s 937ms/step - loss: 0.6128 - regression_loss: 0.5537 - classification_loss: 0.0591 - val_loss: 0.5834 - val_regression_loss: 0.5286 - val_classification_loss: 0.0548\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 0.5992 - regression_loss: 0.5423 - classification_loss: 0.0569 - val_loss: 0.6030 - val_regression_loss: 0.5449 - val_classification_loss: 0.0580\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 117s 938ms/step - loss: 0.5843 - regression_loss: 0.5293 - classification_loss: 0.0549 - val_loss: 0.5682 - val_regression_loss: 0.5153 - val_classification_loss: 0.0529\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 0.5665 - regression_loss: 0.5135 - classification_loss: 0.0531 - val_loss: 0.5578 - val_regression_loss: 0.5076 - val_classification_loss: 0.0501\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 0.5523 - regression_loss: 0.5011 - classification_loss: 0.0512 - val_loss: 0.5818 - val_regression_loss: 0.5296 - val_classification_loss: 0.0522\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 117s 939ms/step - loss: 0.5332 - regression_loss: 0.4832 - classification_loss: 0.0500 - val_loss: 0.5386 - val_regression_loss: 0.4907 - val_classification_loss: 0.0479\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 118s 942ms/step - loss: 0.5253 - regression_loss: 0.4763 - classification_loss: 0.0490 - val_loss: 0.4981 - val_regression_loss: 0.4514 - val_classification_loss: 0.0467\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 118s 944ms/step - loss: 0.5167 - regression_loss: 0.4686 - classification_loss: 0.0482 - val_loss: 0.5382 - val_regression_loss: 0.4877 - val_classification_loss: 0.0506\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 118s 940ms/step - loss: 0.5098 - regression_loss: 0.4625 - classification_loss: 0.0473 - val_loss: 0.5305 - val_regression_loss: 0.4811 - val_classification_loss: 0.0494\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 0.5039 - regression_loss: 0.4576 - classification_loss: 0.0463 - val_loss: 0.5253 - val_regression_loss: 0.4779 - val_classification_loss: 0.0474\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.4972 - regression_loss: 0.4514 - classification_loss: 0.0458 - val_loss: 0.5035 - val_regression_loss: 0.4578 - val_classification_loss: 0.0458\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 118s 941ms/step - loss: 0.4903 - regression_loss: 0.4454 - classification_loss: 0.0449 - val_loss: 0.4919 - val_regression_loss: 0.4455 - val_classification_loss: 0.0464\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.4837 - regression_loss: 0.4394 - classification_loss: 0.0442 - val_loss: 0.4639 - val_regression_loss: 0.4206 - val_classification_loss: 0.0433\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 117s 934ms/step - loss: 0.4791 - regression_loss: 0.4355 - classification_loss: 0.0437 - val_loss: 0.4616 - val_regression_loss: 0.4191 - val_classification_loss: 0.0426\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 117s 940ms/step - loss: 0.4727 - regression_loss: 0.4299 - classification_loss: 0.0429 - val_loss: 0.4444 - val_regression_loss: 0.4058 - val_classification_loss: 0.0386\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 118s 943ms/step - loss: 0.4643 - regression_loss: 0.4219 - classification_loss: 0.0424 - val_loss: 0.4508 - val_regression_loss: 0.4098 - val_classification_loss: 0.0410\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "history = training_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=1000//batch_size,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=100//batch_size,\n",
    "        callbacks=[checkpoint, lr_scheduler]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
