{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from research.weight_estimation.keypoint_utils.body_parts import core_body_parts\n",
    "from research.weight_estimation.keypoint_utils.keypoint_transformations import get_raw_3d_coordinates\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "from research.utils.data_access_utils import RDSAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select * from prod.biomass_computations\n",
    "    where pen_id=88\n",
    "    and captured_at >= '2020-02-10'\n",
    "    and captured_at <= '2020-02-20'\n",
    "    and akpd_score >= 0.0\n",
    "\"\"\"\n",
    "\n",
    "df = rds.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FishDetection = namedtuple('FishDetection', ['left_crop_url', 'right_crop_url', 'captured_at',\n",
    "                                             'annotation', 'camera_metadata', 'estimated_weight_g',\n",
    "                                             'estimated_k_factor', 'akpd_score'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def ts_to_unix_epoch(ts):\n",
    "    epoch = time.mktime(ts.timetuple())\n",
    "    return epoch\n",
    "\n",
    "def time_gap_between_fds(fd, hist_fd):\n",
    "    time_gap = ts_to_unix_epoch(fd.captured_at) - ts_to_unix_epoch(hist_fd.captured_at)\n",
    "    return time_gap\n",
    "\n",
    "\n",
    "def check_if_consecutive_match(fd: FishDetection, hist_fd: FishDetection,\n",
    "                               lookback_period_s: float, pixel_threshold: int = 300) -> bool:\n",
    "\n",
    "#     print(fd.captured_at, hist_fd.captured_at, ts_to_unix_epoch(fd.captured_at), time_gap)\n",
    "    time_gap = time_gap_between_fds(fd, hist_fd)\n",
    "    if time_gap == 0 or time_gap > lookback_period_s:\n",
    "        return False\n",
    "    \n",
    "    X_left, X_right = get_left_right_keypoint_arrs(fd.annotation)\n",
    "    X_left_hist, X_right_hist = get_left_right_keypoint_arrs(hist_fd.annotation)\n",
    "\n",
    "    # perform reasonable shift check\n",
    "    eye, tail = core_body_parts.index('EYE'), core_body_parts.index('TAIL_NOTCH')\n",
    "    eye_translation = X_left[eye] - X_left_hist[eye]\n",
    "    tail_translation = X_left[tail] - X_left_hist[tail]\n",
    "    if ts_to_unix_epoch(fd.captured_at) == 1597203250.0:\n",
    "        print(np.linalg.norm(eye_translation - tail_translation))\n",
    "    if np.linalg.norm(eye_translation - tail_translation) > pixel_threshold:\n",
    "        return False\n",
    "\n",
    "    # perform forward movement check\n",
    "    fish_displacement = X_left[eye] - X_left[tail]\n",
    "    angle_difference = np.arccos(np.dot(eye_translation, fish_displacement) / (np.linalg.norm(eye_translation) * np.linalg.norm(fish_displacement)))\n",
    "    if np.abs(angle_difference) > np.pi / 4.0:\n",
    "        return False\n",
    "    if np.linalg.norm(eye_translation) > 2 * np.linalg.norm(fish_displacement):\n",
    "        return False\n",
    "    \n",
    "#     forward_movement_check = np.sign(X_left[eye][0] - X_left[tail][0]) == \\\n",
    "#                              np.sign(X_left_hist[eye][0] - X_left_hist[tail][0]) == \\\n",
    "#                              np.sign(X_left[eye][0] - X_left_hist[eye][0])\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def compute_speed(fd: FishDetection, hist_fd: FishDetection) -> float:\n",
    "    X_world = get_raw_3d_coordinates(fd.annotation, fd.camera_metadata)\n",
    "    X_world_hist = get_raw_3d_coordinates(hist_fd.annotation, hist_fd.camera_metadata)\n",
    "    distance = np.median(np.linalg.norm(X_world - X_world_hist, axis=0))\n",
    "    time = ts_to_unix_epoch(fd.captured_at) - ts_to_unix_epoch(hist_fd.captured_at)\n",
    "    return float(distance) / time\n",
    "\n",
    "\n",
    "def compute_swimming_speeds(fish_detections: List[FishDetection],\n",
    "                           lookback_period_s: float = 5.0) -> List:\n",
    "\n",
    "    historical_fds = []\n",
    "    speed_objects = []\n",
    "    for fd in sorted(fish_detections, key=lambda x: x.captured_at):\n",
    "        if fd.annotation is None:\n",
    "            continue\n",
    "        if 'leftCrop' not in fd.annotation or 'rightCrop' not in fd.annotation:\n",
    "            continue\n",
    "        \n",
    "        # purge historical fds\n",
    "        historical_fds = [hist_fd for hist_fd in historical_fds if time_gap_between_fds(fd, hist_fd) < lookback_period_s]\n",
    "        \n",
    "        for hist_fd in historical_fds:\n",
    "            is_consecutive_match = check_if_consecutive_match(fd, hist_fd, lookback_period_s)\n",
    "            if is_consecutive_match:\n",
    "                speed = compute_speed(fd, hist_fd)\n",
    "                if speed < 1.0:\n",
    "                    speed_obj = (fd, hist_fd, hist_fd.captured_at, speed, hist_fd.left_crop_url, \n",
    "                                 fd.left_crop_url, hist_fd.estimated_weight_g, fd.estimated_weight_g,\n",
    "                                 hist_fd.akpd_score, fd.akpd_score)\n",
    "                    speed_objects.append(speed_obj)\n",
    "        historical_fds.append(fd)\n",
    "\n",
    "    return speed_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_detections = []\n",
    "for idx, row in df.iterrows():\n",
    "    fd = FishDetection(\n",
    "        left_crop_url=row.left_crop_url,\n",
    "        right_crop_url=row.right_crop_url,\n",
    "        captured_at=row.captured_at,\n",
    "        annotation=row.annotation,\n",
    "        camera_metadata=row.camera_metadata,\n",
    "        estimated_weight_g=row.estimated_weight_g,\n",
    "        estimated_k_factor=row.estimated_k_factor,\n",
    "        akpd_score=row.akpd_score\n",
    "    )\n",
    "    fish_detections.append(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd1 = dict(speed_objects[0][0]._asdict())\n",
    "fd2 = dict(speed_objects[0][1]._asdict())\n",
    "fd1['captured_at'] = str(fd1['captured_at'])\n",
    "fd2['captured_at'] = str(fd2['captured_at'])\n",
    "\n",
    "print(json.dumps([fd1, fd2], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(fish_detections[0].captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.mktime(dt.datetime.strptime(str(fish_detections[0].captured_at).split('+')[0], '%Y-%m-%d %H:%M:%S.%f').timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_objects = compute_swimming_speeds(fish_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([(speed_obj[4], speed_obj[5], speed_obj[6], speed_obj[7]) for speed_obj in speed_objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((x[:, 0] - x[:, 1]) / x[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist([speed_obj[1] for speed_obj in speed_objects], bins=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimming_speed_df = pd.DataFrame({\n",
    "    'captured_at': [so[0] for so in speed_objects],\n",
    "    'speed': [so[1] for so in speed_objects]\n",
    "})\n",
    "\n",
    "swimming_speed_df = swimming_speed_df.sort_values('captured_at', ascending=True)\n",
    "swimming_speed_df.index = swimming_speed_df.captured_at\n",
    "swimming_speed_df.index = pd.to_datetime(swimming_speed_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = swimming_speed_df.speed.resample('D').agg(lambda x: x.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(swimming_speed_df.index, swimming_speed_df.speed)\n",
    "tdf = swimming_speed_df.rolling('6H').mean().resample('H').agg(lambda x: x.mean())\n",
    "plt.plot(tdf.index, tdf.values, color='red', linewidth=7)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.index.date.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'date': tdf.index.date.astype(str),\n",
    "    'speed': tdf.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
