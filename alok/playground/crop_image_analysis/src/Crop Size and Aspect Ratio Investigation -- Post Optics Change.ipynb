{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set pandas options\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load crop dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_annotations_path = '/root/data/alok/crop_data/data_dumps/new_optics_annotations.csv'\n",
    "analysis_df_annotations_reconciled_path = '/root/data/alok/crop_data/data_dumps/new_optics_annotations_reconciled.csv'\n",
    "analysis_df_annotations = pd.read_csv(analysis_df_annotations_path)\n",
    "analysis_df_reconciled_annotations = pd.read_csv(analysis_df_annotations_reconciled_path)\n",
    "\n",
    "features = ['created_by', 'adult_female_count_adjusted', 'image_width_px', 'image_height_px', 'is_too_dark', 'metadata']\n",
    "\n",
    "analysis_df = pd.concat([analysis_df_annotations[features], analysis_df_reconciled_annotations[features]], axis=0)\n",
    "\n",
    "# compute crop size and aspect ratio \n",
    "analysis_df['crop_size'] = analysis_df.image_width_px * analysis_df.image_height_px\n",
    "analysis_df['aspect_ratio'] = analysis_df.image_width_px / analysis_df.image_height_px\n",
    "analysis_df = analysis_df[~analysis_df.metadata.isnull()].copy(deep=True)\n",
    "analysis_df['mean_luminance'] = analysis_df.metadata.apply(lambda x: json.loads(x)['mean_luminance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualize crop size for crops that were accepted in QA vs. rejected by Cogito </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop size histogram for crops that are accepted in QA\n",
    "\n",
    "accepted_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "plt.hist(analysis_df[accepted_mask].crop_size)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop size histogram for crops that are rejected by Cogito\n",
    "\n",
    "# rejected_mask = (analysis_df.is_skipped == True)\n",
    "rejected_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "plt.hist(analysis_df[rejected_mask].crop_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualize aspect ratio for crops that were accepted in QA versus rejected by Cogito </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect ratio histogram for crops that are accepted in QA\n",
    "\n",
    "accepted_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "plt.hist(analysis_df[accepted_mask].aspect_ratio)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect ratio histogram for crops that are rejected by Cogito\n",
    "\n",
    "# rejected_mask = (analysis_df.is_skipped == True)\n",
    "rejected_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "plt.hist(analysis_df[rejected_mask].aspect_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create precision / recall curve for training data </h1>\n",
    "\n",
    "<h3> Define positive outcome as a crop being rejected due to size threshold, and negative outcome as crop being accepted </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "true_positive_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "\n",
    "metric = 'crop_size'\n",
    "thresholds = np.percentile(analysis_df[metric], list(range(100)))\n",
    "precisions, recalls = [], []\n",
    "for t in thresholds:\n",
    "    positive_predictions_mask = (analysis_df[metric] < t) & ((true_negative_mask) | (true_positive_mask))\n",
    "    negative_predictions_mask = (analysis_df[metric] > t) & ((true_negative_mask) | (true_positive_mask))\n",
    "    if analysis_df[positive_predictions_mask].shape[0] > 0:\n",
    "        precision = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[positive_predictions_mask].shape[0]\n",
    "        recall = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[true_positive_mask].shape[0]\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "true_negative_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "\n",
    "metric = 'crop_size'\n",
    "thresholds = np.percentile(analysis_df[metric], list(range(100)))\n",
    "precisions, recalls = [], []\n",
    "for t in thresholds:\n",
    "    positive_predictions_mask = (analysis_df[metric] > t) & ((true_negative_mask) | (true_positive_mask))\n",
    "    negative_predictions_mask = (analysis_df[metric] < t) & ((true_negative_mask) | (true_positive_mask))\n",
    "    if analysis_df[negative_predictions_mask].shape[0] > 0:\n",
    "        precision = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[positive_predictions_mask].shape[0]\n",
    "        recall = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[true_positive_mask].shape[0]\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision vs. Recall for {} based classifier'.format(metric))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, p, r in list(zip(thresholds, precisions, recalls)):\n",
    "    print(t, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_mask_mask = (analysis_df['crop_size'] < 936919.0)\n",
    "too_dark_mask = (analysis_df['mean_luminance'] < 20)\n",
    "analysis_df[too_mask_mask & (~too_dark_mask)].shape[0] / analysis_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(~true_positive_mask) & (~true_negative_mask)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Investigate bad cases </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(analysis_df.crop_size, list(range(100)))[5]\n",
    "false_positive_mask = positive_predictions_mask & ~true_positive_mask\n",
    "tdf = analysis_df[false_positive_mask].sort_values('crop_size', ascending=True).head(10)\n",
    "tdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO()\n",
    "coco.imgs = [\n",
    "    {\n",
    "        'height': 3000,\n",
    "        'width': 4096\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "image_f = tdf.image_path.iloc[i]\n",
    "im = Image.open(image_f)\n",
    "ann = {\n",
    "    'image_id': 0,\n",
    "    'segmentation': json.loads(tdf.segmentation.iloc[i])['segmentation']\n",
    "}\n",
    "m = coco.annToMask(ann)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.array(im.convert('L')) * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
