{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set pandas options\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load crop dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df_path, key = '/root/data/alok/crop_data/data_dumps/analysis_df.h5', 'df'\n",
    "analysis_df = pd.read_hdf(analysis_df_path, key)\n",
    "\n",
    "# compute crop size and aspect ratio \n",
    "analysis_df['crop_size'] = analysis_df.image_width_px * analysis_df.image_height_px\n",
    "analysis_df['aspect_ratio'] = analysis_df.image_width_px / analysis_df.image_height_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualize crop size for crops that were accepted in QA vs. rejected by Cogito </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop size histogram for crops that are accepted in QA\n",
    "\n",
    "accepted_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "plt.hist(analysis_df[accepted_mask].crop_size)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop size histogram for crops that are rejected by Cogito\n",
    "\n",
    "# rejected_mask = (analysis_df.is_skipped == True)\n",
    "rejected_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "plt.hist(analysis_df[rejected_mask].crop_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualize aspect ratio for crops that were accepted in QA versus rejected by Cogito </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect ratio histogram for crops that are accepted in QA\n",
    "\n",
    "accepted_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "plt.hist(analysis_df[accepted_mask].aspect_ratio)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect ratio histogram for crops that are rejected by Cogito\n",
    "\n",
    "# rejected_mask = (analysis_df.is_skipped == True)\n",
    "rejected_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "plt.hist(analysis_df[rejected_mask].aspect_ratio)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create precision / recall curve for training data </h1>\n",
    "\n",
    "<h3> Define positive outcome as a crop being rejected due to size threshold, and negative outcome as crop being accepted </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative_mask = (analysis_df.created_by == 'gunnar@aquabyte.ai') & (analysis_df.adult_female_count_adjusted >= 0)\n",
    "true_positive_mask = analysis_df.adult_female_count_adjusted.isnull()\n",
    "\n",
    "metric = 'crop_size'\n",
    "thresholds = np.percentile(analysis_df[metric], list(range(100)))\n",
    "precisions, recalls = [], []\n",
    "for t in thresholds:\n",
    "    positive_predictions_mask = analysis_df[metric] < t\n",
    "    negative_predictions_mask = analysis_df[metric] > t\n",
    "    false_positive_cnt = analysis_df[positive_predictions_mask & true_negative_mask].shape[0]\n",
    "    false_negative_cnt = analysis_df[negative_predictions_mask & true_positive_mask].shape[0]\n",
    "    if analysis_df[positive_predictions_mask].shape[0] > 0:\n",
    "        precision = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[positive_predictions_mask].shape[0]\n",
    "        recall = analysis_df[positive_predictions_mask & true_positive_mask].shape[0] / \\\n",
    "                    analysis_df[true_positive_mask].shape[0]\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision vs. Recall for {} based classifier'.format(metric))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, p, r in list(zip(thresholds, precisions, recalls)):\n",
    "    print(t, p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[true_positive_mask].shape[0] / analysis_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Investigate bad cases </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(analysis_df.crop_size, list(range(100)))[5]\n",
    "false_positive_mask = positive_predictions_mask & ~true_positive_mask\n",
    "tdf = analysis_df[false_positive_mask].sort_values('crop_size', ascending=True).head(10)\n",
    "tdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO()\n",
    "coco.imgs = [\n",
    "    {\n",
    "        'height': 3000,\n",
    "        'width': 4096\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "image_f = tdf.image_path.iloc[i]\n",
    "im = Image.open(image_f)\n",
    "ann = {\n",
    "    'image_id': 0,\n",
    "    'segmentation': json.loads(tdf.segmentation.iloc[i])['segmentation']\n",
    "}\n",
    "m = coco.annToMask(ann)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.array(im.convert('L')) * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
