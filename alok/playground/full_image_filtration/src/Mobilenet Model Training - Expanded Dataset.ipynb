{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Mobilenet Model Training </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> In this notebook, we will train a Mobilenet binary classifier that can classify images into \"contains fish\" and \"does not contain fish\". </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/repos/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> First step: Prepare the data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data ready\n",
    "\n",
    "# define input locations\n",
    "nonzero_crop_image_dir = '/root/data/alok/filtration_classifier_data/nonzero_crops/images_resized'\n",
    "nonzero_crop_image_fs = glob.glob(os.path.join(nonzero_crop_image_dir, '*.jpg'))\n",
    "nonzero_crop_metadata = [1] * len(nonzero_crop_image_fs)\n",
    "\n",
    "zero_crop_image_dir = '/root/data/alok/filtration_classifier_data/zero_crops/images_resized'\n",
    "zero_crop_image_fs = glob.glob(os.path.join(zero_crop_image_dir, '*.jpg'))\n",
    "zero_crop_metadata = [0] * len(nonzero_crop_image_fs)\n",
    "\n",
    "\n",
    "# create the full dataset\n",
    "nonzero_crops_dataset = list(zip(nonzero_crop_image_fs, nonzero_crop_metadata))\n",
    "zero_crops_dataset = list(zip(zero_crop_image_fs, zero_crop_metadata))\n",
    "\n",
    "train_pct, val_pct, test_pct = 0.6, 0.1, 0.3\n",
    "\n",
    "nonzero_N, zero_N = len(nonzero_crops_dataset), len(zero_crops_dataset)\n",
    "\n",
    "\n",
    "training_dataset = nonzero_crops_dataset[:int(train_pct*nonzero_N)] + zero_crops_dataset[:int(train_pct*zero_N)]\n",
    "validation_dataset = nonzero_crops_dataset[int(train_pct*nonzero_N):int((train_pct+val_pct)*nonzero_N)] + zero_crops_dataset[int(train_pct*zero_N):int((train_pct+val_pct)*zero_N)]\n",
    "testing_dataset = nonzero_crops_dataset[int((train_pct+val_pct)*nonzero_N):] + zero_crops_dataset[int((train_pct+val_pct)*zero_N):]\n",
    "\n",
    "shuffle(training_dataset)\n",
    "shuffle(validation_dataset)\n",
    "shuffle(testing_dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, N_val, N_test = len(training_dataset), len(validation_dataset), len(testing_dataset)\n",
    "\n",
    "X_train = np.empty((N_train, 224, 224, 3))\n",
    "y_train = np.empty(N_train)\n",
    "X_val = np.empty((N_val, 224, 224, 3))\n",
    "y_val = np.empty(N_val)\n",
    "X_test = np.empty((N_test, 224, 224, 3))\n",
    "y_test = np.empty(N_test)\n",
    "\n",
    "for i, data_point in enumerate(training_dataset):\n",
    "    image_f, cls = data_point\n",
    "    im = Image.open(image_f)\n",
    "    X_train[i, :] = np.array(im) / 255.0\n",
    "    y_train[i] = cls\n",
    "    \n",
    "print('Training matrix populated')\n",
    "    \n",
    "for i, data_point in enumerate(validation_dataset):\n",
    "    image_f, cls = data_point\n",
    "    im = Image.open(image_f)\n",
    "    X_val[i, :] = np.array(im) / 255.0\n",
    "    y_val[i] = cls\n",
    "    \n",
    "print('Validation matrix populated')\n",
    "    \n",
    "for i, data_point in enumerate(testing_dataset):\n",
    "    image_f, cls = data_point\n",
    "    im = Image.open(image_f)\n",
    "    X_test[i, :] = np.array(im) / 255.0\n",
    "    y_test[i] = cls\n",
    "    \n",
    "    \n",
    "print('Testing matrix populated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define The Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "mobilenet = MobileNet(input_shape=(224, 224, 3))\n",
    "x = Dense(1, activation='sigmoid')(mobilenet.layers[-1].output)\n",
    "model = Model(input=mobilenet.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "false_positive_cnt = 0\n",
    "true_positive_cnt = 0\n",
    "false_negative_cnt = 0\n",
    "for p, gt in zip(predictions, y_test):\n",
    "    if gt == 1 and p < threshold:\n",
    "        false_positive_cnt += 1\n",
    "    if gt == 0 and p < threshold:\n",
    "        true_positive_cnt += 1\n",
    "    if gt == 0 and p > threshold:\n",
    "        false_negative_cnt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_cnt / len([k for k in y_test if k == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_cnt / len([k for k in y_test if k == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_cnt / len([p for p in predictions if p > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define Generator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dset, steps_per_epoch, batch_size, input_shape):\n",
    "    N = len(dset)\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((batch_size, *input_shape))\n",
    "        y_batch = np.empty(batch_size)\n",
    "        batch = dset[batch_size * i : min(batch_size * (i + 1), N)]\n",
    "        for idx, d in enumerate(batch):\n",
    "            image_f, metadata = d\n",
    "            im = Image.open(image_f)\n",
    "            \n",
    "            # normalize image\n",
    "            \n",
    "            x_batch[idx, :] = im\n",
    "            y_batch[idx] = metadata\n",
    "        \n",
    "        i += 1\n",
    "        if i > steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "steps_per_epoch = int(len(training_dataset)/BATCH_SIZE) + 1\n",
    "gen = data_generator(training_dataset, steps_per_epoch, BATCH_SIZE, (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "batches = len(testing_dataset) // BATCH_SIZE\n",
    "eval_gen = data_generator(testing_dataset, np.inf, BATCH_SIZE, (224, 224, 3))\n",
    "scores = model.evaluate_generator(eval_gen, batches)\n",
    "print(scores)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = data_generator(testing_dataset, np.inf, BATCH_SIZE, (224, 224, 3))\n",
    "predictions = model.predict_generator(eval_gen, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_classes = [i[1] for i in testing_dataset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "false_positive_cnt = 0\n",
    "filter_cnt = 0\n",
    "for p, gt in zip(predictions, ground_truth_classes):\n",
    "    if gt == 1 and p[0] < threshold:\n",
    "        false_positive_cnt += 1\n",
    "    if gt == 0 and p[0] < threshold:\n",
    "        filter_cnt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(false_positive_cnt / len([g for g in ground_truth_classes if g == 1]))\n",
    "print(filter_cnt / len([g for g in ground_truth_classes if g == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_classes = []\n",
    "for i in range(1025):\n",
    "    c = json.load(open(testing_dataset[i][1]))['model']\n",
    "    ground_truth_classes.append(1 if c == 'contains_fish' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Quick test </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/root/data/alok/filtration_classifier_data/fish_present/images_resized/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adhoc_dataset = []\n",
    "for i, f in enumerate(files):\n",
    "    adhoc_dataset.append((f, dataset[i][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "adhoc_gen = data_generator(adhoc_dataset, np.inf, BATCH_SIZE, (224, 224, 3))\n",
    "predictions = model.predict_generator(adhoc_gen, len(adhoc_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_cnt = 0\n",
    "for p in predictions:\n",
    "    if p > 0.5:\n",
    "        pass_cnt += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "762 / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(750 - 476) / 750."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1500 - 937) / 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
