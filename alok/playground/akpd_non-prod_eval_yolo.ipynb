{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# AKPD Non-Production Interface\n",
    "import boto3\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from aquabyte.optics import pixel2world\n",
    "\n",
    "# load config\n",
    "import json\n",
    "\n",
    "config_path = '/root/data/bati/model/config.json' \n",
    "checkpoint_path = '/root/data/bati/model/model.pb'\n",
    "config = json.load(open(config_path))\n",
    "\n",
    "class FLAGS(object):\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = config[\"cpm_stages\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    crop = config[\"crop\"]\n",
    "    augmentation = None\n",
    "    \n",
    "import csv\n",
    "# with open('/root/data/depth_values_gt_eye_depth.csv') as csv_file:\n",
    "# with open('/root/data/yolo_matches.csv') as csv_file:\n",
    "# with open('/root/data/imr_austevoll_yolo_localized.csv') as csv_file:\n",
    "data=[]\n",
    "with open('/root/data/imr_austevoll_yolo_localized_overlap.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            # data.append([row[17],row[5],row[6],row[7],row[8],row[18],row[19]])\n",
    "            data.append([row[18],row[6],row[7],row[8],row[9]])\n",
    "            line_count += 1\n",
    "    print(line_count)\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\", region_name=\"eu-west-1\", aws_access_key_id=\"AKIAUFQLGRHU7YGONOQO\", aws_secret_access_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-production research code evaluation\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "from models.nets import fish_test\n",
    "from utils import cpm_utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# config_path = '/root/data/bati/model/config_bak.json' # config_4_stage.json # config_bak.json (for deployed May model) # config.json (for all data Sept)\n",
    "# checkpoint_path = '/root/data/bati/model/model_20.pb' # all-hi-res=model_49.pb #fish_test-6' #model_6.pb' # 25/199 for Sept all # 99 for Sept # model_20 for May\n",
    "config_path = '/root/data/bati/model/config.json' # config_4_stage.json # config_bak.json (for deployed May model) # config.json (for all data Sept)\n",
    "checkpoint_path = '/root/data/bati/model/model_199.pb' # all-hi-res=model_49.pb #fish_test-6' #model_6.pb' # 25/199 for Sept all # 99 for Sept # model_20 for May\n",
    "pca_model_path = '/root/data/bati/model/model.pkl' \n",
    "biomass_out_path = '/root/data/bati/model/biomass_overlap.csv'\n",
    "lkp_out_path = '/root/data/bati/model/kpl_overlap.json'\n",
    "rkp_out_path = '/root/data/bati/model/kpr_overlap.json'\n",
    "akpd_scorer_path = '/root/data/bati/model/akpd_scorer_model.h5'\n",
    "\n",
    "\n",
    "config = json.load(open(config_path))\n",
    "print(config)\n",
    "\n",
    "class FLAGS(object):\n",
    "    stages = 3\n",
    "    crop = False    \n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    augmentation = None\n",
    "    \n",
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, input_map=None,\n",
    "                                return_elements=None,\n",
    "                                name=\"\",\n",
    "                                op_dict=None,\n",
    "                                producer_op_list=None)\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "        for t in graph_nodes:\n",
    "            print(t.name)\n",
    "        return graph\n",
    "\n",
    "mod=load_pb(checkpoint_path)\n",
    "print(mod)\n",
    "print(checkpoint_path)\n",
    "\n",
    "with open(pca_model_path, \"rb\") as f:\n",
    "    pca_model = pickle.load(f)\n",
    "\n",
    "# print(pca_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkp_out_path = '/root/data/bati/model/kpl_overlap.json'\n",
    "rkp_out_path = '/root/data/bati/model/kpr_overlap.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import math\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.graph.as_default()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tf_device = '/gpu:0'\n",
    "with tf.device(tf_device):\n",
    "    model = mod\n",
    "\n",
    "print(model)\n",
    "print(FLAGS.model_path)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from utils.utils import DataGenerator, load_image_keypoints\n",
    "\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def image_resize(image, FLAGS):\n",
    "    height, width, _ = image.shape\n",
    "    ratio_width = width / FLAGS.input_size[0]\n",
    "    ratio_height = height / FLAGS.input_size[1]\n",
    "    image = cv2.resize(image, FLAGS.input_size)\n",
    "    image  = image / 255.0 - 0.5\n",
    "    image = image[np.newaxis, ...]\n",
    "    return image\n",
    "\n",
    "def load_gt_keypoints(FLAGS, xoff, yoff, gtdata, left):\n",
    "    \"\"\"from gt load keypoints\"\"\"\n",
    "    gtkeypoints = []\n",
    "    for i in range(FLAGS.joints):\n",
    "        for j in range(FLAGS.joints):\n",
    "            if left==True and FLAGS.keypoints_order[i]==gtdata['leftCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['leftCrop'][j]['xFrame']\n",
    "                valueY = gtdata['leftCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "            elif left==False and FLAGS.keypoints_order[i]==gtdata['rightCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['rightCrop'][j]['xFrame']\n",
    "                valueY = gtdata['rightCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "    gtkeypoints = np.array(gtkeypoints) \n",
    "    return gtkeypoints\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "def coord2biomass(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5\n",
    "\n",
    "\n",
    "class AKPDNormalizationTransform(object):\n",
    "    \"\"\"\n",
    "        Transforms AKPD predictions such that they are normalized with respect to image width\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, stereo_pair_id, cm = \\\n",
    "            sample['kp_input'], sample['label'], sample['stereo_pair_id'], sample['cm']\n",
    "        \n",
    "        normalized_kp_input = {}\n",
    "        for bp in BODY_PARTS:\n",
    "            normalized_kp_input[bp] = [\n",
    "                kp_input[bp][0] / cm['pixelCountWidth'],\n",
    "                kp_input[bp][1] / cm['pixelCountWidth'],\n",
    "                kp_input[bp][2] / cm['pixelCountWidth'],\n",
    "                kp_input[bp][3] / cm['pixelCountWidth']\n",
    "            ]\n",
    "\n",
    "            \n",
    "        transformed_sample = {\n",
    "            'kp_input': normalized_kp_input,\n",
    "            'label': label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample\n",
    "\n",
    "from torch import nn\n",
    "    \n",
    "class AKPDScorerNetwork(nn.Module):\n",
    "    def __ingit__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(32, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# class AKPDPredictionScorer(object):\n",
    "    \n",
    "#     def __init__(self, model_f, body_parts):\n",
    "#         self.model = load_model(model_f)\n",
    "#         self.body_parts = sorted(body_parts)\n",
    "\n",
    "#     def _get_left_right_keypoints(self, keypoints):\n",
    "#         left_keypoints, right_keypoints = {}, {}\n",
    "#         for item in keypoints['leftCrop']:\n",
    "#             left_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "\n",
    "#         for item in keypoints['rightCrop']:\n",
    "#             right_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "\n",
    "#         return left_keypoints, right_keypoints\n",
    "\n",
    "    \n",
    "#     def _rotate(self, point, angle, origin=(0, 0)):\n",
    "#         \"\"\"\n",
    "#         Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "#         The angle should be given in radians.\n",
    "#         \"\"\"\n",
    "#         ox, oy = origin\n",
    "#         px, py = point\n",
    "\n",
    "#         qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "#         qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "#         return qx, qy\n",
    "\n",
    "\n",
    "#     def _normalize_keypoints(self, keypoints, origin_bp='TAIL_NOTCH'):\n",
    "#         # translation\n",
    "#         for bp in self.body_parts:\n",
    "#             keypoints[bp] = keypoints[bp] - keypoints[origin_bp]\n",
    "#             keypoints[bp][1] = -keypoints[bp][1]\n",
    "\n",
    "#         # rotation & compression\n",
    "#         angle = np.arctan(keypoints['UPPER_LIP'][1] / keypoints['UPPER_LIP'][0])\n",
    "#         for bp in self.body_parts:\n",
    "#             keypoints[bp] = self._rotate(keypoints[bp], -angle)\n",
    "#             keypoints[bp] = keypoints[bp] / np.linalg.norm(keypoints['UPPER_LIP'])\n",
    "\n",
    "#         return keypoints\n",
    "    \n",
    "#     def _generate_one_side_score(self, coords):\n",
    "#         X = np.array([coords, ])\n",
    "#         X = np.swapaxes(X, 1, 2)\n",
    "#         return self.model.predict(X)\n",
    "        \n",
    "\n",
    "\n",
    "#     def get_confidence_score(self, pred_keypoints):\n",
    "\n",
    "#         pred_left_keypoints, pred_right_keypoints = self._get_left_right_keypoints(pred_keypoints)\n",
    "#         pred_norm_left_keypoints = self._normalize_keypoints(pred_left_keypoints)\n",
    "#         pred_norm_right_keypoints = self._normalize_keypoints(pred_right_keypoints)\n",
    "\n",
    "#         coords_left, coords_right = [], []\n",
    "#         for bp in self.body_parts:\n",
    "#             coords_left.append(pred_norm_left_keypoints[bp])\n",
    "#             coords_right.append(pred_norm_right_keypoints[bp])\n",
    "            \n",
    "#         left_score = self._generate_one_side_score(coords_left)[0][0]\n",
    "#         right_score = self._generate_one_side_score(coords_right)[0][0]\n",
    "#         return min(left_score, right_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "GOOD_PERC = 0.7\n",
    "sift = cv2.KAZE_create()\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "    \n",
    "config['input_name']='input_placeholder:0'\n",
    "config['output_name']='stage_3/mid_conv7/BiasAdd:0'\n",
    "\n",
    "np3_biomass=[]\n",
    "kpLeft=[]\n",
    "kpRight=[]\n",
    "kpdist=[]\n",
    "bmi = 0\n",
    "useSIFT = 0\n",
    "matchColor = (255,0,0)\n",
    "drawColor = (255,255,255)\n",
    "for i in range(len(data)):\n",
    "    imL=data[i][0]\n",
    "    imR=data[i][1]\n",
    "    lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "    rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "    meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "#     confL=float(data[i][5])\n",
    "#     confR=float(data[i][6])\n",
    "#     if confL<conf_thresh or confR<conf_thresh:\n",
    "#         continue\n",
    "\n",
    "    tic = time.clock()\n",
    "    \n",
    "    imageL = url_to_image(imL)\n",
    "    \n",
    "    toc = time.clock()\n",
    "    dlTime = toc-tic\n",
    "    tic=toc\n",
    "    \n",
    "    # imageL = enhance(imageL)\n",
    "    heightL, widthL, _ = imageL.shape\n",
    "    img_input = image_resize(imageL, FLAGS)\n",
    "    with tf.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "    \n",
    "    toc = time.clock()\n",
    "    leftTime = toc-tic\n",
    "    tic=toc\n",
    "    \n",
    "    imageR = url_to_image(imR)\n",
    "    # imageR = enhance(imageR)\n",
    "    heightR, widthR, _ = imageR.shape\n",
    "    img_input = image_resize(imageR, FLAGS)\n",
    "    with tf.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "    \n",
    "    toc = time.clock()\n",
    "    rightTime = toc-tic\n",
    "    tic=toc\n",
    "    \n",
    "    if useSIFT==1:\n",
    "        # SIFT matching\n",
    "        scale_percent = 50 # percent\n",
    "        width = int(imageL.shape[1] * scale_percent / 100)\n",
    "        height = int(imageL.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        imageLrz = cv2.resize(imageL, dim, interpolation = cv2.INTER_AREA)\n",
    "        width = int(imageR.shape[1] * scale_percent / 100)\n",
    "        height = int(imageR.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        imageRrz = cv2.resize(imageR, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "        img1 = enhance(imageLrz)\n",
    "        img2 = enhance(imageRrz)\n",
    "        kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < GOOD_PERC*n.distance:\n",
    "                good.append(m)\n",
    "        if len(good)>=MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            for j in range(len(src_pts)):\n",
    "                src_pts[j][0][0]*=100/scale_percent\n",
    "                src_pts[j][0][1]*=100/scale_percent\n",
    "            for j in range(len(dst_pts)):\n",
    "                dst_pts[j][0][0]*=100/scale_percent\n",
    "                dst_pts[j][0][1]*=100/scale_percent\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "        else:\n",
    "            print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "            matchesMask = None\n",
    "    \n",
    "#     img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,False)\n",
    "#     img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,True)\n",
    "#     alpha = 0.3  # Transparency factor.\n",
    "#     img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(img3)\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "    \n",
    "    toc = time.clock()\n",
    "    SIFTTime = toc-tic\n",
    "    tic=toc\n",
    "    \n",
    "    kpL = []\n",
    "    kpR = []    \n",
    "    kpL2R = []\n",
    "    kpR2L = [] \n",
    "    im1ps = []\n",
    "    im2ps = []\n",
    "    Hx=M\n",
    "    Hy=np.linalg.inv(M)\n",
    "    for c in range(FLAGS.joints):\n",
    "        hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "        hm_maxL = list(np.where(hm == hm.max()))   \n",
    "        kpL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "        if useSIFT==1:\n",
    "            ptx=np.array([kpL[c][0],kpL[c][1],1])\n",
    "            zx=np.dot(Hx,ptx)\n",
    "            kpL2R.append([int(zx[0]/zx[2]), int(zx[1]/zx[2])]) \n",
    "        hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "        hm_maxR = np.where(hm == hm.max())\n",
    "        kpR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "        if useSIFT==1:\n",
    "            pty=np.array([kpR[c][0],kpR[c][1],1])\n",
    "            zy=np.dot(Hy,pty)\n",
    "            kpR2L.append([int(zy[0]/zy[2]), int(zy[1]/zy[2])]) \n",
    "    \n",
    "        if useSIFT==0:\n",
    "            im1ps.append([kpL[c][0], kpL[c][1]]) \n",
    "            im2ps.append([kpR[c][0], kpR[c][1]])   \n",
    "        else:\n",
    "            im1ps.append([int((kpL[c][0]+kpR2L[c][0])/2), int((kpL[c][1]+kpR2L[c][1])/2)]) \n",
    "            im2ps.append([int((kpR[c][0]+kpL2R[c][0])/2), int((kpR[c][1]+kpL2R[c][1])/2)])   \n",
    "    \n",
    "    kpL = np.array(kpL) \n",
    "    kpR = np.array(kpR) \n",
    "    if useSIFT==1:\n",
    "        kpL2R = np.array(kpL2R) \n",
    "        kpR2L = np.array(kpR2L)\n",
    "    im1ps = np.array(im1ps)\n",
    "    im2ps = np.array(im2ps)\n",
    "    \n",
    "    kpsL=[];\n",
    "    kpsR=[];\n",
    "    for c in range(FLAGS.joints):\n",
    "        kpsiL={}\n",
    "        kpsiL['xCrop']=im1ps[c,0]\n",
    "        kpsiL['yCrop']=im1ps[c,1]\n",
    "        kpsiL['xFrame']=im1ps[c,0]+lco['x_coord']\n",
    "        kpsiL['yFrame']=im1ps[c,1]+lco['y_coord']\n",
    "        kpsiL['keypointType']=FLAGS.keypoints_order[c]\n",
    "        kpsL.append(kpsiL)\n",
    "        kpsiR={}\n",
    "        kpsiR['xCrop']=im2ps[c,0]\n",
    "        kpsiR['yCrop']=im2ps[c,1]\n",
    "        kpsiR['xFrame']=im2ps[c,0]+rco['x_coord']\n",
    "        kpsiR['yFrame']=im2ps[c,1]+rco['y_coord']\n",
    "        kpsiR['keypointType']=FLAGS.keypoints_order[c]\n",
    "        kpsR.append(kpsiR)\n",
    "\n",
    "    kpLeft.append(kpsL)\n",
    "    kpRight.append(kpsR)\n",
    "    \n",
    "    wp=pixel2world(kpsL, kpsR, meta)\n",
    "    biomass = coord2biomass(wp, pca_model)\n",
    "    np3_biomass.append(biomass)\n",
    "    bmi += 1\n",
    "\n",
    "    toc = time.clock()\n",
    "    biomassTime = toc-tic\n",
    "    \n",
    "    ldist=0\n",
    "    if useSIFT==1:\n",
    "        for c in range(FLAGS.joints):\n",
    "            ldist+=math.sqrt((kpL[c,0]-kpR2L[c,0])**2+(kpL[c,1]-kpR2L[c,1])**2)\n",
    "    rdist=0\n",
    "    if useSIFT==1:\n",
    "        for c in range(FLAGS.joints):\n",
    "            rdist+=math.sqrt((kpR[c,0]-kpL2R[c,0])**2+(kpR[c,1]-kpL2R[c,1])**2)\n",
    "    kpdist.append((ldist/FLAGS.joints+rdist/FLAGS.joints)/2)\n",
    "        \n",
    "    print(\"Frame %d of %d - %d matches - biomass %1.2f - dist %1.2f, dlt=%1.2f, lt=%1.2f, rt=%1.2f, st=%1.2f, bt=%1.2f, total=%1.2f\" % (i, len(data), len(good), np3_biomass[bmi-1], kpdist[bmi-1], dlTime, leftTime, rightTime, SIFTTime, biomassTime, leftTime+rightTime+SIFTTime+biomassTime))\n",
    "#     print(data[i][0])\n",
    "#     print(data[i][1])\n",
    "    \n",
    "#     height, width, _ = imageL.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     if useSIFT==1:\n",
    "#         for c in range(FLAGS.joints):\n",
    "#             end1 = tuple(np.round(kpL[c, :]).astype(int))\n",
    "#             end2 = tuple(np.round(kpR2L[c,:]).astype(int))\n",
    "#             cv2.line(imageL, end1, end2, drawColor, 3)\n",
    "#     ax.imshow(imageL)\n",
    "#     if useSIFT==1:\n",
    "#         plt.scatter(kpL[:, 0], kpL[:, 1], c=\"b\")\n",
    "#         plt.scatter(kpR2L[:, 0], kpR2L[:, 1], c=\"g\")\n",
    "#     plt.scatter(im1ps[:, 0], im1ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     height, width, _ = imageR.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     if useSIFT==1:\n",
    "#         for c in range(FLAGS.joints):\n",
    "#             end1 = tuple(np.round(kpR[c, :]).astype(int))\n",
    "#             end2 = tuple(np.round(kpL2R[c,:]).astype(int))\n",
    "#             cv2.line(imageR, end1, end2, drawColor, 3)\n",
    "#     ax.imshow(imageR)\n",
    "#     if useSIFT==1:\n",
    "#         plt.scatter(kpR[:, 0], kpR[:, 1], c=\"b\")\n",
    "#         plt.scatter(kpL2R[:, 0], kpL2R[:, 1], c=\"g\")\n",
    "#     plt.scatter(im2ps[:, 0], im2ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "np.savetxt(biomass_out_path, np3_biomass, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(src_pts)):\n",
    "#     print(src_pts[j][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(o):\n",
    "    if isinstance(o, np.int64): return int(o)  \n",
    "    raise TypeError\n",
    "\n",
    "json.dump(kpLeft, open(lkp_out_path, 'w'), default=convert)\n",
    "json.dump(kpRight, open(rkp_out_path, 'w'), default=convert)\n",
    "# np.savetxt('/root/data/bati/model/kpdist.csv', kpdist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.akpd_scorer import AKPDNormalizationTransform, AKPDScorerNetwork\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# initialize data transforms so that we can run inference with AKPD scorer network\n",
    "normalize_centered_2D_transform_akpd = NormalizeCentered2D(rotate=False, center=True)\n",
    "akpd_normalization_transform = AKPDNormalizationTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n",
    "akpd_scorer_network = torch.load('/root/data/alok/biomass_estimation/playground/akpd_scorer_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpLeft = json.load(open(lkp_out_path))\n",
    "kpRight = json.load(open(rkp_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_predictions = []\n",
    "for idx in range(len(data)):\n",
    "    idx = 6\n",
    "    d = data[idx]\n",
    "    left_crop_metadata, right_crop_metadata = json.loads(d[2]), json.loads(d[3])\n",
    "    cm = json.loads(d[4])\n",
    "    kps = {'leftCrop': kpLeft[idx], 'rightCrop': kpRight[idx]}\n",
    "\n",
    "    # run AKPD\n",
    "\n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': kps,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': 0,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_akpd.__call__(input_sample)\n",
    "\n",
    "    akpd_normalized_kps = akpd_normalization_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "    score = akpd_scorer_network(tensorized_kps['kp_input']).item()\n",
    "\n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': kps,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': 0,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    weight_predictions.append(weight_prediction)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.akpd_scorer import AKPDNormalizationTransform, AKPDScorerNetwork\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# apsObj = AKPDPredictionScorer(akpd_scorer_path, FLAGS.keypoints_order)\n",
    "pred_keypoints={}\n",
    "pred_keypoints['version']=2\n",
    "\n",
    "# network = Network()\n",
    "network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb') # 798 # 192\n",
    "normalize_centered_2D_transform = NormalizeCentered2D()\n",
    "normalize_centered_2D_transform_scorer = NormalizeCentered2D(rotate=False, center=True)\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "akpd_normalization_transform = AKPDNormalizationTransform()\n",
    "scorer_network = torch.load('/root/data/bati/model/akpd_scorer_model.pb')\n",
    "\n",
    "nn_biomass=[]\n",
    "aps_scores=[]\n",
    "scoreth=0.5\n",
    "score_cnt=0;\n",
    "ascores=[]\n",
    "for i in range(len(kpLeft)):\n",
    "    meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "    pred_keypoints['leftCrop']=kpLeft[i]\n",
    "    pred_keypoints['rightCrop']=kpRight[i]\n",
    "    #score=apsObj.get_confidence_score(pred_keypoints)\n",
    "    input_sample = {'keypoints': pred_keypoints, 'cm': meta, 'stereo_pair_id': i, 'single_point_inference': True}\n",
    "    normalized_centered_2D_kps = normalize_centered_2D_transform_scorer.__call__(input_sample)\n",
    "    akpd_normalized_kps = akpd_normalization_transform.__call__(normalized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "    score = scorer_network(tensorized_kps['kp_input']).item()\n",
    "    #print(score)\n",
    "    aps_scores.append(score)\n",
    "    if score>=scoreth:\n",
    "        score_cnt+=1\n",
    "        ascores.append(1)        \n",
    "        normalized_centered_2D_kps = normalize_centered_2D_transform.__call__(input_sample)\n",
    "        normalized_stability_kps = normalized_stability_transform.__call__(normalized_centered_2D_kps)\n",
    "        tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "#         tensorized_kps = to_tensor_transform.__call__(normalized_centered_2D_kps)\n",
    "        weight_prediction = network(tensorized_kps['kp_input']).item() * 1e4\n",
    "        nn_biomass.append(weight_prediction)\n",
    "        print(\"Frame %d of %d has nn_weight %1.2f pca_biomass %1.2f with score %1.2f and kpdist %1.2f\" % (i+1, len(kpLeft), weight_prediction, np3_biomass[i], score, kpdist[i]))\n",
    "    else:\n",
    "        ascores.append(0)\n",
    "        nn_biomass.append(-1)\n",
    "        print(\"Frame %d of %d with score %1.2f\" % (i+1, len(kpLeft), score))\n",
    "\n",
    "print(score_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kpLeft))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/root/data/bati/model/akpd_scores.csv', aps_scores, delimiter=\",\")\n",
    "np.savetxt('/root/data/bati/model/akpd_nn_biomass.csv', nn_biomass, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = sorted([\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'EYE',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'TAIL_NOTCH',\n",
    "    'UPPER_LIP'\n",
    "])\n",
    "\n",
    "class NormalizeCentered2D(object):\n",
    "    \n",
    "    def flip_center_kps(self, left_kps, right_kps):\n",
    "        x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "        x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "        x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "\n",
    "        y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "        y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "        y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "\n",
    "        x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "        x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "        x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "\n",
    "        y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "        y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "        y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "\n",
    "        fc_left_kps, fc_right_kps = {}, {}\n",
    "        flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            if flip_factor > 0:\n",
    "                fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "                fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "            else:\n",
    "                fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "                fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "            fc_left_kps[bp] = fc_left_kp\n",
    "            fc_right_kps[bp] = fc_right_kp\n",
    "\n",
    "        return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "    def _rotate_cc(self, p, theta):\n",
    "        R = np.array([\n",
    "            [np.cos(theta), -np.sin(theta)],\n",
    "            [np.sin(theta), np.cos(theta)]\n",
    "        ])\n",
    "\n",
    "        rotated_kp = np.dot(R, p)\n",
    "        return rotated_kp\n",
    "\n",
    "\n",
    "    def rotate_kps(self, left_kps, right_kps):\n",
    "        upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "        theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "        r_left_kps, r_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            rotated_kp = self._rotate_cc(left_kps[bp], -theta)\n",
    "            r_left_kps[bp] = rotated_kp\n",
    "            disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "            r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "\n",
    "        return r_left_kps, r_right_kps\n",
    "\n",
    "\n",
    "    def scale_kps(self, left_kps, right_kps, factor):\n",
    "        s_left_kps, s_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            s_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "            s_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "\n",
    "        return s_left_kps, s_right_kps\n",
    "\n",
    "\n",
    "    def jitter_kps(self, left_kps, right_kps, jitter):\n",
    "        j_left_kps, j_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                       left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "            j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                        right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "\n",
    "        return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "\n",
    "    def modify_kps(self, left_kps, right_kps, factor, jitter, cm, rotate=True, center=False):\n",
    "        fc_left_kps, fc_right_kps = self.flip_center_kps(left_kps, right_kps)\n",
    "        if rotate:\n",
    "            r_left_kps, r_right_kps = self.rotate_kps(fc_left_kps, fc_right_kps)\n",
    "            s_left_kps, s_right_kps = self.scale_kps(r_left_kps, r_right_kps, factor)\n",
    "        else:\n",
    "            s_left_kps, s_right_kps = self.scale_kps(fc_left_kps, fc_right_kps, factor)\n",
    "        j_left_kps, j_right_kps  = self.jitter_kps(s_left_kps, s_right_kps, jitter)\n",
    "        j_left_kps_list, j_right_kps_list = [], []\n",
    "        if not center:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "        else:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0],\n",
    "                    'yFrame': j_left_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0],\n",
    "                    'yFrame': j_right_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "\n",
    "\n",
    "        modified_kps = {\n",
    "            'leftCrop': j_left_kps_list,\n",
    "            'rightCrop': j_right_kps_list\n",
    "        }\n",
    "\n",
    "        return modified_kps\n",
    "\n",
    "    \n",
    "    def __init__(self, lo=None, hi=None, jitter=0.0, rotate=True, center=False):\n",
    "        self.lo = lo\n",
    "        self.hi = hi\n",
    "        self.jitter = jitter\n",
    "        self.rotate = rotate\n",
    "        self.center = center\n",
    "    \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        keypoints, cm, stereo_pair_id, label = \\\n",
    "            sample['keypoints'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "        left_keypoints_list = keypoints['leftCrop']\n",
    "        right_keypoints_list = keypoints['rightCrop']\n",
    "        left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "        right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "        \n",
    "        factor = 1.0 \n",
    "        if self.lo and self.hi:\n",
    "            factor = np.random.uniform(low=self.lo, high=self.hi)\n",
    "            \n",
    "        jitter = np.random.uniform(high=self.jitter)\n",
    "        \n",
    "        modified_kps = self.modify_kps(left_kps, right_kps, factor, jitter, cm, \n",
    "            rotate=self.rotate, center=self.center)\n",
    "\n",
    "        kp_input = {}\n",
    "        for idx, _ in enumerate(modified_kps['leftCrop']):\n",
    "            left_item, right_item = modified_kps['leftCrop'][idx], modified_kps['rightCrop'][idx]\n",
    "            bp = left_item['keypointType']\n",
    "            kp_input[bp] = [left_item['xFrame'], left_item['yFrame'], right_item['xFrame'], right_item['yFrame']]\n",
    "\n",
    "\n",
    "        transformed_sample = {\n",
    "            'kp_input': kp_input,\n",
    "            'modified_kps': modified_kps,\n",
    "            'label': label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'cm': cm,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample\n",
    "        \n",
    "\n",
    "class NormalizedStabilityTransform(object):\n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, stereo_pair_id = sample['kp_input'], sample['label'], sample['stereo_pair_id']\n",
    "        stabilized_coordinates = {}\n",
    "        for bp in BODY_PARTS:\n",
    "            wkp = kp_input[bp]\n",
    "            stabilized_kp_info = [0.5 * wkp[0]/wkp[1], 0.5 * wkp[2]/wkp[1], 0.5 * 0.1/wkp[1]]\n",
    "            stabilized_coordinates[bp] = stabilized_kp_info\n",
    "            \n",
    "        normalized_label = label * 1e-4 if label else None\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': stabilized_coordinates,\n",
    "            'label': normalized_label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }       \n",
    "        return transformed_sample\n",
    "        \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, stereo_pair_id = \\\n",
    "            sample['kp_input'], sample.get('label'), sample.get('stereo_pair_id')\n",
    "        \n",
    "        x = []\n",
    "        for bp in BODY_PARTS:\n",
    "            kp_data = kp_input[bp]\n",
    "            x.append(kp_data)\n",
    "        if sample.get('single_point_inference'):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.array([x])\n",
    "        \n",
    "        kp_input_tensor = torch.from_numpy(x).float()\n",
    "        label_tensor = torch.from_numpy(np.array([label])).float() if label else None\n",
    "        \n",
    "        tensorized_sample = {\n",
    "            'kp_input': kp_input_tensor,\n",
    "            'label': label_tensor,\n",
    "            'stereo_pair_id': stereo_pair_id\n",
    "        }\n",
    "        return tensorized_sample\n",
    "    \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
