{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Keypoint Detection Model (Small Dataset) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/repos/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Data </h1>\n",
    "\n",
    "<h3> Create list of file paths for easy access in generator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_dir = '/root/data/alok/keypoint_detection/crops'\n",
    "metadata_dir = '/root/data/alok/keypoint_detection/new_crop_metadata'\n",
    "\n",
    "crop_fs = sorted(glob.glob(os.path.join(crops_dir, '*.jpg')))\n",
    "metadata_fs = sorted(glob.glob(os.path.join(metadata_dir, '*.json')))\n",
    "dataset = list(zip(crop_fs, metadata_fs))\n",
    "dataset.pop(2)\n",
    "dataset.pop(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define some constants </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'Body / Adipose Fin',\n",
    "    'Body / Anal Fin',\n",
    "    'Body / Dorsal Fin',\n",
    "    'Body / Pectoral Fin',\n",
    "    'Body / Pelvic Fin',\n",
    "    'Bottom Corner of Tail',\n",
    "    'Eye',\n",
    "    'Top Corner of Tail',\n",
    "    'Upper Lip'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define helper functions for resizing crop and getting the corresponding keypoints </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_crop_and_keypoints(crop_f, metadata_f, new_dims):\n",
    "    crop = imread(crop_f)\n",
    "    metadata = json.load(open(metadata_f))\n",
    "    keypoints = metadata['keypoints']\n",
    "    \n",
    "    original_dims = np.array(crop).shape\n",
    "    \n",
    "    # get resized crop\n",
    "    crop_resized = resize(crop, new_dims)\n",
    "    \n",
    "    # normalize cro\n",
    "    crop_resized = crop_resized / 255.0\n",
    "    \n",
    "    transformed_keypoints_list = []\n",
    "    for c in CLASSES:\n",
    "        kp = keypoints[c]\n",
    "        tkp_x = int(kp[0] * new_dims[0] / original_dims[1])\n",
    "        tkp_y = int(kp[1] * new_dims[1] / original_dims[0])\n",
    "        transformed_keypoints_list.append(tkp_x)\n",
    "        transformed_keypoints_list.append(tkp_y)\n",
    "    \n",
    "    transformed_keypoints = np.array(transformed_keypoints_list)\n",
    "    \n",
    "    return crop_resized, transformed_keypoints\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define the Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights=, include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(18, name='predictions')(vgg16.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=vgg16.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define the Generator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dset, steps_per_epoch, batch_size, input_shape, output_size):\n",
    "    N = len(dset)\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((batch_size, *input_shape))\n",
    "        y_batch = np.empty((batch_size, output_size))\n",
    "        batch = dset[batch_size * i : min(batch_size * (i + 1), N)]\n",
    "        for idx, d in enumerate(batch):\n",
    "            crop_f, metadata_f = d\n",
    "            crop_resized, transformed_keypoints = \\\n",
    "                get_transformed_crop_and_keypoints(crop_f, metadata_f, (input_shape[0], input_shape[1]))\n",
    "            x_batch[idx, :] = crop_resized\n",
    "            y_batch[idx, :] = transformed_keypoints\n",
    "        \n",
    "        i += 1\n",
    "        if i > steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "steps_per_epoch = math.ceil(len(dataset) / BATCH_SIZE)\n",
    "input_shape = (224, 224, 3)\n",
    "output_size = 18\n",
    "gen = data_generator(dataset, steps_per_epoch, BATCH_SIZE, input_shape, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train the Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    " \n",
    "optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_generator(dataset, steps_per_epoch, BATCH_SIZE, input_shape, output_size)\n",
    "predictions = model.predict_generator(gen, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_resized, transformed_keypoints = get_transformed_crop_and_keypoints(crop_fs[0], metadata_fs[0], (224, 224))\n",
    "plt.imshow(255 * crop_resized)\n",
    "for i in range(9):\n",
    "    kp_x = predictions[0][2*i]\n",
    "    kp_y = predictions[0][2*i + 1]\n",
    "    plt.scatter(kp_x, kp_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
