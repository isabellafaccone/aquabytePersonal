{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from aquabyte.data_access_utils import DataAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_access_utils = DataAccessUtils('/root/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get images ready for annotation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download raw images\n",
    "\n",
    "image_s3_bucket = 'aquabyte-axiom'\n",
    "left_image_key = 'fishId=190620-4e4e0640-d4eb-405d-8fcf-57fda11d7660/date=2019-06-20/hour=12/at=2019-06-20T12:41:45.636408000Z/left_frame.jpg'\n",
    "right_image_key = 'fishId=190620-4e4e0640-d4eb-405d-8fcf-57fda11d7660/date=2019-06-20/hour=12/at=2019-06-20T12:41:45.636408000Z/right_frame.jpg'\n",
    "\n",
    "left_image_f = data_access_utils.download_from_s3(image_s3_bucket, left_image_key)\n",
    "right_image_f = data_access_utils.download_from_s3(image_s3_bucket, right_image_key)\n",
    "\n",
    "# download stereo parameters\n",
    "\n",
    "stereo_parameters_s3_bucket = 'aquabyte-stereo-parameters'\n",
    "stereo_parameters_key = 'L40020185_R40020187/2019-07-02T00:00:00Z_L40020185_R40020187_stereo-parameters.json'\n",
    "# stereo_parameters_key = 'L40020185_R40020187/2019-05-20T00:00:00Z_L40020185_R40020187_stereo-parameters.json'\n",
    "stereo_parameters_f = data_access_utils.download_from_s3(stereo_parameters_s3_bucket, stereo_parameters_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rectification utils (should be imported from Aquabyte library)\n",
    "\n",
    "def load_params(stereo_params_file):\n",
    "    \"\"\" load rectification parameters and create maps\"\"\"\n",
    "    params = json.load(open(stereo_params_file))\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                  params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                  [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                  params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                  [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "    imageSize = (4096, 3000)\n",
    "    # rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2,\n",
    "                                                               distCoeffs2, imageSize, R, T, None, None, None, None,\n",
    "                                                               None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "\n",
    "    return left_maps, right_maps\n",
    "\n",
    "def stereo_rectify(stereo_parameters_f, left_frame_f, right_frame_f, \n",
    "                   rectified_left_frame_f, rectified_right_frame_f):\n",
    "    left_maps, right_maps = load_params(stereo_parameters_f)    \n",
    "\n",
    "    left_frame = cv2.imread(left_frame_f)\n",
    "    rectified_left_frame = cv2.remap(left_frame, left_maps[0], left_maps[1], cv2.INTER_LANCZOS4)\n",
    "    cv2.imwrite(rectified_left_frame_f, rectified_left_frame)\n",
    "\n",
    "    right_frame = cv2.imread(right_frame_f)\n",
    "    rectified_right_frame = cv2.remap(right_frame, right_maps[0], right_maps[1], cv2.INTER_LANCZOS4)\n",
    "    cv2.imwrite(rectified_right_frame_f, rectified_right_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectify the images\n",
    "\n",
    "rectified_left_image_f = left_image_f.replace('left_frame.jpg', 'rectified_left_frame.jpg')\n",
    "rectified_right_image_f = right_image_f.replace('right_frame.jpg', 'rectified_right_frame.jpg')\n",
    "stereo_rectify(stereo_parameters_f, left_image_f, right_image_f, rectified_left_image_f, rectified_right_image_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_parameters_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load in the Labelbox annotations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = [\n",
    "    'UPPER_LIP',\n",
    "    'TAIL_NOTCH',\n",
    "    'DORSAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'EYE'\n",
    "]\n",
    "\n",
    "annotations_f = '/root/data/underwater_live_gtsf_axiom_calibration.json'\n",
    "annotations = json.load(open(annotations_f))\n",
    "\n",
    "keypoints_df = pd.DataFrame()\n",
    "for idx, obj in enumerate(annotations):\n",
    "    if obj['Label'] == 'Skip':\n",
    "        continue\n",
    "\n",
    "    if not all([key in obj['Label'].keys() for key in body_parts]):\n",
    "        continue\n",
    "\n",
    "    # get image file name and epoch\n",
    "    camera = 'left' if 'left' in obj['Labeled Data'] else 'right'\n",
    "\n",
    "    for body_part in body_parts:\n",
    "        kp_dict = obj['Label'][body_part][0]['geometry']\n",
    "        kp = (kp_dict['x'], kp_dict['y'])\n",
    "\n",
    "        row = {\n",
    "            'body_part': body_part,\n",
    "            'camera': camera,\n",
    "            'keypoint': kp\n",
    "        }\n",
    "\n",
    "        keypoints_df = keypoints_df.append(row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point(x, y, d, pixel_count_width, \n",
    "                           pixel_count_height, image_sensor_width, \n",
    "                           image_sensor_height, focal_length):\n",
    "    \"\"\" from pixel coordinates to world coordinates \"\"\"\n",
    "    \n",
    "    image_center_x = pixel_count_width / 2.0  \n",
    "    image_center_y = pixel_count_height / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (image_sensor_width / pixel_count_width)\n",
    "    sensor_z = px_z * (image_sensor_height / pixel_count_height)\n",
    "\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "    return [world_x, world_y, world_z]\n",
    "\n",
    "\n",
    "\n",
    "def depth_from_disp(disp, focal_length_pixel, baseline):\n",
    "    \"\"\" calculate the depth of the point based on the disparity value \"\"\"\n",
    "    depth = focal_length_pixel*baseline / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_frame_pairs_df = pd.DataFrame()\n",
    "stereo_params = json.load(open(stereo_parameters_f))\n",
    "focal_length_pixel = stereo_params['CameraParameters1']['FocalLength'][0]\n",
    "baseline = abs(stereo_params['TranslationOfCamera2'][0] / 1e3) # convert millimeters to meters and use absolute value\n",
    "pixel_size_m = 3.45 * 1e-6\n",
    "focal_length = focal_length_pixel * pixel_size_m\n",
    "image_sensor_width = 0.01412\n",
    "image_sensor_height = 0.01035\n",
    "pixel_count_width = 4096\n",
    "pixel_count_height = 3000\n",
    "\n",
    "epoch_mask = keypoints_df.body_part == body_part\n",
    "row = {}\n",
    "row['body_part'] = body_part\n",
    "\n",
    "left_keypoints, right_keypoints, world_keypoints = {}, {}, {}\n",
    "\n",
    "for body_part in body_parts:\n",
    "    left_row = keypoints_df[(keypoints_df.body_part == body_part) & (keypoints_df.camera == 'left')].iloc[0]\n",
    "    lkp = left_row['keypoint']\n",
    "    left_keypoints[body_part] = lkp\n",
    "\n",
    "    right_row = keypoints_df[(keypoints_df.body_part == body_part) & (keypoints_df.camera == 'right')].iloc[0]\n",
    "    rkp = right_row['keypoint']\n",
    "    right_keypoints[body_part] = rkp\n",
    "\n",
    "    d = abs(lkp[0] - rkp[0])\n",
    "\n",
    "    # compute world key point\n",
    "    depth = depth_from_disp(d, focal_length_pixel, baseline)\n",
    "    wkp = convert_to_world_point(lkp[0], lkp[1], depth, pixel_count_width, \n",
    "                                 pixel_count_height, image_sensor_width, \n",
    "                                 image_sensor_height, focal_length)\n",
    "\n",
    "    world_keypoints[body_part] = wkp\n",
    "\n",
    "row['left_keypoints'] = left_keypoints\n",
    "row['right_keypoints'] = right_keypoints\n",
    "row['world_keypoints'] = world_keypoints\n",
    "\n",
    "stereo_frame_pairs_df = stereo_frame_pairs_df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2biomass_linear(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    print(body_parts)\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('/root/data/alok/biomass_estimation/models/20190715_model_4_eig.pkl', 'rb'))\n",
    "world_keypoints = stereo_frame_pairs_df.world_keypoints.iloc[0]\n",
    "biomass = coord2biomass_linear(world_keypoints, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
