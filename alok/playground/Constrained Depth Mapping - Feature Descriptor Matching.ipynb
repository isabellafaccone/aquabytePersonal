{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will try to estimate the 3D coordinates of an extrapolated keypoint located on the lateral side of the fish. The extrapolated keypoint will be the part of the fish that appears as the midpoint of the dorsal fin coordinates and the pelvic fic coordinates in the left iamge. We will use prior knowledge of fish dimensions to determine the disparity bounds on this point. This means that we can constrain the search for the right image correspondency to a patch based on these disparity bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load a sample stereo image and associated image keypoint coordinates </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1549544491230\n",
    "left_image_path = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/rectification/data/gtsf_a/rectified_images/left_small-pen-test-site_1_{}.jpg'.format(epoch)\n",
    "right_image_path = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/rectification/data/gtsf_a/rectified_images/right_small-pen-test-site_1_{}.jpg'.format(epoch)\n",
    "\n",
    "left_image = cv2.imread(left_image_path)\n",
    "right_image = cv2.imread(right_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "plt.imshow(left_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get keypoint world coordinates and 2D left and right image coordinates </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_data = json.load(open('/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/playground/keypoint_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kp_data_json = [kp for kp in keypoint_data if kp['External ID'] == 'left_small-pen-test-site_1_{}.jpg'.format(epoch)][0]\n",
    "right_kp_data_json = [kp for kp in keypoint_data if kp['External ID'] == 'right_small-pen-test-site_1_{}.jpg'.format(epoch)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kp_data = {}\n",
    "right_kp_data = {}\n",
    "body_parts = list(left_kp_data_json['Label'].keys())\n",
    "for body_part in body_parts:\n",
    "    left_kp_dict = left_kp_data_json['Label'][body_part][0]['geometry']\n",
    "    left_kp = np.array([left_kp_dict['x'], left_kp_dict['y']])\n",
    "    \n",
    "    right_kp_dict = right_kp_data_json['Label'][body_part][0]['geometry']\n",
    "    right_kp = np.array([right_kp_dict['x'], right_kp_dict['y']])\n",
    "    left_kp_data[body_part] = left_kp\n",
    "    right_kp_data[body_part] = right_kp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Compute the 3D world coordinates of the keypoints </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE OPTICAL PROPERTIES\n",
    "\n",
    "# all distance are in meters\n",
    "FOCAL_LENGTH = 0.0085\n",
    "BASELINE = 0.1044\n",
    "PIXEL_SIZE_M = 3.45 * 1e-6\n",
    "FOCAL_LENGTH_PIXEL = FOCAL_LENGTH / PIXEL_SIZE_M\n",
    "IMAGE_SENSOR_WIDTH = 0.01412\n",
    "IMAGE_SENSOR_HEIGHT = 0.01035\n",
    "PIXEL_COUNT_WIDTH = 4096\n",
    "PIXEL_COUNT_HEIGHT = 3000\n",
    "CHECKERBOARD_SIDE_LENGTH = 0.0495\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point(x, y, d):\n",
    "    \"\"\" from pixel coordinates to world coordinates \"\"\"\n",
    "    \n",
    "    image_center_x = PIXEL_COUNT_WIDTH / 2.0  \n",
    "    image_center_y = PIXEL_COUNT_HEIGHT / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (IMAGE_SENSOR_WIDTH / PIXEL_COUNT_WIDTH)\n",
    "    sensor_z = px_z * (IMAGE_SENSOR_HEIGHT / PIXEL_COUNT_HEIGHT)\n",
    "\n",
    "    # d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / FOCAL_LENGTH\n",
    "    world_z = (world_y * sensor_z) / FOCAL_LENGTH\n",
    "    return np.array([world_x, world_y, world_z])\n",
    "\n",
    "\n",
    "\n",
    "def depth_from_disp(disp):\n",
    "    \"\"\" calculate the depth of the point based on the disparity value \"\"\"\n",
    "    depth = FOCAL_LENGTH_PIXEL*BASELINE / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "def disp_from_depth(depth):\n",
    "    disp = FOCAL_LENGTH_PIXEL * BASELINE / depth\n",
    "    return disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_kp_data = {}\n",
    "for body_part in body_parts:\n",
    "    left_kp = left_kp_data[body_part]\n",
    "    right_kp = right_kp_data[body_part]\n",
    "    \n",
    "    disp = abs(left_kp[0] - right_kp[0])\n",
    "    depth = depth_from_disp(disp)\n",
    "    world_kp = convert_to_world_point(left_kp[0], left_kp[1], depth)\n",
    "    world_kp_data[body_part] = world_kp\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get extrapolated keypoint coordinates in left image, and associated disparity bounds for determining the corresponding pixel in the right image </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_1, bp_2 = 'upper lip', 'tail: notch'\n",
    "\n",
    "left_extrap_kp = (0.5 * left_kp_data[bp_1] + 0.5 * left_kp_data[bp_2]).astype('int64')\n",
    "bp_1_depth = world_kp_data[bp_1][1]\n",
    "bp_2_depth = world_kp_data[bp_2][1]\n",
    "\n",
    "# need to determine lower and upper bounds here in a data driven fashion from GTSF data\n",
    "extrap_kp_max_depth = (bp_1_depth + bp_2_depth) / 2.0 - 0.02\n",
    "extrap_kp_min_depth = (bp_1_depth + bp_2_depth) / 2.0 - 0.1\n",
    "\n",
    "extrap_kp_min_disp = disp_from_depth(extrap_kp_max_depth)\n",
    "extrap_kp_max_disp = disp_from_depth(extrap_kp_min_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Compute the feature descriptor for the extrapolated keypoint in the left image </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_window_size = 100\n",
    "left_box = left_image[left_extrap_kp[1]-left_window_size//2:left_extrap_kp[1]+left_window_size//2, \n",
    "                      left_extrap_kp[0]-left_window_size//2:left_extrap_kp[0]+left_window_size//2]\n",
    "right_box = right_image[left_extrap_kp[1]-left_window_size//2:left_extrap_kp[1]+left_window_size//2,\n",
    "                        left_extrap_kp[0]-int(extrap_kp_max_disp)-left_window_size//2:left_extrap_kp[0]-int(extrap_kp_min_disp)+left_window_size//2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(left_box,None)\n",
    "kp2, des2 = orb.detectAndCompute(right_box,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "img3 = cv2.drawMatches(left_box,kp1,right_box,kp2,matches[:5], None, flags=2)\n",
    "plt.figure(figsize=(50, 50))\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[0].distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
