{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import Pool, pool\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/calibration/data/sf_test_images_4/all_images/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_fs = sorted(glob.glob(os.path.join(training_dir, 'left*.jpg')))\n",
    "right_image_fs = sorted(glob.glob(os.path.join(training_dir, 'right*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(left_image_fs[0])\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "print(gray.shape[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkerboard dimensions and other optical properties\n",
    "CHECKERBOARD_WIDTH = 9\n",
    "CHECKERBOARD_HEIGHT = 6\n",
    "IMAGE_PIXEL_WIDTH = 4096\n",
    "IMAGE_PIXEL_HEIGHT = 3000\n",
    "RESIZE_FACTOR = 4\n",
    "CHECKERBOARD_SIDE_LENGTH = 0.0495\n",
    "\n",
    "# create object points\n",
    "obj_pts = np.zeros((CHECKERBOARD_HEIGHT*CHECKERBOARD_WIDTH,3), np.float32)\n",
    "obj_pts[:,:2] = np.mgrid[0:CHECKERBOARD_WIDTH,0:CHECKERBOARD_HEIGHT].T.reshape(-1,2)\n",
    "obj_pts = obj_pts * CHECKERBOARD_SIDE_LENGTH\n",
    "\n",
    "\n",
    "# helper method for finding the checkerboard points in a given file path\n",
    "def find_checkerboard_points(im):\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    resized_gray_im = cv2.resize(gray_im, (IMAGE_PIXEL_WIDTH // RESIZE_FACTOR, IMAGE_PIXEL_HEIGHT // RESIZE_FACTOR))\n",
    "    ret, resized_corners = cv2.findChessboardCorners(resized_gray_im, (CHECKERBOARD_WIDTH, CHECKERBOARD_HEIGHT),None)\n",
    "    unadjusted_corners, corners = None, None\n",
    "    if ret:\n",
    "        unadjusted_corners = resized_corners * RESIZE_FACTOR\n",
    "        corners = cv2.cornerSubPix(gray, unadjusted_corners, (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "    return ret, corners\n",
    "\n",
    "\n",
    "# method for generating calibration matrix for each individual camera and then for the entire stereo system\n",
    "def calibrate_stereo_camera(left_image_fs, right_image_fs):\n",
    "    \n",
    "    # first, perform calibration for each individual camera (left and right)\n",
    "    left_intersection_pts = []\n",
    "    right_intersection_pts = []\n",
    "    for left_image_f, right_image_f in zip(left_image_fs, right_image_fs):\n",
    "        left_im, right_im = cv2.imread(left_image_f), cv2.imread(right_image_f)\n",
    "        left_ret, left_corners = find_checkerboard_points(left_im)\n",
    "        right_ret, right_corners = find_checkerboard_points(right_im)\n",
    "        \n",
    "        # only consider well-behaved frame pairs (i.e. left and right image pairs where all checkerboard\n",
    "        # points were found)\n",
    "        if left_ret or right_ret:\n",
    "            if left_ret and right_ret:\n",
    "                print('Checkerboard points found for stereo image pair')\n",
    "            else:\n",
    "                print('Checkerboard points found for at least one image in stereo pair')\n",
    "            left_intersection_pts.append(left_corners)\n",
    "            right_intersection_pts.append(right_corners)\n",
    "        else:\n",
    "            print('Checkerboard points not found!')\n",
    "    \n",
    "    # get valid points\n",
    "    valid_left_intersection_pts, valid_right_intersection_pts = [], []\n",
    "    stereo_valid_left_intersection_pts, stereo_valid_right_intersection_pts = [], []\n",
    "    for lip, rip in zip(left_intersection_pts, right_intersection_pts):\n",
    "        if lip is not None:\n",
    "            valid_left_intersection_pts.append(lip)\n",
    "        if rip is not None:\n",
    "            valid_right_intersection_pts.append(rip)\n",
    "        if lip is not None and rip is not None:\n",
    "            stereo_valid_left_intersection_pts.append(lip)\n",
    "            stereo_valid_right_intersection_pts.append(rip)\n",
    "        \n",
    "    \n",
    "    # generate rectification parameters for left camera\n",
    "    valid_left_object_pts = [obj_pts] * len(valid_left_intersection_pts)\n",
    "    left_ret, left_mtx, left_dist, left_rvecs, left_tvecs = \\\n",
    "        cv2.calibrateCamera(valid_left_object_pts, valid_left_intersection_pts, (IMAGE_PIXEL_WIDTH, IMAGE_PIXEL_HEIGHT), None, None)\n",
    "    \n",
    "    print('Left camera rectified!')\n",
    "    \n",
    "    # generate rectification parameters for right camera\n",
    "    valid_right_object_pts = [obj_pts] * len(valid_right_intersection_pts)\n",
    "    right_ret, right_mtx, right_dist, right_rvecs, right_tvecs = \\\n",
    "        cv2.calibrateCamera(valid_right_object_pts, valid_right_intersection_pts, (IMAGE_PIXEL_WIDTH, IMAGE_PIXEL_HEIGHT), None, None)\n",
    "        \n",
    "    print('Right camera rectified!')\n",
    "    \n",
    "    # generate rectification parameters for stereo system\n",
    "    \n",
    "    valid_stereo_object_pts = [obj_pts] * len(stereo_valid_left_intersection_pts)\n",
    "    stereocalibration_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "    stereocalibration_flags = cv2.CALIB_FIX_INTRINSIC\n",
    "    stereocalibration_retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F = cv2.stereoCalibrate(valid_stereo_object_pts, stereo_valid_left_intersection_pts, stereo_valid_right_intersection_pts, \n",
    "                       left_mtx, left_dist, right_mtx, right_dist, (IMAGE_PIXEL_WIDTH, IMAGE_PIXEL_HEIGHT),\n",
    "                       criteria=stereocalibration_criteria, flags=stereocalibration_flags)\n",
    "    \n",
    "    print('Stereo system rectified')\n",
    "    \n",
    "    return stereocalibration_retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, left_mtx\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereocalibration_retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, lm = calibrate_stereo_camera(left_image_fs, right_image_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraMatrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcameramtx1, roi1 = cv2.getOptimalNewCameraMatrix(cameraMatrix1, distCoeffs1, (4096, 3000), 1, (4096, 3000))\n",
    "newcameramtx2, roi2 = cv2.getOptimalNewCameraMatrix(cameraMatrix2, distCoeffs2, (4096, 3000), 1, (4096, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereocalibration_retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Assess Calibration Accuracy </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/calibration/data/sf_test_images_4/validation_images'\n",
    "left_validation_image_fs = sorted(glob.glob(os.path.join(validation_dir, 'left*.jpg')))\n",
    "right_validation_image_fs = sorted(glob.glob(os.path.join(validation_dir, 'right*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_checkerboard_points_list = []\n",
    "for left_image_f, right_image_f in zip(left_validation_image_fs, right_validation_image_fs):\n",
    "    left_im = cv2.imread(left_image_f)\n",
    "    right_im = cv2.imread(right_image_f)\n",
    "    left_rectified = cv2.undistort(left_im, cameraMatrix1, distCoeffs1, None, newcameramtx1)\n",
    "    right_rectified = cv2.undistort(right_im, cameraMatrix2, distCoeffs2, None, newcameramtx2)\n",
    "    \n",
    "    left_ret, left_corners = find_checkerboard_points(left_im)\n",
    "    right_ret, right_corners = find_checkerboard_points(right_im)\n",
    "    \n",
    "    \n",
    "    if left_ret and right_ret:\n",
    "        print('Checkerboard points found!')\n",
    "        print(left_image_f)\n",
    "        P1 = np.dot(cameraMatrix1, np.hstack([np.eye(3), np.array([[0], [0], [0]])]))\n",
    "        P2 = np.dot(cameraMatrix2, np.hstack([R, T]))\n",
    "        wcp = cv2.triangulatePoints(P1, P2, left_corners, right_corners).T\n",
    "        world_checkerboard_points = wcp[:,:3] / wcp[:,3, None]\n",
    "        world_checkerboard_points_list.append(world_checkerboard_points)\n",
    "        \n",
    "world_coordinate_matrix = np.empty([len(world_checkerboard_points_list), CHECKERBOARD_WIDTH*CHECKERBOARD_HEIGHT, 3])\n",
    "for i, world_checkerboard_points in enumerate(world_checkerboard_points_list):\n",
    "        world_coordinate_matrix[i, :] = world_checkerboard_points\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5\n",
    "\n",
    "def distance_between_positions(i, j):\n",
    "    p1_ax_0_pos = i // CHECKERBOARD_WIDTH\n",
    "    p1_ax_1_pos = i % CHECKERBOARD_WIDTH\n",
    "    p2_ax_0_pos = j // CHECKERBOARD_WIDTH\n",
    "    p2_ax_1_pos = j % CHECKERBOARD_WIDTH\n",
    "    return CHECKERBOARD_SIDE_LENGTH * ((p1_ax_0_pos - p2_ax_0_pos)**2 + (p1_ax_1_pos - p2_ax_1_pos)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame()\n",
    "for idx in range(world_coordinate_matrix.shape[0]):\n",
    "    for i in range(world_coordinate_matrix.shape[1]-1):\n",
    "        for j in range(i+1, world_coordinate_matrix.shape[1]):\n",
    "            p1 = world_coordinate_matrix[idx, i, :]\n",
    "            p2 = world_coordinate_matrix[idx, j, :]\n",
    "            predicted_distance = euclidean_distance(p1, p2)\n",
    "            ground_truth_distance = distance_between_positions(i, j)\n",
    "            row = {\n",
    "                'idx': idx,\n",
    "                'predicted_distance': predicted_distance,\n",
    "                'ground_truth_distance': ground_truth_distance,\n",
    "                'p1_x': p1[0],\n",
    "                'p1_y': p1[1],\n",
    "                'p1_z': p1[2],\n",
    "                'p2_x': p2[0],\n",
    "                'p2_y': p2[1],\n",
    "                'p2_z': p2[2],\n",
    "            }\n",
    "            analysis_df = analysis_df.append(row, ignore_index=True)\n",
    "    \n",
    "analysis_df['deviation'] = analysis_df['predicted_distance'] - analysis_df['ground_truth_distance']\n",
    "analysis_df['pct_deviation'] = analysis_df['deviation'] / analysis_df['ground_truth_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df.deviation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['abs_deviation'] = analysis_df.deviation.abs()\n",
    "analysis_df['yaw'] = (180 / np.pi) * np.arctan((analysis_df.p1_x - analysis_df.p2_x)/(analysis_df.p1_z - analysis_df.p2_z))\n",
    "analysis_df['abs_yaw'] = analysis_df['yaw'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df[(analysis_df.ground_truth_distance < 0.3) & (analysis_df.ground_truth_distance < 0.5)].deviation)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(analysis_df.predicted_distance, analysis_df.ground_truth_distance)\n",
    "plt.xlabel('Predicted Distance')\n",
    "plt.plot([0, 0.5], [0, 0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df.ground_truth_distance > 0.45].sort_values('deviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
