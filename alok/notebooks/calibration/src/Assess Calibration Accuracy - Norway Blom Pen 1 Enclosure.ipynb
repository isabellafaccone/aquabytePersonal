{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import Pool, pool\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Calibration Facilitator Notebook </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define directory structure for calibration images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_validation_dir = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/calibration/data/blom_pen_1_enclosure/validation_images/left'\n",
    "right_validation_dir = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/calibration/data/blom_pen_1_enclosure/validation_images/right'\n",
    "stereo_params_f = '/Users/aloksaxena/Documents/aquabyteai/repos/cv_research/alok/notebooks/calibration/data/blom_pen_1_enclosure/2019-04-26_blom_kjeppevikholmen_pen_1.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(params_file):\n",
    "    params = json.load(open(params_file))\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "\n",
    "    imageSize = (4096, 3000)\n",
    "    \n",
    "    # perform rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, None, None, None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "    \n",
    "    return left_maps, right_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps, right_maps = load_params(stereo_params_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_pair(left_img_path, right_img_path, left_maps, right_maps):\n",
    "    \n",
    "    img_left = cv2.imread(left_img_path)\n",
    "    img_right = cv2.imread(right_img_path)\n",
    "    remap_left = cv2.remap(img_left, left_maps[0], left_maps[1], cv2.INTER_LANCZOS4)\n",
    "    remap_right = cv2.remap(img_right, right_maps[0], right_maps[1], cv2.INTER_LANCZOS4)\n",
    "    return remap_left, remap_right\n",
    "\n",
    "def find_corners(remap):\n",
    "    gray = cv2.cvtColor(remap,cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (1024, 750))\n",
    "    \n",
    "    ret, resized_corners = cv2.findChessboardCorners(resized, (9,6),None)\n",
    "    if ret:\n",
    "        corners = resized_corners * 4\n",
    "        adj_corners = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        return np.squeeze(adj_corners)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_checkerboard_points = {}\n",
    "left_image_fs = glob.glob(os.path.join(left_validation_dir, 'left_*.jpg'))[:7]\n",
    "for left_image_f in left_image_fs:\n",
    "    right_image_f = left_image_f.replace('left', 'right')\n",
    "    if not os.path.exists(right_image_f):\n",
    "        print('Path does not exist: {}'.format(right_image_f))\n",
    "        continue\n",
    "    \n",
    "    remap_left, remap_right = remap_pair(left_image_f, right_image_f, left_maps, right_maps)\n",
    "    \n",
    "    left_corners = find_corners(remap_left)\n",
    "    right_corners = find_corners(remap_right)\n",
    "    if left_corners is not None and right_corners is not None:\n",
    "        image_to_checkerboard_points[left_image_f] = {}\n",
    "        image_to_checkerboard_points[left_image_f]['left_corners'] = left_corners\n",
    "        image_to_checkerboard_points[left_image_f]['right_corners'] = right_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get predicted vs. ground truth distances </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all distance are in meters\n",
    "stereo_params = json.load(open(stereo_params_f))\n",
    "FOCAL_LENGTH_PIXEL = stereo_params['CameraParameters1']['FocalLength'][0]\n",
    "BASELINE = abs(stereo_params['TranslationOfCamera2'][0] / 1e3) # convert millimeters to meters and use absolute value\n",
    "PIXEL_SIZE_M = 3.45 * 1e-6\n",
    "FOCAL_LENGTH = FOCAL_LENGTH_PIXEL * PIXEL_SIZE_M\n",
    "IMAGE_SENSOR_WIDTH = 0.01412\n",
    "IMAGE_SENSOR_HEIGHT = 0.01035\n",
    "PIXEL_COUNT_WIDTH = 4096\n",
    "PIXEL_COUNT_HEIGHT = 3000\n",
    "CHECKERBOARD_SIDE_LENGTH = 0.049294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point(x, y, d):\n",
    "    \"\"\" from pixel coordinates to world coordinates \"\"\"\n",
    "    \n",
    "    image_center_x = PIXEL_COUNT_WIDTH / 2.0  \n",
    "    image_center_y = PIXEL_COUNT_HEIGHT / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (IMAGE_SENSOR_WIDTH / 4096)\n",
    "    sensor_z = px_z * (IMAGE_SENSOR_HEIGHT / 3000)\n",
    "\n",
    "    # d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / FOCAL_LENGTH\n",
    "    world_z = (world_y * sensor_z) / FOCAL_LENGTH\n",
    "    return np.array([world_x, world_y, world_z])\n",
    "\n",
    "\n",
    "\n",
    "def depth_from_disp(disp):\n",
    "    \"\"\" calculate the depth of the point based on the disparity value \"\"\"\n",
    "    depth = FOCAL_LENGTH_PIXEL*BASELINE / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5\n",
    "\n",
    "def distance_between_positions(i, j):\n",
    "    p1_ax_0_pos = i // 9\n",
    "    p1_ax_1_pos = i % 9\n",
    "    p2_ax_0_pos = j // 9\n",
    "    p2_ax_1_pos = j % 9\n",
    "    return CHECKERBOARD_SIDE_LENGTH * ((p1_ax_0_pos - p2_ax_0_pos)**2 + (p1_ax_1_pos - p2_ax_1_pos)**2)**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_coordinate_matrix = np.empty([len(list(image_to_checkerboard_points.keys())), 54, 3])\n",
    "for idx, left_image_f in enumerate(image_to_checkerboard_points.keys()):\n",
    "    left_corners = image_to_checkerboard_points[left_image_f]['left_corners']\n",
    "    right_corners = image_to_checkerboard_points[left_image_f]['right_corners']\n",
    "    for i in range(42):\n",
    "        disp = abs(left_corners[i][0] - right_corners[i][0])\n",
    "        print(abs(left_corners[i][1] - right_corners[i][1]))\n",
    "        depth = depth_from_disp(disp)\n",
    "        world_coordinate_matrix[idx, i, :] = convert_to_world_point(left_corners[i][0], left_corners[i][1], depth)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame()\n",
    "for idx in range(world_coordinate_matrix.shape[0]):\n",
    "    for i in range(world_coordinate_matrix.shape[1]-1):\n",
    "        for j in range(i+1, world_coordinate_matrix.shape[1]):\n",
    "            p1 = world_coordinate_matrix[idx, i, :]\n",
    "            p2 = world_coordinate_matrix[idx, j, :]\n",
    "            predicted_distance = euclidean_distance(p1, p2)\n",
    "            ground_truth_distance = distance_between_positions(i, j)\n",
    "            row = {\n",
    "                'predicted_distance': predicted_distance,\n",
    "                'ground_truth_distance': ground_truth_distance\n",
    "            }\n",
    "            analysis_df = analysis_df.append(row, ignore_index=True)\n",
    "    \n",
    "analysis_df['deviation'] = analysis_df['predicted_distance'] - analysis_df['ground_truth_distance']\n",
    "analysis_df['pct_deviation'] = analysis_df['deviation'] / analysis_df['ground_truth_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(analysis_df[analysis_df.ground_truth_distance > 0.4]['deviation'])\n",
    "plt.xlabel('Predicted distance deviation (meters)')\n",
    "plt.ylabel('Ground distance deviation (meters)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x - x2)**2 + (y-y2)**2 + (z-z2)**2)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(left_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
