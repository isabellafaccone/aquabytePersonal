{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get lice annotation data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where (pen_id = 57 or pen_id=58 or pen_id=59 or pen_id=60)\n",
    "    and captured_at >= '2019-09-14';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations_reconciled where (pen_id = 57 or pen_id=58 or pen_id=59 or pen_id=60)\n",
    "    and captured_at >= '2019-09-14';\n",
    "\"\"\"\n",
    "reconciled_df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.0656\n",
    "FISH_LENGTH_M = 0.2944\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    df['stereo_depth_m'] = df.metadata.apply(lambda x: x.get('depth_m'))\n",
    "    return df\n",
    "\n",
    "df = process_data_df(df)\n",
    "reconciled_df = process_data_df(reconciled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stereo_depth_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_focus_mask = (df.stereo_depth_m > 0.4) & (df.stereo_depth_m < 0.5)\n",
    "cogito_accept_mask = ~df.is_skipped\n",
    "is_blurry_mask = df.is_blurry\n",
    "is_bad_crop_mask = df.is_bad_crop == True\n",
    "reconciled_in_focus_mask = (reconciled_df.stereo_depth_m > 0.4) & (reconciled_df.stereo_depth_m < 0.5)\n",
    "reconciled_accept_mask = ~reconciled_df.is_skipped\n",
    "reconciled_is_blurry_mask = reconciled_df.is_blurry\n",
    "reconciled_is_bad_crop_mask = reconciled_df.is_bad_crop == True\n",
    "\n",
    "\n",
    "n = df.shape[0]\n",
    "n_in_focus = df[in_focus_mask].shape[0]\n",
    "n_in_focus_accepted_cogito = df[in_focus_mask & (cogito_accept_mask)].shape[0]\n",
    "n_not_in_focus_accepted_cogito = df[~in_focus_mask & (cogito_accept_mask)].shape[0]\n",
    "n_in_focus_accepted_reconciled = reconciled_df[reconciled_in_focus_mask & (reconciled_accept_mask)].shape[0]\n",
    "\n",
    "\n",
    "print('Total number of images inspected by Cogito over the weekend: {}'.format(n))\n",
    "print('Total number of these images within in-focus range (45 cm - 55 cm): {}'.format(n_in_focus))\n",
    "print('Total number of in-focus images accepted by Cogito: {}'.format(n_in_focus_accepted_cogito))\n",
    "print('Total number of not-in-focus images accepted by Cogito: {}'.format(n_not_in_focus_accepted_cogito))\n",
    "print('Total number of in-focus inmages accepted in QA: {}'.format(n_in_focus_accepted_reconciled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> What should Cogito have done? </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df[in_focus_mask].iterrows():\n",
    "    s3_access_utils.download_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~in_focus_mask & cogito_accept_mask][['image_url', 'is_too_dark', 'is_blurry', 'is_bad_crop', 'is_cleaner_fish', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[cogito_accept_mask].stereo_depth_m, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1034**2+727**2)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4015*250 / (1263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4015 * 0.005) / 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_df[reconciled_df.adult_female_count > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_df[['adult_female_count_adjusted', 'moving_count_adjusted']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_df[reconciled_df.moving_count_adjusted == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = 0.0138 / 3.45e-6\n",
    "baseline = 0.101\n",
    "disparity = (248-200) * (4096/512.)\n",
    "depth = focal_length * baseline / disparity\n",
    "print(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reconciled_df[~reconciled_df.is_skipped].depth, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconciled_df.loc[~reconciled_df.is_skipped, ['image_url', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_skipped == True].sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_images_dir = '/root/data/alok/biomass_estimation/modified_images/'\n",
    "object_length_m = 0.01\n",
    "N = 50\n",
    "\n",
    "cogito_accept_mask = ~df.is_skipped\n",
    "qa_accept_mask = ~reconciled_df.is_skipped\n",
    "depth_values = [round(x, 1) for x in np.arange(0.2, 0.8, 0.1)]\n",
    "\n",
    "depth_field = 'stereo_depth_m'\n",
    "for i in range(len(depth_values)-1):\n",
    "    print(i)\n",
    "    lo, hi = depth_values[i], depth_values[i+1]\n",
    "    depth_mask = (df[depth_field] >= lo) & (df[depth_field] <= hi)\n",
    "    reconciled_depth_mask = (reconciled_df[depth_field] >= lo) & (reconciled_df[depth_field] <= hi)\n",
    "    \n",
    "    # rejected images\n",
    "    for idx, row in df[depth_mask & is_blurry_mask & (~is_bad_crop_mask)].head(N).iterrows():\n",
    "        depth_m = row[depth_field]\n",
    "        line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "        image_url = row.image_url\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "        \n",
    "        image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "        \n",
    "        im = Image.open(image_f)\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "        \n",
    "        f_name = os.path.basename(key)\n",
    "        f = os.path.join(modified_images_dir, '{}_{}'.format(lo, hi), 'rejected', f_name)\n",
    "        if not os.path.exists(os.path.dirname(f)):\n",
    "            os.makedirs(os.path.dirname(f))\n",
    "        im.save(f)\n",
    "        \n",
    "    # accepted images\n",
    "    for idx, row in reconciled_df[reconciled_depth_mask & qa_accept_mask].head(N).iterrows():\n",
    "        depth_m = row[depth_field]\n",
    "        line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "        image_url = row.image_url\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "        image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "        \n",
    "        im = Image.open(image_f)\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "        \n",
    "        f_name = os.path.basename(key)\n",
    "        f = os.path.join(modified_images_dir, '{}_{}'.format(lo, hi), 'accepted', f_name)\n",
    "        if not os.path.exists(os.path.dirname(f)):\n",
    "            os.makedirs(os.path.dirname(f))\n",
    "        im.save(f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.stereo_depth_m >= 0.43) & (df.stereo_depth_m <= 0.46) & is_blurry_mask & (~is_bad_crop_mask)].head(20).image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('702_1953_3290_3000')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('366_1350_2442_2229')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('0_1127_2674_2012')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate depth values </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'stereo_depth_m'\n",
    "valid_mask = (reconciled_df[depth_field] > 0.2) & (reconciled_df[depth_field] < 0.7)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[valid_mask & reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'single_image_depth_m'\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
