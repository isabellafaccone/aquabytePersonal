{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get lice annotation data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id=40;\n",
    "\"\"\"\n",
    "cogito_df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "# get rid of rows that would already appear in the reconciled table\n",
    "cogito_df = cogito_df[cogito_df.is_skipped == True]\n",
    "cogito_df['is_accepted_in_qa'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations_reconciled where pen_id=40\n",
    "\"\"\"\n",
    "reconciled_df = rds_access_utils.extract_from_database(query)\n",
    "reconciled_df['is_accepted_in_qa'] = False\n",
    "reconciled_df.loc[reconciled_df.adult_female_count >= 0, 'is_accepted_in_qa'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cogito_df, reconciled_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_df.to_csv('/root/data/alok/aggregate_df_bremnes_tittelsnes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.133\n",
    "FISH_LENGTH_M = 0.685\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    df['stereo_depth_m'] = df.metadata.apply(lambda x: x.get('depth_m'))\n",
    "    return df\n",
    "\n",
    "df = process_data_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/alok/aggregate_hiskholmen_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.adult_female_count >= 0].adult_female_count.resample('D', how=lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cogito_df.index = pd.to_datetime(cogito_df.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cogito_df[cogito_df.adult_female_count >= 0].adult_female_count.resample('D', how=lambda x: x.median())\n",
    "y = cogito_df[cogito_df.adult_female_count >= 0].adult_female_count.resample('D', how=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y, x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_focus_mask = (df.stereo_depth_m > 0.8) & (df.stereo_depth_m < 1.0)\n",
    "accept_mask = ~df.is_skipped\n",
    "skip_masks = {}\n",
    "skip_reasons = [\n",
    "    'is_accepted_in_qa', \n",
    "    'is_blurry', \n",
    "    'is_bad_crop', \n",
    "    'is_too_dark', \n",
    "    'is_bad_crop_many_fish', \n",
    "    'is_bad_orientation', \n",
    "    'is_bad_crop_cut_off', \n",
    "    'is_obstructed'\n",
    "]\n",
    "for skip_reason in skip_reasons:\n",
    "    skip_masks[skip_reason] = df[skip_reason] == True\n",
    "\n",
    "n = df.shape[0]\n",
    "n_in_focus = df[in_focus_mask].shape[0]\n",
    "n_in_focus_accepted = df[in_focus_mask & accept_mask].shape[0]\n",
    "n_not_in_focus_accepted = df[~in_focus_mask & accept_mask].shape[0]\n",
    "\n",
    "\n",
    "print('Total number of images inspected by Cogito over the weekend: {}'.format(n))\n",
    "print('Total number of these images within in-focus range (45 cm - 55 cm): {}'.format(n_in_focus))\n",
    "print('Total number of in-focus images accepted in QA: {}'.format(n_in_focus_accepted))\n",
    "print('Total number of not-in-focus images accepted by Cogito: {}'.format(n_not_in_focus_accepted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "valid_depth_mask = (df.stereo_depth_m > 0.0) & (df.stereo_depth_m < 2.0)\n",
    "plt.hist(df[valid_depth_mask & accept_mask].stereo_depth_m, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_skipped == True].sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, skip_reason):\n",
    "    depth_m = row[depth_field]\n",
    "    line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "    image_url = row.image_url\n",
    "    bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "\n",
    "    im = Image.open(image_f)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "\n",
    "    f_name = os.path.basename(key)\n",
    "    f = os.path.join(modified_images_dir, '{}_{}'.format(lo, hi), skip_reason, f_name)\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    im.save(f)\n",
    "\n",
    "\n",
    "modified_images_dir = '/root/data/alok/lice_counting/bremnes_tittelsnes_image_breakdown'\n",
    "object_length_m = 0.01\n",
    "N = 20\n",
    "\n",
    "cogito_accept_mask = ~df.is_skipped\n",
    "qa_accept_mask = ~reconciled_df.is_skipped\n",
    "depth_values = [round(x, 1) for x in np.arange(0.2, 1.5, 0.1)]\n",
    "\n",
    "depth_field = 'stereo_depth_m'\n",
    "for i in range(len(depth_values)-1):\n",
    "    print(i)\n",
    "    lo, hi = depth_values[i], depth_values[i+1]\n",
    "    depth_mask = (df[depth_field] >= lo) & (df[depth_field] <= hi)\n",
    "    \n",
    "    # accepted images\n",
    "    for idx, row in df[depth_mask & accept_mask].head(N).iterrows():\n",
    "        process_row(row, 'accepted')\n",
    "    \n",
    "    # rejected images due to blurriness\n",
    "    for idx, row in df[depth_mask & is_blurry_mask & (~is_bad_crop_mask) & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_blurry')\n",
    "        \n",
    "    # rejected images due to darkness\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & (~is_bad_crop_mask) & is_too_dark_mask & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_too_dark')\n",
    "        \n",
    "    # rejected images due to bad crop\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & is_bad_crop_mask & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_bad_crop')\n",
    "        \n",
    "    # rejected images due to bad orientation\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & (~is_bad_crop_mask) & (~is_too_dark_mask) & (is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_bad_orientation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, skip_reason):\n",
    "    depth_m = row[depth_field]\n",
    "    line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "    image_url = row.image_url\n",
    "    if 'aquabyte-crops-lati' not in image_url:\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    else:\n",
    "        components = urlparse(image_url, allow_fragments=False).path.lstrip('/').split('/')\n",
    "        bucket, key = components[0], os.path.join(*components[1:])\n",
    "    print(bucket, key)\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "\n",
    "    im = Image.open(image_f)\n",
    "#     draw = ImageDraw.Draw(im)\n",
    "#     draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "\n",
    "    f_name = os.path.basename(key)\n",
    "    f = os.path.join(modified_images_dir, skip_reason, f_name)\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    im.save(f)\n",
    "\n",
    "\n",
    "modified_images_dir = '/root/data/alok/lice_counting/bremnes_tittelsnes_breakdown_depth_independent'\n",
    "object_length_m = 0.01\n",
    "N = 50\n",
    "\n",
    "\n",
    "# rejected images due to skip reason\n",
    "for target_skip_reason in skip_reasons:\n",
    "    mask = skip_masks[target_skip_reason]\n",
    "    for skip_reason, skip_mask in skip_masks.items():\n",
    "        if skip_reason != target_skip_reason:\n",
    "            mask = mask & ~skip_mask\n",
    "        for idx, row in df[mask].head(N).iterrows():\n",
    "            process_row(row, skip_reason)\n",
    "\n",
    "# # rejected images due to darkness\n",
    "# for idx, row in df[(~is_blurry_mask) & (~is_bad_crop_mask) & is_too_dark_mask & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_too_dark')\n",
    "\n",
    "# # rejected images due to bad crop\n",
    "# for idx, row in df[(~is_blurry_mask) & is_bad_crop_mask & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_bad_crop')\n",
    "\n",
    "# # rejected images due to bad orientation\n",
    "# for idx, row in df[(~is_blurry_mask) & (~is_bad_crop_mask) & (~is_too_dark_mask) & (is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_bad_orientation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('702_1953_3290_3000')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('366_1350_2442_2229')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('0_1127_2674_2012')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate depth values </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'stereo_depth_m'\n",
    "valid_mask = (reconciled_df[depth_field] > 0.2) & (reconciled_df[depth_field] < 0.7)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[valid_mask & reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'single_image_depth_m'\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
