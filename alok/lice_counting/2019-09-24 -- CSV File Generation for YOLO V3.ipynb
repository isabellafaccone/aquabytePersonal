{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get lice annotation data across all pens </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_key(url):\n",
    "    parsed_url = urlparse(url, allow_fragments=False)\n",
    "    if parsed_url.netloc.startswith('s3'):\n",
    "        url_components = parsed_url.path.lstrip('/').split('/')\n",
    "        bucket, key = url_components[0], os.path.join(*url_components[1:])\n",
    "    else:\n",
    "        bucket = parsed_url.netloc.split('.')[0]\n",
    "        key = parsed_url.path.lstrip('/')\n",
    "    return bucket, key\n",
    "\n",
    "def get_reconciled_df(pen_id, start_date, end_date):\n",
    "    \n",
    "    query = \"\"\"\n",
    "        select * from lati_fish_detections_lice_annotations_reconciled where pen_id={} \n",
    "        and captured_at between '{}' and '{}' and adult_female_count >= 0\n",
    "        order by random() limit 800;\n",
    "    \"\"\".format(pen_id, start_date, end_date)\n",
    "    reconciled_df = rds_access_utils.extract_from_database(query)\n",
    "    reconciled_df = reconciled_df[reconciled_df.is_skipped == False]\n",
    "    reconciled_df = reconciled_df.drop(columns=['lati_fish_detections_lice_annotations_id'])\n",
    "    return reconciled_df\n",
    "\n",
    "\n",
    "def get_blurry_df(pen_id, start_date, end_date):\n",
    "    query = \"\"\"\n",
    "        select * from lati_fish_detections_lice_annotations where pen_id={} \n",
    "        and captured_at between '{}' and '{}'\n",
    "        and is_skipped != False and is_blurry = True and is_bad_crop = False\n",
    "        order by random() limit 800;\n",
    "    \"\"\".format(pen_id, start_date, end_date)\n",
    "    blurry_df = rds_access_utils.extract_from_database(query)\n",
    "    blurry_df = blurry_df.drop(columns=['completed_at'])\n",
    "    return blurry_df\n",
    "\n",
    "\n",
    "def get_dark_df(pen_id, start_date, end_date):\n",
    "    query = \"\"\"\n",
    "        select * from lati_fish_detections_lice_annotations where pen_id={} \n",
    "        and captured_at between '{}' and '{}'\n",
    "        and is_skipped != False and is_too_dark = True and is_bad_crop = False \n",
    "        order by random() limit 800;\n",
    "    \"\"\".format(pen_id, start_date, end_date)\n",
    "    dark_df = rds_access_utils.extract_from_database(query)\n",
    "    dark_df = dark_df.drop(columns=['completed_at'])\n",
    "    return dark_df\n",
    "\n",
    "def get_bad_crop_df(pen_id, start_date, end_date):\n",
    "    query = \"\"\"\n",
    "        select * from lati_fish_detections_lice_annotations where pen_id={} \n",
    "        and captured_at between '{}' and '{}'\n",
    "        and is_skipped != False and is_bad_crop = True  \n",
    "        order by random() limit 800;\n",
    "    \"\"\".format(pen_id, start_date, end_date)\n",
    "    bad_crop_df = rds_access_utils.extract_from_database(query)\n",
    "    bad_crop_df = bad_crop_df.drop(columns=['completed_at'])\n",
    "    return bad_crop_df\n",
    "\n",
    "def get_cleaner_fish_df(pen_id, start_date, end_date):\n",
    "    query = \"\"\"\n",
    "        select * from lati_fish_detections_lice_annotations where pen_id={} \n",
    "        and captured_at between '{}' and '{}'\n",
    "        and is_skipped != False and is_cleaner_fish = True  \n",
    "        order by random() limit 800;\n",
    "    \"\"\".format(pen_id, start_date, end_date)\n",
    "    bad_crop_df = rds_access_utils.extract_from_database(query)\n",
    "    bad_crop_df = bad_crop_df.drop(columns=['completed_at'])\n",
    "    return bad_crop_df\n",
    "\n",
    "\n",
    "def process_data_for_pen_id(pen_id, start_date, end_date, df_dict, data_root):\n",
    "    \n",
    "    if not os.path.exists(data_root):\n",
    "        os.makedirs(data_root)\n",
    "    \n",
    "    print(pen_id)\n",
    "    print('---'*10)\n",
    "#     reconciled_df = get_reconciled_df(pen_id, start_date, end_date)\n",
    "#     blurry_df = get_blurry_df(pen_id, start_date, end_date)\n",
    "#     dark_df = get_dark_df(pen_id, start_date, end_date)\n",
    "#     bad_crop_df = get_bad_crop_df(pen_id, start_date, end_date)\n",
    "    cleaner_fish_df = get_cleaner_fish_df(pen_id, start_date, end_date)\n",
    "            \n",
    "#     count = 0\n",
    "#     for idx, row in reconciled_df.iterrows():\n",
    "#         captured_at = row.captured_at\n",
    "#         image_url = row.image_url\n",
    "#         bucket, key = get_bucket_key(image_url)\n",
    "#         key = key.replace('dev', 'environment=production')\n",
    "#         key_directory = os.path.dirname(key)\n",
    "#         full_image_bucket, full_image_key = 'aquabyte-frames-resized-inbound', os.path.join(key_directory, 'left_frame.resize_512_512.jpg')\n",
    "#         full_image_f = os.path.join(data_root, full_image_key.replace('/', '_'))\n",
    "#         s3_access_utils.download_from_s3(full_image_bucket, full_image_key, full_image_f)\n",
    "#         df_dict['full_image_bucket'].append(full_image_bucket)\n",
    "#         df_dict['full_image_key'].append(full_image_key)\n",
    "#         df_dict['full_image_f'].append(full_image_f)\n",
    "#         for k, v in dict(row).items():\n",
    "#             df_dict[k].append(v)\n",
    "        \n",
    "#         if count % 100 == 0:\n",
    "#             print(count)\n",
    "#         count += 1\n",
    "        \n",
    "#     print('Reconciled df complete!')\n",
    "    \n",
    "#     count = 0\n",
    "#     for idx, row in blurry_df.iterrows():\n",
    "#         captured_at = row.captured_at\n",
    "#         image_url = row.image_url\n",
    "#         bucket, key = get_bucket_key(image_url)\n",
    "#         key = key.replace('dev', 'environment=production')\n",
    "#         key_directory = os.path.dirname(key)\n",
    "#         full_image_bucket, full_image_key = 'aquabyte-frames-resized-inbound', os.path.join(key_directory, 'left_frame.resize_512_512.jpg')\n",
    "#         full_image_f = os.path.join(data_root, full_image_key.replace('/', '_'))\n",
    "#         s3_access_utils.download_from_s3(full_image_bucket, full_image_key, full_image_f)\n",
    "#         df_dict['full_image_bucket'].append(full_image_bucket)\n",
    "#         df_dict['full_image_key'].append(full_image_key)\n",
    "#         df_dict['full_image_f'].append(full_image_f)\n",
    "#         for k, v in dict(row).items():\n",
    "#             df_dict[k].append(v)\n",
    "        \n",
    "#         if count % 100 == 0:\n",
    "#             print(count)\n",
    "#         count += 1\n",
    "\n",
    "#     print('Blurry df complete!')\n",
    "    \n",
    "#     count = 0\n",
    "#     for idx, row in dark_df.iterrows():\n",
    "#         captured_at = row.captured_at\n",
    "#         image_url = row.image_url\n",
    "#         bucket, key = get_bucket_key(image_url)\n",
    "#         key = key.replace('dev', 'environment=production')\n",
    "#         key_directory = os.path.dirname(key)\n",
    "#         full_image_bucket, full_image_key = 'aquabyte-frames-resized-inbound', os.path.join(key_directory, 'left_frame.resize_512_512.jpg')\n",
    "#         full_image_f = os.path.join(data_root, full_image_key.replace('/', '_'))\n",
    "#         s3_access_utils.download_from_s3(full_image_bucket, full_image_key, full_image_f)\n",
    "#         df_dict['full_image_bucket'].append(full_image_bucket)\n",
    "#         df_dict['full_image_key'].append(full_image_key)\n",
    "#         df_dict['full_image_f'].append(full_image_f)\n",
    "#         for k, v in dict(row).items():\n",
    "#             df_dict[k].append(v)\n",
    "            \n",
    "#         if count % 100 == 0:\n",
    "#             print(count)\n",
    "#         count += 1\n",
    "            \n",
    "#     print('Dark df complete!')\n",
    "\n",
    "#     count = 0\n",
    "#     for idx, row in bad_crop_df.iterrows():\n",
    "#         captured_at = row.captured_at\n",
    "#         image_url = row.image_url\n",
    "#         bucket, key = get_bucket_key(image_url)\n",
    "#         key = key.replace('dev', 'environment=production')\n",
    "#         key_directory = os.path.dirname(key)\n",
    "#         full_image_bucket, full_image_key = 'aquabyte-frames-resized-inbound', os.path.join(key_directory, 'left_frame.resize_512_512.jpg')\n",
    "#         full_image_f = s3_access_utils.download_from_s3(full_image_bucket, full_image_key)\n",
    "#         df_dict['full_image_bucket'].append(full_image_bucket)\n",
    "#         df_dict['full_image_key'].append(full_image_key)\n",
    "#         df_dict['full_image_f'].append(full_image_f)\n",
    "#         for k, v in dict(row).items():\n",
    "#             df_dict[k].append(v)\n",
    "        \n",
    "#         if count % 100 == 0:\n",
    "#             print(count)\n",
    "#         count += 1\n",
    "            \n",
    "#     print('Bad crop df complete!')\n",
    "    \n",
    "    count = 0\n",
    "    for idx, row in cleaner_fish_df.iterrows():\n",
    "        captured_at = row.captured_at\n",
    "        image_url = row.image_url\n",
    "        bucket, key = get_bucket_key(image_url)\n",
    "        key = key.replace('dev', 'environment=production')\n",
    "        key_directory = os.path.dirname(key)\n",
    "        full_image_bucket, full_image_key = 'aquabyte-frames-resized-inbound', os.path.join(key_directory, 'left_frame.resize_512_512.jpg')\n",
    "        full_image_f = s3_access_utils.download_from_s3(full_image_bucket, full_image_key)\n",
    "        df_dict['full_image_bucket'].append(full_image_bucket)\n",
    "        df_dict['full_image_key'].append(full_image_key)\n",
    "        df_dict['full_image_f'].append(full_image_f)\n",
    "        for k, v in dict(row).items():\n",
    "            df_dict[k].append(v)\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "            \n",
    "    print('Cleaner fish df complete!')\n",
    "            \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate all valid pens\n",
    "pen_ids = [56, 57, 58, 59, 60, 37, 65]\n",
    "start_date, end_date = '2019-11-05', '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "df_dict = defaultdict(list)\n",
    "data_root = '/root/data/alok/yolo_multiclassifier_data_cleaner_fish'\n",
    "for pen_id in pen_ids:\n",
    "    process_data_for_pen_id(pen_id, start_date, end_date, df_dict, data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/alok/yolo_multiclass_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('/root/data/alok/yolo_multiclass_data_cleaner_fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/alok/yolo_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/data/alok/cropper_experiment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fs = []\n",
    "for idx, row in df.iterrows():\n",
    "    image_url = row.image_url\n",
    "    image_url = row.image_url\n",
    "    bucket, key = get_bucket_key(image_url)\n",
    "    print(image_url)\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "    image_fs.append(image_f)\n",
    "    \n",
    "df['crop_image_f'] = image_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/alok/cropper_experiment_data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from lati_fish_detections_lice_annotations where pen_id={} limit 2000;'.format(pen_id)\n",
    "cogito_df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(get_bucket_key(cogito_df.image_url.iloc[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.065\n",
    "FISH_LENGTH_M = 0.294\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    df['stereo_depth_m'] = df.metadata.apply(lambda x: x.get('depth_m'))\n",
    "    return df\n",
    "\n",
    "df = process_data_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/alok/aggregate_vikane_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/data/alok/aggregate_vikane_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_focus_mask = (df.stereo_depth_m > 0.8) & (df.stereo_depth_m < 1.0)\n",
    "accept_mask = ~df.is_skipped\n",
    "skip_masks = {}\n",
    "skip_reasons = [\n",
    "    'is_accepted_in_qa', \n",
    "    'is_blurry', \n",
    "    'is_bad_crop', \n",
    "    'is_too_dark', \n",
    "    'is_bad_crop_many_fish', \n",
    "    'is_bad_orientation', \n",
    "    'is_bad_crop_cut_off', \n",
    "    'is_obstructed'\n",
    "]\n",
    "for skip_reason in skip_reasons:\n",
    "    skip_masks[skip_reason] = df[skip_reason] == True\n",
    "\n",
    "n = df.shape[0]\n",
    "n_in_focus = df[in_focus_mask].shape[0]\n",
    "n_in_focus_accepted = df[in_focus_mask & accept_mask].shape[0]\n",
    "n_not_in_focus_accepted = df[~in_focus_mask & accept_mask].shape[0]\n",
    "\n",
    "\n",
    "print('Total number of images inspected by Cogito over the weekend: {}'.format(n))\n",
    "print('Total number of these images within in-focus range (45 cm - 55 cm): {}'.format(n_in_focus))\n",
    "print('Total number of in-focus images accepted in QA: {}'.format(n_in_focus_accepted))\n",
    "print('Total number of not-in-focus images accepted by Cogito: {}'.format(n_not_in_focus_accepted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "valid_depth_mask = (df.stereo_depth_m > 0.0) & (df.stereo_depth_m < 2.0)\n",
    "plt.hist(df[valid_depth_mask].stereo_depth_m, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_skipped == True].sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, skip_reason):\n",
    "    depth_m = row[depth_field]\n",
    "    line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "    image_url = row.image_url\n",
    "    bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "\n",
    "    im = Image.open(image_f)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "\n",
    "    f_name = os.path.basename(key)\n",
    "    f = os.path.join(modified_images_dir, '{}_{}'.format(lo, hi), skip_reason, f_name)\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    im.save(f)\n",
    "\n",
    "\n",
    "modified_images_dir = '/root/data/alok/lice_counting/bremnes_tittelsnes_image_breakdown'\n",
    "object_length_m = 0.01\n",
    "N = 20\n",
    "\n",
    "cogito_accept_mask = ~df.is_skipped\n",
    "qa_accept_mask = ~reconciled_df.is_skipped\n",
    "depth_values = [round(x, 1) for x in np.arange(0.2, 1.5, 0.1)]\n",
    "\n",
    "depth_field = 'stereo_depth_m'\n",
    "for i in range(len(depth_values)-1):\n",
    "    print(i)\n",
    "    lo, hi = depth_values[i], depth_values[i+1]\n",
    "    depth_mask = (df[depth_field] >= lo) & (df[depth_field] <= hi)\n",
    "    \n",
    "    # accepted images\n",
    "    for idx, row in df[depth_mask & accept_mask].head(N).iterrows():\n",
    "        process_row(row, 'accepted')\n",
    "    \n",
    "    # rejected images due to blurriness\n",
    "    for idx, row in df[depth_mask & is_blurry_mask & (~is_bad_crop_mask) & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_blurry')\n",
    "        \n",
    "    # rejected images due to darkness\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & (~is_bad_crop_mask) & is_too_dark_mask & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_too_dark')\n",
    "        \n",
    "    # rejected images due to bad crop\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & is_bad_crop_mask & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_bad_crop')\n",
    "        \n",
    "    # rejected images due to bad orientation\n",
    "    for idx, row in df[depth_mask & (~is_blurry_mask) & (~is_bad_crop_mask) & (~is_too_dark_mask) & (is_bad_orientation_mask)].head(N).iterrows():\n",
    "        process_row(row, 'is_bad_orientation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, skip_reason):\n",
    "    depth_m = row[depth_field]\n",
    "    line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "    image_url = row.image_url\n",
    "    if 'aquabyte-crops-lati' not in image_url:\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    else:\n",
    "        components = urlparse(image_url, allow_fragments=False).path.lstrip('/').split('/')\n",
    "        bucket, key = components[0], os.path.join(*components[1:])\n",
    "    print(bucket, key)\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "\n",
    "    im = Image.open(image_f)\n",
    "#     draw = ImageDraw.Draw(im)\n",
    "#     draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "\n",
    "    f_name = os.path.basename(key)\n",
    "    f = os.path.join(modified_images_dir, skip_reason, f_name)\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    im.save(f)\n",
    "\n",
    "\n",
    "modified_images_dir = '/root/data/alok/lice_counting/bremnes_tittelsnes_breakdown_depth_independent'\n",
    "object_length_m = 0.01\n",
    "N = 50\n",
    "\n",
    "\n",
    "# rejected images due to skip reason\n",
    "for target_skip_reason in skip_reasons:\n",
    "    mask = skip_masks[target_skip_reason]\n",
    "    for skip_reason, skip_mask in skip_masks.items():\n",
    "        if skip_reason != target_skip_reason:\n",
    "            mask = mask & ~skip_mask\n",
    "        for idx, row in df[mask].head(N).iterrows():\n",
    "            process_row(row, skip_reason)\n",
    "\n",
    "# # rejected images due to darkness\n",
    "# for idx, row in df[(~is_blurry_mask) & (~is_bad_crop_mask) & is_too_dark_mask & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_too_dark')\n",
    "\n",
    "# # rejected images due to bad crop\n",
    "# for idx, row in df[(~is_blurry_mask) & is_bad_crop_mask & (~is_too_dark_mask) & (~is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_bad_crop')\n",
    "\n",
    "# # rejected images due to bad orientation\n",
    "# for idx, row in df[(~is_blurry_mask) & (~is_bad_crop_mask) & (~is_too_dark_mask) & (is_bad_orientation_mask)].head(N).iterrows():\n",
    "#     process_row(row, 'is_bad_orientation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('702_1953_3290_3000')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('366_1350_2442_2229')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_url.str.contains('0_1127_2674_2012')].stereo_depth_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate depth values </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'stereo_depth_m'\n",
    "valid_mask = (reconciled_df[depth_field] > 0.2) & (reconciled_df[depth_field] < 0.7)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[valid_mask & reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_field = 'single_image_depth_m'\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reconciled_df.loc[reconciled_accept_mask, depth_field], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://aquabyte-images-adhoc-public.s3.amazonaws.com/bremnes_tittelsnes_image_breakdown/0.9_1.0/is_blurry/left_frame_crop_1070_1016_3242_2018.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = s3_access_utils.get_matching_s3_keys('aquabyte-images-adhoc-public', prefix='bremnes_tittelsnes_image_breakdown', suffixes='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://aquabyte-images-adhoc-public.s3.amazonaws.com'\n",
    "bucket = 'aquabyte-images-adhoc-public'\n",
    "urls = []\n",
    "for key in gen:\n",
    "    url = os.path.join(prefix, key)\n",
    "    urls.append(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/alok/urls.csv', 'w') as f:\n",
    "    f.write(',\\n'.join(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
