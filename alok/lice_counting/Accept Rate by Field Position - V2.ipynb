{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id = 56 and captured_at between '2019-12-01' and '2020-01-12';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_submitted = df.is_skipped == False\n",
    "reasonable_duration_mask = df.work_duration_ms < 600*1e3\n",
    "\n",
    "print(df[is_submitted].work_duration_ms.median() * 1e-3)\n",
    "print(df[~is_submitted].work_duration_ms.median() * 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[~is_submitted & reasonable_duration_mask].work_duration_ms, bins=20, color='blue')\n",
    "plt.hist(df[is_submitted & reasonable_duration_mask].work_duration_ms, bins=20, color='red')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~is_submitted & reasonable_duration_mask].work_duration_ms.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_center_coordinate(metadata, x_direction=True):\n",
    "    if x_direction:\n",
    "        x = metadata['x_coord'] + 0.5 * metadata['width']\n",
    "        return x\n",
    "    y = metadata['y_coord'] + 0.5 * metadata['height']\n",
    "    return y\n",
    "\n",
    "def retrieve_depth(metadata):\n",
    "    if 'depth_m_weekly_linear_model' in metadata.keys():\n",
    "        return metadata['depth_m_weekly_linear_model']['value']\n",
    "    return None\n",
    "\n",
    "\n",
    "df['centroid_x'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=True))\n",
    "df['centroid_y'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=False))\n",
    "df['depth'] = df.metadata.apply(lambda x: retrieve_depth(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WIDTH, MAX_HEIGHT = 4096, 3000+1\n",
    "SQUARE_SIZE = 500\n",
    "x_values = list(np.arange(0, MAX_WIDTH, SQUARE_SIZE))\n",
    "y_values = list(np.arange(0, MAX_HEIGHT, SQUARE_SIZE))\n",
    "results = np.zeros([len(x_values)-1, len(y_values)-1])\n",
    "counts = np.zeros([len(x_values)-1, len(y_values)-1])\n",
    "good_crop_mask = (df.is_bad_crop != True)# | (df.is_bad_crop != False)\n",
    "accept_mask = (df.is_skipped == False)\n",
    "for x_idx in range(len(x_values)-1):\n",
    "    for y_idx in range(len(y_values)-1):\n",
    "        x_low, x_high = x_values[x_idx], x_values[x_idx+1]\n",
    "        y_low, y_high = y_values[y_idx], y_values[y_idx+1]\n",
    "        mask_x = (df.centroid_x > x_low) & (df.centroid_x < x_high)\n",
    "        mask_y = (df.centroid_y > y_low) & (df.centroid_y < y_high)\n",
    "        tile_mask = mask_x & mask_y\n",
    "        if df[good_crop_mask & tile_mask].shape[0] > 0:\n",
    "            accept_rate = df[good_crop_mask & tile_mask & accept_mask].shape[0] / df[good_crop_mask & tile_mask].shape[0]\n",
    "        else:\n",
    "            accept_rate = 0\n",
    "        if accept_rate > 0.49:\n",
    "            accept_rate = 0\n",
    "        results[x_idx, y_idx] = accept_rate\n",
    "        counts[x_idx, y_idx] = df[good_crop_mask & tile_mask].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(results.T, annot=True)\n",
    "plt.title('Accept rate by Field Position, Pen ID = 65, October 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(counts.T, annot=True)\n",
    "plt.title('Crop Count by Field Position, Pen ID = 65, October 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "sns.heatmap(results.T, annot=True, ax=axes[0])\n",
    "sns.heatmap(counts.T, annot=True, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate large dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 37\n",
    "date_ranges = [\n",
    "    ('2019-10-01', '2019-11-01'),\n",
    "    ('2019-11-01', '2019-12-01'),\n",
    "    ('2019-12-01', '2020-01-01')\n",
    "]\n",
    "\n",
    "figs, axes = plt.subplots(2, len(date_ranges), figsize=(30, 10))\n",
    "\n",
    "count = 0\n",
    "for date_idx, date_range in enumerate(date_ranges):\n",
    "    start_date, end_date = date_range\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    MAX_WIDTH, MAX_HEIGHT = 4096, 3000+1\n",
    "    SQUARE_SIZE = 500\n",
    "    x_values = list(np.arange(0, MAX_WIDTH, SQUARE_SIZE))\n",
    "    y_values = list(np.arange(0, MAX_HEIGHT, SQUARE_SIZE))\n",
    "    results = np.zeros([len(x_values)-1, len(y_values)-1])\n",
    "    counts = np.zeros([len(x_values)-1, len(y_values)-1])\n",
    "    accept_mask = (df.is_skipped == False)\n",
    "    for x_idx in range(len(x_values)-1):\n",
    "        for y_idx in range(len(y_values)-1):\n",
    "            x_low, x_high = x_values[x_idx], x_values[x_idx+1]\n",
    "            y_low, y_high = y_values[y_idx], y_values[y_idx+1]\n",
    "            mask_x = (df.centroid_x > x_low) & (df.centroid_x < x_high)\n",
    "            mask_y = (df.centroid_y > y_low) & (df.centroid_y < y_high)\n",
    "            tile_mask = mask_x & mask_y\n",
    "            if df[date_mask & tile_mask].shape[0] > 0:\n",
    "                accept_rate = df[date_mask & tile_mask & accept_mask].shape[0] / df[date_mask & tile_mask].shape[0]\n",
    "            else:\n",
    "                accept_rate = 0\n",
    "            if accept_rate > 0.49:\n",
    "                accept_rate = 0\n",
    "            results[x_idx, y_idx] = accept_rate\n",
    "            counts[x_idx, y_idx] = df[date_mask & tile_mask].shape[0]\n",
    "\n",
    "    sns.heatmap(results.T, annot=True, ax=axes[0, date_idx])\n",
    "    sns.heatmap(counts.T, annot=True, ax=axes[1, date_idx])\n",
    "    axes[0, date_idx].set_title('Accept rate, Pen ID = {}, {} - {}'.format(pen_id, start_date, end_date))\n",
    "    axes[1, date_idx].set_title('Counts, Pen ID = {}, {} - {}'.format(pen_id, start_date, end_date))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(tdf.shape[0])), np.cumsum(tdf.is_submitted.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate out of sample results </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id = 57 and captured_at between '2020-01-10' and '2020-01-11';\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "df = df[~df.image_url.str.contains('research')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline simulation\n",
    "\n",
    "df['score'] = df.metadata.apply(lambda row: row['quality_score'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=2)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "queue, submits = [], []\n",
    "last_ts = None\n",
    "i = 0\n",
    "start_date, end_date = '2020-01-10', '2020-01-11'\n",
    "date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "tdf = df[date_mask].copy(deep=True)\n",
    "print(tdf.captured_at.iloc[-1])\n",
    "for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "    if not last_ts: \n",
    "        additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "        \n",
    "    else:\n",
    "        additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "    \n",
    "    last_ts = row.simulated_completed_at\n",
    "    additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                    tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "\n",
    "    queue.extend(additional_scores_and_submits)\n",
    "    queue.sort(key=lambda x: x[0], reverse=True)\n",
    "    _, submit = queue.pop(0)\n",
    "    submits.append(submit)\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)\n",
    "#     i += 1\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "# ax1.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "ax1.plot(list(range(tdf.shape[0])), np.cumsum(tdf.is_submitted.values), color='blue', label='Depth-Based Prioritization')\n",
    "ax1.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='2D Field Position-Based Prioritization')\n",
    "ax1.set_xlabel('Num. images analyzed by Cogito')\n",
    "ax1.set_ylabel('Num. images submitted to QA', color='blue')\n",
    "ax1.axhline(50, linestyle='dashed', label='KPI', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend()\n",
    "\n",
    "plt.title('Pen ID 65 (Hisdalen), Date={}'.format(start_date))\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(list(range(df.shape[0])), np.cumsum(df.sort_values('score', ascending=False).is_submitted))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('score', ascending=False).iloc[:5].captured_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('score', ascending=False).iloc[:5].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('completed_at').iloc[:5].captured_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research simulation\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id = 65 and captured_at between '2020-01-10' and '2020-01-11';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "df = df[~df.image_url.str.contains('research')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df.metadata.apply(lambda row: row['quality_score'])\n",
    "df['simulated_completed_at'] = df.completed_at# + dt.timedelta(hours=0)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "queue, submits = [], []\n",
    "last_ts = None\n",
    "i = 0\n",
    "start_date, end_date = '2020-01-10', '2020-01-11'\n",
    "date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "tdf = df[date_mask].copy(deep=True)\n",
    "for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "    if not last_ts:\n",
    "        additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "    else:\n",
    "        additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "    \n",
    "        \n",
    "\n",
    "    last_ts = row.simulated_completed_at\n",
    "    additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                    tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "\n",
    "    queue.extend(additional_scores_and_submits)\n",
    "    queue.sort(key=lambda x: x[0], reverse=True)\n",
    "    _, submit = queue.pop(0)\n",
    "    submits.append(submit)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "ax1.plot(range(tdf.shape[0]), np.cumsum((tdf.sort_values('simulated_completed_at').is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "ax1.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='2D Field Position-Based Prioritization')\n",
    "ax1.set_xlabel('Num. images analyzed by Cogito')\n",
    "ax1.set_ylabel('Num. images submitted to QA', color='blue')\n",
    "ax1.axhline(50, linestyle='dashed', label='KPI', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend()\n",
    "\n",
    "plt.title('Pen ID 65 (Hisdalen), Date={}'.format(start_date))\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(df.shape[0])), df.sort_values('score', ascending=False).is_submitted.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://aquabyte-crops.s3.eu-west-1.amazonaws.com/environment=production/site-id=43/pen-id=65/date=2020-01-10/hour=00/at=2020-01-10T00:15:49.348188000Z/left_frame_crop_362_914_4096_2255.jpg'\n",
    "df[df.image_url == url]\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select d.group_id, d.url_key, ROW_NUMBER() OVER (PARTITION BY d.group_id ORDER BY d.group_id, d.captured_at asc) as r, SUM(QA) OVER (PARTITION BY d.group_id ORDER BY d.group_id, d.captured_at asc) as c from (select a.url_key, a.captured_at, a.group_id, CASE when b.url_key is null THEN 0 ELSE 1 end as QA from prod.crop_annotation a left join prod.crop_annotation b on a.pen_id=b.pen_id and a.service_id=b.service_id and a.url_key=b.url_key and a.captured_at=b.captured_at and b.annotation_state_id=3 where a.annotation_state_id=2 and a.service_id=1 and a.pen_id=73 and a.captured_at between '2020-01-10' and '2020-01-11') d;\n",
    "\"\"\"\n",
    "sql_df = rds_access_utils.extract_from_database(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(list(range(sql_df.shape[0])), sql_df.c)\n",
    "plt.plot(list(range(tdf.shape[0])), np.cumsum(tdf.is_submitted.values), color='blue', label='Depth-Based Prioritization')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id = 56 and captured_at between '2019-12-18' and '2019-12-31';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.captured_at.astype(str).apply(lambda x: x[:10])\n",
    "df['score'] = df.metadata.apply(lambda x: x['quality_score'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=24)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "\n",
    "\n",
    "queue, submits = [], []\n",
    "intermediate_backlog_count = 0\n",
    "intermediate_backlog_counts = []\n",
    "last_ts = None\n",
    "i = 0\n",
    "start_date, end_date = '2019-11-20', '2019-11-21'\n",
    "date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "tdf = df[date_mask].copy(deep=True)\n",
    "for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "    if not last_ts:\n",
    "        additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "    else:\n",
    "        additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "    \n",
    "        \n",
    "\n",
    "    last_ts = row.simulated_completed_at\n",
    "    additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                    tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "    intermediate_backlog_count += len(additional_scores_and_submits) - 1\n",
    "    intermediate_backlog_counts.append(intermediate_backlog_count)\n",
    "\n",
    "    queue.extend(additional_scores_and_submits)\n",
    "    queue.sort(key=lambda x: x[0], reverse=True)\n",
    "    _, submit = queue.pop(0)\n",
    "    submits.append(submit)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "ax1.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "ax1.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='1h delay Depth-Based Prioritization')\n",
    "ax1.set_xlabel('Num. images analyzed by Cogito')\n",
    "ax1.set_ylabel('Num. images submitted to QA')\n",
    "ax1.axhline(50, linestyle='dashed', label='KPI', color='green')\n",
    "ax1.legend()\n",
    "\n",
    "plt.title('Pen ID 65 (Hisdalen), Date={}'.format(start_date))\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.captured_at.astype(str).apply(lambda x: x[:10])\n",
    "df['score'] = df.metadata.apply(lambda x: x['crop_area'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=24)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "\n",
    "\n",
    "queue, submits = [], []\n",
    "intermediate_backlog_count = 0\n",
    "intermediate_backlog_counts = []\n",
    "last_ts = None\n",
    "i = 0\n",
    "start_date, end_date = '2019-12-20', '2019-12-21'\n",
    "date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "tdf = df[date_mask].copy(deep=True)\n",
    "for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "    if not last_ts:\n",
    "        additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "    else:\n",
    "        additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "    \n",
    "        \n",
    "\n",
    "    last_ts = row.simulated_completed_at\n",
    "    additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                    tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "    intermediate_backlog_count += len(additional_scores_and_submits) - 1\n",
    "    intermediate_backlog_counts.append(intermediate_backlog_count)\n",
    "\n",
    "    queue.extend(additional_scores_and_submits)\n",
    "    queue.sort(key=lambda x: x[0], reverse=True)\n",
    "    _, submit = queue.pop(0)\n",
    "    submits.append(submit)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "ax1.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "ax1.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='1h delay Depth-Based Prioritization')\n",
    "ax1.set_xlabel('Num. images analyzed by Cogito')\n",
    "ax1.set_ylabel('Num. images submitted to QA')\n",
    "ax1.axhline(50, linestyle='dashed', label='KPI', color='green')\n",
    "ax1.legend()\n",
    "\n",
    "plt.title('Pen ID 65 (Hisdalen), Date={}'.format(start_date))\n",
    "ax1.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.captured_at.astype(str).apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = 5\n",
    "dates = list(df.date.unique())\n",
    "figs, axes = plt.subplots((len(dates) // column_count)+1, column_count, figsize=(30, 20))\n",
    "\n",
    "df['score'] = df.metadata.apply(lambda x: x['quality_score'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=2)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "\n",
    "\n",
    "count = 0\n",
    "for date_idx in range(len(dates) - 1):\n",
    "    start_date, end_date = dates[date_idx], dates[date_idx+1]\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    tdf = df[date_mask].copy(deep=True)\n",
    "    queue, submits = [], []\n",
    "    intermediate_backlog_count = 0\n",
    "    intermediate_backlog_counts = []\n",
    "    last_ts = None\n",
    "\n",
    "    for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "        if not last_ts:\n",
    "            additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "        else:\n",
    "            additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "\n",
    "\n",
    "\n",
    "        last_ts = row.simulated_completed_at\n",
    "        additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                        tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "        intermediate_backlog_count += len(additional_scores_and_submits) - 1\n",
    "        intermediate_backlog_counts.append(intermediate_backlog_count)\n",
    "\n",
    "        queue.extend(additional_scores_and_submits)\n",
    "        queue.sort(key=lambda x: x[0], reverse=True)\n",
    "        _, submit = queue.pop(0)\n",
    "        submits.append(submit)\n",
    "    \n",
    "    row, col = date_idx // column_count, date_idx % column_count\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "    ax.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='1h delay Depth-Based Prioritization')\n",
    "    ax.set_xlabel('Num. images analyzed by Cogito')\n",
    "    ax.set_ylabel('Num. images submitted to QA')\n",
    "    ax.axhline(50, linestyle='dashed', label='KPI', color='green')\n",
    "    ax.set_title(start_date)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    print('Completed date: {}'.format(start_date))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = 5\n",
    "dates = list(df.date.unique())\n",
    "figs, axes = plt.subplots((len(dates) // column_count)+1, column_count, figsize=(30, 20))\n",
    "\n",
    "df['score'] = df.metadata.apply(lambda x: x['crop_area'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=2)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "\n",
    "\n",
    "count = 0\n",
    "for date_idx in range(len(dates) - 1):\n",
    "    start_date, end_date = dates[date_idx], dates[date_idx+1]\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    tdf = df[date_mask].copy(deep=True)\n",
    "    queue, submits = [], []\n",
    "    intermediate_backlog_count = 0\n",
    "    intermediate_backlog_counts = []\n",
    "    last_ts = None\n",
    "\n",
    "    for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "        if not last_ts:\n",
    "            additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "        else:\n",
    "            additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "\n",
    "\n",
    "\n",
    "        last_ts = row.simulated_completed_at\n",
    "        additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                        tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "        intermediate_backlog_count += len(additional_scores_and_submits) - 1\n",
    "        intermediate_backlog_counts.append(intermediate_backlog_count)\n",
    "\n",
    "        queue.extend(additional_scores_and_submits)\n",
    "        queue.sort(key=lambda x: x[0], reverse=True)\n",
    "        _, submit = queue.pop(0)\n",
    "        submits.append(submit)\n",
    "    \n",
    "    row, col = date_idx // column_count, date_idx % column_count\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "    ax.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='1h delay Depth-Based Prioritization')\n",
    "    ax.set_xlabel('Num. images analyzed by Cogito')\n",
    "    ax.set_ylabel('Num. images submitted to QA')\n",
    "    ax.axhline(50, linestyle='dashed', label='KPI', color='green')\n",
    "    ax.set_title(start_date)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    print('Completed date: {}'.format(start_date))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.image_url.str.contains('research')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = 5\n",
    "dates = list(df.date.unique())\n",
    "# figs, axes = plt.subplots((len(dates) // column_count)+1, column_count, figsize=(30, 40))\n",
    "figs, axes = plt.subplots((len(dates) // column_count)+1, column_count, figsize=(30, 20))\n",
    "\n",
    "df['score'] = df.metadata.apply(lambda x: x['quality_score'])\n",
    "df['simulated_completed_at'] = df.completed_at + dt.timedelta(hours=4)\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "\n",
    "\n",
    "count = 0\n",
    "for date_idx in range(len(dates) - 1):\n",
    "    start_date, end_date = dates[date_idx], dates[date_idx+1]\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    date_mask = (df.captured_at > start_date) & (df.captured_at < end_date)\n",
    "    tdf = df[date_mask].copy(deep=True)\n",
    "    queue, submits = [], []\n",
    "    intermediate_backlog_count = 0\n",
    "    intermediate_backlog_counts = []\n",
    "    last_ts = None\n",
    "\n",
    "    for idx, row in tdf.sort_values('simulated_completed_at').iterrows():\n",
    "        if not last_ts:\n",
    "            additional_captures_mask = (tdf.captured_at <= row.simulated_completed_at)\n",
    "        else:\n",
    "            additional_captures_mask = (tdf.captured_at > last_ts) & (tdf.captured_at <= row.simulated_completed_at)\n",
    "\n",
    "\n",
    "\n",
    "        last_ts = row.simulated_completed_at\n",
    "        additional_scores_and_submits = list(zip(tdf[additional_captures_mask].score.tolist(), \n",
    "                                        tdf[additional_captures_mask].is_submitted.tolist()))\n",
    "        intermediate_backlog_count += len(additional_scores_and_submits) - 1\n",
    "        intermediate_backlog_counts.append(intermediate_backlog_count)\n",
    "\n",
    "        queue.extend(additional_scores_and_submits)\n",
    "        queue.sort(key=lambda x: x[0], reverse=True)\n",
    "        _, submit = queue.pop(0)\n",
    "        submits.append(submit)\n",
    "    \n",
    "    row, col = date_idx // column_count, date_idx % column_count\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(range(tdf.shape[0]), np.cumsum((tdf.is_skipped == False).astype(int)), color='blue', label='Depth-Based Prioritization')\n",
    "    ax.plot(range(len(submits)), np.cumsum(np.array(submits)), color='red', label='1h delay Depth-Based Prioritization')\n",
    "    ax.set_xlabel('Num. images analyzed by Cogito')\n",
    "    ax.set_ylabel('Num. images submitted to QA')\n",
    "    ax.axhline(50, linestyle='dashed', label='KPI', color='green')\n",
    "    ax.set_title(start_date)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    print('Completed date: {}'.format(start_date))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(df.apply(lambda row: get_score(row.centroid_x, row.centroid_y), axis=1), \n",
    "            df.metadata.apply(lambda x: x['quality_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(intermediate_backlog_counts, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mask = (df.captured_at > '2019-12-20') & (df.captured_at < '2019-12-21')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx, y_idx = 3, 1\n",
    "mask_x = (df.centroid_x > x_values[x_idx]) & (df.centroid_x < x_values[x_idx+1])\n",
    "mask_y = (df.centroid_y > y_values[y_idx]) & (df.centroid_y < y_values[y_idx+1])\n",
    "tile_mask = mask_x & mask_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[tile_mask & (~accept_mask) & (df.is_bad_crop != True)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[[c for c in tdf.columns if 'is_' in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
