{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "from multiprocessing import Pool\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download all available data for Vikane and Tittelsnes </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "# get Cogito data\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where pen_id=40;\n",
    "\"\"\"\n",
    "cogito_df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "cogito_df = cogito_df[cogito_df.is_skipped == True]\n",
    "cogito_df['is_accepted_in_qa'] = False\n",
    "\n",
    "# get reconciled data\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations_reconciled where pen_id = 40;\n",
    "\"\"\"\n",
    "reconciled_df = rds_access_utils.extract_from_database(query)\n",
    "reconciled_df['is_accepted_in_qa'] = False\n",
    "reconciled_df.loc[reconciled_df.adult_female_count >= 0, 'is_accepted_in_qa'] = True\n",
    "\n",
    "\n",
    "# combine into single dataframe\n",
    "df = pd.concat([cogito_df, reconciled_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Metric Generator (Bryton) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_key(image_url):\n",
    "    if 'aquabyte-crops-lati' not in image_url:\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    else:\n",
    "        components = urlparse(image_url, allow_fragments=False).path.lstrip('/').split('/')\n",
    "        bucket, key = components[0], os.path.join(*components[1:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_green_luminance(filename):\n",
    "    img = np.array(Image.open(filename))\n",
    "    \n",
    "    black_threshold = 15\n",
    "    glare_threshold = 100\n",
    "\n",
    "    test2 = img[:,:,1][(img[:,:,1] > black_threshold) & (img[:,:,1] < glare_threshold)]\n",
    "    return np.mean(test2)\n",
    "\n",
    "def download_from_url(image_url):\n",
    "    bucket, key = get_bucket_key(image_url)\n",
    "    s3_access_utils.download_from_s3(bucket, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Blom  Vikane Depth / Luminance Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mask = df.captured_at >= '2019-09-15'\n",
    "pen_id_mask = df.pen_id == 40\n",
    "df = df[ts_mask & pen_id_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.133\n",
    "FISH_LENGTH_M = 0.685\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['stereo_depth_m'] = df.metadata.apply(lambda x: x.get('depth_m'))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    return df\n",
    "\n",
    "df = process_data_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.single_image_depth_m, bins=20, color='blue', alpha=0.5)\n",
    "plt.hist(df[df.is_accepted_in_qa].single_image_depth_m, bins=20, color='red', alpha=0.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof_mask = (df.single_image_depth_m > 0.55) & (df.single_image_depth_m < 1.1)\n",
    "bad_crop_mask = (df.is_bad_crop | df.is_bad_crop_cut_off | df.is_bad_crop_many_fish | df.is_bad_orientation | df.is_cleaner_fish | df.is_obstructed )\n",
    "reject_mask = df.is_accepted_in_qa == False\n",
    "\n",
    "original_skip_rate = df[reject_mask].shape[0] / df.shape[0]\n",
    "print('Original skip rate: {}'.format(original_skip_rate))\n",
    "\n",
    "skip_rate_after_hard_depth_cutoff = df[dof_mask & reject_mask].shape[0] / df[dof_mask].shape[0]\n",
    "print('Skip rate after hard depth cutoff: {}'.format(skip_rate_after_hard_depth_cutoff))\n",
    "\n",
    "\n",
    "pct_rejects_in_dof_bad_crop = (df[dof_mask & bad_crop_mask].shape[0] / df[dof_mask & reject_mask].shape[0])\n",
    "print('Percentage of rejects within depth of field that are bad crops: {}'.format(pct_rejects_in_dof_bad_crop))\n",
    "\n",
    "skip_rate_assuming_perfect_cropper = (df[dof_mask & reject_mask & ~bad_crop_mask].shape[0] / df[dof_mask & ~bad_crop_mask].shape[0])\n",
    "print('Skip rate assuming hard depth cutoff & perfect cropper: {}'.format(skip_rate_assuming_perfect_cropper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "92% too blurry, 35% bad crop, 32% too dark, 7% obstructed, 20% bad orientation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[(~rdf.is_accepted_in_qa) & (rdf.is_bad_crop_cut_off | rdf.is_bad_crop | rdf.is_bad_crop_many_fish | rdf.is_bad_orientation | rdf.is_obstructed) & (rdf.single_image_depth_m < 1.1)].shape[0] / rdf[(~rdf.is_accepted_in_qa) & (rdf.single_image_depth_m < 1.1)].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25/(25+37.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
