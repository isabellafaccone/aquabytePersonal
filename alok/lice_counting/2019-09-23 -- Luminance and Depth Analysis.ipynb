{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "from multiprocessing import Pool\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download all available data for Vikane and Tittelsnes </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "# get Cogito data\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations where \n",
    "    (pen_id=37 or pen_id=56 or pen_id=57 or pen_id=58 or pen_id=59 or pen_id=60);\n",
    "\"\"\"\n",
    "cogito_df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "cogito_df = cogito_df[cogito_df.is_skipped == True]\n",
    "cogito_df['is_accepted_in_qa'] = False\n",
    "\n",
    "# get reconciled data\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations_reconciled where \n",
    "    (pen_id=37 or pen_id=56 or pen_id=57 or pen_id=58 or pen_id=59 or pen_id=60);\n",
    "\"\"\"\n",
    "reconciled_df = rds_access_utils.extract_from_database(query)\n",
    "reconciled_df['is_accepted_in_qa'] = False\n",
    "reconciled_df.loc[reconciled_df.adult_female_count >= 0, 'is_accepted_in_qa'] = True\n",
    "\n",
    "\n",
    "# combine into single dataframe\n",
    "df = pd.concat([cogito_df, reconciled_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Metric Generator (Bryton) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_key(image_url):\n",
    "    if 'aquabyte-crops-lati' not in image_url:\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    else:\n",
    "        components = urlparse(image_url, allow_fragments=False).path.lstrip('/').split('/')\n",
    "        bucket, key = components[0], os.path.join(*components[1:])\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_green_luminance(filename):\n",
    "    img = np.array(Image.open(filename))\n",
    "    \n",
    "    black_threshold = 15\n",
    "    glare_threshold = 100\n",
    "\n",
    "    test2 = img[:,:,1][(img[:,:,1] > black_threshold) & (img[:,:,1] < glare_threshold)]\n",
    "    return np.mean(test2)\n",
    "\n",
    "def download_from_url(image_url):\n",
    "    bucket, key = get_bucket_key(image_url)\n",
    "    s3_access_utils.download_from_s3(bucket, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Blom  Vikane Depth / Luminance Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mask = df.captured_at >= '2019-09-15'\n",
    "pen_id_mask = df.pen_id == 37\n",
    "accept_mask = df.is_accepted_in_qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(20)\n",
    "pool.map(download_from_url, df[ts_mask & pen_id_mask & accept_mask].image_url.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[ts_mask & pen_id_mask & ~accept_mask].sample(2000)\n",
    "pool.map(download_from_url, tdf.image_url.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.concat([df[ts_mask & pen_id_mask & accept_mask], tdf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_luminances = []\n",
    "count = 0\n",
    "\n",
    "ts_mask = df.captured_at >= '2019-09-20'\n",
    "pen_id_mask = df.pen_id == 56\n",
    "\n",
    "for idx, row in rdf.iterrows():\n",
    "    try:\n",
    "        image_url = row.image_url\n",
    "        bucket, key = get_bucket_key(image_url)\n",
    "        f_name = s3_access_utils.download_from_s3(bucket, key)\n",
    "        green_luminance = get_green_luminance(f_name)\n",
    "        green_luminances.append(green_luminance)\n",
    "    except:\n",
    "        green_luminances.append(None)\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cache = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ts_mask & pen_id_mask, 'green_luminance'] = green_luminances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_cache = rdf.copy()\n",
    "rdf['green_luminance'] = green_luminances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.065\n",
    "FISH_LENGTH_M = 0.294\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    return df\n",
    "\n",
    "df = process_data_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(df[ts_mask & pen_id_mask & ~accept_mask].single_image_depth_m, \n",
    "            df[ts_mask & pen_id_mask & ~accept_mask].green_luminance, color='blue', label='Rejected', s=50)\n",
    "\n",
    "plt.scatter(df[ts_mask & pen_id_mask & accept_mask].single_image_depth_m, \n",
    "            df[ts_mask & pen_id_mask & accept_mask].green_luminance, color='red', label='Accepted', s=80)\n",
    "\n",
    "plt.title('Accepts / Rejects in depth & luminance space')\n",
    "plt.xlabel('Depth (m) (based on single image)')\n",
    "plt.ylabel('Green luminance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_WIDTH_M = 0.108\n",
    "FISH_LENGTH_M = 0.534\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def depth_fn(x):\n",
    "    w, h = x['width'], x['height']\n",
    "    theta = np.arctan(h / w) * (180.0 / np.pi)\n",
    "    phi = np.arctan(FISH_WIDTH_M / FISH_LENGTH_M) * (180.0 / np.pi)\n",
    "    if theta < phi:\n",
    "        return w\n",
    "    elif theta > 90.0 - phi:\n",
    "        return h\n",
    "    else:\n",
    "        return (h**2 + w**2)**0.5\n",
    "\n",
    "def process_data_df(df):\n",
    "    df = df[df.is_cleaner_fish != True]\n",
    "    df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "    df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "    df['length_px'] = df.metadata.apply(lambda x: depth_fn(x))\n",
    "    df['single_image_depth_m'] = FOCAL_LENGTH * FISH_LENGTH_M / df.length_px\n",
    "    return df\n",
    "\n",
    "rdf = process_data_df(rdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(rdf[rdf.is_accepted_in_qa == False].single_image_depth_m, \n",
    "            rdf[rdf.is_accepted_in_qa == False].green_luminance, color='blue', label='Rejected', s=50)\n",
    "\n",
    "plt.scatter(rdf[rdf.is_accepted_in_qa == True].single_image_depth_m, \n",
    "            rdf[rdf.is_accepted_in_qa == True].green_luminance, color='red', label='Accepted', s=80)\n",
    "\n",
    "plt.title('Accepts / Rejects in depth & luminance space')\n",
    "plt.xlabel('Depth (m) (based on single image)')\n",
    "plt.ylabel('Green luminance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(rdf.single_image_depth_m, bins=20, color='blue', alpha=0.5)\n",
    "plt.hist(rdf[rdf.is_accepted_in_qa].single_image_depth_m, bins=20, color='red', alpha=0.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[rdf.is_accepted_in_qa & (rdf.single_image_depth_m < 1.1)].shape[0] / rdf[rdf.single_image_depth_m < 1.1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[(~rdf.is_accepted_in_qa) & (rdf.is_bad_crop_cut_off) & (rdf.single_image_depth_m < 1.1)].shape[0] / rdf[(~rdf.is_accepted_in_qa) & (rdf.single_image_depth_m < 1.1)].shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "92% too blurry, 35% bad crop, 32% too dark, 7% obstructed, 20% bad orientation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[(~rdf.is_accepted_in_qa) & (rdf.is_bad_crop_cut_off | rdf.is_bad_crop | rdf.is_bad_crop_many_fish | rdf.is_bad_orientation | rdf.is_obstructed) & (rdf.single_image_depth_m < 1.1)].shape[0] / rdf[(~rdf.is_accepted_in_qa) & (rdf.single_image_depth_m < 1.1)].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25/(25+37.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
