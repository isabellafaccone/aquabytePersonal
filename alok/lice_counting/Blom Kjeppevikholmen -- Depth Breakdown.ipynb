{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load LATI data for Blom Kjeppevikholmen Pen ID 5 joined with keypoint annotations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from lati_fish_detections_lice_annotations a left join \n",
    "    (select keypoints, left_image_url, right_image_url, captured_at, camera_metadata, is_qa from keypoint_annotations) b\n",
    "    on a.captured_at = b.captured_at\n",
    "    where b.keypoints is not null\n",
    "    and b.is_qa = true\n",
    "    and a.pen_id = 5;\n",
    "\"\"\"\n",
    "cogito_df = rds_access_utils.extract_from_database(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cogito_df.copy(deep=True)\n",
    "cols = df.columns.tolist()\n",
    "matches = []\n",
    "for idx, row in df.iterrows():\n",
    "    if row.left_image_url.replace('aquabyte-crops', 'aquabyte-crops-lati') == row.image_url:\n",
    "        matches.append(True)\n",
    "    else:\n",
    "        matches.append(False)\n",
    "df['is_match'] = matches\n",
    "df = df[(df.is_match == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Stereo Depth Values </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "cogito_df['world_keypoints'] = cogito_df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "def get_centroid_depth(world_keypoints):\n",
    "    if world_keypoints:\n",
    "        depths = []\n",
    "        for bp, wkp in world_keypoints.items():\n",
    "            depths.append(wkp[1])\n",
    "\n",
    "        return np.median(np.array(depths))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_length(world_keypoints):\n",
    "    if world_keypoints:\n",
    "        return euclidean_distance(world_keypoints['UPPER_LIP'], world_keypoints['ANAL_FIN'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_x_length(world_keypoints):\n",
    "    if world_keypoints:\n",
    "        x = np.array([world_keypoints['UPPER_LIP'][0], 0, world_keypoints['UPPER_LIP'][2]])\n",
    "        y = np.array([world_keypoints['ANAL_FIN'][0], 0, world_keypoints['ANAL_FIN'][2]])\n",
    "        return euclidean_distance(x, y)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "df['world_keypoints'] = df.apply(lambda x: get_world_keypoints(x), axis=1)\n",
    "df['centroid_depth'] = df.world_keypoints.apply(lambda x: get_centroid_depth(x))\n",
    "df['length'] = df.world_keypoints.apply(lambda x: get_length(x))\n",
    "df['x_length'] = df.world_keypoints.apply(lambda x: get_x_length(x))\n",
    "df['image_width'] = df.metadata.apply(lambda x: x['width'])\n",
    "df['image_height'] = df.metadata.apply(lambda x: x['height'])\n",
    "df['is_accepted'] = df.is_skipped == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Plot Accepts vs. Rejects by Depth </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.centroid_depth, color='blue', alpha=0.5, bins=20)\n",
    "plt.hist(df[df.is_accepted].centroid_depth, color='red', alpha=0.5, bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_mask = (df.centroid_depth > 0.75) & (df.centroid_depth < 0.95)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[~df.is_accepted & (df.is_bad_crop == False) & depth_mask].x_length, color='blue')\n",
    "plt.hist(df[df.is_accepted & depth_mask].x_length, color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_accepted & depth_mask].x_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.is_accepted & depth_mask & (df.x_length > 0.45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download Kjeppevikholmen Images Locally </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_reasons = ['is_accepted', 'is_too_dark', 'is_blurry']\n",
    "skip_masks = {}\n",
    "for skip_reason in skip_reasons:\n",
    "    skip_masks[skip_reason] = df[skip_reason] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "FOCAL_LENGTH = 4015\n",
    "\n",
    "def process_row(row, skip_reason, lo, hi):\n",
    "    depth_m = row['centroid_depth']\n",
    "    line_segment_length_px = object_length_m * FOCAL_LENGTH / depth_m\n",
    "    image_url = row.image_url\n",
    "    if 'aquabyte-crops-lati' not in image_url:\n",
    "        bucket, key = 'aquabyte-crops', urlparse(image_url, allow_fragments=False).path.lstrip('/')\n",
    "    else:\n",
    "        components = urlparse(image_url, allow_fragments=False).path.lstrip('/').split('/')\n",
    "        bucket, key = components[0], os.path.join(*components[1:])\n",
    "    print(bucket, key)\n",
    "    image_f = s3_access_utils.download_from_s3(bucket, key)\n",
    "\n",
    "    im = Image.open(image_f)\n",
    "#     draw = ImageDraw.Draw(im)\n",
    "#     draw.line((100, 100, 100+line_segment_length_px, 100))\n",
    "\n",
    "    f_name = os.path.basename(key)\n",
    "    f = os.path.join(modified_images_dir, '{}_{}'.format(lo, hi), skip_reason, f_name)\n",
    "    if not os.path.exists(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    im.save(f)\n",
    "\n",
    "\n",
    "modified_images_dir = '/root/data/alok/lice_counting/blom_kjeppevikholmen_breakdown_v3'\n",
    "object_length_m = 0.01\n",
    "N = 20\n",
    "\n",
    "depth_values = [round(x, 1) for x in np.arange(0.5, 1.4, 0.1)]\n",
    "\n",
    "# rejected images due to skip reason\n",
    "for i in range(len(depth_values)-1):\n",
    "    print(i)\n",
    "    lo, hi = depth_values[i], depth_values[i+1]\n",
    "    depth_mask = (df['centroid_depth'] >= lo) & (df['centroid_depth'] <= hi)\n",
    "    for target_skip_reason in skip_reasons:\n",
    "        print(target_skip_reason)\n",
    "        mask = skip_masks[target_skip_reason]\n",
    "#         for skip_reason, skip_mask in skip_masks.items():\n",
    "#             if skip_reason != target_skip_reason:\n",
    "#                 mask = mask & ~skip_mask\n",
    "        for idx, row in df[mask & depth_mask].sample(min(N, df[mask & depth_mask].shape[0])).iterrows():\n",
    "            process_row(row, target_skip_reason, lo, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.centroid_depth, bins=20, color='blue')\n",
    "plt.hist(df[df.is_skipped != True].centroid_depth, bins=20, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_center_coordinate(metadata, x_direction=True):\n",
    "    if x_direction:\n",
    "        x = metadata['x_coord'] + 0.5 * metadata['width']\n",
    "        return x\n",
    "    y = metadata['y_coord'] + 0.5 * metadata['height']\n",
    "    return y\n",
    "\n",
    "df['centroid_x'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=True))\n",
    "df['centroid_y'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=False))\n",
    "df['is_submitted'] = df.is_skipped == False\n",
    "df['depth'] = df.centroid_depth\n",
    "df['crop_area'] = df.metadata.apply(lambda x: x['crop_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_rates = []\n",
    "is_submitted_mask = df.is_submitted == True\n",
    "crop_area_list = list(np.percentile(df.crop_area, range(0, 110, 10)))\n",
    "for idx in range(len(crop_area_list) - 1):\n",
    "    low_ca, high_ca = crop_area_list[idx], crop_area_list[idx+1]\n",
    "    mask = (df.crop_area > low_ca) & (df.crop_area < high_ca)\n",
    "    if df[mask].shape[0] > 0:\n",
    "        accept_rate = df[mask & is_submitted_mask].shape[0] / df[mask].shape[0]\n",
    "    accept_rates.append(accept_rate)\n",
    "\n",
    "plt.bar(x=range(len(accept_rates)), height=accept_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_rates = []\n",
    "is_submitted_mask = df.is_submitted == True\n",
    "depth_list = list(np.percentile(df[df.depth.notnull()].depth, range(0, 110, 10)))\n",
    "for idx in range(len(depth_list) - 1):\n",
    "    low_d, high_d = depth_list[idx], depth_list[idx+1]\n",
    "    mask = (df.depth > low_d) & (df.depth < high_d)\n",
    "    \n",
    "    if df[mask].shape[0] > 0:\n",
    "        accept_rate = df[mask & is_submitted_mask].shape[0] / df[mask].shape[0]\n",
    "    accept_rates.append(accept_rate)\n",
    "\n",
    "plt.bar(x=range(len(accept_rates)), height=accept_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_size = 10\n",
    "is_submitted_mask = df.is_submitted == True\n",
    "crop_area_list = list(np.percentile(df.crop_area, range(0, 100+percentile_size, percentile_size)))\n",
    "accept_rates = np.zeros([len(crop_area_list)-1, len(crop_area_list)-1])\n",
    "for i in range(len(crop_area_list) - 1):\n",
    "    low_ca, high_ca = crop_area_list[i], crop_area_list[i+1]\n",
    "    ca_mask = (df.crop_area > low_ca) & (df.crop_area < high_ca)\n",
    "    depth_list = list(np.percentile(df[ca_mask & df.depth.notnull()].depth, range(0, 110, 10)))\n",
    "    print(depth_list)\n",
    "    for j in range(len(depth_list) - 1):\n",
    "        low_d, high_d = depth_list[j], depth_list[j+1]\n",
    "        d_mask = (df.depth > low_d) & (df.depth < high_d)\n",
    "        mask = ca_mask & d_mask\n",
    "        if df[mask].shape[0] > 0:\n",
    "            accept_rates[i, j] = df[mask & is_submitted_mask].shape[0] / df[mask].shape[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(accept_rates.T, annot=True)\n",
    "plt.xlabel('Crop Area Percentiles')\n",
    "plt.ylabel('Depth Percentiles (conditional on crop area)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_size = 10\n",
    "is_submitted_mask = df.is_submitted == True\n",
    "crop_area_list = list(np.percentile(df.crop_area, range(0, 100+percentile_size, percentile_size)))\n",
    "accept_rates = np.zeros([len(crop_area_list)-1, len(crop_area_list)-1])\n",
    "for i in range(len(crop_area_list) - 1):\n",
    "    low_ca, high_ca = crop_area_list[i], crop_area_list[i+1]\n",
    "    ca_mask = (df.crop_area > low_ca) & (df.crop_area < high_ca)\n",
    "    theta_list = list(np.percentile(df[ca_mask & df.theta.notnull()].theta, range(0, 110, 10)))\n",
    "    for j in range(len(theta_list) - 1):\n",
    "        low_t, high_t = theta_list[j], theta_list[j+1]\n",
    "        t_mask = (df.theta > low_t) & (df.theta < high_t)\n",
    "        mask = ca_mask & t_mask\n",
    "        if df[mask].shape[0] > 0:\n",
    "            accept_rates[i, j] = df[mask & is_submitted_mask].shape[0] / df[mask].shape[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(accept_rates.T, annot=True)\n",
    "plt.xlabel('A')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[df.crop_area > np.percentile(df.crop_area, 90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.percentile(tdf[tdf.depth.notnull()].depth, range(0, 100+percentile_size, percentile_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkp = df.world_keypoints.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angle(wkp):\n",
    "    if wkp:\n",
    "        v = wkp['UPPER_LIP'] - wkp['TAIL_NOTCH']\n",
    "        theta = np.arctan(v[1] / v[0]) * 180 / np.pi\n",
    "        return theta\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def generate_center_coordinate(metadata, x_direction=True):\n",
    "    if x_direction:\n",
    "        x = metadata['x_coord'] + 0.5 * metadata['width']\n",
    "        return x\n",
    "    y = metadata['y_coord'] + 0.5 * metadata['height']\n",
    "    return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['theta'] = df.world_keypoints.apply(lambda x: compute_angle(x))\n",
    "df['depth'] = df.centroid_depth\n",
    "df['square_depth'] = df.depth**2\n",
    "df['square_length'] = df.length**2\n",
    "df['square_theta'] = df.theta**2\n",
    "df['length_theta'] = df.length * df.theta\n",
    "df['length_depth'] = df.length * df.depth\n",
    "df['length_square_theta'] = df.length * df.square_theta\n",
    "df['depth_theta'] = df.depth * df.theta\n",
    "df['depth_square_theta'] = df.depth * df.theta**2\n",
    "df['centroid_x'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=True)) - 2048\n",
    "df['centroid_y'] = df.metadata.apply(lambda x: generate_center_coordinate(x, x_direction=False)) - 1500\n",
    "df['square_centroid_x'] = df.centroid_x**2\n",
    "df['square_centroid_y'] = df.centroid_y**2\n",
    "df['is_accepted'] = 1.0 - df.is_skipped.astype(int)\n",
    "\n",
    "# features = ['theta', 'square_length', 'square_theta', 'length_theta', 'length_square_theta', 'centroid_x', \n",
    "#             'centroid_y', 'square_centroid_x', 'square_centroid_y', 'depth', 'square_depth']\n",
    "\n",
    "# features = ['depth', 'square_depth', 'centroid_x', 'centroid_y', 'square_centroid_x', 'square_centroid_y']\n",
    "# features = ['centroid_x', 'centroid_y', 'square_centroid_x', 'square_centroid_y']\n",
    "features = ['theta', 'square_theta', 'depth', 'square_depth', 'centroid_x', 'square_centroid_x', 'centroid_y', 'square_centroid_y']\n",
    "# features = ['theta', 'square_theta', 'depth', 'square_depth']\n",
    "\n",
    "null_mask = df[features + ['is_accepted']].isnull().any(axis=1)\n",
    "X = df.loc[~null_mask, features].values\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = df.loc[~null_mask, 'is_accepted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y, preds)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(precision, recall)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X)[:, 1]\n",
    "preds = np.random.random(len(preds))\n",
    "precision, recall, thresholds = precision_recall_curve(y, preds)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(precision, recall)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15\n",
    "y[preds > threshold].sum() / y[preds > threshold].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[preds > threshold].sum() / y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
