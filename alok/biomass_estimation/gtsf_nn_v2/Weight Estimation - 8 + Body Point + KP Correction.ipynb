{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import random\n",
    "import torch\n",
    "from aquabyte.data_loader import KeypointsDataset, NormalizeCentered2D, ToTensor, BODY_PARTS\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy, deepcopy\n",
    "import pyarrow.parquet as pq\n",
    "from scipy.spatial import Delaunay\n",
    "from pyobb.obb import OBB\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = sorted([\n",
    "    'UPPER_LIP',\n",
    "    'ADIPOSE_FIN',\n",
    "    'TAIL_NOTCH',\n",
    "    'EYE',\n",
    "    'PELVIC_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'UPPER_PRECAUDAL_PIT',\n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE',\n",
    "    'DORSAL_FIN',\n",
    "    'ANAL_FIN'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints -> 'leftCrop' is not null\n",
    "    and b.keypoints -> 'rightCrop' is not null\n",
    "    and b.is_qa = false\n",
    "    and b.captured_at < '2019-09-20';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "df = df[~df.id.isin(blacklisted_keypoint_annotation_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Append World Keypoints to this Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def is_well_behaved(wkps, cutoff_depth=10.0):\n",
    "    if any([abs(wkp[1]) > cutoff_depth for wkp in wkps.values()]):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "is_well_behaved_mask = df.world_keypoints.apply(lambda x: is_well_behaved(x))\n",
    "df = df[is_well_behaved_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Add template matching results to this base dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "gen = s3_access_utils.get_matching_s3_keys('aquabyte-research', prefix='template-matching/2019-12-05T02:50:57', suffixes=['.parquet'])\n",
    "keys = []\n",
    "for key in gen:\n",
    "    keys.append(key)\n",
    "\n",
    "f = s3_access_utils.download_from_s3('aquabyte-research', keys[0])\n",
    "pdf = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['homography'] = pdf.homography_and_matches.apply(lambda x: np.array(x[0].tolist(), dtype=np.float))\n",
    "pdf['matches'] = pdf.homography_and_matches.apply(lambda x: np.array(x[1].tolist(), dtype=np.int) if len(x) > 1 else None)\n",
    "df = pd.merge(df, pdf[['left_image_url', 'homography', 'matches']], how='inner', on='left_image_url')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Add Body Keypoints </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull(p, hull):\n",
    "    hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "modified_keypoints_list = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    X_keypoints = np.array([[item['xFrame'], item['yFrame']] for item in row.keypoints['leftCrop']])\n",
    "    X_body = np.array(row.matches)\n",
    "    is_valid = in_hull(X_body[:, :2], X_keypoints)\n",
    "    X_body = X_body[np.where(is_valid)]\n",
    "    \n",
    "    keypoints = deepcopy(row.keypoints)\n",
    "    left_keypoints, right_keypoints = keypoints['leftCrop'], keypoints['rightCrop']\n",
    "    left_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 0],\n",
    "        'yFrame': X_body[:, 1]\n",
    "    }\n",
    "    \n",
    "    right_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 2],\n",
    "        'yFrame': X_body[:, 3]\n",
    "    }\n",
    "    \n",
    "    left_keypoints.append(left_item)\n",
    "    right_keypoints.append(right_item)\n",
    "    modified_keypoints = {\n",
    "        'leftCrop': left_keypoints,\n",
    "        'rightCrop': right_keypoints\n",
    "    }\n",
    "\n",
    "    modified_keypoints_list.append(modified_keypoints)\n",
    "\n",
    "df['old_keypoints'] = df.keypoints\n",
    "df['keypoints'] = modified_keypoints_list\n",
    "\n",
    "\n",
    "df = df[df.keypoints.apply(lambda x: x['leftCrop'][-1]['xFrame'].shape[0]) > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Construct Point Cloud Data Transform </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull(p, hull):\n",
    "    hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "def get_raw_3D_coordinates(keypoints, cm):\n",
    "    wkps = pixel2world([item for item in keypoints['leftCrop'] if item['keypointType'] != 'BODY'], \n",
    "                       [item for item in keypoints['rightCrop'] if item['keypointType'] != 'BODY'],\n",
    "                       cm)\n",
    "    \n",
    "    # compute BODY world keypoint coordinates\n",
    "    if 'BODY' in [item['keypointType'] for item in keypoints['leftCrop']]:\n",
    "        left_item = [item for item in keypoints['leftCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "        right_item = [item for item in keypoints['rightCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "        disps = np.abs(left_item['xFrame'] - right_item['xFrame'])\n",
    "        focal_length_pixel = cm[\"focalLengthPixel\"]\n",
    "        baseline = cm[\"baseline\"]\n",
    "        depths = focal_length_pixel * baseline / np.array(disps)\n",
    "\n",
    "        pixel_count_width = cm[\"pixelCountWidth\"]\n",
    "        pixel_count_height = cm[\"pixelCountHeight\"]\n",
    "        sensor_width = cm[\"imageSensorWidth\"]\n",
    "        sensor_height = cm[\"imageSensorHeight\"]\n",
    "        focal_length = cm[\"focalLength\"]\n",
    "\n",
    "        image_center_x = pixel_count_width / 2.0\n",
    "        image_center_y = pixel_count_height / 2.0\n",
    "        x = left_item['xFrame']\n",
    "        y = left_item['yFrame']\n",
    "        px_x = x - image_center_x\n",
    "        px_z = image_center_y - y\n",
    "\n",
    "        sensor_x = px_x * (sensor_width / pixel_count_width)\n",
    "        sensor_z = px_z * (sensor_height / pixel_count_height)\n",
    "\n",
    "        world_y = depths\n",
    "        world_x = (world_y * sensor_x) / focal_length\n",
    "        world_z = (world_y * sensor_z) / focal_length\n",
    "        wkps['BODY'] = np.column_stack([world_x, world_y, world_z])\n",
    "        \n",
    "    \n",
    "    all_wkps = [list(wkps[bp]) for bp in BODY_PARTS]\n",
    "    if 'BODY' in wkps.keys():\n",
    "        random.seed(0)\n",
    "        body_wkps = random.sample([list(wkp) for wkp in list(wkps['BODY'])], 500)\n",
    "        all_wkps.extend(body_wkps)\n",
    "    return np.array(all_wkps)\n",
    "    \n",
    "\n",
    "def _generate_rotation_matrix(n, theta):\n",
    "\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0]**2*(1-np.cos(theta)), \n",
    "        n[0]*n[1]*(1-np.cos(theta)) - n[2]*np.sin(theta),\n",
    "        n[0]*n[2]*(1-np.cos(theta)) + n[1]*np.sin(theta)\n",
    "    ], [\n",
    "        n[1]*n[0]*(1-np.cos(theta)) + n[2]*np.sin(theta),\n",
    "        np.cos(theta) + n[1]**2*(1-np.cos(theta)),\n",
    "        n[1]*n[2]*(1-np.cos(theta)) - n[0]*np.sin(theta),\n",
    "    ], [\n",
    "        n[2]*n[0]*(1-np.cos(theta)) - n[1]*np.sin(theta),\n",
    "        n[2]*n[1]*(1-np.cos(theta)) + n[0]*np.sin(theta),\n",
    "        np.cos(theta) + n[2]**2*(1-np.cos(theta))\n",
    "    ]])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def normalize_3D_coordinates(wkps):\n",
    "    \n",
    "    # translate keypoints such that medoid is at origin\n",
    "    wkps = wkps - 0.5*(np.max(wkps[:8], axis=0) + np.min(wkps[:8], axis=0))\n",
    "\n",
    "    # perform rotation\n",
    "    upper_lip_idx = BODY_PARTS.index('UPPER_LIP')\n",
    "    \n",
    "    n = np.array([0, 1, 0])\n",
    "    theta = np.arctan(wkps[upper_lip_idx][2] / wkps[upper_lip_idx][0])\n",
    "    R = _generate_rotation_matrix(n, theta)\n",
    "    wkps = np.dot(R, wkps.T).T\n",
    "    \n",
    "    # perform reflecton if necessary\n",
    "    tail_notch_idx = BODY_PARTS.index('TAIL_NOTCH')\n",
    "    if wkps[upper_lip_idx][0] < wkps[tail_notch_idx][0]:\n",
    "        R = np.array([\n",
    "            [-1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        wkps = np.dot(R, wkps.T).T\n",
    "    \n",
    "    return wkps\n",
    "    \n",
    "\n",
    "def jitter_wkps(wkps, cm):\n",
    "    wkps_jittered = []\n",
    "    for idx, body_part in enumerate(BODY_PARTS):\n",
    "        jitter = 0\n",
    "        if body_part in ['TAIL_NOTCH', 'HYPURAL_PLATE', 'UPPER_PRECAUDAL_PIT', 'UPPER_LIP', 'DORSAL_FIN']:\n",
    "            jitter = 10\n",
    "        x_p_left = wkps[idx, 0] * cm['focalLengthPixel'] / wkps[idx, 1]\n",
    "        y_p_left = wkps[idx, 2] * cm['focalLengthPixel'] / wkps[idx, 1]\n",
    "        disparity = cm['focalLengthPixel'] * cm['baseline'] / wkps[idx, 1]\n",
    "        x_p_left_jitter = np.random.normal(0, jitter)\n",
    "        x_p_right_jitter = np.random.normal(0, jitter)\n",
    "        disparity_jitter = x_p_left_jitter + x_p_right_jitter\n",
    "        \n",
    "        x_p_left_jittered = x_p_left + x_p_left_jitter\n",
    "        disparity_jittered = disparity + disparity_jitter\n",
    "        depth_jittered = cm['focalLengthPixel'] * cm['baseline'] / disparity_jittered\n",
    "        x_jittered = x_p_left_jittered * depth_jittered / cm['focalLengthPixel']\n",
    "        y_jittered = wkps[idx, 2]\n",
    "        wkp_jittered = [x_jittered, depth_jittered, y_jittered]\n",
    "        wkps_jittered.append(wkp_jittered)\n",
    "    wkps_jittered.append(wkps[len(BODY_PARTS), :].tolist())\n",
    "    wkps_jittered = np.array(wkps_jittered)\n",
    "    return wkps_jittered\n",
    "\n",
    "\n",
    "# def jitter_wkps(wkps, cm, base_jitter=5):\n",
    "#     wkps_jittered = []\n",
    "#     for idx in range(len(BODY_PARTS)):\n",
    "#         x_p_left = wkps[idx, 0] * cm['focalLengthPixel'] / wkps[idx, 1]\n",
    "#         y_p_left = wkps[idx, 2] * cm['focalLengthPixel'] / wkps[idx, 1]\n",
    "#         disparity = cm['focalLengthPixel'] * cm['baseline'] / wkps[idx, 1]\n",
    "#         x_p_left_jitter = np.random.normal(0, base_jitter)\n",
    "#         x_p_right_jitter = np.random.normal(0, base_jitter)\n",
    "#         disparity_jitter = x_p_left_jitter + x_p_right_jitter\n",
    "        \n",
    "#         x_p_left_jittered = x_p_left + x_p_left_jitter\n",
    "#         disparity_jittered = disparity + disparity_jitter\n",
    "#         depth_jittered = cm['focalLengthPixel'] * cm['baseline'] / disparity_jittered\n",
    "#         x_jittered = x_p_left_jittered * depth_jittered / cm['focalLengthPixel']\n",
    "#         y_jittered = wkps[idx, 2]\n",
    "#         wkp_jittered = [x_jittered, depth_jittered, y_jittered]\n",
    "#         wkps_jittered.append(wkp_jittered)\n",
    "#     wkps_jittered.append(wkps[len(BODY_PARTS), :].tolist())\n",
    "#     wkps_jittered = np.array(wkps_jittered)\n",
    "#     return wkps_jittered\n",
    "\n",
    "\n",
    "def get_augmented_keypoints(keypoints, cm, base_depth=0.5):\n",
    "#     dorsal_fin_idx, pelvic_fin_idx = BODY_PARTS.index('DORSAL_FIN'), BODY_PARTS.index('PELVIC_FIN')\n",
    "    dorsal_fin_idx, pelvic_fin_idx = BODY_PARTS.index('UPPER_LIP'), BODY_PARTS.index('HYPURAL_PLATE')\n",
    "    wkps = get_raw_3D_coordinates(keypoints, cm)\n",
    "    norm_wkps = normalize_3D_coordinates(wkps)\n",
    "    body_norm_wkps = norm_wkps[len(BODY_PARTS):, :]\n",
    "    mid_point = 0.5*(norm_wkps[dorsal_fin_idx] + norm_wkps[pelvic_fin_idx])\n",
    "    idx = np.argmin(np.linalg.norm(body_norm_wkps[:, [0, 2]] - np.array([mid_point[0], mid_point[2]]), axis=1))\n",
    "    body_wkp = body_norm_wkps[idx]\n",
    "    \n",
    "    augmented_wkps = np.vstack([norm_wkps[:len(BODY_PARTS), :], body_wkp])\n",
    "    return augmented_wkps\n",
    "\n",
    "\n",
    "\n",
    "def get_jittered_keypoints(wkps, cm):    \n",
    "    # put at random depth and apply jitter\n",
    "    depth = np.random.uniform(low=0.5, high=2.0)\n",
    "    wkps[:, 1] = wkps[:, 1] + depth\n",
    "    \n",
    "    # apply jitter\n",
    "    jittered_wkps = jitter_wkps(wkps, cm)\n",
    "    return jittered_wkps\n",
    "    \n",
    "    # normalize\n",
    "    final_wkps = np.column_stack([0.5 * jittered_wkps[:, 0] / jittered_wkps[:, 1], \n",
    "                            0.5 * jittered_wkps[:, 2] / jittered_wkps[:, 1], \n",
    "                            0.05 / jittered_wkps[:, 1]])\n",
    "    return final_wkps\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_keypoints_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    keypoints, cm = row.keypoints, row.camera_metadata\n",
    "    augmented_keypoints = get_augmented_keypoints(keypoints, cm)\n",
    "    augmented_keypoints_list.append(augmented_keypoints)\n",
    "df['augmented_keypoints'] = augmented_keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps = df.world_keypoints.iloc[1]\n",
    "augmented_wkps = df.augmented_keypoints.iloc[1]\n",
    "cm = df.camera_metadata.iloc[1]\n",
    "jittered_wkps = get_jittered_keypoints(deepcopy(augmented_wkps), cm)\n",
    "idx_0, idx_1 = 2, 7\n",
    "print(euclidean_distance(wkps[BODY_PARTS[idx_0]], wkps[BODY_PARTS[idx_1]]))\n",
    "print(euclidean_distance(augmented_wkps[idx_0], augmented_wkps[idx_1]))\n",
    "print(euclidean_distance(jittered_wkps[idx_0], jittered_wkps[idx_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Neural Network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    \"\"\"Keypoints dataset\n",
    "    This is the base version of the dataset that is used to map 3D keypoints to a\n",
    "    biomass estimate. The label is the weight, and the input is the 3D workd keypoints\n",
    "    obtained during triangulation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.transform:\n",
    "            input_sample = {\n",
    "                'kp_input': row.augmented_keypoints,\n",
    "                'cm': row.camera_metadata,\n",
    "                'stereo_pair_id': row.id,\n",
    "            }\n",
    "            if 'weight' in dict(row).keys():\n",
    "                input_sample['label'] = row.weight\n",
    "            sample = self.transform(input_sample)\n",
    "            return sample\n",
    "\n",
    "        world_keypoints = row.world_keypoints\n",
    "        weight = row.weight\n",
    "\n",
    "        sample = {'kp_input': world_keypoints, 'label': weight, 'stereo_pair_id': row.id}\n",
    "\n",
    "        return sample\n",
    "\n",
    "class NormalizedCentered3D(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        augmented_wkps, cm, stereo_pair_id, label = \\\n",
    "            sample['kp_input'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "    \n",
    "        jittered_wkps = get_jittered_keypoints(augmented_wkps, cm)\n",
    "        normalized_label = label * 1e-4\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': jittered_wkps,\n",
    "            'label': normalized_label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'cm': cm,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "\n",
    "        return transformed_sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        x, label, stereo_pair_id = \\\n",
    "            sample['kp_input'], sample.get('label'), sample.get('stereo_pair_id')\n",
    "        \n",
    "        if sample.get('single_point_inference'):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        kp_input_tensor = torch.from_numpy(x).float()\n",
    "        \n",
    "        tensorized_sample = {\n",
    "            'kp_input': kp_input_tensor\n",
    "        }\n",
    "\n",
    "        if label:\n",
    "            label_tensor = torch.from_numpy(np.array([label])).float() if label else None\n",
    "            tensorized_sample['label'] = label_tensor\n",
    "\n",
    "        if stereo_pair_id:\n",
    "            tensorized_sample['stereo_pair_id'] = stereo_pair_id\n",
    "\n",
    "        \n",
    "        return tensorized_sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define train and test data loaders </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)\n",
    "\n",
    "train_dataset = KeypointsDataset(df[train_mask], transform=transforms.Compose([\n",
    "                                                  NormalizedCentered3D(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=1)\n",
    "\n",
    "test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                      NormalizedCentered3D(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataloader:\n",
    "    new_wkps = data['kp_input']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(new_wkps[1][:, 0], new_wkps[1][:, 2], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(36, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'batch_25_with_scaled_jitter_v1'\n",
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, run_name, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "    # run on test set\n",
    "    else:\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            network.eval()\n",
    "            for i, data_batch in enumerate(test_dataloader):\n",
    "                X_batch, y_batch, kpid_batch = \\\n",
    "                    data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "                y_pred = network(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "    test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "    train_losses.append(train_loss_for_epoch)\n",
    "    test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "    # save current state of network\n",
    "    if write_outputs:\n",
    "        f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "        f_path = os.path.join(output_dir, f_name)\n",
    "        torch.save(network, f_path)\n",
    "    \n",
    "    # print current loss values\n",
    "    print('-'*20)\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "    print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(len(train_losses)), train_losses, color='blue', label='training loss')\n",
    "plt.plot(range(len(test_losses)), test_losses, color='orange', label='validation loss')\n",
    "plt.ylim([0, 0.01])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value (MSE)')\n",
    "plt.title('Loss curves (MSE - Adam optimizer)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "weights = []\n",
    "for i, data_batch in enumerate(test_dataloader):\n",
    "    X_batch, y_batch, kpid_batch = \\\n",
    "        data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "    y_pred = network(X_batch)\n",
    "    p = [1e4*x[0]**0.5 for x in y_pred.tolist()]\n",
    "    w = [1e4*x[0]**0.5 for x in y_batch.tolist()]\n",
    "    predictions.extend(p)\n",
    "    weights.extend(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(weights, predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg = AccuracyMetricsGenerator()\n",
    "amg.generate_accuracy_metrics(np.array(predictions), np.array(weights), w=np.ones(len(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(np.abs((np.array(predictions) - np.array(weights))/np.array(weights)), 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataloader:\n",
    "    x = data['kp_input']\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wkps = data['kp_input'][1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# get x, y, and z lists\n",
    "\n",
    "x_values = all_wkps[:,0]\n",
    "y_values = all_wkps[:,1]\n",
    "z_values = all_wkps[:,2]\n",
    "\n",
    "ax.scatter(x_values, y_values, z_values)\n",
    "\n",
    "# Create cubic bounding box to simulate equal aspect ratio\n",
    "max_range = np.array([x_values.max()-x_values.min(), y_values.max()-y_values.min(), z_values.max()-z_values.min()]).max()\n",
    "Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x_values.max()+x_values.min())\n",
    "Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y_values.max()+y_values.min())\n",
    "Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z_values.max()+z_values.min())\n",
    "# Comment or uncomment following both lines to test the fake bounding box:\n",
    "for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "    ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = df[df.id == 710764].keypoints.iloc[0]\n",
    "cm = df[df.id == 710764].camera_metadata.iloc[0]\n",
    "wkps = pixel2world(kps['leftCrop'], kps['rightCrop'], cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance(wkps['UPPER_LIP'], wkps['EYE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance(all_wkps[3], all_wkps[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    'keypoints': df.keypoints.iloc[0],\n",
    "    'stereo_pair_id': 0,\n",
    "    'cm': df.camera_metadata.iloc[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array([[1, 2, 3], [4, 5, 6]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_keypoints_list = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    X_keypoints = np.array([[item['xFrame'], item['yFrame']] for item in row.keypoints['leftCrop']])\n",
    "    X_body = np.array(row.matches)\n",
    "    is_valid = in_hull(X_body[:, :2], X_keypoints)\n",
    "    X_body = X_body[np.where(is_valid)]\n",
    "    \n",
    "    keypoints = deepcopy(row.keypoints)\n",
    "    left_keypoints, right_keypoints = keypoints['leftCrop'], keypoints['rightCrop']\n",
    "    left_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 0],\n",
    "        'yFrame': X_body[:, 1]\n",
    "    }\n",
    "    \n",
    "    right_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 2],\n",
    "        'yFrame': X_body[:, 3]\n",
    "    }\n",
    "    \n",
    "    left_keypoints.append(left_item)\n",
    "    right_keypoints.append(right_item)\n",
    "    modified_keypoints = {\n",
    "        'leftCrop': left_keypoints,\n",
    "        'rightCrop': right_keypoints\n",
    "    }\n",
    "\n",
    "    modified_keypoints_list.append(modified_keypoints)\n",
    "\n",
    "df['old_keypoints'] = df.keypoints\n",
    "df['keypoints'] = modified_keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask], transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                  WorldKeypointTransform(),\n",
    "                                                  PrismTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=1)\n",
    "\n",
    "test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                  WorldKeypointTransform(),\n",
    "                                                  PrismTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "#     # run on test set\n",
    "#     else:\n",
    "#         test_running_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             network.eval()\n",
    "#             for i, data_batch in enumerate(test_dataloader):\n",
    "#                 X_batch, y_batch, kpid_batch = \\\n",
    "#                     data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "#                 y_pred = network(X_batch)\n",
    "#                 loss = criterion(y_pred, y_batch)\n",
    "#                 test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "#     test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "#     train_losses.append(train_loss_for_epoch)\n",
    "#     test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "#     # save current state of network\n",
    "#     if write_outputs:\n",
    "#         f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "#         f_path = os.path.join(output_dir, f_name)\n",
    "#         torch.save(network, f_path)\n",
    "    \n",
    "#     # print current loss values\n",
    "#     print('-'*20)\n",
    "#     print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "#     print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
