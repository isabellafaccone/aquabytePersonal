{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from utils import rotate_and_reposition, get_2D_coords_from_3D, get_3D_coords_from_2D, jitter_2D_coords, \\\n",
    "    deg_to_rad, rad_to_deg, CameraMetadata, center_3D_coordinates, rotation_matrix_to_euler_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run simple cube experiment </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generate base model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish base 3D coordinates\n",
    "\n",
    "base_3D_coordinates = np.array([\n",
    "    [-0.5, 0.5, -0.5],\n",
    "    [-0.5, 0.5, 0.5],\n",
    "    [0.5, 0.5, 0.5],\n",
    "    [0.5, 0.5, -0.5],\n",
    "    [0.5, 1.5, -0.5],\n",
    "    [0.5, 1.5, 0.5],\n",
    "    [-0.5, 1.5, 0.5],\n",
    "    [-0.5, 1.5, -0.5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = CameraMetadata(\n",
    "    focal_length=4050 * 3.45e-6,\n",
    "    focal_length_pixel=4050,\n",
    "    baseline_m=0.105,\n",
    "    pixel_count_width=4000,\n",
    "    pixel_count_height=3096,\n",
    "    image_sensor_width=0.01412,\n",
    "    image_sensor_height=0.01035\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orthonormal_basis(coords):\n",
    "    \"\"\"Given a set of jittered cube coordinates, approximate the orthonormal basis \n",
    "    corresponding to the new coordinate system that is axis-aligned with the coordinates.\"\"\"\n",
    "    print(coords)\n",
    "    u = coords[3] - coords[0]\n",
    "    v = coords[7] - coords[0]\n",
    "    u = u / np.linalg.norm(u)\n",
    "    v = v - (np.dot(u, v))*u\n",
    "    v = v / np.linalg.norm(v)\n",
    "    w = np.cross(u, v)\n",
    "    w = w / np.linalg.norm(w)\n",
    "    return np.vstack((u, v, w)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = compute_orthonormal_basis(rotate_and_reposition(base_3D_coordinates, \n",
    "                                                    deg_to_rad(0), \n",
    "                                                    deg_to_rad(1), \n",
    "                                                    deg_to_rad(0), [0, 0, 0]))\n",
    "rotation_matrix_to_euler_angles(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Validate data and functions via 2D / 3D rendering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_df(coords):\n",
    "    df = pd.DataFrame({\n",
    "        'x': list(coords[:, 0]),\n",
    "        'y': list(coords[:, 1]),\n",
    "        'z': list(coords[:, 2])\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 1.0\n",
    "volume = scaling_factor**3\n",
    "rescaled_3D_coordinates = volume * base_3D_coordinates\n",
    "yaw_deg, pitch_deg, roll_deg = 10, 20, -10\n",
    "yaw, pitch, roll = [deg_to_rad(x) for x in (yaw_deg, pitch_deg, roll_deg)]\n",
    "new_centroid_position = [0, 0, 0]\n",
    "repositioned_3D_coords = rotate_and_reposition(rescaled_3D_coordinates, yaw, pitch, roll, new_centroid_position)\n",
    "centered_3D_coords = center_3D_coordinates(repositioned_3D_coords)\n",
    "B = compute_orthonormal_basis(centered_3D_coords)\n",
    "local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "print(np.array([local_yaw, local_pitch, local_roll]) * 180.0 / np.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = transform_into_df(rescaled_3D_coordinates)\n",
    "df2 = transform_into_df(repositioned_3D_coords)\n",
    "df3 = transform_into_df(centered_3D_coords)\n",
    "fig = px.scatter_3d(df1, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df2, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df3, x='x', y='y', z='z')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_left, X_right = get_2D_coords_from_3D(base_3D_coordinates, camera_metadata)\n",
    "plt.scatter(X_left[:, 0], X_left[:, 1], color='blue')\n",
    "plt.scatter(X_right[:, 0], X_right[:, 1], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generate large dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_range = [0.5, 10.0]\n",
    "yaw_range_deg = [-50, 50]\n",
    "pitch_range_deg = [-50, 50]\n",
    "roll_range_deg = [-50, 50]\n",
    "centroid_range_x = [-0.5, 0.5]\n",
    "centroid_range_y = [0.5, 1.5]\n",
    "centroid_range_z = [-0.5, 0.5]\n",
    "\n",
    "N = 500000\n",
    "jitter_std = 10\n",
    "\n",
    "dataset = defaultdict(list)\n",
    "for t in range(N):\n",
    "    \n",
    "    volume = np.random.uniform(*volume_range)\n",
    "    scaling_factor = volume**(1.0 / 3)\n",
    "    rescaled_3D_coordinates = scaling_factor * base_3D_coordinates\n",
    "    \n",
    "    yaw = deg_to_rad(np.random.uniform(*yaw_range_deg))\n",
    "    pitch = deg_to_rad(np.random.uniform(*pitch_range_deg))\n",
    "    roll = deg_to_rad(np.random.uniform(*roll_range_deg))\n",
    "    \n",
    "    new_centroid_position = np.array([np.random.uniform(*x) for x in (centroid_range_x, centroid_range_y, centroid_range_z)])\n",
    "    repositioned_3D_coords = rotate_and_reposition(rescaled_3D_coordinates, yaw, pitch, roll, new_centroid_position)\n",
    "    repositioned_X_left, repositioned_X_right = get_2D_coords_from_3D(repositioned_3D_coords, camera_metadata)\n",
    "    jittered_X_left, jittered_X_right = jitter_2D_coords(repositioned_X_left, repositioned_X_right, jitter_std)\n",
    "    jittered_3D_coords = get_3D_coords_from_2D(jittered_X_left, jittered_X_right, camera_metadata)\n",
    "    \n",
    "    centered_3D_coords = center_3D_coordinates(jittered_3D_coords)\n",
    "    B = compute_orthonormal_basis(centered_3D_coords)\n",
    "    local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "    \n",
    "    \n",
    "    dataset['X'].append(centered_3D_coords.tolist())\n",
    "    dataset['y'].append(volume)\n",
    "    dataset['yaw'].append(rad_to_deg(yaw))\n",
    "    dataset['pitch'].append(rad_to_deg(pitch))\n",
    "    dataset['roll'].append(rad_to_deg(roll))\n",
    "    \n",
    "    dataset['local_yaw'].append(rad_to_deg(local_yaw))\n",
    "    dataset['local_pitch'].append(rad_to_deg(local_pitch))\n",
    "    dataset['local_roll'].append(rad_to_deg(local_roll))\n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        print(t)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train neural network architecture </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor and get final hiddel layer weights.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "def convert_to_pytorch(model):\n",
    "    pytorch_model = Network()\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    pytorch_model.fc1.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "    pytorch_model.fc1.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "    pytorch_model.fc2.weight.data = torch.from_numpy(np.transpose(weights[2]))\n",
    "    pytorch_model.fc2.bias.data = torch.from_numpy(np.transpose(weights[3]))\n",
    "    pytorch_model.fc3.weight.data = torch.from_numpy(np.transpose(weights[4]))\n",
    "    pytorch_model.fc3.bias.data = torch.from_numpy(np.transpose(weights[5]))\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "    \n",
    "    return pytorch_model\n",
    "\n",
    "\n",
    "def apply_final_layer_ols(pytorch_model):\n",
    "    X_ols = pytorch_model.forward_intermediate(torch.from_numpy(X_train).float()).detach().numpy()\n",
    "    lr = LinearRegression().fit(X_ols, y_train)\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.array(lr.coef_).reshape(1, -1))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.array([lr.intercept_]))\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inputs = Input(shape=(24,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, train_config):\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct, val_pct, test_pct = 0.6, 0.2, 0.2\n",
    "train_idx = int(train_pct * df.shape[0])\n",
    "val_idx = int((train_pct + val_pct) * df.shape[0])\n",
    "train_mask = df.index < train_idx\n",
    "val_mask = (df.index >= train_idx) & (df.index < val_idx)\n",
    "test_mask = (df.index >= val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(df[train_mask].X.values))\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2], -1)\n",
    "y_train = df[train_mask].y.values\n",
    "\n",
    "X_val = np.array(list(df[val_mask].X.values))\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1]*X_val.shape[2], -1)\n",
    "y_val = df[val_mask].y.values\n",
    "\n",
    "X_test = np.array(list(df[test_mask].X.values))\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2], -1)\n",
    "y_test = df[test_mask].y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = dict(\n",
    "    epochs=1000,\n",
    "    batch_size=64, \n",
    "    learning_rate=1e-4,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "train_model(model, X_train, y_train, X_val, y_val, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Accuracy Reporting </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = convert_to_pytorch(model)\n",
    "apply_final_layer_ols(pytorch_model)\n",
    "\n",
    "X = np.array(list(df.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "df['y_pred'] = y_pred\n",
    "df['pct_error'] = (df.y_pred - df.y) / df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "pitch_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "roll_bucket_cutoffs = np.arange(-50, 55, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_heatmap(df, angle_1, angle_2, bucket_cutoffs_1, bucket_cutoffs_2):\n",
    "    heatmap_arr = np.zeros([len(bucket_cutoffs_1) - 1, len(bucket_cutoffs_2) - 1])\n",
    "\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        for j, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "            angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "            angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "            angle_1_mask = (df[angle_1] > angle_1_low) & (df[angle_1] < angle_1_high)\n",
    "            angle_2_mask = (df[angle_2] > angle_2_low) & (df[angle_2] < angle_2_high)\n",
    "            orientation_mask = angle_1_mask & angle_2_mask\n",
    "            mean_error_pct = (df[orientation_mask].y_pred.mean() - df[orientation_mask].y.mean()) / df[orientation_mask].y.mean()\n",
    "            heatmap_arr[i][j] = round(100 * mean_error_pct, 2)\n",
    "\n",
    "    angle_1_buckets = []\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "        angle_1_bucket = '{} <-> {}'.format(angle_1_low, angle_1_high)\n",
    "        angle_1_buckets.append(angle_1_bucket)\n",
    "\n",
    "    angle_2_buckets = []\n",
    "    for i, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "        angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "        angle_2_bucket = '{} <-> {}'.format(angle_2_low, angle_2_high)\n",
    "        angle_2_buckets.append(angle_2_bucket)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_arr, xticklabels=angle_1_buckets, yticklabels=angle_2_buckets, annot=True)\n",
    "    plt.xlabel('{} range (degrees)'.format(angle_1))\n",
    "    plt.ylabel('{} range (degrees)'.format(angle_2))\n",
    "    plt.title('Error percentage (%) broken down by Orientation Bucket')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'local_yaw', 'local_pitch', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'local_yaw', 'local_roll', yaw_bucket_cutoffs, roll_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'local_pitch', 'local_roll', pitch_bucket_cutoffs, roll_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
