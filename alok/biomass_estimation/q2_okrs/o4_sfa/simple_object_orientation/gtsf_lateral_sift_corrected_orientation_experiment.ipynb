{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load lateral, SIFT corrected GTSF data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/alok/biomass_estimation/playground/filtered_lateral_sift_corrected_gtsf.csv'\n",
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "for idx, row in df.iterrows():\n",
    "#     ann = json.loads(row.modified_ann.replace(\"'\", '\"'))\n",
    "    ann = json.loads(row.keypoints.replace(\"'\", '\"'))\n",
    "    camera_metadata = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "    cm = CameraMetadata(\n",
    "        focal_length=camera_metadata['focalLength'],\n",
    "        focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "        baseline_m=camera_metadata['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    X_left, X_right = get_2D_coords_from_ann(ann)\n",
    "    X = get_3D_coords_from_2D(X_left, X_right, cm)\n",
    "    X_list.append(X)\n",
    "    \n",
    "df['modified_X'] = X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.modified_X.apply(lambda x: np.linalg.norm(x[6]-x[7])), df.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Training Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orthonormal_basis(coords):\n",
    "    \"\"\"Given a set of jittered fish coordinates, approximate the orthonormal basis \n",
    "    corresponding to the new coordinate system that is axis-aligned with the coordinates.\"\"\"\n",
    "    \n",
    "    u = coords[7] - coords[6] # vector from TAIL_NOTCH to UPPER_LIP\n",
    "    w = coords[2] - coords[5] # vector from PELVIC_FIN to DORSAL_FIN\n",
    "    u = u / np.linalg.norm(u)\n",
    "    w = w - (np.dot(u, w))*u\n",
    "    w = w / np.linalg.norm(w)\n",
    "    v = np.cross(w, u)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    return np.vstack((u, v, w)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "yaw_range_deg = [-30, 30]\n",
    "pitch_range_deg = [-50, 50]\n",
    "roll_range_deg = [-30, 30]\n",
    "centroid_range_x = [-0.0, 0.0]\n",
    "centroid_range_y = [0.5, 1.5]\n",
    "centroid_range_z = [-0.0, 0.0]\n",
    "\n",
    "jitter_std = 5\n",
    "\n",
    "dataset = defaultdict(list)\n",
    "\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    camera_metadata_dict = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "    camera_metadata = CameraMetadata(\n",
    "        focal_length=camera_metadata_dict['focalLength'],\n",
    "        focal_length_pixel=camera_metadata_dict['focalLengthPixel'],\n",
    "        baseline_m=camera_metadata_dict['baseline'],\n",
    "        pixel_count_width=camera_metadata_dict['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata_dict['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata_dict['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata_dict['imageSensorHeight']\n",
    "    )\n",
    "    for n in range(N):\n",
    "        volume_factor = np.random.uniform(1.0, 1.0)\n",
    "        scaling_factor = volume_factor**(1.0/3)\n",
    "        X = scaling_factor * row.modified_X\n",
    "        y = row.weight * volume_factor * 1e-4\n",
    "        \n",
    "        yaw = deg_to_rad(np.random.uniform(*yaw_range_deg))\n",
    "        pitch = deg_to_rad(np.random.uniform(*pitch_range_deg))\n",
    "        roll = deg_to_rad(np.random.uniform(*roll_range_deg))\n",
    "        \n",
    "        new_centroid_position = np.array([np.random.uniform(*x) for x in (centroid_range_x, centroid_range_y, centroid_range_z)])\n",
    "        repositioned_3D_coords = rotate_and_reposition(X, yaw, pitch, roll, new_centroid_position)\n",
    "        repositioned_X_left, repositioned_X_right = get_2D_coords_from_3D(repositioned_3D_coords, camera_metadata)\n",
    "        jittered_X_left, jittered_X_right = jitter_2D_coords(repositioned_X_left, repositioned_X_right, jitter_std)\n",
    "        jittered_3D_coords = get_3D_coords_from_2D(jittered_X_left, jittered_X_right, camera_metadata)\n",
    "\n",
    "        # get local orientation (i.e. orientation of jittered key-points relative to \n",
    "        # rotated coordinate system where depth axis passes through fish medoid)\n",
    "        centered_3D_coords = center_3D_coordinates(jittered_3D_coords)\n",
    "        B = compute_orthonormal_basis(centered_3D_coords)\n",
    "        local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "\n",
    "        # get global orientation (i.e. coordinate system's depth axis is aligned with \n",
    "        # camera line of sight)\n",
    "        B = compute_orthonormal_basis(jittered_3D_coords)\n",
    "        global_yaw, global_pitch, global_roll = rotation_matrix_to_euler_angles(B)\n",
    "        \n",
    "#         dataset['X'].append(jittered_3D_coords.tolist())\n",
    "        dataset['X'].append(jittered_3D_coords)\n",
    "        dataset['y'].append(y)\n",
    "        dataset['global_yaw'].append(rad_to_deg(yaw))\n",
    "        dataset['global_pitch'].append(rad_to_deg(pitch))\n",
    "        dataset['global_roll'].append(rad_to_deg(roll))\n",
    "        dataset['local_yaw'].append(rad_to_deg(local_yaw))\n",
    "        dataset['local_pitch'].append(rad_to_deg(local_pitch))\n",
    "        dataset['local_roll'].append(rad_to_deg(local_roll))\n",
    "        \n",
    "        if count % 10000 == 0:\n",
    "            print(count)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train neural network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = Input(shape=(24,))\n",
    "#     x = Dense(64, activation='relu')(inputs)\n",
    "#     x = Dense(128, activation='relu')(inputs)\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, train_config):\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct, val_pct, test_pct = 0.6, 0.2, 0.2\n",
    "train_idx = int(train_pct * df.shape[0])\n",
    "val_idx = int((train_pct + val_pct) * df.shape[0])\n",
    "train_mask = df.index < train_idx\n",
    "val_mask = (df.index >= train_idx) & (df.index < val_idx)\n",
    "test_mask = (df.index >= val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(df[train_mask].X.values))\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2], -1)\n",
    "y_train = df[train_mask].y.values\n",
    "\n",
    "X_val = np.array(list(df[val_mask].X.values))\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1]*X_val.shape[2], -1)\n",
    "y_val = df[val_mask].y.values\n",
    "\n",
    "X_test = np.array(list(df[test_mask].X.values))\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2], -1)\n",
    "y_test = df[test_mask].y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "train_config = dict(\n",
    "    epochs=1000,\n",
    "    batch_size=64, \n",
    "    learning_rate=1e-4,\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "model = train_model(model, X_train, y_train, X_val, y_val, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.fc1 = nn.Linear(24, 64)\n",
    "#         self.fc2 = nn.Linear(64, 128)\n",
    "#         self.fc3 = nn.Linear(128, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)\n",
    "#         self.output = nn.Linear(64, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc5(x)\n",
    "#         x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor and get final hiddel layer weights.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc5(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "def convert_to_pytorch(model):\n",
    "    pytorch_model = Network()\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    pytorch_model.fc1.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "    pytorch_model.fc1.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "    pytorch_model.fc2.weight.data = torch.from_numpy(np.transpose(weights[2]))\n",
    "    pytorch_model.fc2.bias.data = torch.from_numpy(np.transpose(weights[3]))\n",
    "    pytorch_model.fc3.weight.data = torch.from_numpy(np.transpose(weights[4]))\n",
    "    pytorch_model.fc3.bias.data = torch.from_numpy(np.transpose(weights[5]))\n",
    "#     pytorch_model.fc4.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "#     pytorch_model.fc4.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "#     pytorch_model.fc5.weight.data = torch.from_numpy(np.transpose(weights[8]))\n",
    "#     pytorch_model.fc5.bias.data = torch.from_numpy(np.transpose(weights[9]))\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "    \n",
    "    return pytorch_model\n",
    "\n",
    "\n",
    "def apply_final_layer_ols(pytorch_model):\n",
    "    X_ols = pytorch_model.forward_intermediate(torch.from_numpy(X_train).float()).detach().numpy()\n",
    "    lr = LinearRegression().fit(X_ols, y_train)\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.array(lr.coef_).reshape(1, -1))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.array([lr.intercept_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = convert_to_pytorch(model)\n",
    "apply_final_layer_ols(pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Accuracy Reporting </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "df['y_pred'] = y_pred\n",
    "df['pct_error'] = (df.y_pred - df.y) / df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(df[train_mask].y, df[train_mask].y_pred)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_heatmap(df, angle_1, angle_2, bucket_cutoffs_1, bucket_cutoffs_2):\n",
    "    heatmap_arr = np.zeros([len(bucket_cutoffs_1) - 1, len(bucket_cutoffs_2) - 1])\n",
    "\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        for j, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "            angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "            angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "            angle_1_mask = (df[angle_1] > angle_1_low) & (df[angle_1] < angle_1_high)\n",
    "            angle_2_mask = (df[angle_2] > angle_2_low) & (df[angle_2] < angle_2_high)\n",
    "            orientation_mask = angle_1_mask & angle_2_mask\n",
    "            mean_error_pct = (df[orientation_mask].y_pred.mean() - df[orientation_mask].y.mean()) / df[orientation_mask].y.mean()\n",
    "            heatmap_arr[i][j] = round(100 * mean_error_pct, 2)\n",
    "\n",
    "    angle_1_buckets = []\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "        angle_1_bucket = '{} <-> {}'.format(angle_1_low, angle_1_high)\n",
    "        angle_1_buckets.append(angle_1_bucket)\n",
    "\n",
    "    angle_2_buckets = []\n",
    "    for i, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "        angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "        angle_2_bucket = '{} <-> {}'.format(angle_2_low, angle_2_high)\n",
    "        angle_2_buckets.append(angle_2_bucket)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_arr, xticklabels=angle_1_buckets, yticklabels=angle_2_buckets, annot=True)\n",
    "    plt.xlabel('{} range (degrees)'.format(angle_1))\n",
    "    plt.ylabel('{} range (degrees)'.format(angle_2))\n",
    "    plt.title('Error percentage (%) broken down by Orientation Bucket')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_bucket_cutoffs = np.arange(-30, 35, 5)\n",
    "pitch_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "roll_bucket_cutoffs = np.arange(-30, 35, 5)\n",
    "\n",
    "for low_roll, high_roll in zip(roll_bucket_cutoffs, roll_bucket_cutoffs[1:]):\n",
    "    print('Roll range: {} <-> {}'.format(low_roll, high_roll))\n",
    "    roll_mask = (df.global_roll > low_roll) & (df.global_roll < high_roll)\n",
    "    produce_heatmap(df[roll_mask].copy(deep=True), 'global_yaw', 'global_pitch', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Toy fish - orientation bias experiment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/alok/biomass_estimation/playground/sample_toy_fish_dataset.csv'\n",
    "tdf = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "local_yaws, local_pitches, local_rolls = [], [], []\n",
    "\n",
    "for idx, row in tdf.iterrows():\n",
    "    ann = json.loads(row.ann.replace(\"'\", '\"'))\n",
    "    camera_metadata_dict = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "    camera_metadata = CameraMetadata(\n",
    "        focal_length=camera_metadata_dict['focalLength'],\n",
    "        focal_length_pixel=camera_metadata_dict['focalLengthPixel'],\n",
    "        baseline_m=camera_metadata_dict['baseline'],\n",
    "        pixel_count_width=camera_metadata_dict['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata_dict['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata_dict['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata_dict['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    X_left, X_right = get_2D_coords_from_ann(ann)\n",
    "    X = get_3D_coords_from_2D(X_left, X_right, camera_metadata)\n",
    "    \n",
    "    centered_3D_coords = center_3D_coordinates(X)\n",
    "    B = compute_orthonormal_basis(centered_3D_coords)\n",
    "    local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "    local_yaws.append(local_yaw)\n",
    "    local_pitches.append(local_pitch)\n",
    "    local_rolls.append(local_roll)\n",
    "    \n",
    "    X_list.append(centered_3D_coords)\n",
    "    \n",
    "tdf['X'] = X_list\n",
    "tdf['local_yaw'] = local_yaws\n",
    "tdf['local_pitch'] = local_pitches\n",
    "tdf['local_roll'] = local_rolls\n",
    "\n",
    "X = np.array(list(tdf.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "tdf['pred_weight'] = y_pred * 1e4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize weight predictions vs. local yaw, local pitch, and local roll </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 20))\n",
    "axes[0].scatter(tdf.local_yaw.values * 180 / np.pi, tdf.pred_weight.values)\n",
    "axes[1].scatter(tdf.local_pitch.values * 180 / np.pi, tdf.pred_weight.values)\n",
    "axes[2].scatter(tdf.local_roll.values * 180 / np.pi, tdf.pred_weight.values)\n",
    "[axes[i].grid() for i in range(3)]\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 20))\n",
    "axes[0].scatter(tdf.local_yaw.values * 180 / np.pi, tdf.weight.values)\n",
    "axes[1].scatter(tdf.local_pitch.values * 180 / np.pi, tdf.weight.values)\n",
    "axes[2].scatter(tdf.local_roll.values * 180 / np.pi, tdf.weight.values)\n",
    "[axes[i].grid() for i in range(3)]\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
