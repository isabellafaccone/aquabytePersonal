{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from utils import rotate_and_reposition, get_2D_coords_from_3D, get_3D_coords_from_2D, jitter_2D_coords, \\\n",
    "    deg_to_rad, rad_to_deg, CameraMetadata, center_3D_coordinates, rotation_matrix_to_euler_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run simple fish experiment </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generate base model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish base 3D coordinates\n",
    "\n",
    "\n",
    "base_3D_coordinates = np.array([\n",
    "    [ 0.35766454,  1.16197692, -0.01824493],\n",
    "    [ 0.30937074,  1.20844312, -0.10601642],\n",
    "    [ 0.13337256,  1.20080287,  0.06284855],\n",
    "    [-0.10068471,  1.17529033, -0.01376725],\n",
    "    [-0.04026903,  1.18897391, -0.06134045],\n",
    "    [ 0.16120037,  1.22363095, -0.09758986],\n",
    "    [ 0.51754564,  1.11791647, -0.11590627],\n",
    "    [-0.16064665,  1.16861833, -0.00902898]\n",
    "])\n",
    "\n",
    "# base_3D_coordinates[:, 0] = -base_3D_coordinates[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = CameraMetadata(\n",
    "    focal_length=0.013842509663066934,\n",
    "    focal_length_pixel=4012.3216414686767,\n",
    "    baseline_m=0.10079791852561114,\n",
    "    pixel_count_width=4096,\n",
    "    pixel_count_height=3000,\n",
    "    image_sensor_width=0.01412,\n",
    "    image_sensor_height=0.01035\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orthonormal_basis(coords):\n",
    "    \"\"\"Given a set of jittered fish coordinates, approximate the orthonormal basis \n",
    "    corresponding to the new coordinate system that is axis-aligned with the coordinates.\"\"\"\n",
    "    \n",
    "    u = coords[7] - coords[6]\n",
    "    w = coords[2] - coords[5]\n",
    "    u = u / np.linalg.norm(u)\n",
    "    w = w - (np.dot(u, w))*u\n",
    "    w = w / np.linalg.norm(w)\n",
    "    v = np.cross(w, u)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    return np.vstack((u, v, w)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = compute_orthonormal_basis(base_3D_coordinates)\n",
    "local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Validate data and functions via 2D / 3D rendering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_df(coords):\n",
    "    df = pd.DataFrame({\n",
    "        'x': list(coords[:, 0]),\n",
    "        'y': list(coords[:, 1]),\n",
    "        'z': list(coords[:, 2])\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor_x, scaling_factor_y, scaling_factor_z = 1.0, 1.0, 1.0\n",
    "rescaled_3D_coordinates = np.zeros_like(base_3D_coordinates)\n",
    "rescaled_3D_coordinates[:] = base_3D_coordinates\n",
    "rescaled_3D_coordinates[:, 0] *= scaling_factor_x\n",
    "rescaled_3D_coordinates[:, 1] *= scaling_factor_y\n",
    "rescaled_3D_coordinates[:, 2] *= scaling_factor_z\n",
    "\n",
    "volume = scaling_factor_x * scaling_factor_y * scaling_factor_z\n",
    "\n",
    "yaw_deg, pitch_deg, roll_deg = 0, 30, 30\n",
    "yaw, pitch, roll = [deg_to_rad(x) for x in (yaw_deg, pitch_deg, roll_deg)]\n",
    "new_centroid_position = [0.5, 0.5, 0]\n",
    "repositioned_3D_coords = rotate_and_reposition(rescaled_3D_coordinates, yaw, pitch, roll, new_centroid_position)\n",
    "\n",
    "# get local orientation (i.e. orientation of jittered key-points relative to \n",
    "# rotated coordinate system where depth axis passes through fish medoid)\n",
    "centered_3D_coords = center_3D_coordinates(repositioned_3D_coords)\n",
    "B = compute_orthonormal_basis(centered_3D_coords)\n",
    "local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "\n",
    "# get global orientation (i.e. coordinate system's depth axis is aligned with \n",
    "# camera line of sight)\n",
    "B = compute_orthonormal_basis(repositioned_3D_coords)\n",
    "global_yaw, global_pitch, global_roll = rotation_matrix_to_euler_angles(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([local_yaw, local_pitch, local_roll]) * 180 / np.pi)\n",
    "print(np.array([global_yaw, global_pitch, global_roll]) * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = transform_into_df(centered_3D_coords)\n",
    "df2 = transform_into_df(repositioned_3D_coords)\n",
    "fig = px.scatter_3d(df1, x='x', y='y', z='z')\n",
    "fig.update_layout(scene=dict(xaxis=dict(),\n",
    "           yaxis=dict(),\n",
    "           zaxis=dict(),aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df2, x='x', y='y', z='z')\n",
    "fig.update_layout(scene=dict(xaxis=dict(),\n",
    "           yaxis=dict(),\n",
    "           zaxis=dict(),aspectmode='data'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_left, X_right = get_2D_coords_from_3D(base_3D_coordinates, camera_metadata)\n",
    "plt.scatter(X_left[:, 0], X_left[:, 1], color='blue')\n",
    "plt.scatter(X_right[:, 0], X_right[:, 1], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generate large dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on orientation: yaw, pitch, and roll are expressed in terms of Euler angles. Yaw, pitch, and roll are zero for a perfectly lateral fish facing right (i.e positive x-axis). \n",
    "\n",
    "Any given orientation can be described as a series of three rotations. The first rotation is yaw, which is the rotation of the fish about the z-axis (i.e. axis cutting vertically through fish from its top to bottom). Positive value means a counter-clockwise rotation looking from above down towards the upper-back of the fish i.e. dorsal fin. Second rotation is pitch, which is the axis cutting horizontally through the body of the fish from its right side to left side. Note that the axis of rotation here is defined AFTER the first yaw rotation. Positive value means a counter-clockwise rotation about the new positive y-axis i.e. fish is looking \"up\". Roll is the third rotation, which is rotation about the axis cutting longitudinally through the fish (i.e. tail notch through upper lip). A positive value means it is a counter-clockwise rotation about this axis, which is the new positive x-axis after the yaw and pitch rotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_range = [0.5, 10.0]\n",
    "\n",
    "yaw_range_deg = [-50, 50]\n",
    "pitch_range_deg = [-50, 50]\n",
    "roll_range_deg = [-50, 50]\n",
    "centroid_range_x = [-0.5, 0.5]\n",
    "centroid_range_y = [0.5, 1.5]\n",
    "centroid_range_z = [-0.5, 0.5]\n",
    "\n",
    "N = 5000\n",
    "jitter_std = 10\n",
    "\n",
    "dataset = defaultdict(list)\n",
    "for t in range(N):\n",
    "    \n",
    "    volume = np.random.uniform(*volume_range)\n",
    "    scaling_factor = volume**(1.0/3)\n",
    "    rescaled_3D_coordinates = scaling_factor * base_3D_coordinates\n",
    "    \n",
    "    yaw = deg_to_rad(np.random.uniform(*yaw_range_deg))\n",
    "    pitch = deg_to_rad(np.random.uniform(*pitch_range_deg))\n",
    "    roll = deg_to_rad(np.random.uniform(*roll_range_deg))\n",
    "    \n",
    "    new_centroid_position = np.array([np.random.uniform(*x) for x in (centroid_range_x, centroid_range_y, centroid_range_z)])\n",
    "    repositioned_3D_coords = rotate_and_reposition(rescaled_3D_coordinates, yaw, pitch, roll, new_centroid_position)\n",
    "    repositioned_X_left, repositioned_X_right = get_2D_coords_from_3D(repositioned_3D_coords, camera_metadata)\n",
    "    jittered_X_left, jittered_X_right = jitter_2D_coords(repositioned_X_left, repositioned_X_right, jitter_std)\n",
    "    jittered_3D_coords = get_3D_coords_from_2D(jittered_X_left, jittered_X_right, camera_metadata)\n",
    "    \n",
    "    # get local orientation (i.e. orientation of jittered key-points relative to \n",
    "    # rotated coordinate system where depth axis passes through fish medoid)\n",
    "    centered_3D_coords = center_3D_coordinates(jittered_3D_coords)\n",
    "    B = compute_orthonormal_basis(centered_3D_coords)\n",
    "    local_yaw, local_pitch, local_roll = rotation_matrix_to_euler_angles(B)\n",
    "    \n",
    "    # get global orientation (i.e. coordinate system's depth axis is aligned with \n",
    "    # camera line of sight)\n",
    "    B = compute_orthonormal_basis(jittered_3D_coords)\n",
    "    global_yaw, global_pitch, global_roll = rotation_matrix_to_euler_angles(B)\n",
    "    \n",
    "    dataset['X'].append(jittered_3D_coords.tolist())\n",
    "    dataset['y'].append(volume)\n",
    "    dataset['global_yaw'].append(rad_to_deg(yaw))\n",
    "    dataset['global_pitch'].append(rad_to_deg(pitch))\n",
    "    dataset['global_roll'].append(rad_to_deg(roll))\n",
    "    dataset['local_yaw'].append(rad_to_deg(local_yaw))\n",
    "    dataset['local_pitch'].append(rad_to_deg(local_pitch))\n",
    "    dataset['local_roll'].append(rad_to_deg(local_roll))\n",
    "    \n",
    "    if t % 1000 == 0:\n",
    "        print(t)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train neural network architecture </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    inputs = Input(shape=(24,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, train_config):\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct, val_pct, test_pct = 0.6, 0.2, 0.2\n",
    "train_idx = int(train_pct * df.shape[0])\n",
    "val_idx = int((train_pct + val_pct) * df.shape[0])\n",
    "train_mask = df.index < train_idx\n",
    "val_mask = (df.index >= train_idx) & (df.index < val_idx)\n",
    "test_mask = (df.index >= val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(df[train_mask].X.values))\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2], -1)\n",
    "y_train = df[train_mask].y.values\n",
    "\n",
    "X_val = np.array(list(df[val_mask].X.values))\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1]*X_val.shape[2], -1)\n",
    "y_val = df[val_mask].y.values\n",
    "\n",
    "X_test = np.array(list(df[test_mask].X.values))\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2], -1)\n",
    "y_test = df[test_mask].y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "train_config = dict(\n",
    "    epochs=1000,\n",
    "    batch_size=64, \n",
    "    learning_rate=1e-4,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "train_model(model, X_train, y_train, X_val, y_val, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor and get final hiddel layer weights.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "def convert_to_pytorch(model):\n",
    "    pytorch_model = Network()\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    pytorch_model.fc1.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "    pytorch_model.fc1.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "    pytorch_model.fc2.weight.data = torch.from_numpy(np.transpose(weights[2]))\n",
    "    pytorch_model.fc2.bias.data = torch.from_numpy(np.transpose(weights[3]))\n",
    "    pytorch_model.fc3.weight.data = torch.from_numpy(np.transpose(weights[4]))\n",
    "    pytorch_model.fc3.bias.data = torch.from_numpy(np.transpose(weights[5]))\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "    \n",
    "    return pytorch_model\n",
    "\n",
    "\n",
    "def apply_final_layer_ols(pytorch_model):\n",
    "    X_ols = pytorch_model.forward_intermediate(torch.from_numpy(X_train).float()).detach().numpy()\n",
    "    lr = LinearRegression().fit(X_ols, y_train)\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.array(lr.coef_).reshape(1, -1))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.array([lr.intercept_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = convert_to_pytorch(model)\n",
    "apply_final_layer_ols(pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Accuracy Reporting </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "df['y_pred'] = y_pred\n",
    "df['pct_error'] = (df.y_pred - df.y) / df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "pitch_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "roll_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "\n",
    "analysis_data = defaultdict(list)\n",
    "for yaw_low, yaw_high in zip(yaw_bucket_cutoffs, yaw_bucket_cutoffs[1:]):\n",
    "    for pitch_low, pitch_high in zip(pitch_bucket_cutoffs, pitch_bucket_cutoffs[1:]):\n",
    "        for roll_low, roll_high in zip(roll_bucket_cutoffs, roll_bucket_cutoffs[1:]):\n",
    "            \n",
    "            yaw_bucket = '{} <-> {}'.format(yaw_low, yaw_high)\n",
    "            pitch_bucket = '{} <-> {}'.format(pitch_low, pitch_high)\n",
    "            roll_bucket = '{} <-> {}'.format(roll_low, roll_high)\n",
    "            \n",
    "            yaw_mask = (df.yaw > yaw_low) & (df.yaw < yaw_high)\n",
    "            pitch_mask = (df.pitch > pitch_low) & (df.pitch < pitch_high)\n",
    "            roll_mask = (df.roll > roll_low) & (df.roll < roll_high)\n",
    "            orientation_mask = yaw_mask & pitch_mask & roll_mask\n",
    "            mean_error_pct = (df[orientation_mask].y_pred.mean() - df[orientation_mask].y.mean()) / df[orientation_mask].y.mean()\n",
    "            mean_abs_error_pct = np.mean(np.abs((df[orientation_mask].y_pred - df[orientation_mask].y) / df[orientation_mask].y))\n",
    "            \n",
    "            analysis_data['yaw_bucket'].append(yaw_bucket)\n",
    "            analysis_data['pitch_bucket'].append(pitch_bucket)\n",
    "            analysis_data['roll_bucket'].append(roll_bucket)\n",
    "            analysis_data['mean_error_pct'].append(mean_error_pct)\n",
    "            analysis_data['mean_abs_error_pct'].append(mean_abs_error_pct)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df.mean_error_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_heatmap(df, angle_1, angle_2, bucket_cutoffs_1, bucket_cutoffs_2):\n",
    "    heatmap_arr = np.zeros([len(bucket_cutoffs_1) - 1, len(bucket_cutoffs_2) - 1])\n",
    "\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        for j, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "            angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "            angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "            angle_1_mask = (df[angle_1] > angle_1_low) & (df[angle_1] < angle_1_high)\n",
    "            angle_2_mask = (df[angle_2] > angle_2_low) & (df[angle_2] < angle_2_high)\n",
    "            orientation_mask = angle_1_mask & angle_2_mask\n",
    "            mean_error_pct = (df[orientation_mask].y_pred.mean() - df[orientation_mask].y.mean()) / df[orientation_mask].y.mean()\n",
    "            heatmap_arr[i][j] = round(100 * mean_error_pct, 2)\n",
    "\n",
    "    angle_1_buckets = []\n",
    "    for i, angle_1_cutoffs in enumerate(zip(bucket_cutoffs_1, bucket_cutoffs_1[1:])):\n",
    "        angle_1_low, angle_1_high = angle_1_cutoffs\n",
    "        angle_1_bucket = '{} <-> {}'.format(angle_1_low, angle_1_high)\n",
    "        angle_1_buckets.append(angle_1_bucket)\n",
    "\n",
    "    angle_2_buckets = []\n",
    "    for i, angle_2_cutoffs in enumerate(zip(bucket_cutoffs_2, bucket_cutoffs_2[1:])):\n",
    "        angle_2_low, angle_2_high = angle_2_cutoffs\n",
    "        angle_2_bucket = '{} <-> {}'.format(angle_2_low, angle_2_high)\n",
    "        angle_2_buckets.append(angle_2_bucket)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_arr, xticklabels=angle_1_buckets, yticklabels=angle_2_buckets, annot=True)\n",
    "    plt.xlabel('{} range (degrees)'.format(angle_1))\n",
    "    plt.ylabel('{} range (degrees)'.format(angle_2))\n",
    "    plt.title('Error percentage (%) broken down by Orientation Bucket')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for low_roll, high_roll in zip(roll_bucket_cutoffs, roll_bucket_cutoffs[1:]):\n",
    "    print('Roll range: {} <-> {}'.format(low_roll, high_roll))\n",
    "    roll_mask = (df.roll > low_roll) & (df.roll < high_roll)\n",
    "    produce_heatmap(df[roll_mask].copy(deep=True), 'yaw', 'pitch', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df[test_mask].copy(deep=True), 'yaw', 'roll', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'yaw', 'roll', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'pitch', 'roll', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "# Generate fake data\n",
    "x = df[test_mask].y.values\n",
    "y = df[test_mask].y_pred.values\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Production Model Orientation Bias Assessment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_lib.utils.data_access_utils import S3AccessUtils\n",
    "from weight_estimation.utils import normalize_left_right_keypoint_arrs, stabilize_keypoints, convert_to_world_point_arr\n",
    "s3 = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb')\n",
    "weight_model = Network()\n",
    "weight_model.load_state_dict(torch.load(weight_model_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "y_pred = (weight_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "df['y_pred'] = y_pred\n",
    "df['pct_error'] = (df.y_pred - df.y) / df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_y = 4680\n",
    "preds, ys = [], []\n",
    "count = 0\n",
    "mask = (df.yaw.abs() < 5) & (df.pitch.abs() < 5) & (df.roll.abs() < 5)\n",
    "for idx, row in df[mask].iterrows():\n",
    "    X_left, X_right = get_2D_coords_from_3D(np.array(row.X), camera_metadata)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    pred = 1e4 * weight_model(nn_input).item() / base_y\n",
    "    preds.append(pred)\n",
    "    ys.append(row.y)\n",
    "    \n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaws, pitches, rolls, preds = [], [], [], []\n",
    "\n",
    "yaw_range_deg = [-50, 50]\n",
    "pitch_range_deg = [-50, 50]\n",
    "roll_range_deg = [-5, 5]\n",
    "\n",
    "for i in range(100000):\n",
    "    volume = 1.0\n",
    "    scaling_factor = volume**(1.0/3)\n",
    "    rescaled_3D_coordinates = scaling_factor * base_3D_coordinates\n",
    "    \n",
    "    yaw = deg_to_rad(np.random.uniform(*yaw_range_deg))\n",
    "    pitch = deg_to_rad(np.random.uniform(*pitch_range_deg))\n",
    "    roll = deg_to_rad(np.random.uniform(*roll_range_deg))\n",
    "    \n",
    "    new_centroid_position = np.array([np.random.uniform(*x) for x in (centroid_range_x, centroid_range_y, centroid_range_z)])\n",
    "    repositioned_3D_coords = rotate_and_reposition(rescaled_3D_coordinates, yaw, pitch, roll, new_centroid_position)\n",
    "    repositioned_X_left, repositioned_X_right = get_2D_coords_from_3D(repositioned_3D_coords, camera_metadata)\n",
    "    jittered_X_left, jittered_X_right = jitter_2D_coords(repositioned_X_left, repositioned_X_right, 10)\n",
    "    jittered_3D_coords = get_3D_coords_from_2D(jittered_X_left, jittered_X_right, camera_metadata)\n",
    "    \n",
    "    X_left, X_right = get_2D_coords_from_3D(jittered_3D_coords, camera_metadata)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    pred = 1e4 * weight_model(nn_input).item() / base_y\n",
    "    preds.append(pred)\n",
    "    yaws.append(rad_to_deg(yaw))\n",
    "    pitches.append(rad_to_deg(pitch))\n",
    "    rolls.append(rad_to_deg(roll))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf = pd.DataFrame({\n",
    "    'y_pred': preds,\n",
    "    'yaw': yaws,\n",
    "    'pitch': pitches,\n",
    "    'roll': rolls\n",
    "})\n",
    "\n",
    "kdf['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "pitch_bucket_cutoffs = np.arange(-50, 55, 5)\n",
    "roll_bucket_cutoffs = np.arange(-5, 5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(kdf, 'yaw', 'pitch', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Repeat training - reproduce plots above to see how picture changes when only random seed is altered </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "train_config = dict(\n",
    "    epochs=1000,\n",
    "    batch_size=64, \n",
    "    learning_rate=1e-4,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "train_model(model, X_train, y_train, X_val, y_val, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df.X.values))\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2], -1)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "df['y_pred'] = y_pred\n",
    "df['pct_error'] = (df.y_pred - df.y) / df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'yaw', 'pitch', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'yaw', 'roll', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_heatmap(df, 'pitch', 'roll', yaw_bucket_cutoffs, pitch_bucket_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_venv",
   "language": "python",
   "name": "local_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
