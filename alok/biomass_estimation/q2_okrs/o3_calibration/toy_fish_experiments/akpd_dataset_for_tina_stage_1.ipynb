{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from thumbnail_selector import PEN_SITE_MAPPING, get_capture_keys, get_image_urls_and_crop_metadatas, \\\n",
    "    get_random_image_urls_and_crop_metadatas\n",
    "from construct_fish_detection_dataset_o2kr2 import establish_plali_connection, insert_into_plali\n",
    "\n",
    "\n",
    "from video_service.video_generation import generate_video\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Set up stage 1 annotation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stage 1, we will only identify which 512x512 left images contain a full fish. These will then cascade onto stage 2 for full key-point annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prepare image URL data for 2020-02-13 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_video(89, '2020-02-13', 0, 24, 1.0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INBOUND_BUCKET = 'aquabyte-images-raw'\n",
    "\n",
    "def get_image_urls(capture_keys):\n",
    "    \"\"\"Gets left urls, right urls, and crop metadatas corresponding to capture keys.\"\"\"\n",
    "\n",
    "    left_urls, crop_metadatas = [], []\n",
    "    for capture_key in capture_keys:\n",
    "\n",
    "        # get image URLs\n",
    "        left_image_key = capture_key.replace('capture.json', 'left_frame.resize_512_512.jpg')\n",
    "        left_image_url = os.path.join('s3://', INBOUND_BUCKET, left_image_key)\n",
    "        left_urls.append(left_image_url)\n",
    "\n",
    "    return left_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id, start_date, end_date = 89, '2020-02-13', '2020-02-13'\n",
    "capture_keys = get_capture_keys(pen_id, start_date, end_date, inbound_bucket='aquabyte-images-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_to_include = [7, 8, 9, 10, 12, 13, 14, 15, 16]\n",
    "capture_keys_to_include = []\n",
    "for capture_key in capture_keys:\n",
    "    key_components = capture_key.split('/')\n",
    "    hour_component = [component for component in key_components if 'hour=' in component][0]\n",
    "    hour = int(hour_component[-2:])\n",
    "    if hour in hours_to_include:\n",
    "        capture_keys_to_include.append(capture_key)\n",
    "        \n",
    "image_urls = get_image_urls(capture_keys_to_include)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Insert into PLALI </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_into_plali_records(image_urls):\n",
    "\n",
    "    values_to_insert = []\n",
    "    for idx, image_url in enumerate(image_urls):\n",
    "        id = str(uuid.uuid4())\n",
    "        images = {image_url}\n",
    "        metadata = {}\n",
    "        priority = float(idx) / len(image_urls)\n",
    "\n",
    "        values = {\n",
    "            'id': id,\n",
    "            'workflow_id': '00000000-0000-0000-0000-000000000047',\n",
    "            'images': images,\n",
    "            'metadata': metadata,\n",
    "            'priority': priority\n",
    "        }\n",
    "\n",
    "        values_to_insert.append(values)\n",
    "\n",
    "    return values_to_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_insert = process_into_plali_records(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PLALI_SQL_CREDENTIALS'] = '/run/secrets/plali_sql_credentials.json'\n",
    "engine, sql_metadata = establish_plali_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert[2:], n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prepare image URL data for 2020-02-14 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_video(89, '2020-02-14', 0, 24, 1.0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id, start_date, end_date = 89, '2020-02-14', '2020-02-14'\n",
    "capture_keys = get_capture_keys(pen_id, start_date, end_date, inbound_bucket='aquabyte-images-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_to_include = [6, 7, 8, 9, 10, 11, 12]\n",
    "capture_keys_to_include = []\n",
    "for capture_key in capture_keys:\n",
    "    key_components = capture_key.split('/')\n",
    "    hour_component = [component for component in key_components if 'hour=' in component][0]\n",
    "    hour = int(hour_component[-2:])\n",
    "    \n",
    "    if hour == 6:\n",
    "        ts_component = [component for component in key_components if 'at=' in component][0]\n",
    "        minute = int(ts_component.split(':')[1])\n",
    "        if minute < 35: \n",
    "            continue\n",
    "    \n",
    "    if hour == 10:\n",
    "        ts_component = [component for component in key_components if 'at=' in component][0]\n",
    "        minute = int(ts_component.split(':')[1])\n",
    "        if minute > 30: \n",
    "            continue\n",
    "    if hour == 11:\n",
    "        ts_component = [component for component in key_components if 'at=' in component][0]\n",
    "        minute = int(ts_component.split(':')[1])\n",
    "        if minute < 28: \n",
    "            continue\n",
    "    \n",
    "    if hour in hours_to_include:\n",
    "        capture_keys_to_include.append(capture_key)\n",
    "        \n",
    "image_urls = get_image_urls(capture_keys_to_include)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_insert = process_into_plali_records(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert[2:], n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Complete right image annotations corresponding to left images that had a full fish bounding box <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RDSAccessUtils(json.load(open(os.environ['PLALI_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from plali.plali_annotations x\n",
    "    inner join \n",
    "    ( select a.id as plali_image_id, a.images, a.metadata, b.id as workflow_id, b.name from plali.plali_images a\n",
    "    inner join plali.plali_workflows b\n",
    "    on a.workflow_id = b.id ) y\n",
    "    on x.plali_image_id = y.plali_image_id\n",
    "    where workflow_id = '00000000-0000-0000-0000-000000000047';\n",
    "\"\"\"\n",
    "\n",
    "annotated_df = rds.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Confirm from random subset that annotations are well-behaved </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['annotation_count'] = annotated_df.annotation.apply(lambda x: len(x['annotations']) if x.get('annotations') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only on images in which full fish was found\n",
    "mask = annotated_df.annotation_count == 1\n",
    "for idx, row in annotated_df[mask].head(10).iterrows():\n",
    "    \n",
    "    # download image\n",
    "    image_s3_url = row.images[0]\n",
    "    url_components = image_s3_url.replace('s3://', '').split('/')\n",
    "    bucket = url_components[0]\n",
    "    key = os.path.join(*url_components[1:])\n",
    "    image_f = s3.download_from_s3(bucket, key)\n",
    "    \n",
    "    # plot image\n",
    "    fig, ax = plt.subplots()\n",
    "    im = cv2.imread(image_f)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(im)\n",
    "    \n",
    "    # plot rectangle\n",
    "    ann = row.annotation['annotations'][0]\n",
    "    x, y, w, h = ann['xCrop'], ann['yCrop'], ann['width'], ann['height']\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get list of right image URLs for full fish </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_image_s3_urls = []\n",
    "\n",
    "mask = annotated_df.annotation_count == 1\n",
    "for idx, row in annotated_df[mask].iterrows():\n",
    "    image_s3_url = row.images[0]\n",
    "    if 'left_frame' in image_s3_url:\n",
    "        right_image_s3_url = image_s3_url.replace('left_frame', 'right_frame')\n",
    "        right_image_s3_urls.append(right_image_s3_url)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_insert = process_into_plali_records(right_image_s3_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert, n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(values_to_insert[0]['images'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert, n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_insert_modified = []\n",
    "for v in values_to_insert:\n",
    "    v_modified = dict(v)\n",
    "    v_modified['images'] = list(v['images'])\n",
    "    values_to_insert_modified.append(v_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(values_to_insert_modified, open('/root/data/alok/biomass_estimation/playground/values_to_insert.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
