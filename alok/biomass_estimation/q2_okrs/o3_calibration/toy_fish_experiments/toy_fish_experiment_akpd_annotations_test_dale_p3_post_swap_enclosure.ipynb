{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../q1_o2kr2_dataset_annotations/')\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "import uuid\n",
    "from construct_fish_detection_dataset_o2kr2 import establish_plali_connection, insert_into_plali\n",
    "from rectification import rectify\n",
    "from weight_estimation.weight_estimator import WeightEstimator, CameraMetadata\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get raw images from toy fish experiment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'environment=production/site-id=55/pen-id=102/hour=11'\n",
    "suffixes = ['frame.jpg']\n",
    "keygen = s3.get_matching_s3_keys('aquabyte-images-raw', prefix, suffixes=suffixes)\n",
    "keys = []\n",
    "for key in keygen:\n",
    "    keys.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pair_dict = defaultdict(dict)\n",
    "for key in keys:\n",
    "    dirname = os.path.dirname(key)\n",
    "    if 'left' in key:\n",
    "        image_pair_dict[dirname]['left'] = key\n",
    "    elif 'right' in key:\n",
    "        image_pair_dict[dirname]['right'] = key\n",
    "    else:\n",
    "        raise Exception('Key not valid')\n",
    "        \n",
    "image_pairs = []\n",
    "for dirname in sorted(list(image_pair_dict.keys())):\n",
    "    keys = image_pair_dict[dirname]\n",
    "    try:\n",
    "        image_pairs.append((keys['left'], keys['right']))\n",
    "    except KeyError as err:\n",
    "        print(err)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Check frames </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url):\n",
    "    image_s3_url = image_url\n",
    "    url_components = image_s3_url.replace('s3://', '').split('/')\n",
    "    bucket = url_components[0]\n",
    "    key = os.path.join(*url_components[1:])\n",
    "    image_f = s3.download_from_s3(bucket, key)\n",
    "    return image_f\n",
    "\n",
    "\n",
    "def plot_stereo_image(left_image_f, right_image_f):\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    \n",
    "    # show left image\n",
    "    left_im = cv2.imread(left_image_f)\n",
    "    left_im = cv2.cvtColor(left_im, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(left_im)\n",
    "    \n",
    "    # show right image\n",
    "    right_im = cv2.imread(right_image_f)\n",
    "    right_im = cv2.cvtColor(right_im, cv2.COLOR_BGR2RGB)\n",
    "    axes[1].imshow(right_im)\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for left_key, right_key in image_pairs:\n",
    "    print(idx)\n",
    "    idx += 1\n",
    "    \n",
    "    left_full_res_frame_s3_url, right_full_res_frame_s3_url = [os.path.join('s3://', 'aquabyte-images-raw', key) for key in (left_key, right_key)]\n",
    "    left_frame_s3_url, right_frame_s3_url = [x.replace('.jpg', '.resize_512_512.jpg') for x in (left_full_res_frame_s3_url, right_full_res_frame_s3_url)]\n",
    "    \n",
    "    # download left image\n",
    "    left_image_f = download_image(left_frame_s3_url)\n",
    "    right_image_f = download_image(right_frame_s3_url)\n",
    "    \n",
    "    # plot image\n",
    "    plot_stereo_image(left_image_f, right_image_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Rectify raw images and upload to s3 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_s3_url(s3_url):\n",
    "    url_components = s3_url.replace('s3://', '').split('/')\n",
    "    bucket = url_components[0]\n",
    "    key = os.path.join(*url_components[1:])\n",
    "    f = s3.download_from_s3(bucket, key)\n",
    "    return f, bucket, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_rectified_s3_urls, right_image_rectified_s3_urls = [], []\n",
    "stereo_parameters_url = 'https://aquabyte-abc.s3-eu-west-1.amazonaws.com/rook/2021-03-10T13%3A57%3A48Z-pfe-1421920048928-187-4bd8/cal_output/2021-03-10T14-07-03.821272000Z/stereo_params.json'.replace('%3A', ':')\n",
    "count = 0\n",
    "\n",
    "for left_key, right_key in image_pairs:\n",
    "    \n",
    "    # get unrectified full resolution frames\n",
    "    left_full_res_frame_s3_url, right_full_res_frame_s3_url = [os.path.join('s3://', 'aquabyte-images-raw', key) for key in (left_key, right_key)]\n",
    "    left_full_res_frame_f, _, left_full_res_frame_key = download_from_s3_url(left_full_res_frame_s3_url)\n",
    "    right_full_res_frame_f, _, right_full_res_frame_key = download_from_s3_url(right_full_res_frame_s3_url)\n",
    "    stereo_parameters_f, _, _ = s3.download_from_url(stereo_parameters_url)\n",
    "    \n",
    "    # rectify into full resolution stereo frame pair and save to disk\n",
    "    left_image_rectified, right_image_rectified = rectify(left_full_res_frame_f, right_full_res_frame_f, stereo_parameters_f)\n",
    "    left_image_rectified_f = os.path.join(os.path.dirname(left_full_res_frame_f), 'left_frame.rectified.jpg')\n",
    "    right_image_rectified_f = os.path.join(os.path.dirname(right_full_res_frame_f), 'right_frame.rectified.jpg')\n",
    "    cv2.imwrite(left_image_rectified_f, left_image_rectified)\n",
    "    cv2.imwrite(right_image_rectified_f, right_image_rectified)\n",
    "    \n",
    "    # upload rectified stereo frame pairs to s3\n",
    "    left_rectified_full_res_frame_key = left_full_res_frame_key.replace('.jpg', '.rectified.jpg')\n",
    "    right_rectified_full_res_frame_key = right_full_res_frame_key.replace('.jpg', '.rectified.jpg')\n",
    "    s3.s3_client.upload_file(left_image_rectified_f, 'aquabyte-images-raw', left_rectified_full_res_frame_key)\n",
    "    s3.s3_client.upload_file(right_image_rectified_f, 'aquabyte-images-raw', right_rectified_full_res_frame_key)\n",
    "    \n",
    "    # append to url lists\n",
    "    left_image_rectified_s3_url = os.path.join('s3://', 'aquabyte-images-raw', left_rectified_full_res_frame_key)\n",
    "    right_image_rectified_s3_url = os.path.join('s3://', 'aquabyte-images-raw', right_rectified_full_res_frame_key)\n",
    "    left_image_rectified_s3_urls.append(left_image_rectified_s3_url)\n",
    "    right_image_rectified_s3_urls.append(right_image_rectified_s3_url)\n",
    "    \n",
    "    print(count)\n",
    "    count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Insert into PLALI for key-point annotation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_into_plali_records(image_url_pairs, workflow_id):\n",
    "\n",
    "    values_to_insert = []\n",
    "    for idx, image_url_pair in enumerate(image_url_pairs):\n",
    "        id = str(uuid.uuid4())\n",
    "        images = set(image_url_pair)\n",
    "        metadata = { 'type': 'Dale P3 post-swap enclosure' }\n",
    "        priority = float(idx) / len(image_url_pairs)\n",
    "\n",
    "        values = {\n",
    "            'id': id,\n",
    "            'workflow_id': workflow_id,\n",
    "            'images': images,\n",
    "            'metadata': metadata,\n",
    "            'priority': priority\n",
    "        }\n",
    "\n",
    "        values_to_insert.append(values)\n",
    "\n",
    "    return values_to_insert\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_pairs = list(zip(left_image_rectified_s3_urls, right_image_rectified_s3_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_ID = '00000000-0000-0000-0000-000000000055'\n",
    "values_to_insert = process_into_plali_records(image_url_pairs, WORKFLOW_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PLALI_SQL_CREDENTIALS'] = '/run/secrets/plali_sql_credentials'\n",
    "\n",
    "engine, sql_metadata = establish_plali_connection()\n",
    "\n",
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert[:], n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.images.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Calculate weights </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Parse annotations into standard form </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PLALI_SQL_CREDENTIALS'] = '/run/secrets/plali_sql_credentials'\n",
    "rds = RDSAccessUtils(json.load(open(os.environ['PLALI_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from plali.plali_annotations x\n",
    "    inner join \n",
    "    ( select a.id as plali_image_id, a.images, a.metadata, b.id as workflow_id, b.name from plali.plali_images a\n",
    "    inner join plali.plali_workflows b\n",
    "    on a.workflow_id = b.id ) y\n",
    "    on x.plali_image_id = y.plali_image_id\n",
    "    where workflow_id = '00000000-0000-0000-0000-000000000055';\n",
    "\"\"\"\n",
    "\n",
    "annotated_df = rds.extract_from_database(query)\n",
    "annotated_df = annotated_df[annotated_df.metadata.apply(lambda x: x.get('type') is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationFormatError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "anns = []\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    try:\n",
    "        raw_ann = row.annotation\n",
    "        if 'skipReasons' in raw_ann:\n",
    "            raise AnnotationFormatError\n",
    "\n",
    "        ann = {'leftCrop': [], 'rightCrop': []}\n",
    "\n",
    "        for side in ['leftCrop', 'rightCrop']:\n",
    "            for raw_item in row.annotation[side]['annotation']['annotations']:\n",
    "                if 'xCrop' not in raw_item or 'yCrop' not in raw_item:\n",
    "                    raise AnnotationFormatError\n",
    "                item = {\n",
    "                    'xCrop': raw_item['xCrop'],\n",
    "                    'yCrop': raw_item['yCrop'],\n",
    "                    'xFrame': raw_item['xCrop'],\n",
    "                    'yFrame': raw_item['yCrop'],\n",
    "                    'keypointType': raw_item['category']\n",
    "                }\n",
    "                \n",
    "                ann[side].append(item)\n",
    "\n",
    "        if any([len(ann[side]) != 11 for side in ['leftCrop', 'rightCrop']]):\n",
    "            raise AnnotationFormatError\n",
    "        \n",
    "        anns.append(ann)\n",
    "        \n",
    "    except AnnotationFormatError as err:\n",
    "        anns.append(None)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['ann'] = anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Check annotations / disparity values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is not None:\n",
    "        left_mean_x = np.mean([item['xFrame'] for item in ann['leftCrop']])\n",
    "        right_mean_x = np.mean([item['xFrame'] for item in ann['rightCrop']])\n",
    "        print(left_mean_x - right_mean_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Compute weights </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_parameters_url = 'https://aquabyte-abc.s3-eu-west-1.amazonaws.com/rook/2021-03-10T13%3A57%3A48Z-pfe-1421920048928-187-4bd8/cal_output/2021-03-10T14-07-03.821272000Z/stereo_params.json'.replace('%3A', ':')\n",
    "stereo_parameters_f, _, _ = s3.download_from_url(stereo_parameters_url)\n",
    "\n",
    "stereo_params = json.load(open(stereo_parameters_f))\n",
    "camera_metadata = {\n",
    "    'focalLengthPixel': stereo_params['CameraParameters1']['FocalLength'][0],\n",
    "    'baseline': abs(stereo_params['TranslationOfCamera2'][0] / 1e3),\n",
    "    'focalLength': stereo_params['CameraParameters1']['FocalLength'][0] * 3.45e-6,\n",
    "    'pixelCountWidth': 4096,\n",
    "    'pixelCountHeight': 3000,\n",
    "    'imageSensorWidth': 0.01412,\n",
    "    'imageSensorHeight': 0.01035\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb')\n",
    "kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/trained_models/2020-08-08T000000/kf_predictor_v2.pb')\n",
    "weight_estimator = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "pred_weights, pred_kfs = [], []\n",
    "\n",
    "count = 0\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is not None:\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        weight, _, kf = weight_estimator.predict(ann, cm)\n",
    "        pred_weights.append(weight)\n",
    "        pred_kfs.append(kf)\n",
    "    else:\n",
    "        pred_weights.append(None)\n",
    "        pred_kfs.append(None)\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['weight'] = pred_weights\n",
    "annotated_df['kf'] = pred_kfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['weight'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['kf'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Calculate length </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "\n",
    "def calculate_length_1(ann, cm):\n",
    "    if ann is None:\n",
    "        return None\n",
    "\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    return np.linalg.norm(wkps['UPPER_LIP'] - wkps['TAIL_NOTCH'])\n",
    "\n",
    "def calculate_length_2(ann, cm):\n",
    "    if ann is None:\n",
    "        return None\n",
    "\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    return np.linalg.norm(wkps['DORSAL_FIN'] - wkps['PELVIC_FIN'])\n",
    "\n",
    "def calculate_length_3(ann, cm):\n",
    "    if ann is None:\n",
    "        return None\n",
    "\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    return np.linalg.norm(wkps['ADIPOSE_FIN'] - wkps['PELVIC_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['length_1'] = annotated_df.ann.apply(lambda x: calculate_length_1(x, camera_metadata))\n",
    "annotated_df['length_2'] = annotated_df.ann.apply(lambda x: calculate_length_2(x, camera_metadata))\n",
    "annotated_df['length_3'] = annotated_df.ann.apply(lambda x: calculate_length_3(x, camera_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotated_df.length_1.median())\n",
    "print(annotated_df.length_2.median())\n",
    "print(annotated_df.length_3.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(annotated_df['length_3'], bins=50)\n",
    "plt.xlim([0.06, 0.1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth(ann, cm):\n",
    "    if ann is None:\n",
    "        return None\n",
    "\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    return np.median([x[1] for x in wkps.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['length_1'] = annotated_df.ann.apply(lambda x: calculate_length_1(x, camera_metadata))\n",
    "annotated_df['length_2'] = annotated_df.ann.apply(lambda x: calculate_length_2(x, camera_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(annotated_df['length_3'], bins=200)\n",
    "plt.xlim(0.12, 0.15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['length_2'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.xlim([0.125, 0.2])\n",
    "plt.hist(annotated_df['length_2'], bins=200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['length'] = annotated_df.ann.apply(lambda x: calculate_length(x, camera_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['depth'] = annotated_df.ann.apply(lambda x: calculate_depth(x, camera_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(annotated_df.weight, bins=20)\n",
    "plt.axvline(annotated_df.weight.median(), color='red', linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(annotated_df.length, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.length.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in annotated_df.weight:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Unrectify and Re-rectify </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def load_params(params):\n",
    "    print(\"Loading params...\")\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "\n",
    "    imageSize = (4096, 3000)\n",
    "\n",
    "    # perform rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, None, None, None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "\n",
    "    print(\"Params loaded.\")\n",
    "    return left_maps, right_maps\n",
    "\n",
    "IMAGE_WIDTH = 4096\n",
    "IMAGE_HEIGHT = 3000\n",
    "\n",
    "def get_camera_parameters(params: dict) -> Tuple:\n",
    "    \"\"\"Return individual camera parameters from JSON stereo parameters contents.\"\"\"\n",
    "    \n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "    \n",
    "    imageSize = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, \n",
    "                                                               distCoeffs2, imageSize, R, T, None, None, \n",
    "                                                               None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "    \n",
    "    return left_maps, right_maps, cameraMatrix1, distCoeffs1, R1, P1, cameraMatrix2, distCoeffs2, R2, P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_parameters_o_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40020184_R40029797/2021-02-25T11%3A54%3A31.569694000Z_L40020184_R40029797_stereo-parameters.json'.replace('%3A', ':')\n",
    "stereo_parameters_n_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40029797_R40020184/2021-02-25T11%3A30%3A42.149694000Z_L40029797_R40020184_stereo-parameters.json'.replace('%3A', ':')\n",
    "\n",
    "stereo_parameters_o_f, _, _ = s3.download_from_url(stereo_parameters_o_url)\n",
    "stereo_parameters_n_f, _, _ = s3.download_from_url(stereo_parameters_n_url)\n",
    "\n",
    "stereo_params_o = json.load(open(stereo_parameters_o_f))\n",
    "stereo_params_n = json.load(open(stereo_parameters_n_f))\n",
    "left_maps_o, right_maps_o, cameraMatrix1_o, distCoeffs1_o, R1_o, P1_o, cameraMatrix2_o, distCoeffs2_o, R2_o, P2_o = get_camera_parameters(stereo_params_o)\n",
    "left_maps_n, right_maps_n, cameraMatrix1_n, distCoeffs1_n, R1_n, P1_n, cameraMatrix2_n, distCoeffs2_n, R2_n, P2_n = get_camera_parameters(stereo_params_n)\n",
    "\n",
    "ann_u_rs = []\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is None:\n",
    "        ann_u_rs.append(None)\n",
    "        continue\n",
    "    \n",
    "    # un-rectify with matlab params, re-rectify with circular params\n",
    "    ann_u_r = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann[side]:\n",
    "            bp = item['keypointType']\n",
    "            x = item['xFrame']\n",
    "            y = item['yFrame']\n",
    "            if side == 'leftCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[left_maps_o[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix1_n, distCoeffs1_n, R=R1_n, P=P1_n)[0][0]\n",
    "            elif side == 'rightCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[right_maps_o[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix2_n, distCoeffs2_n, R=R2_n, P=P2_n)[0][0]\n",
    "                \n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            ann_u_r[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new,\n",
    "            })\n",
    "    \n",
    "    ann_u_rs.append(ann_u_r)\n",
    "\n",
    "annotated_df['ann_u_r'] = ann_u_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_parameters_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40020184_R40029797/2021-02-19T13:20:20.603005000Z_L40020184_R40029797_stereo-parameters.json'\n",
    "stereo_parameters_f, _, _ = s3.download_from_url(stereo_parameters_url)\n",
    "\n",
    "stereo_params = json.load(open(stereo_parameters_f))\n",
    "camera_metadata = {\n",
    "    'focalLengthPixel': stereo_params['CameraParameters1']['FocalLength'][0],\n",
    "    'baseline': abs(stereo_params['TranslationOfCamera2'][0] / 1e3),\n",
    "    'focalLength': stereo_params['CameraParameters1']['FocalLength'][0] * 3.45e-6,\n",
    "    'pixelCountWidth': 4096,\n",
    "    'pixelCountHeight': 3000,\n",
    "    'imageSensorWidth': 0.01412,\n",
    "    'imageSensorHeight': 0.01035\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb')\n",
    "kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/trained_models/2020-08-08T000000/kf_predictor_v2.pb')\n",
    "weight_estimator = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "pred_weights = []\n",
    "\n",
    "count = 0\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann_u_r\n",
    "    if ann is not None:\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        weight, _, _ = weight_estimator.predict(ann, cm)\n",
    "        pred_weights.append(weight)\n",
    "    else:\n",
    "        pred_weights.append(None)\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['weight_u_r'] = pred_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight_u_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(annotated_df.weight_u_r.values, bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, ann, overlay_keypoints=True, show_labels=True):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    \n",
    "    left_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['leftCrop']}\n",
    "    right_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['rightCrop']}\n",
    "    \n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is None:\n",
    "        continue\n",
    "    \n",
    "    left_image_s3_url = row.images[0]\n",
    "    right_image_s3_url = row.images[1]\n",
    "    left_image_key = os.path.join(*left_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    right_image_key = os.path.join(*right_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    left_image_key, right_image_key = sorted([left_image_key, right_image_key])\n",
    "    left_image_f = s3.download_from_s3('aquabyte-images-raw', left_image_key)\n",
    "    right_image_f = s3.download_from_s3('aquabyte-images-raw', right_image_key)\n",
    "    \n",
    "    print(row.length_2)\n",
    "    display_crops(left_image_f, right_image_f, ann)\n",
    "    \n",
    "#     if count > 10:\n",
    "#         break\n",
    "    count += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_depth(df):\n",
    "    yaws, pitches, rolls, depths = [], [], [], []\n",
    "    for idx, row in df.iterrows():\n",
    "#         ann, cm = row.annotation, row.camera_metadata\n",
    "        ann, cm = row.ann, camera_metadata\n",
    "        try:\n",
    "            world_keypoints = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "            depth = np.median([x[1] for x in world_keypoints.values()])\n",
    "            u = world_keypoints['DORSAL_FIN'] - world_keypoints['PELVIC_FIN']\n",
    "            v = world_keypoints['UPPER_LIP'] - world_keypoints['TAIL_NOTCH']\n",
    "            yaw = np.arctan(v[1] / abs(v[0])) * (180.0 / np.pi)\n",
    "            pitch = np.arctan(v[2] / abs(v[0])) * (180.0 / np.pi)\n",
    "            roll = np.arctan(u[1] / u[0]) * (180.0 / np.pi)\n",
    "        except TypeError as err:\n",
    "            yaw, pitch, roll, depth = None, None, None, None\n",
    "        yaws.append(yaw)\n",
    "        pitches.append(pitch)\n",
    "        depths.append(depth)\n",
    "        rolls.append(roll)\n",
    "        \n",
    "    df['yaw'] = yaws\n",
    "    df['pitch'] = pitches\n",
    "    df['roll'] = rolls\n",
    "    df['depth'] = depths\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(annotated_df.yaw, annotated_df.weight)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df[annotated_df.roll.abs() < 10].weight.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(annotated_df.pitch)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(annotated_df[mask].depth, annotated_df[mask].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "mask = annotated_df.length_2 < 0.2\n",
    "plt.scatter(annotated_df[mask].length_2, annotated_df[mask].weight)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate video </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DIR = '/root/data/s3'\n",
    "OUTPUT_BASE_DIR = '/root/data/alok/biomass_estimation/playground/toy_fish_video_dale_post_swap_enclosure'\n",
    "WIDTH = 512\n",
    "\n",
    "def stitch_frames(left_thumbnail_f, right_thumbnail_f, weight):\n",
    "\n",
    "    # open images and metadata files\n",
    "    left_im = Image.open(left_thumbnail_f)\n",
    "    right_im = Image.open(right_thumbnail_f)\n",
    "\n",
    "    # stitch images\n",
    "    result = Image.new('RGB', (2 * WIDTH, WIDTH))\n",
    "    result.paste(im=left_im, box=(0, 0))\n",
    "    result.paste(im=right_im, box=(WIDTH, 0))\n",
    "\n",
    "    # write timestamp on stitched image\n",
    "    result_draw = ImageDraw.Draw(result)\n",
    "#     selected_font = \"arial.ttf\"\n",
    "#     font_size = 30\n",
    "#     font = ImageFont.truetype(selected_font, font_size)\n",
    "    result_draw.text((0, 0), '{} g'.format(str(weight)), (255, 255, 255))\n",
    "\n",
    "    output_f = left_thumbnail_f.replace(S3_DIR, OUTPUT_BASE_DIR).replace('left_', 'stereo_')\n",
    "    if not os.path.exists(os.path.dirname(output_f)):\n",
    "        os.makedirs(os.path.dirname(output_f))\n",
    "    result.save(output_f)\n",
    "    return output_f\n",
    "    \n",
    "\n",
    "def stitch_frames_into_video(image_fs, video_f):\n",
    "    im = cv2.imread(image_fs[0])\n",
    "    height, width, layers = im.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video = cv2.VideoWriter(video_f, fourcc, 1, (width, height), True)\n",
    "    for idx, image_f in enumerate(image_fs):\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "        im = cv2.imread(image_f, cv2.IMREAD_COLOR)\n",
    "        video.write(im)\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~annotated_df.ann.isnull()\n",
    "output_fs = []\n",
    "for idx, row in annotated_df[mask].iterrows():\n",
    "    left_image_s3_url = row.images[0]\n",
    "    right_image_s3_url = row.images[1]\n",
    "    weight = round(row.weight, 2)\n",
    "    left_image_key = os.path.join(*left_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    right_image_key = os.path.join(*right_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    left_thumbnail_key, right_thumbnail_key = [x.replace('.rectified.jpg', '.resize_512_512.jpg') for x in (left_image_key, right_image_key)\n",
    "                                              ]\n",
    "    left_thumbnail_f = s3.download_from_s3('aquabyte-images-raw', left_thumbnail_key)\n",
    "    right_thumbnail_f = s3.download_from_s3('aquabyte-images-raw', right_thumbnail_key)\n",
    "    \n",
    "    output_f = stitch_frames(left_thumbnail_f, right_thumbnail_f, weight)\n",
    "    output_fs.append(output_f)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[output_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_frames_into_video(sorted(output_fs), '/root/data/alok/biomass_estimation/playground/toy_fish_video_dale_post_swap_enclosure/toy_fish_video_dale_post_swap_enclosure.avi')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight_u_r.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
