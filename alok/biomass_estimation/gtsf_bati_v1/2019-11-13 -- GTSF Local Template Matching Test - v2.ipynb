{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "# from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "from copy import copy\n",
    "from scipy.stats import norm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from multiprocessing import Pool, Manager\n",
    "import matplotlib.cm as cm\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extract base data from database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null and b.is_qa = false;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Sample Template Matching Results </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import datetime\n",
    "import json, os\n",
    "\n",
    "import boto3\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import psycopg2.extras\n",
    "import psycopg2\n",
    "\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import convert_to_world_point, depth_from_disp, pixel2world, euclidean_distance\n",
    "\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image\n",
    "\n",
    "def crop_images(imageL, imageR, left_crop_metadata, right_crop_metadata, left_keypoints_dict=None, \n",
    "    right_keypoints_dict=None, PADDING=100):\n",
    "    \n",
    "    # crop the data\n",
    "    l_width = left_crop_metadata['width']\n",
    "    l_height = left_crop_metadata['height']\n",
    "    r_width = right_crop_metadata['width']\n",
    "    r_height = right_crop_metadata['height']\n",
    "    \n",
    "    cropL_x_left = max(min([kp[0] for kp in left_keypoints_dict.values()]) - PADDING, 0)\n",
    "    cropL_x_right = min(max([kp[0] for kp in left_keypoints_dict.values()]) + PADDING, l_width)\n",
    "    cropL_y_top = max(min([kp[1] for kp in left_keypoints_dict.values()]) - PADDING, 0)\n",
    "    cropL_y_bottom = min(max([kp[1] for kp in left_keypoints_dict.values()]) + PADDING, l_height)\n",
    "\n",
    "    cropR_x_left = max(min([kp[0] for kp in right_keypoints_dict.values()]) - PADDING, 0)\n",
    "    cropR_x_right = min(max([kp[0] for kp in right_keypoints_dict.values()]) + PADDING, r_width)\n",
    "    cropR_y_top = max(min([kp[1] for kp in right_keypoints_dict.values()]) - PADDING, 0)\n",
    "    cropR_y_bottom = min(max([kp[1] for kp in right_keypoints_dict.values()]) + PADDING, r_height)\n",
    "\n",
    "    imageL = imageL[cropL_y_top:cropL_y_bottom, cropL_x_left:cropL_x_right]\n",
    "    imageR = imageR[cropR_y_top:cropR_y_bottom, cropR_x_left:cropR_x_right]\n",
    "\n",
    "    return imageL, imageR, cropL_x_left, cropL_y_top, cropR_x_left, cropR_y_top\n",
    "\n",
    "\n",
    "def get_body_keypoints(kp1, kp2, matches, matchesMask, left_crop_metadata, right_crop_metadata): \n",
    "    kps = []\n",
    "    for i, m in enumerate(matches):\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.            \n",
    "        if matchesMask[i] == 1:\n",
    "            p1 = tuple(np.round(kp1[m.queryIdx].pt).astype(float))\n",
    "            p2 = tuple(np.round(kp2[m.trainIdx].pt).astype(float))\n",
    "            p1_x_frame = p1[0] + left_crop_metadata['x_coord']\n",
    "            p1_y_frame = p1[1] + left_crop_metadata['y_coord']\n",
    "            p2_x_frame = p2[0] + right_crop_metadata['x_coord']\n",
    "            p2_y_frame = p2[1] + right_crop_metadata['y_coord']\n",
    "            disp = abs(p1_x_frame - p2_x_frame)\n",
    "            kp = [p1_x_frame, p1_y_frame, p2_x_frame, p2_y_frame]\n",
    "            kps.append(kp)\n",
    "    \n",
    "    return kps\n",
    "\n",
    "def get_modified_crop_metadata(left_crop_metadata, right_crop_metadata, cropL_x_left, cropL_y_top, cropR_x_left, cropR_y_top):\n",
    "    modified_left_crop_metadata = {\n",
    "        'x_coord': left_crop_metadata['x_coord'] + cropL_x_left,\n",
    "        'y_coord': left_crop_metadata['y_coord'] + cropL_y_top\n",
    "    }\n",
    "\n",
    "    modified_right_crop_metadata = {\n",
    "        'x_coord': right_crop_metadata['x_coord'] + cropR_x_left,\n",
    "        'y_coord': right_crop_metadata['y_coord'] + cropR_y_top\n",
    "    }\n",
    "\n",
    "    return modified_left_crop_metadata, modified_right_crop_metadata\n",
    "\n",
    "\n",
    "\n",
    "def find_matches_and_homography(imageL, imageR, cm, left_crop_metadata, right_crop_metadata, keypoints=None,\n",
    "    MIN_MATCH_COUNT=11, GOOD_PERC=0.7, FLANN_INDEX_KDTREE=0):\n",
    "\n",
    "    if keypoints is not None:\n",
    "        if 'leftCrop' in keypoints and 'rightCrop' in keypoints:\n",
    "            left_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['leftCrop']}\n",
    "            right_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['rightCrop']}\n",
    "            \n",
    "            # crop images to speed up the template matching process\n",
    "            imageL, imageR, cropL_x_left, cropL_y_top, cropR_x_left, cropR_y_top = \\\n",
    "                crop_images(imageL, imageR, left_crop_metadata, right_crop_metadata, left_keypoints_dict, right_keypoints_dict)\n",
    "\n",
    "            modified_left_crop_metadata, modified_right_crop_metadata = \\\n",
    "                get_modified_crop_metadata(left_crop_metadata, right_crop_metadata, cropL_x_left, cropL_y_top, cropR_x_left, cropR_y_top)\n",
    "\n",
    "        print(left_crop_metadata)\n",
    "        print(modified_left_crop_metadata)\n",
    "    else:\n",
    "        modified_left_crop_metadata, modified_right_crop_metadata = left_crop_metadata, right_crop_metadata\n",
    "\n",
    "    \n",
    "    # find template matches\n",
    "    sift = cv2.KAZE_create()\n",
    "    img1 = enhance(imageL)\n",
    "    img2 = enhance(imageR)\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2, k=2)\n",
    "    good = []\n",
    "    matchesMask = []\n",
    "    \n",
    "    for m,n in matches:\n",
    "        if m.distance < GOOD_PERC*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>=MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1, 1 ,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        if H is None:\n",
    "            return [[[]]]\n",
    "        H = H.tolist()\n",
    "        kps = get_body_keypoints(kp1, kp2, good, matchesMask, modified_left_crop_metadata, modified_right_crop_metadata)\n",
    "        return [H, kps]\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        return [[[]]]\n",
    "\n",
    "    return [[[]]]\n",
    "\n",
    "\n",
    "def get_wkps(kps, cm): \n",
    "    wkps = []\n",
    "    for kp in kps:\n",
    "        p1_x_frame, p1_y_frame, p2_x_frame, p2_y_frame = kp\n",
    "        disp = abs(p1_x_frame - p2_x_frame)\n",
    "        depth = depth_from_disp(disp, cm)\n",
    "        wkp = convert_to_world_point(p1_x_frame, p1_y_frame, depth, cm)\n",
    "        wkps.append(list(wkp))\n",
    "        \n",
    "    return wkps\n",
    "\n",
    "\n",
    "def determine_fish_distance(kps, cm):    \n",
    "    wkps = get_wkps(kps, cm)\n",
    "    dist = np.median([wkp[1] for wkp in wkps])\n",
    "    return dist\n",
    "\n",
    "\n",
    "def main():\n",
    "    s3_access_utils = S3AccessUtils('/root/data')\n",
    "    rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT * FROM prod.crop_annotation ca\n",
    "        INNER JOIN prod.annotation_state pas on pas.id=ca.annotation_state_id\n",
    "        WHERE ca.service_id = (SELECT ID FROM prod.service where name='LATI')\n",
    "        AND ca.left_crop_url is not null\n",
    "        AND ca.right_crop_url is not null\n",
    "        AND ca.pen_id = 64\n",
    "        AND (ca.annotation_state_id=6 OR ca.annotation_state_id=7)\n",
    "        AND ca.captured_at > '2019-09-01'\n",
    "        LIMIT 2;\n",
    "    \"\"\"\n",
    "\n",
    "    df = rds_access_utils.extract_from_database(query)\n",
    "    distances_from_camera = []\n",
    "    for idx, row in df.iterrows():\n",
    "        left_image_url, right_image_url = row.left_crop_url, row.right_crop_url\n",
    "        left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "        keypoints = row.keypoints\n",
    "        cm = row.camera_metadata\n",
    "\n",
    "        left_image_f, _, _ = s3_access_utils.download_from_url(left_image_url)\n",
    "        right_image_f, _, _ = s3_access_utils.download_from_url(right_image_url)\n",
    "        imageL = cv2.imread(left_image_f)\n",
    "        imageR = cv2.imread(right_image_f)\n",
    "        H, kps = find_matches_and_homography(imageL, imageR, cm, left_crop_metadata, right_crop_metadata, keypoints)\n",
    "        dist = determine_fish_distance(kps, cm)\n",
    "        distances_from_camera.append(dist)\n",
    "    df['distance_from_camera'] = distances_from_camera\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "row = df[~df.left_image_url.str.contains('aquabyte-crops')].iloc[idx]\n",
    "left_image_url = row.left_image_url\n",
    "right_image_url = row.right_image_url\n",
    "keypoints = row.keypoints\n",
    "# left_image_url, right_image_url = df.left_image_url.iloc[idx], df.right_image_url.iloc[idx]\n",
    "left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "cm = row.camera_metadata\n",
    "keypoints = row.keypoints\n",
    "\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(left_image_url)\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(right_image_url)\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n",
    "H, kps = find_matches_and_homography(imageL, imageR, cm, left_crop_metadata, right_crop_metadata, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([item['xFrame'] for item in keypoints['leftCrop']], [item['yFrame'] for item in keypoints['leftCrop']], color='blue')\n",
    "plt.scatter(np.array(kps)[:, 0], np.array(kps)[:, 1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[idx]\n",
    "keypoints = row.keypoints\n",
    "plt.scatter([item['xFrame'] for item in keypoints['rightCrop']], [item['yFrame'] for item in keypoints['rightCrop']], color='blue')\n",
    "plt.scatter(np.array(kps)[:, 2], np.array(kps)[:, 3], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wkps(kps, cm): \n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    wkps = []\n",
    "    for kp in kps:\n",
    "        p1_x_frame, p1_y_frame, p2_x_frame, p2_y_frame = kp\n",
    "        disp = abs(p1_x_frame - p2_x_frame)\n",
    "        depth = depth_from_disp(disp, cm)\n",
    "        wkp = convert_to_world_point(p1_x_frame, p1_y_frame, depth, cm)\n",
    "        wkps.append(list(wkp))\n",
    "        \n",
    "    return wkps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_wkps = np.array(get_wkps(kps, cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize World Keypoints </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create local util functions for body world keypoint visualizations (will override original imports)\n",
    "\n",
    "def _generate_rotation_matrix(u_base, v):\n",
    "    u = v / np.linalg.norm(v)\n",
    "    n = np.cross(u_base, u)\n",
    "    n = n / np.linalg.norm(n)\n",
    "    theta = -np.arccos(np.dot(u, u_base))\n",
    "\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0]**2*(1-np.cos(theta)), \n",
    "        n[0]*n[1]*(1-np.cos(theta)) - n[2]*np.sin(theta),\n",
    "        n[0]*n[2]*(1-np.cos(theta)) + n[1]*np.sin(theta)\n",
    "    ], [\n",
    "        n[1]*n[0]*(1-np.cos(theta)) + n[2]*np.sin(theta),\n",
    "        np.cos(theta) + n[1]**2*(1-np.cos(theta)),\n",
    "        n[1]*n[2]*(1-np.cos(theta)) - n[0]*np.sin(theta),\n",
    "    ], [\n",
    "        n[2]*n[0]*(1-np.cos(theta)) - n[1]*np.sin(theta),\n",
    "        n[2]*n[1]*(1-np.cos(theta)) + n[0]*np.sin(theta),\n",
    "        np.cos(theta) + n[2]**2*(1-np.cos(theta))\n",
    "    ]])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def _normalize_world_keypoints(wkps, rotate=True):\n",
    "    body_parts = wkps.keys()\n",
    "    \n",
    "    # translate keypoints such that tail notch is at origin\n",
    "    translated_wkps = {bp: wkps[bp] - wkps['HYPURAL_PLATE'] for bp in body_parts}\n",
    "\n",
    "    if not rotate:\n",
    "        return translated_wkps\n",
    "    \n",
    "    # perform first rotation\n",
    "    u_base=np.array([1, 0, 0])\n",
    "    v = translated_wkps['UPPER_LIP']\n",
    "    R = _generate_rotation_matrix(u_base, v)\n",
    "    norm_wkps_intermediate = {bp: np.dot(R, translated_wkps[bp].T) for bp in body_parts}\n",
    "    \n",
    "    # perform second rotation\n",
    "    u_base = np.array([0, 0, 1])\n",
    "    v = norm_wkps_intermediate['ADIPOSE_FIN'] - np.array([norm_wkps_intermediate['ADIPOSE_FIN'][0], 0, 0])\n",
    "    R = _generate_rotation_matrix(u_base, v)\n",
    "    norm_wkps = {bp: np.dot(R, norm_wkps_intermediate[bp]) for bp in body_parts}\n",
    "    \n",
    "    # perform reflecton if necessary\n",
    "    if norm_wkps['PECTORAL_FIN'][1] > 0:\n",
    "        norm_wkps = {bp: np.array([\n",
    "            norm_wkps[bp][0],\n",
    "            -norm_wkps[bp][1],\n",
    "            norm_wkps[bp][2]\n",
    "        ]) for bp in body_parts}\n",
    "    \n",
    "    return norm_wkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps = {}\n",
    "wkps['BODY'] = np.array(body_wkps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "body_parts = [k for k in norm_wkps.keys() if k != 'BODY']\n",
    "xs = [norm_wkps[bp][0] for bp in body_parts]\n",
    "ys = [norm_wkps[bp][1] for bp in body_parts]\n",
    "zs = [norm_wkps[bp][2] for bp in body_parts]\n",
    "xs.extend(list(norm_wkps['BODY'][0]))\n",
    "ys.extend(list(norm_wkps['BODY'][1]))\n",
    "zs.extend(list(norm_wkps['BODY'][2]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(0, max(xs))\n",
    "ax.set_ylim3d(-0.3, 0.3)\n",
    "ax.set_zlim3d(-0.3, 0.3)\n",
    "ax.scatter(xs, ys, zs, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "xs = list(wkps['BODY'][:, 0])\n",
    "ys = list(wkps['BODY'][:, 1])\n",
    "zs = list(wkps['BODY'][:, 2])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.set_xlim3d(0, max(xs))\n",
    "# ax.set_ylim3d(-0.3, 0.3)\n",
    "# ax.set_zlim3d(-0.3, 0.3)\n",
    "ax.scatter(xs, ys, zs, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get Vikane Focusing Distance </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_from_camera = []\n",
    "row_count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    left_image_url, right_image_url = row.left_crop_url, row.right_crop_url\n",
    "    if left_image_url is not None and right_image_url is not None:\n",
    "        left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "        cm = row.camera_metadata\n",
    "\n",
    "        left_image_f, _, _ = s3_access_utils.download_from_url(left_image_url)\n",
    "        right_image_f, _, _ = s3_access_utils.download_from_url(right_image_url)\n",
    "        imageL = cv2.imread(left_image_f)\n",
    "        imageR = cv2.imread(right_image_f)\n",
    "        H, kps = find_matches_and_homography(imageL, imageR, cm, left_crop_metadata, right_crop_metadata)\n",
    "        wkps = get_wkps(kps, cm)\n",
    "        dist = np.median([wkp[1] for wkp in wkps])\n",
    "        distances_from_camera.append(dist)\n",
    "        print('Row Count: {}, Number of Body Points: {}, Calculated Distance: {}'.format(row_count, len(kps), dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(distances_from_camera, bins=20)\n",
    "plt.grid()\n",
    "plt.xlabel('Distance from camera (m)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distance distribution for accepted Vikane fish (pen_id=56)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_from_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [1/7, 3/7, 3/7]\n",
    "pens = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "e_x = ps[0]\n",
    "var_x = ps[0] * (1 - ps[0])\n",
    "std_x = np.sqrt(var_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_err = std_x / np.sqrt(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([e_x - 2.58 * std_err, e_x + 2.58 * std_err]) * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_x * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "trials = 1000\n",
    "for t in range(trials):\n",
    "    pen_list = []\n",
    "    cum_ps = np.cumsum(ps)\n",
    "    for n in range(N):\n",
    "        r = np.random.uniform()\n",
    "        pen = 1 if r < ps[0] else 0\n",
    "        pen_list.append(pen)\n",
    "    mean = np.mean(pen_list)\n",
    "    means.append(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means[(means > e_x - 2.58 * std_err) & (means < e_x + 2.58 * std_err)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
