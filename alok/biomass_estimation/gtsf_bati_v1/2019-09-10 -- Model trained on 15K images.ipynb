{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "import random\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extract base data from database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null and b.is_qa = false;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Append world kepyoints to the data </h1>\n",
    "<h3> Ideally, this data should already live directly in the database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get the features dataframe from the base data with all pairwise distances </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = defaultdict(list)\n",
    "\n",
    "body_parts = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    world_keypoints = row.world_keypoints\n",
    "    if world_keypoints:\n",
    "        for i in range(len(body_parts)-1):\n",
    "            for j in range(i+1, len(body_parts)):\n",
    "                d = euclidean_distance(world_keypoints[body_parts[i]], \n",
    "                                       world_keypoints[body_parts[j]])\n",
    "                features_data['{0}-{1}'.format(i, j)].append(d)\n",
    "\n",
    "        features_data['weight'].append(row.weight)\n",
    "        features_data['captured_at'].append(row.captured_at)\n",
    "        features_data['gtsf_fish_identifier'].append(row.fish_id)\n",
    "        features_data['pen_id'].append(row.pen_id)\n",
    "        features_data['keypoint_annotation_id'].append(row.id)\n",
    "        features_data['kf'].append(1e5 * row.weight / row['data']['lengthMms']**3) \n",
    "        features_data['length'].append(row['data']['lengthMms'] * 1e-3)\n",
    "        features_data['breadth'].append(row['data']['breadthMms'] * 1e-3 if 'breadhMms' in row['data'] else None)\n",
    "\n",
    "features_df = pd.DataFrame(features_data)\n",
    "\n",
    "# get rid of bad keypoint annotation ids\n",
    "\n",
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "blacklist_mask = features_df['8-9'] > 1.0\n",
    "for kp_id in blacklisted_keypoint_annotation_ids:\n",
    "    if blacklist_mask is None:\n",
    "        blacklist_mask = features_df.keypoint_annotation_id == kp_id\n",
    "    else:\n",
    "        blacklist_mask = blacklist_mask | (features_df.keypoint_annotation_id == kp_id)\n",
    "features_df = features_df[~blacklist_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all features\n",
    "\n",
    "body_parts_subset = sorted([\n",
    "    'HYPURAL_PLATE',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE'\n",
    "])\n",
    "\n",
    "body_part_indices = [body_parts.index(bp) for bp in body_parts_subset]\n",
    "\n",
    "pairwise_distance_columns = ['{0}-{1}'.format(x, y) for x, y in list(combinations(body_part_indices, 2))]\n",
    "interaction_columns_quadratic = []\n",
    "interaction_columns_cubic = []\n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        col1 = pairwise_distance_columns[i]\n",
    "        col2 = pairwise_distance_columns[j]\n",
    "        interaction_column = '{},{}'.format(col1, col2)\n",
    "        features_df[interaction_column] = features_df[col1] * features_df[col2]\n",
    "        interaction_columns_quadratic.append(interaction_column)\n",
    "        \n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        for k in range(j, len(pairwise_distance_columns)):\n",
    "            col1 = pairwise_distance_columns[i]\n",
    "            col2 = pairwise_distance_columns[j]\n",
    "            col3 = pairwise_distance_columns[k]\n",
    "            interaction_column = '{},{},{}'.format(col1, col2, col3)\n",
    "            features_df[interaction_column] = features_df[col1] * features_df[col2] * features_df[col3]\n",
    "            interaction_columns_cubic.append(interaction_column)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Weight each datapoint based on the number of stereo images captured for that fish </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "i = 0\n",
    "for idx, row in features_df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "    count = features_df[features_df.gtsf_fish_identifier == row.gtsf_fish_identifier].shape[0]\n",
    "    if count > 1:\n",
    "        weights.append(1.0 / count ** 0.5)\n",
    "#         weights.append(1.0 / count)\n",
    "    else:\n",
    "        weights.append(1)\n",
    "        \n",
    "features_df['w'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model Training </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_mask(df, train_frac, randomize=True):\n",
    "    x = np.zeros((df.shape[0]), dtype=bool)\n",
    "    x[:int(train_frac * df.shape[0])] = True\n",
    "    np.random.shuffle(x)\n",
    "    mask = pd.Series(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def generate_oos_score(features_df, mask, train_size, num_eigenvectors):\n",
    "    np.random.seed(0)\n",
    "    columns = pairwise_distance_columns + interaction_columns_quadratic + interaction_columns_cubic\n",
    "\n",
    "    X_train = features_df.loc[mask, columns].values\n",
    "    y_train = features_df.loc[mask, 'weight'].values\n",
    "    w_train = features_df.loc[mask, 'w'].values\n",
    "    X_test = features_df.loc[~mask, columns].values\n",
    "    y_test = features_df.loc[~mask, 'weight'].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_normalized = scaler.transform(X_train)\n",
    "\n",
    "    pca = PCA(n_components=min(X_train_normalized.shape[0], X_train_normalized.shape[1]))\n",
    "    pca.fit(X_train_normalized)\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
    "    idx = num_eigenvectors\n",
    "\n",
    "    pca = PCA(n_components=idx+1)\n",
    "    pca.fit(X_train_normalized)\n",
    "    X_train_transformed = pca.transform(X_train_normalized)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    X_test_transformed = pca.transform(X_test_normalized)\n",
    "\n",
    "    reg = LinearRegression().fit(X_train_transformed, y_train, sample_weight=w_train)\n",
    "    score = reg.score(X_test_transformed, y_test)\n",
    "\n",
    "    y_pred = reg.predict(pca.transform(scaler.transform(features_df[columns].values)))\n",
    "    features_df['prediction'] = y_pred\n",
    "    features_df['error'] = features_df.prediction - features_df.weight\n",
    "    features_df['error_pct'] = features_df.error / features_df.weight\n",
    "    features_df['abs_error_pct'] = features_df.error_pct.abs()\n",
    "\n",
    "    model = {\n",
    "    'mean': scaler.mean_,\n",
    "    'std': scaler.scale_,\n",
    "    'PCA_components': pca.components_,\n",
    "    'reg_coef': reg.coef_,\n",
    "    'reg_intercept': reg.intercept_,\n",
    "    'body_parts': body_parts_subset   \n",
    "    }\n",
    "    \n",
    "\n",
    "    return mask, model, score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Plot one instance of train / test where the training set consists of 2000 fish </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num eigenvectors = 20\n",
    "\n",
    "train_size = 2000\n",
    "gtsf_fish_identifiers = list(features_df.gtsf_fish_identifier.unique())\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "mask = features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "mask, model, score = generate_oos_score(features_df, mask, 2000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg = AccuracyMetricsGenerator(mask, features_df.prediction.values, features_df.weight.values)\n",
    "amg.plot_predictions_vs_ground_truth(impose_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.display_train_test_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num eigenvectors = 150\n",
    "\n",
    "train_size = 2000\n",
    "gtsf_fish_identifiers = list(features_df.gtsf_fish_identifier.unique())\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "mask = features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "mask, model, score = generate_oos_score(features_df, mask, 2000, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg = AccuracyMetricsGenerator(mask, features_df.prediction.values, features_df.weight.values)\n",
    "amg.plot_predictions_vs_ground_truth(impose_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.display_train_test_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num eigenvectors = 4\n",
    "\n",
    "train_size = 2000\n",
    "gtsf_fish_identifiers = list(features_df.gtsf_fish_identifier.unique())\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "mask = features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "mask, model, score = generate_oos_score(features_df, mask, 2000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg = AccuracyMetricsGenerator(mask, features_df.prediction.values, features_df.weight.values)\n",
    "amg.plot_predictions_vs_ground_truth(impose_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.display_train_test_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('/root/data/alok/biomass_estimation/playground/model_hypural_plate_4_eig.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[['length', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Marginalization Based on Fish Weight </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = list(np.arange(0, 8000, 500))\n",
    "mean_error_pcts = []\n",
    "for i in range(len(weight_list)-1):\n",
    "    m = (features_df.weight > weight_list[i]) & (features_df.weight < weight_list[i+1])\n",
    "    weighted_mean = (features_df[m].error_pct * features_df[m].weight).sum() / features_df[m].weight.sum()\n",
    "    mean_error_pcts.append(weighted_mean)\n",
    "#     mean_error_pcts.append(features_df[m].error_pct.mean())\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(np.arange(len(weight_list[:-1])), 100.0*np.array(mean_error_pcts))\n",
    "plt.xticks(np.arange(len(weight_list[:-1])), [round(x, 2) for x in weight_list[:-1]])\n",
    "plt.title('Average biomass error vs. Fish Weight')\n",
    "plt.xlabel('Fish Weight')\n",
    "plt.ylabel('Avg. Prediction Error Percent (%)')\n",
    "# plt.ylim(-3, 3)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Two Models for Low and High K-Factor </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_kf = features_df.kf.median()\n",
    "low_kf_mask = features_df.kf < cutoff_kf\n",
    "train_size = int(0.95*len(features_df[low_kf_mask].gtsf_fish_identifier.unique()))\n",
    "model_low_kf, _ = generate_oos_score(features_df, low_kf_mask, train_size)\n",
    "\n",
    "high_kf_mask = features_df.kf >= cutoff_kf\n",
    "train_size = int(0.95*len(features_df[high_kf_mask].gtsf_fish_identifier.unique()))\n",
    "model_high_kf, _ = generate_oos_score(features_df, high_kf_mask, train_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pairwise_distance_columns + interaction_columns_quadratic + interaction_columns_cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[low_kf_mask, 'prediction'] = \\\n",
    "    model_low_kf['reg'].predict(model_low_kf['pca'].transform(model_low_kf['scaler'].transform(features_df.loc[low_kf_mask, columns].values)))\n",
    "features_df.loc[high_kf_mask, 'prediction'] = \\\n",
    "    model_high_kf['reg'].predict(model_high_kf['pca'].transform(model_high_kf['scaler'].transform(features_df.loc[high_kf_mask, columns].values)))\n",
    "\n",
    "features_df['error'] = features_df.prediction - features_df.weight\n",
    "features_df['error_pct'] = features_df.error / features_df.weight\n",
    "features_df['abs_error_pct'] = features_df.error_pct.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_list = list(np.arange(0.6, 2.0, 0.05))\n",
    "mean_error_pcts = []\n",
    "for i in range(len(kf_list)-1):\n",
    "    m = (features_df.kf > kf_list[i]) & (features_df.kf < kf_list[i+1])\n",
    "    mean_error_pcts.append(features_df[m].error_pct.mean())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(np.arange(len(kf_list[:-1])), 100.0*np.array(mean_error_pcts))\n",
    "plt.xticks(np.arange(len(kf_list[:-1])), [round(x, 2) for x in kf_list[:-1]])\n",
    "plt.title('Average biomass error vs. K-Factor')\n",
    "plt.xlabel('K-Factor')\n",
    "plt.ylabel('Avg. Prediction Error Percent (%)')\n",
    "# plt.ylim(-5, 5)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(features_df.kf.values.reshape(-1, 1), features_df.error_pct.values)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Reduce the number of eigenvectors </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1500\n",
    "gtsf_fish_identifiers = list(features_df.gtsf_fish_identifier.unique())\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "mask = features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "model, score = generate_oos_score(features_df, mask, train_size, 150)\n",
    "columns = pairwise_distance_columns + interaction_columns_quadratic + interaction_columns_cubic\n",
    "X_transformed = model['pca'].transform(model['scaler'].transform(features_df[columns].values))\n",
    "y = features_df.weight.values\n",
    "mse = []\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Calculate MSE using CV for the 19 principle components, adding one component at the time.\n",
    "for i in np.arange(1, 200):\n",
    "    print(i)\n",
    "    score = -1*cross_val_score(regr, X_transformed[:,:i], y, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(mse)\n",
    "plt.xlabel('Number of eigenvectors')\n",
    "plt.ylabel('Weight estimation MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize some cases </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "credentials = json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS']))\n",
    "rds_access_utils = RDSAccessUtils(credentials)\n",
    "v = Visualizer(s3_access_utils, rds_access_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_fish_id_dict = defaultdict(list)\n",
    "for fish_id in features_df.gtsf_fish_identifier.unique():\n",
    "    m = features_df.gtsf_fish_identifier == fish_id\n",
    "    count = features_df[m].shape[0]\n",
    "    average_error_pct = features_df[m].error_pct.mean()\n",
    "    results_by_fish_id_dict['gtsf_fish_identifier'].append(fish_id)\n",
    "    results_by_fish_id_dict['count'].append(count)    \n",
    "    results_by_fish_id_dict['average_error_pct'].append(average_error_pct)    \n",
    "    \n",
    "results_by_fish_id = pd.DataFrame(results_by_fish_id_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_fish_id.sort_values('count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.sort_values('error_pct')[['keypoint_annotation_id', 'error_pct', 'length', '8-9', 'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "v.load_data(721975)\n",
    "v.display_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "v.display_3d_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
