{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get all GTSF data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null\n",
    "    and (b.is_qa = false or b.captured_at > '2019-09-19');\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "df = df[~df.id.isin(blacklisted_keypoint_annotation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Filter dataset down to well-behaved rows </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_complete_kp_info(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_kp_info_mask = df.apply(lambda x: contains_complete_kp_info(x), axis=1)\n",
    "df = df[complete_kp_info_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Append world keypoints to this data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def is_well_behaved(wkps, cutoff_depth=10.0):\n",
    "    if any([abs(wkp[1]) > cutoff_depth for wkp in wkps.values()]):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "is_well_behaved_mask = df.world_keypoints.apply(lambda x: is_well_behaved(x))\n",
    "df = df[is_well_behaved_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create Datasets + Transforms </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "BODY_PARTS = sorted([\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'EYE',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'TAIL_NOTCH',\n",
    "    'UPPER_LIP'\n",
    "])\n",
    "\n",
    "\n",
    "class KeypointsDataset(Dataset):\n",
    "    \"\"\"Keypoints dataset\"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(row)\n",
    "            return sample\n",
    "\n",
    "        world_keypoints = row.world_keypoints\n",
    "        weight = row.weight\n",
    "\n",
    "        sample = {'kp_input': world_keypoints, 'label': weight, 'keypoint_annotation_id': row.id}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeCentered2D(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Transforms the 2D left and right keypoints such that:\n",
    "        (1) The center of the left image 2D keypoints is located at the center of the left image\n",
    "            (i.e. 2D translation)\n",
    "        (2) The left image keypoints are possibly flipped such that the upper-lip x-coordinate \n",
    "            is greater than the tail-notch coordinate. This is done to reduce the total number of \n",
    "            spatial orientations the network must learn from -> reduces the training size\n",
    "        (3) The left image keypoints are then rotated such that upper-lip is located on the x-axis.\n",
    "            As in (2), this is done to reduce the total number of spatial orientations the network \n",
    "            must learn from -> reduces the training size\n",
    "        (4) For all transformations above, the right image keypoint coordinates are accordingly\n",
    "            transformed such that the original disparity values are preserved for all keypoints\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def flip_center_kps(self, left_kps, right_kps):\n",
    "\n",
    "        x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "        x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "        x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "\n",
    "        y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "        y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "        y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "\n",
    "        x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "        x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "        x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "\n",
    "        y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "        y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "        y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "\n",
    "        fc_left_kps, fc_right_kps = {}, {}\n",
    "        flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            if flip_factor > 0:\n",
    "                fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "                fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "            else:\n",
    "                fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "                fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "            fc_left_kps[bp] = fc_left_kp\n",
    "            fc_right_kps[bp] = fc_right_kp\n",
    "\n",
    "        return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "    def _rotate_cc(self, p, theta):\n",
    "        R = np.array([\n",
    "            [np.cos(theta), -np.sin(theta)],\n",
    "            [np.sin(theta), np.cos(theta)]\n",
    "        ])\n",
    "\n",
    "        rotated_kp = np.dot(R, p)\n",
    "        return rotated_kp\n",
    "\n",
    "\n",
    "    def rotate_kps(self, left_kps, right_kps):\n",
    "        upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "        theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "        r_left_kps, r_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            rotated_kp = self._rotate_cc(left_kps[bp], -theta)\n",
    "            r_left_kps[bp] = rotated_kp\n",
    "            disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "            r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "\n",
    "        return r_left_kps, r_right_kps\n",
    "\n",
    "\n",
    "    def translate_kps(self, left_kps, right_kps, factor):\n",
    "        t_left_kps, t_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            t_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "            t_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "\n",
    "        return t_left_kps, t_right_kps\n",
    "\n",
    "\n",
    "    def jitter_kps(self, left_kps, right_kps, jitter):\n",
    "        j_left_kps, j_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                       left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "            j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                        right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "\n",
    "        return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "\n",
    "    def modify_kps(self, left_kps, right_kps, factor, jitter, cm):\n",
    "        fc_left_kps, fc_right_kps = self.flip_center_kps(left_kps, right_kps)\n",
    "        r_left_kps, r_right_kps = self.rotate_kps(fc_left_kps, fc_right_kps)\n",
    "        t_left_kps, t_right_kps = self.translate_kps(r_left_kps, r_right_kps, factor)\n",
    "        j_left_kps, j_right_kps  = self.jitter_kps(t_left_kps, t_right_kps, jitter)\n",
    "        j_left_kps_list, j_right_kps_list = [], []\n",
    "        for bp in BODY_PARTS:\n",
    "            l_item = {\n",
    "                'keypointType': bp,\n",
    "                'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "            }\n",
    "\n",
    "            r_item = {\n",
    "                'keypointType': bp,\n",
    "                'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "            }\n",
    "\n",
    "            j_left_kps_list.append(l_item)\n",
    "            j_right_kps_list.append(r_item)\n",
    "\n",
    "        modified_kps = {\n",
    "            'leftCrop': j_left_kps_list,\n",
    "            'rightCrop': j_right_kps_list\n",
    "        }\n",
    "\n",
    "        return modified_kps\n",
    "    \n",
    "    def __init__(self, lo=None, hi=None, jitter=0.0):\n",
    "        self.lo = lo\n",
    "        self.hi = hi\n",
    "        self.jitter = jitter\n",
    "    \n",
    "    def __call__(self, row):\n",
    "        left_keypoints_list = row.keypoints['leftCrop']\n",
    "        right_keypoints_list = row.keypoints['rightCrop']\n",
    "        left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "        right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "        cm = row.camera_metadata\n",
    "        \n",
    "        factor = 1.0 \n",
    "        if self.lo and self.hi:\n",
    "            factor = np.random.uniform(low=self.lo, high=self.hi)\n",
    "            \n",
    "        jitter = np.random.uniform(high=self.jitter)\n",
    "        \n",
    "        modified_kps = self.modify_kps(left_kps, right_kps, factor, jitter, cm)\n",
    "        modified_wkps = pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)\n",
    "        \n",
    "        sample = {\n",
    "            'kp_input': modified_wkps,\n",
    "            'label': row.weight,\n",
    "            'keypoint_annotation_id': row.id,\n",
    "            'cm': row.camera_metadata\n",
    "        }\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "\n",
    "\n",
    "class NormalizedStabilityTransform(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, kpid = sample['kp_input'], sample['label'], sample['keypoint_annotation_id']\n",
    "        stabilized_coordinates = {}\n",
    "        for bp in BODY_PARTS:\n",
    "            wkp = kp_input[bp]\n",
    "            stabilized_kp_info = [0.5 * wkp[0]/wkp[1], 0.5 * wkp[2]/wkp[1], 0.5 * 0.1/wkp[1]]\n",
    "            stabilized_coordinates[bp] = stabilized_kp_info\n",
    "            \n",
    "        normalized_label = label * 1e-4\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': stabilized_coordinates,\n",
    "            'label': normalized_label,\n",
    "            'keypoint_annotation_id': kpid\n",
    "        }\n",
    "        \n",
    "        return transformed_sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, keypoint_annotation_id = \\\n",
    "            sample['kp_input'], sample['label'], sample['keypoint_annotation_id']\n",
    "        \n",
    "        x = []\n",
    "        for bp in BODY_PARTS:\n",
    "            kp_data = kp_input[bp]\n",
    "            x.append(kp_data)\n",
    "        x = np.array(x)\n",
    "        \n",
    "        kp_input_tensor = torch.from_numpy(x).float()\n",
    "        label_tensor = torch.from_numpy(np.array([label])).float()\n",
    "        \n",
    "        tensorized_sample = {\n",
    "            'kp_input': kp_input_tensor,\n",
    "            'label': label_tensor,\n",
    "            'keypoint_annotation_id': keypoint_annotation_id\n",
    "        }\n",
    "        \n",
    "        return tensorized_sample\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask], transform=transforms.Compose([\n",
    "                                                      NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                      NormalizedStabilityTransform(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                      NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                      NormalizedStabilityTransform(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish output directory where model .pb files will be written\n",
    "# dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "# output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "# output_dir = os.path.join(output_base, dt_now)\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['keypoint_annotation_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "    # run on test set\n",
    "    else:\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data_batch in enumerate(test_dataloader):\n",
    "                X_batch, y_batch, kpid_batch = \\\n",
    "                    data_batch['kp_input'], data_batch['label'], data_batch['keypoint_annotation_id']\n",
    "                y_pred = network(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "    test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "    train_losses.append(train_loss_for_epoch)\n",
    "    test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "#     # save current state of network\n",
    "#     f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "#     f_path = os.path.join(output_dir, f_name)\n",
    "#     torch.save(network, f_path)\n",
    "    \n",
    "    # print current loss values\n",
    "    print('-'*20)\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "    print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(len(train_losses)), train_losses, color='blue', label='training loss')\n",
    "plt.plot(range(len(test_losses)), test_losses, color='orange', label='validation loss')\n",
    "plt.ylim([0, 0.01])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value (MSE)')\n",
    "plt.title('Loss curves (MSE - Adam optimizer)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.array(test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses[700], test_losses[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unperturbed_test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                                     NormalizeCentered2D(),\n",
    "                                                                     NormalizedStabilityTransform(),\n",
    "                                                                     ToTensor()\n",
    "                                                                     ]))\n",
    "\n",
    "unperturbed_test_dataloader = DataLoader(unperturbed_test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, weights = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data_batch in enumerate(unperturbed_test_dataloader):\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['keypoint_annotation_id']\n",
    "        y_pred = network(X_batch)\n",
    "        \n",
    "        y_batch_list = y_batch.numpy().squeeze().tolist()\n",
    "        y_pred_list = y_pred.numpy().squeeze().tolist()\n",
    "        predictions.extend([1e4 * x for x in y_pred_list])\n",
    "        weights.extend([1e4 * x for x in y_batch_list])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(weights, predictions, color='blue')\n",
    "plt.plot([0, 1e4], [0, 1e4], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(predictions) - np.mean(weights)) / np.mean(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((np.array(predictions) - np.array(weights))/np.array(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
