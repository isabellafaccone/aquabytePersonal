{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null and b.is_qa = false;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "df = df[~df.world_keypoints.isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "df = df[~df.id.isin(blacklisted_keypoint_annotation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_rotation_matrix(u_base, v):\n",
    "    u = v / np.linalg.norm(v)\n",
    "    n = np.cross(u_base, u)\n",
    "    n = n / np.linalg.norm(n)\n",
    "    theta = -np.arccos(np.dot(u, u_base))\n",
    "\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0]**2*(1-np.cos(theta)), \n",
    "        n[0]*n[1]*(1-np.cos(theta)) - n[2]*np.sin(theta),\n",
    "        n[0]*n[2]*(1-np.cos(theta)) + n[1]*np.sin(theta)\n",
    "    ], [\n",
    "        n[1]*n[0]*(1-np.cos(theta)) + n[2]*np.sin(theta),\n",
    "        np.cos(theta) + n[1]**2*(1-np.cos(theta)),\n",
    "        n[1]*n[2]*(1-np.cos(theta)) - n[0]*np.sin(theta),\n",
    "    ], [\n",
    "        n[2]*n[0]*(1-np.cos(theta)) - n[1]*np.sin(theta),\n",
    "        n[2]*n[1]*(1-np.cos(theta)) + n[0]*np.sin(theta),\n",
    "        np.cos(theta) + n[2]**2*(1-np.cos(theta))\n",
    "    ]])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def _normalize_world_keypoints(wkps, rotate=True):\n",
    "    body_parts = wkps.keys()\n",
    "    \n",
    "    # translate keypoints such that tail notch is at origin\n",
    "    if wkps['UPPER_LIP'][0] > wkps['HYPURAL_PLATE'][0]:\n",
    "        front_bp, back_bp = 'UPPER_LIP', 'HYPURAL_PLATE'\n",
    "    else:\n",
    "        front_bp, back_bp = 'HYPURAL_PLATE', 'UPPER_LIP'\n",
    "        \n",
    "    translated_wkps = {bp: wkps[bp] - wkps[back_bp] for bp in body_parts}\n",
    "\n",
    "    if not rotate:\n",
    "        return translated_wkps\n",
    "    \n",
    "    # perform first rotation\n",
    "    u_base=np.array([1, 0, 0])\n",
    "    v = translated_wkps[front_bp]\n",
    "    R = _generate_rotation_matrix(u_base, v)\n",
    "    norm_wkps_intermediate = {bp: np.dot(R, translated_wkps[bp]) for bp in body_parts}\n",
    "    \n",
    "    return norm_wkps_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "# train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "# fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "# train_mask = df.fish_id.isin(fish_ids)\n",
    "train_mask = df.captured_at <= '2019-09-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['focal_length_pixel'] = df.camera_metadata.apply(lambda x: x['focalLengthPixel']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df.world_keypoints.apply(lambda x: euclidean_distance(x['UPPER_LIP'], x['TAIL_NOTCH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gt_length'] = df.data.apply(lambda x: x['lengthMms'] / 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['depth'] = df.world_keypoints.apply(lambda x: np.mean([k[1] for k in x.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length_diff'] = df.length - df.gt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[(~mask) & (df.depth > 0.7), ['depth', 'id', 'length_diff']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask, ['depth', 'id', 'length_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = (df.focal_length_pixel > 2447.71) & (df.focal_length_pixel < 2447.72)# & (df.captured_at < '2019-09-01')\n",
    "np.median(df[mask].length - df[mask].gt_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.focal_length_pixel > 2447.71) & (df.focal_length_pixel < 2447.72)\n",
    "np.median(df[~mask].length - df[~mask].gt_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_behaved(wkps, cutoff_depth=10.0):\n",
    "    if any([abs(wkp[1]) > cutoff_depth for wkp in wkps.values()]):\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def flip_center_kps(left_kps, right_kps, cm):\n",
    "    \n",
    "    x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "    x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "    x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "    \n",
    "    y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "    y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "    y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "    \n",
    "    x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "    x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "    x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "    \n",
    "    y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "    y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "    y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "        \n",
    "    fc_left_kps, fc_right_kps = {}, {}\n",
    "    flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "    for bp in BODY_PARTS:\n",
    "        left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "        if flip_factor > 0:\n",
    "            fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "            fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "        else:\n",
    "            fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "            fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "        fc_left_kps[bp] = fc_left_kp\n",
    "        fc_right_kps[bp] = fc_right_kp\n",
    "        \n",
    "    return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "def translate_kps(left_kps, right_kps, factor):\n",
    "    t_left_kps, t_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "        t_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "        t_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "    \n",
    "    return t_left_kps, t_right_kps\n",
    "\n",
    "\n",
    "def jitter_kps(left_kps, right_kps, jitter):\n",
    "    j_left_kps, j_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                   left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "        j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                    right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "    \n",
    "    return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "def modify_kps(left_kps, right_kps, factor, jitter, cm):\n",
    "    fc_left_kps, fc_right_kps = flip_center_kps(left_kps, right_kps, cm)\n",
    "    t_left_kps, t_right_kps = translate_kps(fc_left_kps, fc_right_kps, factor)\n",
    "    j_left_kps, j_right_kps  = jitter_kps(t_left_kps, t_right_kps, jitter)\n",
    "    j_left_kps_list, j_right_kps_list = [], []\n",
    "    for bp in BODY_PARTS:\n",
    "        l_item = {\n",
    "            'keypointType': bp,\n",
    "            'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "            'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "        }\n",
    "        \n",
    "        r_item = {\n",
    "            'keypointType': bp,\n",
    "            'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "            'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "        }\n",
    "        \n",
    "        j_left_kps_list.append(l_item)\n",
    "        j_right_kps_list.append(r_item)\n",
    "        \n",
    "    modified_kps = {\n",
    "        'leftCrop': j_left_kps_list,\n",
    "        'rightCrop': j_right_kps_list\n",
    "    }\n",
    "    \n",
    "    print(modified_kps)\n",
    "    return modified_kps\n",
    "\n",
    "\n",
    "def process_row(row, n_factors=1, jitters=[0], low=0.3, high=2.5, oos=False, network=None):\n",
    "    X_row, labels_row, est_weights = [], [], []\n",
    "    keypoints = row.keypoints\n",
    "    left_keypoints_list = keypoints.get('leftCrop')\n",
    "    right_keypoints_list = keypoints.get('rightCrop')\n",
    "    cm = row.camera_metadata\n",
    "    \n",
    "    if left_keypoints_list and right_keypoints_list:\n",
    "        wkps = pixel2world(left_keypoints_list, right_keypoints_list, cm)\n",
    "        left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "        right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "        if well_behaved(wkps):\n",
    "            for n in range(n_factors):\n",
    "                factor = 1.0 if n_factors == 1 else np.random.uniform(low=low, high=high)\n",
    "                for jitter in jitters:\n",
    "                    trials = 3 if jitter > 0 else 1\n",
    "                    for t in range(trials):\n",
    "                        modified_kps = modify_kps(left_kps, right_kps, factor, jitter, cm)\n",
    "                        modified_wkps = pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)\n",
    "                        data_point = []\n",
    "                        for bp in BODY_PARTS:\n",
    "                            wkp = modified_wkps[bp]\n",
    "                            data_point.append([wkp[0] / wkp[1], wkp[2] / wkp[1], 0.1 / wkp[1]])\n",
    "                        X_row.append(data_point)\n",
    "                        if not oos:\n",
    "                            labels_row.append(row.weight)\n",
    "                        if network:\n",
    "                            u = torch.from_numpy(np.array(data_point) / 2.0).float()\n",
    "                            est_weights.append(network(u.view(1, *u.shape)).item())\n",
    "\n",
    "    return X_row, labels_row, est_weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ix, row in df[df.index == 11].iterrows():\n",
    "    X_row, labels_row, est_weights = process_row(row, n_factors=1, jitters=[0], network=network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter(np.array(X_row[0])[:, 0], np.array(X_row[0])[:, 1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter(np.array(X_row[0])[:, 0], np.array(X_row[0])[:, 2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.id == kpids[k]].world_keypoints.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_weights, labels_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~train_mask].data.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~train_mask].world_keypoints.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df.world_keypoints.apply(lambda x: euclidean_distance(x['UPPER_LIP'], x['TAIL_NOTCH']))\n",
    "df['gt_length'] = df.data.apply(lambda x: x['lengthMms'] / 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~train_mask].length - df[~train_mask].gt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[train_mask].length - df[train_mask].gt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(df[~train_mask & (df.weight < 1000)].length - df[~train_mask & (df.weight < 1000)].gt_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "idx = 3000\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter(np.array(X[idx])[:, 0], np.array(X[idx])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "X, labels = [], []\n",
    "\n",
    "\n",
    "row_count = 0\n",
    "for idx, row in df[train_mask].iterrows():\n",
    "    \n",
    "    X_row, labels_row, _ = process_row(row, n_factors=5, jitters=[0, 10, 20])\n",
    "    X.extend(X_row)\n",
    "    labels.extend(labels_row)\n",
    "    \n",
    "    if row_count % 1000 == 0:\n",
    "        print('Percentage complete: {}'.format(row_count / df[train_mask].shape[0]))\n",
    "    row_count += 1\n",
    "    \n",
    "X, labels = np.array(X) / 2.0, np.array(labels) / 10000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    \"\"\"Keypoints dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, labels, transform=None):\n",
    "        self.X = X\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(np.array([y])).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(33, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = KeypointsDataset(X, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=25, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = Network()\n",
    "# network = network.to(device)\n",
    "epochs = 2000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = data_batch\n",
    "#         X_batch = X_batch.to(device)\n",
    "#         y_batch = y_batch.to(device)\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(running_loss / i)\n",
    "    \n",
    "    loss_for_epoch = running_loss / len(dataloader)\n",
    "    \n",
    "    # print validation loss\n",
    "    preds = network(torch.from_numpy(X_t).float())\n",
    "    predictions = preds.detach().numpy().squeeze()\n",
    "    weights = labels_t\n",
    "    accuracy = np.mean(abs((predictions - weights) / weights))\n",
    "    \n",
    "    print('Loss for epoch {}: {}'.format(epoch, loss_for_epoch))\n",
    "    print('Validation accuracy: {}'.format(accuracy))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction: {}'.format(predictions[idx] * 1e4))\n",
    "print('Ground Truth: {}'.format(labels_t[idx] * 1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.scatter(X[idx][:, 0], X[idx][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.from_numpy(X[idx]).float()\n",
    "pred = network(u.view(1, *u.shape)).item() * 1e4\n",
    "print('Prediction: {}'.format(pred))\n",
    "print('Ground Truth: {}'.format(labels[idx] * 1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.where(0.05 / X[:, :, 2].mean(axis=1) > 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(0.05 / X_t[:, :, 2].mean(axis=1) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_for_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1833]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpids, X_t, labels_t = [], [], []\n",
    "body_parts = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n",
    "\n",
    "for idx, row in df[~train_mask].iterrows():\n",
    "    X_row, labels_row, _ = process_row(row, n_factors=1, jitters=[0])\n",
    "    X_t.extend(X_row)\n",
    "    labels_t.extend(labels_row)\n",
    "    kpids.append(row.id)\n",
    "    \n",
    "    \n",
    "X_t, labels_t = np.array(X_t) / 2.0, np.array(labels_t) / 10000.0\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpids[22], kpids[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[train_mask].camera_metadata.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(~train_mask) & (df.weight > 1000)].camera_metadata.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(~train_mask) & (df.weight < 1000)].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(torch.from_numpy(X_t).float())\n",
    "predictions = preds.detach().numpy().squeeze()\n",
    "weights = labels_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(weights * 1e4, predictions * 1e4)\n",
    "plt.plot([0, 1e4], [0, 1e4], color='red')\n",
    "plt.xlim([0, 1e4])\n",
    "plt.ylim([0, 1e4])\n",
    "plt.xlabel('Ground truth weight (grams)')\n",
    "plt.ylabel('Prediction (grams)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(.05 / X_t[:, 0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = .05 / X[:, 0, 2]\n",
    "plt.hist(k[(k > 0) & (k < 3.0)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs((predictions - weights)/weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions.mean() - weights.mean())/weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/alok/biomass_estimation/results/model_lateral_only/results_557ec1732d8bc8bc66951d2ea4e69b935d69b111_model_lateral_only_research-exp-id-03-vikingfjord-20190709-20190710.h5'\n",
    "tdf = pd.read_hdf(f, 'table')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_o, est_weights = [], []\n",
    "body_parts = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n",
    "\n",
    "for idx, row in tdf.iterrows():\n",
    "    X_row, _, est_weight = process_row(row, n_factors=1, jitters=[0], oos=True, network=network)\n",
    "    X_o.extend(X_row)\n",
    "    if len(est_weight) > 0:\n",
    "        est_weights.extend(est_weight)\n",
    "    else:\n",
    "        est_weights.append(None)\n",
    "    \n",
    "X_o = np.array(X_o) / 2.0\n",
    "        \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['est_weight'] = est_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.est_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(torch.from_numpy(X_o).float())\n",
    "predictions = preds.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(predictions * 1e4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions * 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(X_o[:, 1, 0], X_o[:, 1, 2], color='r', alpha=0.5)\n",
    "plt.scatter(X[:, 1, 0], X[:, 1, 2], color='b', alpha=0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['depth'] = tdf.world_keypoints.apply(lambda x: x['EYE'][1] if x else None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tdf.depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "725887, 725890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "credentials = json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS']))\n",
    "rds_access_utils = RDSAccessUtils(credentials)\n",
    "v = Visualizer(s3_access_utils, rds_access_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "credentials = json.load(open(os.environ['PROD_SQL_CREDENTIALS']))\n",
    "rds_access_utils = RDSAccessUtils(credentials)\n",
    "v = Visualizer(s3_access_utils, rds_access_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "v.load_data(564449)\n",
    "v.display_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "v.display_3d_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fov_cutoffs(fov, cm):\n",
    "    fov = fov * np.pi / 180.0\n",
    "    field_size_px = 2*cm['focalLengthPixel'] * np.tan(fov / 2.0)\n",
    "    min_cutoff = (cm['pixelCountWidth'] - field_size_px) / 2.0\n",
    "    max_cutoff = (cm['pixelCountWidth'] + field_size_px) / 2.0\n",
    "    return min_cutoff, max_cutoff\n",
    "\n",
    "def is_preserved(keypoints, min_cutoff, max_cutoff):\n",
    "    min_x_left = min([item['xFrame'] for item in keypoints['leftCrop']])\n",
    "    max_x_left = max([item['xFrame'] for item in keypoints['leftCrop']])\n",
    "    min_x_right = min([item['xFrame'] for item in keypoints['rightCrop']])\n",
    "    max_x_right = max([item['xFrame'] for item in keypoints['rightCrop']])\n",
    "    \n",
    "    if (min_x_left < min_cutoff) or (min_x_right < min_cutoff) or (max_x_left > max_cutoff) or (max_x_right > max_cutoff):\n",
    "        return False\n",
    "    return True\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = list(np.arange(10, 55, 1))\n",
    "for fov in fovs:\n",
    "    min_cutoff, max_cutoff = get_fov_cutoffs(fov, tdf.camera_metadata.iloc[0])\n",
    "    is_preserved_list = []\n",
    "    for idx, row in tdf.iterrows():\n",
    "        keypoints = row.keypoints\n",
    "        if 'leftCrop' in keypoints and 'rightCrop' in keypoints:\n",
    "            is_preserved_list.append(is_preserved(keypoints, min_cutoff, max_cutoff))\n",
    "        else:\n",
    "            is_preserved_list.append(False)\n",
    "\n",
    "    tdf['is_preserved_{}'.format(fov)] = is_preserved_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weight_means, sample_sizes = [], []\n",
    "for fov in fovs:\n",
    "    mask = tdf['is_preserved_{}'.format(fov)] == True\n",
    "#     pred_weight_means.append(tdf[mask].est_weight.mean() * 1e4)\n",
    "    pred_weight_means.append(tdf[mask].estimated_biomass_g.median())\n",
    "    sample_sizes.append(tdf[mask].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Waiting pen ID #1 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, pred_weight_means, s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, sample_sizes)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Waiting pen ID #2 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, pred_weight_means, s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, sample_sizes)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Waiting Pen ID #3 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, pred_weight_means, s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, sample_sizes)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, pred_weight_means, s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, sample_sizes)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[tdf.depth > 1.75].est_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[tdf.is_preserved_29 == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
