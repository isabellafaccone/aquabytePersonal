{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Calibration Comparison Bolaks - v1 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "# from keras.models import load_model\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load and Clean Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison_results(key_a, key_b):\n",
    "    csv_s3_url_a = output_csv_urls[key_a]\n",
    "    s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "    csv_f_a, bucket, key = s3_access_utils.download_from_url(csv_s3_url_a)\n",
    "    df_original_a = pd.read_csv(csv_f_a)\n",
    "\n",
    "    csv_s3_url_b = output_csv_urls[key_b]\n",
    "    csv_f_b, bucket, key = s3_access_utils.download_from_url(csv_s3_url_b)\n",
    "    df_original_b = pd.read_csv(csv_f_b)\n",
    "\n",
    "    df_a = df_original_a.copy(deep=True)\n",
    "    df_b = df_original_b.copy(deep=True)\n",
    "    environment_a = [x for x in df_original_a.left_crop_url.iloc[0].split('/') if x.startswith('environment')][0]\n",
    "    environment_b = [x for x in df_original_b.left_crop_url.iloc[0].split('/') if x.startswith('environment')][0]\n",
    "    urls_a = list(df_a.left_crop_url.values)\n",
    "    urls_b = list(df_b.left_crop_url.values)\n",
    "    common_urls_a = list(set(urls_a).intersection(set([x.replace(environment_b, environment_a) for x in urls_b])))\n",
    "    common_urls_b = list(set([x.replace(environment_a, environment_b) for x in urls_a]).intersection(set(urls_b)))\n",
    "    df_a = df_a[df_a.left_crop_url.isin(common_urls_a)].sort_values(['captured_at', 'left_crop_url']).copy(deep=True)\n",
    "    df_b = df_b[df_b.left_crop_url.isin(common_urls_b)].sort_values(['captured_at', 'left_crop_url']).copy(deep=True)\n",
    "    df = pd.DataFrame({\n",
    "        'captured_at': df_a.captured_at,\n",
    "        'weight_a': df_a.estimated_weight_g.values,\n",
    "        'weight_b': df_b.estimated_weight_g.values,\n",
    "        'akpd_score_a': df_a.akpd_score.values,\n",
    "        'akpd_score_b': df_b.akpd_score.values,\n",
    "        'left_crop_url_a': df_a.left_crop_url.values,\n",
    "        'right_crop_url_a': df_a.right_crop_url.values,\n",
    "        'left_crop_url_post': df_b.left_crop_url.values,\n",
    "        'right_crop_url_b': df_b.right_crop_url.values,\n",
    "        'ann_a': df_a.annotation.values,\n",
    "        'ann_b': df_b.annotation.values\n",
    "    })\n",
    "\n",
    "    df = df[(df.akpd_score_a > 0.9) & (df.akpd_score_b > 0.9)].copy(deep=True)\n",
    "    \n",
    "    print('{} parameters weight: {}g'.format(key_a, round(df_original_a[df_original_a.akpd_score > 0.9].estimated_weight_g.mean(), 2)))\n",
    "    print('{} parameters weight: {}g'.format(key_b, round(df_original_b[df_original_b.akpd_score > 0.9].estimated_weight_g.mean(), 2)))\n",
    "    print('--- APPLES TO APPLES COMPARISON')\n",
    "    print('{} parameters weight: {}g'.format(key_a, round(df.weight_a.mean(), 2)))\n",
    "    print('{} parameters weight: {}g'.format(key_b, round(df.weight_b.mean(), 2)))\n",
    "\n",
    "    pct_difference = 100 * (df.weight_b.mean() - df.weight_a.mean()) / df.weight_a.mean()\n",
    "    print('Percentage difference: {}%'.format(round(pct_difference, 2)))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_urls = {\n",
    "    'freshwater_matlab_pre_deployment': 'https://aquabyte-calibrations.s3-eu-west-1.amazonaws.com/biomass_experiments/bolaks.pen88.matlab.02042020.cal.output.csv',\n",
    "    'freshwater_matlab_post_deployment': 'https://aquabyte-calibrations.s3-eu-west-1.amazonaws.com/biomass_experiments/bolaks.pen88.matlab.03112020.cal.output.csv',\n",
    "    'freshwater_circular_post_deployment': 'https://aquabyte-calibrations.s3-eu-west-1.amazonaws.com/biomass_experiments/bolaks.pen88.circular.03112020.cal.output.csv',\n",
    "    'cold_freshwater_matlab_post_deployment': 'https://aquabyte-calibrations.s3-eu-west-1.amazonaws.com/biomass_experiments/bolaks.pen88.matlab.03232020.cal.11degrees.output.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_a, key_b = 'freshwater_matlab_pre_deployment', 'freshwater_matlab_post_deployment'\n",
    "generate_comparison_results(key_a, key_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_a, key_b = 'freshwater_matlab_post_deployment', 'freshwater_circular_post_deployment'\n",
    "generate_comparison_results(key_a, key_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_a, key_b = 'freshwater_matlab_post_deployment', 'cold_freshwater_matlab_post_deployment'\n",
    "generate_comparison_results(key_a, key_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_a, key_b = 'freshwater_matlab_pre_deployment', 'cold_freshwater_matlab_post_deployment'\n",
    "generate_comparison_results(key_a, key_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_s3_url_a = output_csv_urls[key_a]\n",
    "s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "csv_f_a, bucket, key = s3_access_utils.download_from_url(csv_s3_url_a)\n",
    "df_original_a = pd.read_csv(csv_f_a)\n",
    "\n",
    "csv_s3_url_b = output_csv_urls[key_b]\n",
    "csv_f_b, bucket, key = s3_access_utils.download_from_url(csv_s3_url_b)\n",
    "df_original_b = pd.read_csv(csv_f_b)\n",
    "\n",
    "df_a = df_original_a.copy(deep=True)\n",
    "df_b = df_original_b.copy(deep=True)\n",
    "environment_a = [x for x in df_original_a.left_crop_url.iloc[0].split('/') if x.startswith('environment')][0]\n",
    "environment_b = [x for x in df_original_b.left_crop_url.iloc[0].split('/') if x.startswith('environment')][0]\n",
    "urls_a = list(df_a.left_crop_url.values)\n",
    "urls_b = list(df_b.left_crop_url.values)\n",
    "common_urls_a = list(set(urls_a).intersection(set([x.replace(environment_b, environment_a) for x in urls_b])))\n",
    "common_urls_b = list(set([x.replace(environment_a, environment_b) for x in urls_a]).intersection(set(urls_b)))\n",
    "df_a = df_a[df_a.left_crop_url.isin(common_urls_a)].sort_values(['captured_at', 'left_crop_url']).copy(deep=True)\n",
    "df_b = df_b[df_b.left_crop_url.isin(common_urls_b)].sort_values(['captured_at', 'left_crop_url']).copy(deep=True)\n",
    "df = pd.DataFrame({\n",
    "    'captured_at': df_a.captured_at,\n",
    "    'weight_a': df_a.estimated_weight_g.values,\n",
    "    'weight_b': df_b.estimated_weight_g.values,\n",
    "    'akpd_score_a': df_a.akpd_score.values,\n",
    "    'akpd_score_b': df_b.akpd_score.values,\n",
    "    'left_crop_url_a': df_a.left_crop_url.values,\n",
    "    'right_crop_url_a': df_a.right_crop_url.values,\n",
    "    'left_crop_url_post': df_b.left_crop_url.values,\n",
    "    'right_crop_url_b': df_b.right_crop_url.values,\n",
    "    'ann_a': df_a.annotation.values,\n",
    "    'ann_b': df_b.annotation.values\n",
    "})\n",
    "\n",
    "df = df[(df.akpd_score_a > 0.9) & (df.akpd_score_b > 0.9)].copy(deep=True)\n",
    "\n",
    "print('{} parameters weight: {}g'.format(key_a, round(df.weight_a.mean(), 2)))\n",
    "print('{} parameters weight: {}g'.format(key_b, round(df.weight_b.mean(), 2)))\n",
    "\n",
    "pct_difference = 100 * (df.weight_b.mean() - df.weight_a.mean()) / df.weight_a.mean()\n",
    "print('Percentage difference: {}%'.format(round(pct_difference, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_a.left_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_b.left_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Perform Un- and Re-Rectification </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMAGE_WIDTH = 4096\n",
    "IMAGE_HEIGHT = 3000\n",
    "\n",
    "def get_camera_parameters(params: dict) -> Tuple:\n",
    "    \"\"\"Return individual camera parameters from JSON stereo parameters contents.\"\"\"\n",
    "    \n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "    \n",
    "    imageSize = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, \n",
    "                                                               distCoeffs2, imageSize, R, T, None, None, \n",
    "                                                               None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "    \n",
    "    return left_maps, right_maps, cameraMatrix1, distCoeffs1, R1, P1\n",
    "\n",
    "\n",
    "def rectify_keypoints(annotation: dict, stereo_parameters: dict) -> dict:\n",
    "    \"\"\"Generated rectified key-points from unrectified key-point input and stereo parameters.\"\"\"\n",
    "    \n",
    "    left_maps, right_maps, cameraMatrix1, distCoeffs1, R1, P1 = get_camera_parameters(stereo_parameters)\n",
    "    \n",
    "    rectified_ann = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in annotation[side]:\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            maps = left_maps_m if side == 'leftCrop' else right_maps_m\n",
    "            x_new, y_new = cv2.undistortPoints(np.array([[[x, y]]]).astype(float), \n",
    "                                cameraMatrix1, distCoeffs1, R=R1, P=P1)[0][0]\n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            rectified_ann[side].append({\n",
    "                'keypointType': item['keypointType'],\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new\n",
    "            })\n",
    "            \n",
    "    return rectified_ann\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_params_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = json.loads(df.ann_a.iloc[0])\n",
    "matlab_params = json.load(open(matlab_params_f))\n",
    "rectify_keypoints(ann, matlab_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_params_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40013180_R40029775/2020-01-14T00:00:00Z_L40013180_R40029775_stereo-parameters.json'\n",
    "circular_params_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40013180_R40029775/2020-02-16T17:30:33.458096000Z_L40013180_R40029775_stereo-parameters.json'\n",
    "matlab_params_f, _, _ = s3_access_utils.download_from_url(matlab_params_url)\n",
    "circular_params_f, _, _ = s3_access_utils.download_from_url(circular_params_url)\n",
    "left_maps_m, right_maps_m, cameraMatrix1_m, distCoeffs1_m, R1_m, P1_m = load_params(matlab_params_f)\n",
    "left_maps_c, right_maps_c, cameraMatrix1_c, distCoeffs1_c, R1_c, P1_c = load_params(circular_params_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_m_mp_c_cp_m_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    ann_m = json.loads(row.ann_m)\n",
    "    \n",
    "    # un-rectify with matlab params, re-rectify with circular params\n",
    "    ann_m_mp_c = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann_m[side]:\n",
    "            bp = item['keypointType']\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            maps = left_maps_m if side == 'leftCrop' else right_maps_m\n",
    "            x_new, y_new = cv2.undistortPoints(np.array([[maps[0][y, x]]]).astype(float), \n",
    "                                cameraMatrix1_c, distCoeffs1_c, R=R1_c, P=P1_c)[0][0]\n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            ann_m_mp_c[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new\n",
    "            })\n",
    "            \n",
    "    \n",
    "    # now take above result, un-rectify with circular params, re-rectify with matlab params\n",
    "    ann_m_mp_c_cp_m = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann_m_mp_c[side]:\n",
    "            bp = item['keypointType']\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            maps = left_maps_c if side == 'leftCrop' else right_maps_c\n",
    "            x_new, y_new = cv2.undistortPoints(np.array([[maps[0][y, x]]]).astype(float), \n",
    "                                cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            ann_m_mp_c_cp_m[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new\n",
    "            })\n",
    "\n",
    "    ann_m_mp_c_cp_m_list.append(ann_m_mp_c_cp_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = defaultdict(list)\n",
    "for ann_m, ann_m_mp_c_cp_m in zip([json.loads(x) for x in list(df.ann_m.values)], ann_m_mp_c_cp_m_list):\n",
    "    ann_m_left_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m['leftCrop']}\n",
    "    ann_m_right_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m['rightCrop']}\n",
    "    ann_m_mp_c_cp_m_left_kps = \\\n",
    "        {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m_mp_c_cp_m['leftCrop']}\n",
    "    ann_m_mp_c_cp_m_right_kps = \\\n",
    "        {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m_mp_c_cp_m['rightCrop']}\n",
    "    for bp in BODY_PARTS:\n",
    "        analysis_data['body_part'].append(bp)\n",
    "        analysis_data['x_1_l'].append(ann_m_left_kps[bp][0])\n",
    "        analysis_data['y_1_l'].append(ann_m_left_kps[bp][1])\n",
    "        analysis_data['x_1_r'].append(ann_m_right_kps[bp][0])\n",
    "        analysis_data['y_1_r'].append(ann_m_right_kps[bp][1])\n",
    "        analysis_data['x_2_l'].append(ann_m_mp_c_cp_m_left_kps[bp][0])\n",
    "        analysis_data['y_2_l'].append(ann_m_mp_c_cp_m_left_kps[bp][1])\n",
    "        analysis_data['x_2_r'].append(ann_m_mp_c_cp_m_right_kps[bp][0])\n",
    "        analysis_data['y_2_r'].append(ann_m_mp_c_cp_m_right_kps[bp][1])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bp in BODY_PARTS:\n",
    "    body_part_mask = analysis_df.body_part == bp\n",
    "    diffs = analysis_df[body_part_mask].x_1_l - analysis_df[body_part_mask].x_2_l\n",
    "    print('Diffs in left crop x coordinate for {}: {}'.format(bp, diffs.abs().mean()))\n",
    "    \n",
    "    diffs = analysis_df[body_part_mask].y_1_l - analysis_df[body_part_mask].y_2_l\n",
    "    print('Diffs in left crop y coordinate for {}: {}'.format(bp, diffs.abs().mean()))\n",
    "    \n",
    "    diffs = analysis_df[body_part_mask].x_1_r - analysis_df[body_part_mask].x_2_r\n",
    "    print('Diffs in right crop x coordinate for {}: {}'.format(bp, diffs.abs().mean()))\n",
    "    \n",
    "    diffs = analysis_df[body_part_mask].y_1_r - analysis_df[body_part_mask].y_2_r\n",
    "    print('Diffs in right crop y coordinate for {}: {}'.format(bp, diffs.abs().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for idx, row in df.iterrows():\n",
    "    ann_m = json.loads(row.ann_m)\n",
    "    ann_dict_left_kps_m = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m['leftCrop']}\n",
    "    ann_dict_right_kps_m = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_m['rightCrop']}\n",
    "    for bp in BODY_PARTS:\n",
    "        diff = ann_dict_left_kps_m[bp][1] - ann_dict_right_kps_m[bp][1]\n",
    "        diffs.append(diff)\n",
    "\n",
    "print(np.median(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for idx, row in df.iterrows():\n",
    "    ann_c = json.loads(row.ann_c)\n",
    "    ann_dict_left_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['leftCrop']}\n",
    "    ann_dict_right_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['rightCrop']}\n",
    "    for bp in BODY_PARTS:\n",
    "        diff = ann_dict_left_kps_c[bp][1] - ann_dict_right_kps_c[bp][1]\n",
    "        diffs.append(diff)\n",
    "print(np.median(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_diffs = []\n",
    "for idx, row in mdf.iterrows():\n",
    "    ann_c = json.loads(row.annotation)\n",
    "    ann_dict_left_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['leftCrop']}\n",
    "    ann_dict_right_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['rightCrop']}\n",
    "    diffs = []\n",
    "    for bp in BODY_PARTS:\n",
    "        diff = ann_dict_left_kps_c[bp][1] - ann_dict_right_kps_c[bp][1]\n",
    "        diffs.append(diff)\n",
    "    median_diffs.append(np.median(diffs))\n",
    "median_diffs = np.array(median_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(median_diffs > 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['median_diff'] = median_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf = mdf[(mdf.akpd_score > 0.95) & (mdf.median_diff > 15)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Y-Coordinate Deviation Diagnosis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv('/root/data/alok/biomass_estimation/playground/rectification.20200311.184020.MDSB.output.csv')\n",
    "tdf = tdf.sort_values('captured_at').copy(deep=True)\n",
    "tdf2 = pd.read_csv('/root/data/alok/biomass_estimation/playground/rectification_2.csv')\n",
    "tdf2 = tdf2.sort_values('captured_at').copy(deep=True)\n",
    "tdf['annotation'] = tdf2.annotation.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(tdf2[tdf2.captured_at == '2019-09-13T01:15:56.350510000Z'].annotation.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(tdf[tdf.captured_at == '2019-09-13T01:15:56.350510000Z'].left_crop_metadata.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf2.annotation.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.annotation.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(params):\n",
    "    print(\"Loading params...\")\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "\n",
    "    imageSize = (4096, 3000)\n",
    "\n",
    "    # perform rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, None, None, None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "\n",
    "    print(\"Params loaded.\")\n",
    "    return left_maps, right_maps\n",
    "\n",
    "def rectify_crop(crop, maps, crop_metadata):\n",
    "    print(\"Rectifying...\")\n",
    "    new_image = np.zeros([3000, 4096, 3]).astype('uint8')\n",
    "    lower_left = (crop_metadata['y_coord'] + crop_metadata['height'], crop_metadata['x_coord'])\n",
    "    upper_right = (crop_metadata['y_coord'], crop_metadata['x_coord'] + crop_metadata['width'])\n",
    "    new_image[upper_right[0]:lower_left[0], lower_left[1]:upper_right[1], :] = np.array(crop)\n",
    "    remap = cv2.remap(new_image, maps[0], maps[1], cv2.INTER_LANCZOS4)\n",
    "    nonzero_indices = np.where(remap > 0)\n",
    "    y_min, y_max = nonzero_indices[0].min(), nonzero_indices[0].max()\n",
    "    x_min, x_max = nonzero_indices[1].min(), nonzero_indices[1].max()\n",
    "    lower_left = (y_max, x_min)\n",
    "    upper_right = (y_min, x_max)\n",
    "    rectified_crop = remap[upper_right[0]:lower_left[0], lower_left[1]:upper_right[1], :].copy()\n",
    "\n",
    "    # construct rectified crop metadata\n",
    "    rectified_crop_metadata = crop_metadata.copy()\n",
    "    rectified_crop_metadata['x_coord'] = int(x_min)\n",
    "    rectified_crop_metadata['y_coord'] = int(y_min)\n",
    "    rectified_crop_metadata['width'] = int(x_max - x_min)\n",
    "    rectified_crop_metadata['height'] = int(y_max - y_min)\n",
    "\n",
    "    print(\"Rectification done\")\n",
    "    return rectified_crop, rectified_crop_metadata\n",
    "\n",
    "\n",
    "def create_crop_metadata(raw_crop_f):\n",
    "    coords = [int(x) for x in os.path.basename(raw_crop_f).replace('.jpg', '').split('_')[-4:]]\n",
    "    \n",
    "    crop_metadata = {}\n",
    "    crop_metadata['x_coord'] = coords[0]\n",
    "    crop_metadata['y_coord'] = coords[1]\n",
    "    crop_metadata['width'] = coords[2] - coords[0]\n",
    "    crop_metadata['height'] = coords[3] - coords[1]\n",
    "    print(coords[0])\n",
    "    \n",
    "    return crop_metadata\n",
    "\n",
    "def display_crops(left_image, right_image, ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    \n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['leftCrop']}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['rightCrop']}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps\n",
    "matlab_stereo_parameters_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40013180_R40029775/2020-01-14T00:00:00Z_L40013180_R40029775_stereo-parameters.json'\n",
    "matlab_stereo_params_f, _, _ = s3_access_utils.download_from_url(matlab_stereo_parameters_url)\n",
    "matlab_stereo_params = json.load(open(matlab_stereo_params_f))\n",
    "left_maps, right_maps = load_params(matlab_stereo_params)\n",
    "\n",
    "# load crops and metadata\n",
    "i = 2\n",
    "left_crop_url = tdf.left_crop_url.iloc[i]\n",
    "right_crop_url = tdf.right_crop_url.iloc[i]\n",
    "ann = json.loads(tdf.annotation.iloc[i])\n",
    "crops_json_url_base = os.path.dirname(left_crop_url.replace('aquabyte-crops-test', 'aquabyte-frames-resized-inbound'))\n",
    "crops_json_url = os.path.join(crops_json_url_base, 'crops.json')\n",
    "crops_json_f, _, _ = s3_access_utils.download_from_url(crops_json_url)\n",
    "left_raw_crop_url = left_crop_url.replace('aquabyte-crops-test', 'aquabyte-frames-resized-inbound')\n",
    "left_raw_crop_f, _, _ = s3_access_utils.download_from_url(left_raw_crop_url)\n",
    "left_raw_crop = Image.open(left_raw_crop_f)\n",
    "right_raw_crop_url = right_crop_url.replace('aquabyte-crops-test', 'aquabyte-frames-resized-inbound')\n",
    "right_raw_crop_f, _, _ = s3_access_utils.download_from_url(right_raw_crop_url)\n",
    "right_raw_crop = Image.open(right_raw_crop_f)\n",
    "\n",
    "left_crop_metadata = create_crop_metadata(left_raw_crop_f)\n",
    "right_crop_metadata = create_crop_metadata(right_raw_crop_f)\n",
    "\n",
    "rectified_left_crop, rectified_left_crop_metadata = rectify_crop(left_raw_crop, left_maps, left_crop_metadata)\n",
    "rectified_right_crop, rectified_right_crop_metadata = rectify_crop(right_raw_crop, right_maps, right_crop_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_crops(rectified_left_crop, rectified_right_crop, ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_raw_crop_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/data_dump_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf.captured_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.captured_at)\n",
    "odf.index = pd.to_datetime(odf.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf['left_crop_fname'] = odf.left_crop_url.apply(lambda x: os.path.basename(x))\n",
    "df['left_crop_fname'] = df.left_crop_url_m.apply(lambda x: os.path.basename(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.left_crop_fname\n",
    "odf.index = odf.left_crop_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_diffs, right_diffs = [], []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    ann_1 = json.loads(row.ann_m)\n",
    "    if (odf.left_crop_fname == row.left_crop_fname).sum() > 0:\n",
    "        ann_2 = json.loads(odf[odf.left_crop_fname == row.left_crop_fname].annotation.iloc[0])\n",
    "        ann_1_left_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_1['leftCrop']}\n",
    "        ann_1_right_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_1['rightCrop']}\n",
    "        ann_2_left_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_2['leftCrop']}\n",
    "        ann_2_right_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_2['rightCrop']}\n",
    "        for bp in BODY_PARTS:\n",
    "            left_diffs.append(ann_1_left_dict[bp][1] - ann_2_left_dict[bp][1])\n",
    "            right_diffs.append(ann_1_right_dict[bp][1] - ann_2_right_dict[bp][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(right_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
