{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '/root/data/temp/results_c8cc936a26a7645895842f467fe9d88764cf5579_gtsf_mixed_air_v1.h5'\n",
    "df = pd.read_hdf(df_path, key='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(df.weight, df.estimated_biomass_g)\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([0, 10000])\n",
    "plt.plot([0, 10000], [0, 10000])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = defaultdict(list)\n",
    "\n",
    "body_parts = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    world_keypoints = row.world_keypoints\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            d = euclidean_distance(world_keypoints[body_parts[i]], \n",
    "                                   world_keypoints[body_parts[j]])\n",
    "            features_data['{0}-{1}'.format(i, j)].append(d)\n",
    "\n",
    "    features_data['weight'].append(row.weight)\n",
    "    features_data['captured_at'].append(row.captured_at)\n",
    "    features_data['gtsf_fish_identifier'].append(row.fish_id)\n",
    "    features_data['pen_id'].append(row.pen_id)\n",
    "    features_data['keypoint_annotation_id'].append(row.id)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df[features_df.keypoint_annotation_id != 606484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all features\n",
    "\n",
    "body_parts_subset = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE'\n",
    "])\n",
    "\n",
    "body_part_indices = [body_parts.index(bp) for bp in body_parts_subset]\n",
    "\n",
    "pairwise_distance_columns = ['{0}-{1}'.format(x, y) for x, y in list(combinations(body_part_indices, 2))]\n",
    "interaction_columns_quadratic = []\n",
    "interaction_columns_cubic = []\n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        col1 = pairwise_distance_columns[i]\n",
    "        col2 = pairwise_distance_columns[j]\n",
    "        interaction_column = '{},{}'.format(col1, col2)\n",
    "        features_df[interaction_column] = features_df[col1] * features_df[col2]\n",
    "        interaction_columns_quadratic.append(interaction_column)\n",
    "        \n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        for k in range(j, len(pairwise_distance_columns)):\n",
    "            col1 = pairwise_distance_columns[i]\n",
    "            col2 = pairwise_distance_columns[j]\n",
    "            col3 = pairwise_distance_columns[k]\n",
    "            interaction_column = '{},{},{}'.format(col1, col2, col3)\n",
    "            features_df[interaction_column] = features_df[col1] * features_df[col2] * features_df[col3]\n",
    "            interaction_columns_cubic.append(interaction_column)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_mask(df, train_frac, randomize=True):\n",
    "    x = np.zeros((df.shape[0]), dtype=bool)\n",
    "    x[:int(train_frac * df.shape[0])] = True\n",
    "    np.random.shuffle(x)\n",
    "    mask = pd.Series(x)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "mask = generate_train_mask(features_df, train_frac=0.9)\n",
    "mask = mask & (features_df.gtsf_fish_identifier != '190620-4e4e0640-d4eb-405d-8fcf-57fda11d7660')\n",
    "columns = pairwise_distance_columns + interaction_columns_quadratic + interaction_columns_cubic\n",
    "\n",
    "X_train = features_df.loc[mask, columns].values\n",
    "y_train = features_df.loc[mask, 'weight'].values\n",
    "# w_train = features_df.loc[mask, 'w'].values\n",
    "X_test = features_df.loc[~mask, columns].values\n",
    "y_test = features_df.loc[~mask, 'weight'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scaler.fit(features_df.loc[mask & (features_df.pen_id==48), columns].values)\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=min(X_train_normalized.shape[0], X_train_normalized.shape[1]))\n",
    "# pca = WPCA(n_components=min(X_train_normalized.shape[0], X_train_normalized.shape[1]))\n",
    "pca.fit(X_train_normalized)#, weights=np.vstack([w_train] * X_train_normalized.shape[1]).T)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
    "# idx = np.where(explained_variance_ratio > 0.999999)[0][0]\n",
    "idx = \n",
    "print(idx)\n",
    "\n",
    "pca = PCA(n_components=idx+1)\n",
    "# pca = PCA(n_components=idx+1)\n",
    "pca.fit(X_train_normalized)\n",
    "X_train_transformed = pca.transform(X_train_normalized)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "X_test_transformed = pca.transform(X_test_normalized)\n",
    "\n",
    "reg = LinearRegression().fit(X_train_transformed, y_train)#, sample_weight=w_train)\n",
    "print(reg.score(X_test_transformed, y_test))\n",
    "\n",
    "y_pred = reg.predict(pca.transform(scaler.transform(features_df[columns].values)))\n",
    "features_df['prediction'] = y_pred\n",
    "features_df['error'] = features_df.prediction - features_df.weight\n",
    "features_df['error_pct'] = features_df.error / features_df.weight\n",
    "features_df['abs_error_pct'] = features_df.error_pct.abs()\n",
    "\n",
    "model = {\n",
    "    'mean': scaler.mean_,\n",
    "    'std': scaler.scale_,\n",
    "    'PCA_components': pca.components_,\n",
    "    'reg_coef': reg.coef_,\n",
    "    'reg_intercept': reg.intercept_,\n",
    "    'body_parts': body_parts_subset   \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=min(X_train_normalized.shape[0], X_train_normalized.shape[1]))\n",
    "pca.fit(X_train_normalized)\n",
    "X_train_transformed = pca.transform(X_train_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Principal Component Regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_10 = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = []\n",
    "regr = LinearRegression()\n",
    "# Calculate MSE using CV for the 19 principle components, adding one component at the time.\n",
    "for i in np.arange(1, 200):\n",
    "    score = -1*cross_val_score(regr, X_train_transformed[:,:i], y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.ylim([0, 100000])\n",
    "plt.plot(mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.array(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    if all([k in x for k in ['leftCrop', 'rightCrop', 'cameraParameters']]):\n",
    "        return pixel2world(x['leftCrop'], x['rightCrop'], x['cameraParameters'])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keypoints.apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg = AccuracyMetricsGenerator(mask, features_df.prediction.values, features_df.weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.plot_predictions_vs_ground_truth(impose_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ~mask & (features_df.pen_id != 100.0) & (features_df.abs_error_pct < 2.0) & (features_df.weight > 2000)\n",
    "(features_df[m].prediction.mean() - features_df[m].weight.mean()) / features_df[m].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_df[m].abs_error_pct).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_df[m].error_pct).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for idx, row in features_df.iterrows():\n",
    "    count = features_df[(features_df.weight >= row.weight-250) & (features_df.weight <= row.weight+250)].shape[0]\n",
    "    if count > 1:\n",
    "        weights.append(1.0 / count)\n",
    "    else:\n",
    "        weights.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['w'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[features_df.captured_at > '2019-06-22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "x = features_df[(features_df.captured_at >= '2019-05-03') & (features_df.captured_at < '2019-05-04')].error_pct\n",
    "plt.hist(x[x.abs() < 100.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[['keypoint_annotation_id', 'abs_error_pct', 'captured_at']].sort_values('abs_error_pct', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.index = pd.to_datetime(features_df.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.abs_error_pct.resample('D', how=lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[['abs_error_pct', 'keypoint_annotation_id', 'captured_at', 'weight']].sort_values('abs_error_pct', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize Bad Cases </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "credentials = json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS']))\n",
    "rds_access_utils = RDSAccessUtils(credentials)\n",
    "visualizer = Visualizer(s3_access_utils, rds_access_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.load_data(507806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.display_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = df[df.id == 508195].keypoints.iloc[0]\n",
    "wkps = pixel2world(kp['leftCrop'], kp['rightCrop'], kp['cameraParameters'])\n",
    "body_parts = sorted(list(wkps.keys()))\n",
    "for i in range(len(body_parts)-1):\n",
    "    for j in range(i+1, len(body_parts)):\n",
    "        bp1, bp2 = body_parts[i], body_parts[j]\n",
    "        dist = euclidean_distance(wkps[bp1], wkps[bp2])\n",
    "        print('{0}<->{1}: {2}'.format(bp1, bp2, dist))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
