{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "import random\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extract base data from database </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null and b.is_qa = false;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Append world kepyoints to the data </h1>\n",
    "<h3> Ideally, this data should already live directly in the database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get the features dataframe from the base data with all pairwise distances </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2biomass(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    '163_eigs': pickle.load(open('/root/data/alok/biomass_estimation/playground/model_163_eigs.pkl', 'rb')),\n",
    "    '20_eigs': pickle.load(open('/root/data/alok/biomass_estimation/playground/model_20_eigs.pkl', 'rb'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "analysis_dict = defaultdict(list)\n",
    "trials = 20\n",
    "row_count = 0\n",
    "for idx, row in df.sample(1000).iterrows():\n",
    "\n",
    "    gt_weight = row.weight\n",
    "    # random keypoint jitters\n",
    "    keypoints = row.keypoints\n",
    "    for jitter in [0, 5, 10, 20, 50]:\n",
    "        jittered_keypoints = {'leftCrop': [], 'rightCrop': []}\n",
    "        T = trials if jitter > 0 else 1\n",
    "        for t in range(T):\n",
    "            for model_name, model in models.items():\n",
    "                for key in ['leftCrop', 'rightCrop']:\n",
    "                    for item in keypoints[key]:\n",
    "                        jittered_item = copy(item)\n",
    "                        j = np.random.normal(0, jitter)\n",
    "                        jittered_item['xFrame'] += j\n",
    "                        jittered_keypoints[key].append(jittered_item)\n",
    "\n",
    "                jittered_world_keypoints = pixel2world(jittered_keypoints['leftCrop'],\n",
    "                                                       jittered_keypoints['rightCrop'],\n",
    "                                                       row.camera_metadata)\n",
    "                estimated_weight = coord2biomass(jittered_world_keypoints, model)\n",
    "                analysis_dict['jitter'].append(jitter)\n",
    "                analysis_dict['estimated_weight'].append(estimated_weight)\n",
    "                analysis_dict['gt_weight'].append(gt_weight)\n",
    "                analysis_dict['trial'].append(t)\n",
    "                analysis_dict['model_name'].append(model_name)\n",
    "\n",
    "    if row_count % 10 == 0:\n",
    "        print('Row count: {}'.format(row_count))\n",
    "        print('Percentage complete: {}'.format(row_count / 1000.0))\n",
    "        print('-'*20)\n",
    "    row_count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jitter in [0, 5, 10, 20, 50]:\n",
    "    for model_name, model in models.items():\n",
    "        model_mask = analysis_df.model_name == model_name\n",
    "        jitter_mask = analysis_df.jitter == jitter\n",
    "        inliner_mask = (analysis_df.estimated_weight > -100000) & (analysis_df.estimated_weight < 100000)\n",
    "        mask = model_mask & jitter_mask & inliner_mask\n",
    "        mean_weight = analysis_df[mask].estimated_weight.mean()\n",
    "        print('Mean weight for model = {}, jitter = {}: {}'.format(model_name, jitter, mean_weight))\n",
    "print('Mean GT weight: {}'.format(analysis_df[analysis_df.jitter == 0].gt_weight.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize Accuracy Plots </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jitter in [0, 5, 10, 20, 50]:\n",
    "    for model_name, model in models.items():\n",
    "        model_mask = analysis_df.model_name == model_name\n",
    "        jitter_mask = analysis_df.jitter == jitter\n",
    "        trial_mask = analysis_df.trial == 0\n",
    "        mask = model_mask & jitter_mask & trial_mask\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(analysis_df[(analysis_df.jitter == 0) & model_mask].gt_weight, analysis_df[mask].estimated_weight)\n",
    "        plt.plot([0, 10000], [0, 10000], color='red')\n",
    "        plt.xlim([0, 10000])\n",
    "        plt.ylim([0, 10000])\n",
    "        plt.title('Model: {}, Jitter: {}'.format(model_name, jitter))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
