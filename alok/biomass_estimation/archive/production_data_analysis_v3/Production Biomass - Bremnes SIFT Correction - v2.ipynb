{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "from sqlalchemy import create_engine, MetaData, Table, select, and_, func\n",
    "from sqlalchemy.orm import sessionmaker, relationship, join\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import Table, Column, Integer, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from aquabyte.optics import convert_to_world_point, depth_from_disp, pixel2world, euclidean_distance\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "import mpld3\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "from aquabyte.visualize import _normalize_world_keypoints\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/repos/cv_research/alok/biomass_estimation/production_data_analysis_v3')\n",
    "from template_matching import enhance, find_matches_and_homography, adjust_keypoints\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "aws_credentials = json.load(open(os.environ[\"AWS_CREDENTIALS\"]))\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_credentials[\"aws_access_key_id\"],\n",
    "                         aws_secret_access_key=aws_credentials[\"aws_secret_access_key\"],\n",
    "                         region_name=\"eu-west-1\")\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "\n",
    "# prod SQL credentaials\n",
    "sql_credentials = json.load(open(os.environ[\"PROD_RESEARCH_SQL_CREDENTIALS\"]))\n",
    "rds_access_utils = RDSAccessUtils(sql_credentials)\n",
    "\n",
    "sql_query = '''\n",
    "select * from keypoint_annotations\n",
    "where pen_id = 7\n",
    "and keypoints is not NULL;\n",
    "'''\n",
    "\n",
    "original_df = rds_access_utils.extract_from_database(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "original_df['world_keypoints'] = original_df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = '/root/data/temp/results_557ec1732d8bc8bc66951d2ea4e69b935d69b111_model_lateral_only_original_bremnes_data.h5'\n",
    "f = '/root/data/temp/results_f5cfd03d4622c24879cfa9d5f6427bffc4668205_unweighted_model_3800_vikingfjord_experiment_id_3.h5'\n",
    "original_df = pd.read_hdf(f, 'table') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.sort_values('estimated_biomass_g', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5618\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(original_df.left_image_url.iloc[idx])\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(original_df.right_image_url.iloc[idx])\n",
    "keypoints = original_df.keypoints.iloc[idx]\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL = enhance(imageL)\n",
    "imgR = enhance(imageR)\n",
    "good, matchesMask, H = find_matches_and_homography(imgL, imgR)\n",
    "adjusted_keypoints = adjust_keypoints(keypoints, H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_world_keypoints_3D(wkps):\n",
    "    norm_wkps = _normalize_world_keypoints(wkps)\n",
    "    body_parts = [k for k in norm_wkps.keys() if k != 'BODY']\n",
    "    xs = [norm_wkps[bp][0] for bp in body_parts]\n",
    "    ys = [norm_wkps[bp][1] for bp in body_parts]\n",
    "    zs = [norm_wkps[bp][2] for bp in body_parts]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlim3d(0, max(xs))\n",
    "    ax.set_ylim3d(-0.3, 0.3)\n",
    "    ax.set_zlim3d(-0.3, 0.3)\n",
    "    ax.scatter(xs, ys, zs, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "wkps = original_df.world_keypoints.iloc[idx]\n",
    "plot_world_keypoints_3D(wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "cm = original_df.camera_metadata.iloc[idx]\n",
    "adjusted_wkps = pixel2world(adjusted_keypoints['leftCrop'], adjusted_keypoints['rightCrop'], cm)\n",
    "plot_world_keypoints_3D(adjusted_wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2biomass(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = '/root/alok/repos/cv_algorithms/biomass-production/src/model.pkl'\n",
    "model = pickle.load(open(model_f, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adjusted_weight(left_image_url, right_image_url, keypoints, cm, kpid, weight_dict):\n",
    "# def generate_adjusted_weight(row, model):\n",
    "    try:\n",
    "        left_image_f, _, _ = s3_access_utils.download_from_url(left_image_url)\n",
    "        right_image_f, _, _ = s3_access_utils.download_from_url(right_image_url)\n",
    "        imageL = cv2.imread(left_image_f)\n",
    "        imageR = cv2.imread(right_image_f)\n",
    "        good, matchesMask, H = find_matches_and_homography(imageL, imageR)\n",
    "        adjusted_keypoints = adjust_keypoints(keypoints, H)\n",
    "        adjusted_wkps = pixel2world(adjusted_keypoints['leftCrop'], \n",
    "                                    adjusted_keypoints['rightCrop'],\n",
    "                                    cm)\n",
    "        weight = coord2biomass(adjusted_wkps, model)\n",
    "        weight_dict[kpid] = weight\n",
    "    except Exception as e:\n",
    "        print('Error: {}'.format(e))\n",
    "        \n",
    "    print(len(weight_dict.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "weight_dict = manager.dict()\n",
    "\n",
    "args = []\n",
    "for idx, row in original_df.iterrows():\n",
    "    args.append((row.left_image_url, row.right_image_url, row.keypoints, \n",
    "                 row.camera_metadata, row.id, weight_dict))\n",
    "\n",
    "pool = Pool(processes=20)\n",
    "pool.starmap(generate_adjusted_weight, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in weight_dict.keys():\n",
    "    original_weight = original_df[original_df.id == k].estimated_biomass_g.iloc[0]\n",
    "    new_weight = weight_dict[k]\n",
    "    pct_difference = (new_weight - original_weight) / original_weight\n",
    "    print('Original weight: {}, New weight: {}, Pct. Difference: {}'.format(original_weight, new_weight, pct_difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "weights = np.array(weight_dict.values())\n",
    "mask = (weights > 0) & (weights < 20000)\n",
    "plt.hist(weights[mask], bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(weights[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "weights = original_df.estimated_biomass_g.values\n",
    "mask = (weights > 0) & (weights < 20000)\n",
    "plt.hist(weights[mask], bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(weights[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord2biomass(wkps, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord2biomass(adjusted_wkps, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
