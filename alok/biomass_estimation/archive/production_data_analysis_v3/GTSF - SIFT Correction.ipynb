{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "from sqlalchemy import create_engine, MetaData, Table, select, and_, func\n",
    "from sqlalchemy.orm import sessionmaker, relationship, join\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import Table, Column, Integer, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from aquabyte.optics import convert_to_world_point, depth_from_disp, pixel2world, euclidean_distance\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "from aquabyte.visualize import _normalize_world_keypoints\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/repos/cv_research/alok/biomass_estimation/production_data_analysis_v3')\n",
    "from template_matching import enhance, find_matches_and_homography, adjust_keypoints\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "aws_credentials = json.load(open(os.environ[\"AWS_CREDENTIALS\"]))\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_credentials[\"aws_access_key_id\"],\n",
    "                         aws_secret_access_key=aws_credentials[\"aws_secret_access_key\"],\n",
    "                         region_name=\"eu-west-1\")\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null and b.is_qa = false\n",
    "    limit 1;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    keypoints = row.keypoints\n",
    "    if 'leftCrop' in keypoints and 'rightCrop' in keypoints:\n",
    "        if (keypoints['leftCrop'][0]['xCrop'] == 44) and (keypoints['leftCrop'][0]['yCrop'] == 296):\n",
    "            print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(df.left_image_url.iloc[idx])\n",
    "print(df.left_image_url.iloc[idx])\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(df.right_image_url.iloc[idx])\n",
    "keypoints = df.keypoints.iloc[idx]\n",
    "\n",
    "\n",
    "left_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['leftCrop']}\n",
    "right_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['rightCrop']}\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n",
    "\n",
    "# crop the data\n",
    "l_width = df.left_crop_metadata.iloc[idx]['width']\n",
    "l_height = df.left_crop_metadata.iloc[idx]['height']\n",
    "r_width = df.right_crop_metadata.iloc[idx]['width']\n",
    "r_height = df.right_crop_metadata.iloc[idx]['height']\n",
    "print(l_width, l_height, r_width, r_height)\n",
    "padding = 100\n",
    "cropL_x_left = max(min([kp[0] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "cropL_x_right = min(max([kp[0] for kp in left_keypoints_dict.values()]) + padding, l_width)\n",
    "cropL_y_top = max(min([kp[1] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "cropL_y_bottom = min(max([kp[1] for kp in left_keypoints_dict.values()]) + padding, l_height)\n",
    "\n",
    "cropR_x_left = max(min([kp[0] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "cropR_x_right = min(max([kp[0] for kp in right_keypoints_dict.values()]) + padding, r_width)\n",
    "cropR_y_top = max(min([kp[1] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "cropR_y_bottom = min(max([kp[1] for kp in right_keypoints_dict.values()]) + padding, r_height)\n",
    "\n",
    "imageL = imageL[cropL_y_top:cropL_y_bottom, cropL_x_left:cropL_x_right]\n",
    "imageR = imageR[cropR_y_top:cropR_y_bottom, cropR_x_left:cropR_x_right]\n",
    "\n",
    "#modify keypoints\n",
    "modified_keypoints = {'leftCrop': [], 'rightCrop': []}\n",
    "for item in keypoints['leftCrop']:\n",
    "    modified_item = copy(item)\n",
    "    modified_item['xCrop'] = item['xCrop'] - cropL_x_left\n",
    "    modified_item['yCrop'] = item['yCrop'] - cropL_y_top\n",
    "    modified_keypoints['leftCrop'].append(modified_item)\n",
    "\n",
    "for item in keypoints['rightCrop']:\n",
    "    modified_item = copy(item)\n",
    "    modified_item['xCrop'] = item['xCrop'] - cropR_x_left\n",
    "    modified_item['yCrop'] = item['yCrop'] - cropR_y_top\n",
    "    modified_keypoints['rightCrop'].append(modified_item)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url = df.left_image_url.iloc[idx]\n",
    "right_crop_url = df.right_image_url.iloc[idx]\n",
    "keypoints = json.dumps(df.keypoints.iloc[idx])\n",
    "cm = json.dumps(df.camera_metadata.iloc[idx])\n",
    "left_crop_metadata = json.dumps(df.left_crop_metadata.iloc[idx])\n",
    "right_crop_metadata = json.dumps(df.right_crop_metadata.iloc[idx])\n",
    "H = find_matches_and_homography_2(left_crop_url, right_crop_url, keypoints, cm, left_crop_metadata, right_crop_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(H).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good, matchesMask, H, kp1, kp2 = find_matches_and_homography(imageL, imageR)\n",
    "# adjusted_keypoints = adjust_keypoints(modified_keypoints, H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_2(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches_and_homography_2(left_crop_url, right_crop_url, keypoints, cm, left_crop_metadata, right_crop_metadata, MIN_MATCH_COUNT=11, GOOD_PERC=0.7, FLANN_INDEX_KDTREE=0):\n",
    "    \n",
    "    left_image_f, _, _ = s3_access_utils.download_from_url(df.left_image_url.iloc[idx])\n",
    "    right_image_f, _, _ = s3_access_utils.download_from_url(df.right_image_url.iloc[idx])\n",
    "    imageL = cv2.imread(left_image_f)\n",
    "    imageR = cv2.imread(right_image_f)\n",
    "    \n",
    "#     imageL = load_image(left_crop_url)\n",
    "#     imageR = load_image(right_crop_url)\n",
    "\n",
    "    # crop the data\n",
    "\n",
    "    keypoints = json.loads(keypoints)\n",
    "    cm = json.loads(cm)\n",
    "    left_crop_metadata = json.loads(left_crop_metadata)\n",
    "    right_crop_metadata = json.loads(right_crop_metadata)\n",
    "    print('Camera Metadata: {}'.format(cm))\n",
    "    if 'leftCrop' in keypoints and 'rightCrop' in keypoints:\n",
    "        left_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['leftCrop']}\n",
    "        right_keypoints_dict = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['rightCrop']}\n",
    "        print(left_keypoints_dict)\n",
    "        \n",
    "        # crop the data\n",
    "        l_width = left_crop_metadata['width']\n",
    "        l_height = left_crop_metadata['height']\n",
    "        r_width = right_crop_metadata['width']\n",
    "        r_height = right_crop_metadata['height']\n",
    "        padding = 100\n",
    "        cropL_x_left = max(min([kp[0] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "        cropL_x_right = min(max([kp[0] for kp in left_keypoints_dict.values()]) + padding, l_width)\n",
    "        cropL_y_top = max(min([kp[1] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "        cropL_y_bottom = min(max([kp[1] for kp in left_keypoints_dict.values()]) + padding, l_height)\n",
    "\n",
    "        cropR_x_left = max(min([kp[0] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "        cropR_x_right = min(max([kp[0] for kp in right_keypoints_dict.values()]) + padding, r_width)\n",
    "        cropR_y_top = max(min([kp[1] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "        cropR_y_bottom = min(max([kp[1] for kp in right_keypoints_dict.values()]) + padding, r_height)\n",
    "        \n",
    "\n",
    "        imageL = imageL[cropL_y_top:cropL_y_bottom, cropL_x_left:cropL_x_right]\n",
    "        imageR = imageR[cropR_y_top:cropR_y_bottom, cropR_x_left:cropR_x_right]\n",
    "\n",
    "        sift = cv2.KAZE_create()\n",
    "        img1 = enhance(imageL)\n",
    "        img2 = enhance(imageR)\n",
    "        kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks = 50)\n",
    "\n",
    "\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "        good = []\n",
    "        H = []\n",
    "        matchesMask = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < GOOD_PERC*n.distance:\n",
    "                good.append(m)\n",
    "        if len(good)>=MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1, 1 ,2)\n",
    "            dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1, 1, 2)\n",
    "            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            H = [] if H is None else H.tolist()\n",
    "        else:\n",
    "            print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "            matchesMask = None\n",
    "\n",
    "        return H\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_world_keypoints_3D(wkps):\n",
    "    norm_wkps = _normalize_world_keypoints(wkps)\n",
    "    body_parts = [k for k in norm_wkps.keys() if k != 'BODY']\n",
    "    xs = [norm_wkps[bp][0] for bp in body_parts]\n",
    "    ys = [norm_wkps[bp][1] for bp in body_parts]\n",
    "    zs = [norm_wkps[bp][2] for bp in body_parts]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlim3d(0, max(xs))\n",
    "    ax.set_ylim3d(-0.3, 0.3)\n",
    "    ax.set_zlim3d(-0.3, 0.3)\n",
    "    ax.scatter(xs, ys, zs, color='blue')\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "cm = df.camera_metadata.iloc[idx]\n",
    "wkps = pixel2world(adjusted_keypoints['leftCrop'], adjusted_keypoints['rightCrop'], cm)\n",
    "plot_world_keypoints_3D(wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "cm = original_df.camera_metadata.iloc[idx]\n",
    "adjusted_wkps = pixel2world(adjusted_keypoints['leftCrop'], adjusted_keypoints['rightCrop'], cm)\n",
    "plot_world_keypoints_3D(adjusted_wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2biomass(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f = '/root/alok/repos/cv_algorithms/biomass-production/src/model.pkl'\n",
    "model = pickle.load(open(model_f, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches_3D(img1, kp1, img2, kp2, matches, matchesMask): \n",
    "    \n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    i=0\n",
    "    wkps = []\n",
    "    for m in matches:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        \n",
    "        if matchesMask[i] == 1:\n",
    "            p1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "            p2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int))\n",
    "            p1_x_frame = p1[0] + df.left_crop_metadata.iloc[idx]['x_coord']\n",
    "            p1_y_frame = p1[1] + df.left_crop_metadata.iloc[idx]['y_coord']\n",
    "            p2_x_frame = p2[0] + df.right_crop_metadata.iloc[idx]['x_coord']\n",
    "            params = df.camera_metadata.iloc[idx]\n",
    "#             disp = abs(p1_x_frame - p2_x_frame)\n",
    "#             depth = depth_from_disp(disp, params)\n",
    "#             wkp = convert_to_world_point(p1_y_frame, p1_x_frame, depth, params)\n",
    "#             wkps.append(wkp)\n",
    "        i += 1\n",
    "        \n",
    "    return wkps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adjusted_weight(left_image_url, right_image_url, keypoints, cm, kpid, weight_dict):\n",
    "    try:\n",
    "        left_image_f, _, _ = s3_access_utils.download_from_url(left_image_url)\n",
    "        right_image_f, _, _ = s3_access_utils.download_from_url(right_image_url)\n",
    "        imageL = cv2.imread(left_image_f)\n",
    "        imageR = cv2.imread(right_image_f)\n",
    "        \n",
    "        # crop the data\n",
    "        \n",
    "        left_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in keypoints['leftCrop']}\n",
    "        right_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in keypoints['rightCrop']}\n",
    "        \n",
    "        width = cm['pixelCountWidth']\n",
    "        height = cm['pixelCountHeight']\n",
    "        padding = 100\n",
    "        cropL_x_left = max(min([kp[0] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "        cropL_x_right = min(max([kp[0] for kp in left_keypoints_dict.values()]) + padding, width)\n",
    "        cropL_y_top = max(min([kp[1] for kp in left_keypoints_dict.values()]) - padding, 0)\n",
    "        cropL_y_bottom = min(max([kp[1] for kp in left_keypoints_dict.values()]) + padding, height)\n",
    "\n",
    "        cropR_x_left = max(min([kp[0] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "        cropR_x_right = min(max([kp[0] for kp in right_keypoints_dict.values()]) + padding, width)\n",
    "        cropR_y_top = max(min([kp[1] for kp in right_keypoints_dict.values()]) - padding, 0)\n",
    "        cropR_y_bottom = min(max([kp[1] for kp in right_keypoints_dict.values()]) + padding, height)\n",
    "\n",
    "        imageL = imageL[cropL_y_top:cropL_y_bottom, cropL_x_left:cropL_x_right]\n",
    "        imageR = imageR[cropR_y_top:cropR_y_bottom, cropR_x_left:cropR_x_right]\n",
    "\n",
    "        #modify keypoints\n",
    "        modified_keypoints = {'leftCrop': [], 'rightCrop': []}\n",
    "        for item in keypoints['leftCrop']:\n",
    "            modified_item = copy(item)\n",
    "            modified_item['xCrop'] = item['xCrop'] - cropL_x_left\n",
    "            modified_item['yCrop'] = item['yCrop'] - cropL_y_top\n",
    "            modified_keypoints['leftCrop'].append(modified_item)\n",
    "\n",
    "        for item in keypoints['rightCrop']:\n",
    "            modified_item = copy(item)\n",
    "            modified_item['xCrop'] = item['xCrop'] - cropR_x_left\n",
    "            modified_item['yCrop'] = item['yCrop'] - cropR_y_top\n",
    "            modified_keypoints['rightCrop'].append(modified_item)\n",
    "        \n",
    "        good, matchesMask, H, kp1, kp2 = find_matches_and_homography(imageL, imageR)\n",
    "        adjusted_keypoints = adjust_keypoints(modified_keypoints, H)\n",
    "        adjusted_wkps = pixel2world(adjusted_keypoints['leftCrop'], \n",
    "                                    adjusted_keypoints['rightCrop'],\n",
    "                                    cm)\n",
    "        \n",
    "        two_dimensional_locs = []\n",
    "        i=0\n",
    "        for m in good:\n",
    "            if matchesMask[i] == 1:\n",
    "                p1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "                p2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int))\n",
    "                p1_x_frame = p1[0] + cropL_x_left\n",
    "                p1_y_frame = p1[1] + cropL_y_top\n",
    "                p2_x_frame = p2[0] + cropR_x_left\n",
    "                disp = abs(p1_x_frame - p2_x_frame)\n",
    "                two_dimensional_locs.append([p1_x_frame, p1_y_frame, disp])\n",
    "            i += 1\n",
    "        \n",
    "        \n",
    "        item_to_add = {\n",
    "            'adjusted_wkps': adjusted_wkps,\n",
    "            'two_dimensional_locs': two_dimensional_locs,\n",
    "        }\n",
    "        \n",
    "        weight_dict[kpid] = item_to_add\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Error: {}'.format(e))\n",
    "        \n",
    "    print(len(weight_dict.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "weight_dict = manager.dict()\n",
    "\n",
    "args = []\n",
    "for idx, row in df.iterrows():\n",
    "    args.append((row.left_image_url, row.right_image_url, row.keypoints, \n",
    "                 row.camera_metadata, row.id, weight_dict))\n",
    "\n",
    "pool = Pool(processes=10)\n",
    "pool.starmap(generate_adjusted_weight, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in weight_dict.items():\n",
    "    print(v.keys())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "weights = np.array(weight_dict.values())\n",
    "mask = (weights > 0) & (weights < 20000)\n",
    "plt.hist(weights[mask], bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(weights[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "weights = original_df.estimated_biomass_g.values\n",
    "mask = (weights > 0) & (weights < 20000)\n",
    "plt.hist(weights[mask], bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(weights[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord2biomass(wkps, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord2biomass(adjusted_wkps, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv('/root/data/temp/imr_austevoll_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.index = pd.to_datetime(tdf.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.annotation.resample('H', how=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv('/root/data/temp/imr_austevoll_hourly_breakdown.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
