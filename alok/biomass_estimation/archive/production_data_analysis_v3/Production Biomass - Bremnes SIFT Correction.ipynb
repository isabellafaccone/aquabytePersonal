{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "from sqlalchemy import create_engine, MetaData, Table, select, and_, func\n",
    "from sqlalchemy.orm import sessionmaker, relationship, join\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import Table, Column, Integer, ForeignKey\n",
    "from sqlalchemy.orm import relationship\n",
    "from aquabyte.optics import convert_to_world_point, depth_from_disp, pixel2world, euclidean_distance\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "import mpld3\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/repos/cv_research/alok/biomass_estimation/production_data_analysis_v3')\n",
    "from template_matching import enhance, find_matches_and_homography, adjust_keypoints\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Download Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "aws_credentials = json.load(open(os.environ[\"AWS_CREDENTIALS\"]))\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_credentials[\"aws_access_key_id\"],\n",
    "                         aws_secret_access_key=aws_credentials[\"aws_secret_access_key\"],\n",
    "                         region_name=\"eu-west-1\")\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "\n",
    "# prod SQL credentaials\n",
    "sql_credentials = json.load(open(os.environ[\"PROD_RESEARCH_SQL_CREDENTIALS\"]))\n",
    "rds_access_utils = RDSAccessUtils(sql_credentials)\n",
    "\n",
    "sql_query = '''\n",
    "select * from keypoint_annotations\n",
    "where pen_id = 7\n",
    "and keypoints is not NULL;\n",
    "'''\n",
    "\n",
    "original_df = rds_access_utils.extract_from_database(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "original_df['world_keypoints'] = original_df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/temp/results_557ec1732d8bc8bc66951d2ea4e69b935d69b111_model_lateral_only_original_bremnes_data.h5'\n",
    "original_df = pd.read_hdf(f, 'table') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.sort_values('estimated_biomass_g', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.iloc[5618].estimated_biomass_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(original_df.left_image_url.iloc[idx])\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(original_df.right_image_url.iloc[idx])\n",
    "keypoints = original_df.keypoints.iloc[idx]\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good, matchesMask, H = find_matches_and_homography(imageL, imageR)\n",
    "# adjusted_keypoints = adjust_keypoints(keypoints, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SIFT Based Enhancement Techiques </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT based correction - functions\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness, )\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Try SIFT base matching </h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_rotation_matrix(u_base, v):\n",
    "    u = v / np.linalg.norm(v)\n",
    "    n = np.cross(u_base, u)\n",
    "    n = n / np.linalg.norm(n)\n",
    "    theta = -np.arccos(np.dot(u, u_base))\n",
    "\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0]**2*(1-np.cos(theta)), \n",
    "        n[0]*n[1]*(1-np.cos(theta)) - n[2]*np.sin(theta),\n",
    "        n[0]*n[2]*(1-np.cos(theta)) + n[1]*np.sin(theta)\n",
    "    ], [\n",
    "        n[1]*n[0]*(1-np.cos(theta)) + n[2]*np.sin(theta),\n",
    "        np.cos(theta) + n[1]**2*(1-np.cos(theta)),\n",
    "        n[1]*n[2]*(1-np.cos(theta)) - n[0]*np.sin(theta),\n",
    "    ], [\n",
    "        n[2]*n[0]*(1-np.cos(theta)) - n[1]*np.sin(theta),\n",
    "        n[2]*n[1]*(1-np.cos(theta)) + n[0]*np.sin(theta),\n",
    "        np.cos(theta) + n[2]**2*(1-np.cos(theta))\n",
    "    ]])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def _normalize_world_keypoints(wkps, rotate=True):\n",
    "    body_parts = wkps.keys()\n",
    "    \n",
    "    # translate keypoints such that tail notch is at origin\n",
    "    translated_wkps = {bp: wkps[bp] - wkps['HYPURAL_PLATE'] for bp in body_parts}\n",
    "\n",
    "    if not rotate:\n",
    "        return translated_wkps\n",
    "    \n",
    "    # perform first rotation\n",
    "    u_base=np.array([1, 0, 0])\n",
    "    v = translated_wkps['UPPER_LIP']\n",
    "    R = _generate_rotation_matrix(u_base, v)\n",
    "    norm_wkps_intermediate = {bp: np.dot(R, translated_wkps[bp].T) for bp in body_parts}\n",
    "    \n",
    "    # perform second rotation\n",
    "    u_base = np.array([0, 0, 1])\n",
    "    v = norm_wkps_intermediate['ADIPOSE_FIN'] - np.array([norm_wkps_intermediate['ADIPOSE_FIN'][0], 0, 0])\n",
    "    R = _generate_rotation_matrix(u_base, v)\n",
    "    norm_wkps = {bp: np.dot(R, norm_wkps_intermediate[bp]) for bp in body_parts}\n",
    "    \n",
    "    # perform reflecton if necessary\n",
    "    if norm_wkps['PECTORAL_FIN'][1] > 0:\n",
    "        norm_wkps = {bp: np.array([\n",
    "            norm_wkps[bp][0],\n",
    "            -norm_wkps[bp][1],\n",
    "            norm_wkps[bp][2]\n",
    "        ]) for bp in body_parts}\n",
    "    \n",
    "    return norm_wkps\n",
    "\n",
    "\n",
    "def draw_matches_3D(img1, kp1, img2, kp2, matches, matchesMask): \n",
    "    \n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    i=0\n",
    "    wkps = []\n",
    "    for m in matches:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        \n",
    "        if matchesMask[i] == 1:\n",
    "            p1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "            p2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int))\n",
    "            p1_x_frame = p1[0] + original_df.left_crop_metadata.iloc[idx]['x_coord']\n",
    "            p1_y_frame = p1[1] + original_df.left_crop_metadata.iloc[idx]['y_coord']\n",
    "            p2_x_frame = p2[0] + original_df.right_crop_metadata.iloc[idx]['x_coord']\n",
    "            params = original_df.camera_metadata.iloc[idx]\n",
    "            disp = abs(p1_x_frame - p2_x_frame)\n",
    "            depth = depth_from_disp(disp, params)\n",
    "            wkp = convert_to_world_point(p1_y_frame, p1_x_frame, depth, params)\n",
    "            wkps.append(wkp)\n",
    "        i += 1\n",
    "        \n",
    "    return wkps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5154\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(original_df.left_image_url.iloc[idx])\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(original_df.right_image_url.iloc[idx])\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 11\n",
    "GOOD_PERC = 0.7\n",
    "\n",
    "sift = cv2.KAZE_create()\n",
    "img1 = enhance(imageL)\n",
    "img2 = enhance(imageR)\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < GOOD_PERC*n.distance:\n",
    "        good.append(m)\n",
    "if len(good)>=MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,None,False)\n",
    "img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,None,True)\n",
    "alpha = 0.7  # Transparency factor.\n",
    "img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(img3)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_wkps = draw_matches_3D(img1, kp1, img2, kp2, good, matchesMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(matchesMask)/len(matchesMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps = original_df.world_keypoints.iloc[idx]\n",
    "wkps['BODY'] = np.array(body_wkps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_wkps = _normalize_world_keypoints(wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "body_parts = [k for k in norm_wkps.keys() if k != 'BODY']\n",
    "xs = [norm_wkps[bp][0] for bp in body_parts]\n",
    "ys = [norm_wkps[bp][1] for bp in body_parts]\n",
    "zs = [norm_wkps[bp][2] for bp in body_parts]\n",
    "xs.extend(list(norm_wkps['BODY'][0]))\n",
    "ys.extend(list(norm_wkps['BODY'][1]))\n",
    "zs.extend(list(norm_wkps['BODY'][2]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(0, max(xs))\n",
    "ax.set_ylim3d(-0.3, 0.3)\n",
    "ax.set_zlim3d(-0.3, 0.3)\n",
    "ax.scatter(xs, ys, zs, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = original_df.keypoints.iloc[idx]\n",
    "left_keypoints_crop = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['leftCrop']}\n",
    "right_keypoints_crop = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in keypoints['rightCrop']}\n",
    "\n",
    "# adjust left and right keypoints\n",
    "left_keypoints_crop_adjusted, right_keypoints_crop_adjusted = [], []\n",
    "for i, bp in enumerate([item['keypointType'] for item in keypoints['leftCrop']]):\n",
    "    kpL = left_keypoints_crop[bp]\n",
    "    ptx = np.array([kpL[0], kpL[1], 1])\n",
    "    zx = np.dot(M, ptx)\n",
    "    kpL2R = [zx[0] / zx[2], zx[1] / zx[2]]\n",
    "\n",
    "    kpR = right_keypoints_crop[bp]\n",
    "    pty = np.array([kpR[0], kpR[1], 1])\n",
    "    zy = np.dot(np.linalg.inv(M), pty)\n",
    "    kpR2L = [zy[0] / zy[2], zy[1] / zy[2]]\n",
    "\n",
    "#     kpL_adjusted = [(kpL[0] + kpL2R[0]) / 2.0, (kpL[1] + kpL2R[1]) / 2.0]\n",
    "#     kpR_adjusted = [(kpR[0] + kpR2L[0]) / 2.0, (kpR[1] + kpR2L[1]) / 2.0]\n",
    "    kpL_adjusted = [(kpL[0] + kpR2L[0]) / 2.0, (kpL[1] + kpR2L[1]) / 2.0]\n",
    "    kpR_adjusted = [(kpR[0] + kpL2R[0]) / 2.0, (kpR[1] + kpL2R[1]) / 2.0]\n",
    "    item_left = keypoints['leftCrop'][i]\n",
    "    item_right = keypoints['rightCrop'][i]\n",
    "\n",
    "    new_item_left = {\n",
    "        'keypointType': bp,\n",
    "        'xCrop': kpL_adjusted[0],\n",
    "        'xFrame': item_left['xFrame'] - item_left['xCrop'] + kpL_adjusted[0],\n",
    "        'yCrop': kpL_adjusted[1],\n",
    "        'yFrame': item_left['yFrame'] - item_left['yCrop'] + kpL_adjusted[1]\n",
    "    }\n",
    "    left_keypoints_crop_adjusted.append(new_item_left)\n",
    "\n",
    "    new_item_right = {\n",
    "        'keypointType': bp,\n",
    "        'xCrop': kpR_adjusted[0],\n",
    "        'xFrame': item_right['xFrame'] - item_right['xCrop'] + kpR_adjusted[0],\n",
    "        'yCrop': kpR_adjusted[1],\n",
    "        'yFrame': item_right['yFrame'] - item_right['yCrop'] + kpR_adjusted[1]\n",
    "    }\n",
    "    right_keypoints_crop_adjusted.append(new_item_right)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps = pixel2world(left_keypoints_crop_adjusted, right_keypoints_crop_adjusted, original_df.camera_metadata.iloc[idx])\n",
    "norm_wkps = _normalize_world_keypoints(wkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "body_parts = [k for k in norm_wkps.keys() if k != 'BODY']\n",
    "xs = [norm_wkps[bp][0] for bp in body_parts]\n",
    "ys = [norm_wkps[bp][1] for bp in body_parts]\n",
    "zs = [norm_wkps[bp][2] for bp in body_parts]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim3d(0, max(xs))\n",
    "ax.set_ylim3d(-0.3, 0.3)\n",
    "ax.set_zlim3d(-0.3, 0.3)\n",
    "ax.scatter(xs, ys, zs, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_dists=[]\n",
    "kpL = []\n",
    "kpR = []    \n",
    "kpL2R = []\n",
    "kpR2L = [] \n",
    "im1ps = []\n",
    "im2ps = []\n",
    "gtL2R = []\n",
    "gtR2L = [] \n",
    "gt1ps = []\n",
    "gt2ps = []\n",
    "Hx=M\n",
    "Hy=np.linalg.inv(M)\n",
    "for c in range(FLAGS.joints):\n",
    "    hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "    hm_maxL = list(np.where(hm == hm.max()))   \n",
    "    kpL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "    ptx=np.array([kpL[c][0],kpL[c][1],1])\n",
    "    zx=np.dot(Hx,ptx)\n",
    "    kpL2R.append([int(zx[0]/zx[2]), int(zx[1]/zx[2])]) \n",
    "    gtx=np.array([gtkeypointsL[c][0],gtkeypointsL[c][1],1])\n",
    "    gzx=np.dot(Hx,gtx)\n",
    "    gtL2R.append([int(gzx[0]/gzx[2]), int(gzx[1]/gzx[2])]) \n",
    "#         gt_kp = gtkeypointsL[c,:]\n",
    "#         man_distL = np.sqrt(pow(hm_maxL[1][0] - gt_kp[0],2)+pow(hm_maxL[0][0] - gt_kp[1],2))\n",
    "#         man_dists.append(man_distL)\n",
    "#         print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL[0], FLAGS.keypoints_order[c]))\n",
    "    hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "    hm_maxR = np.where(hm == hm.max())\n",
    "    kpR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "    pty=np.array([kpR[c][0],kpR[c][1],1])\n",
    "    zy=np.dot(Hy,pty)\n",
    "    kpR2L.append([int(zy[0]/zy[2]), int(zy[1]/zy[2])]) \n",
    "    gty=np.array([gtkeypointsR[c][0],gtkeypointsR[c][1],1])\n",
    "    gzy=np.dot(Hy,gty)\n",
    "    gtR2L.append([int(gzy[0]/gzy[2]), int(gzy[1]/gzy[2])])\n",
    "#         gt_kp = gtkeypointsR[c,:]\n",
    "#         man_distR = np.sqrt(pow(hm_maxR[1][0] - gt_kp[0],2)+pow(hm_maxR[0][0] - gt_kp[1],2))\n",
    "#         man_dists.append(man_distR)\n",
    "#         print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR[0], FLAGS.keypoints_order[c]))\n",
    "\n",
    "#         np2_ind_dists[c].append((man_distL+man_distR)/2)\n",
    "\n",
    "    im1ps.append([int((kpL[c][0]+kpR2L[c][0])/2), int((kpL[c][1]+kpR2L[c][1])/2)]) \n",
    "    im2ps.append([int((kpR[c][0]+kpL2R[c][0])/2), int((kpR[c][1]+kpL2R[c][1])/2)]) \n",
    "    gt1ps.append([int((gtkeypointsL[c][0]+gtR2L[c][0])/2), int((gtkeypointsL[c][1]+kpR2L[c][1])/2)]) \n",
    "    gt2ps.append([int((gtkeypointsR[c][0]+gtL2R[c][0])/2), int((gtkeypointsR[c][1]+gtL2R[c][1])/2)]) \n",
    "    man_distL = np.sqrt(pow(im1ps[c][0] - gt1ps[c][0],2) + pow(im1ps[c][1] - gt1ps[c][1],2))\n",
    "    man_dists.append(man_distL)\n",
    "    # print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL, FLAGS.keypoints_order[c]))\n",
    "    man_distR = np.sqrt(pow(im2ps[c][0] - gt2ps[c][0],2) + pow(im2ps[c][1] - gt2ps[c][1],2))\n",
    "    man_dists.append(man_distR)\n",
    "    # print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR, FLAGS.keypoints_order[c]))\n",
    "    np2_ind_dists[c].append((man_distL+man_distR)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
