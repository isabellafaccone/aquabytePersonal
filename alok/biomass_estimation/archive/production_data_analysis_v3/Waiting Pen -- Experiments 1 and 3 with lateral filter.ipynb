{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from wpca import WPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from PIL import Image, ImageDraw\n",
    "from urllib.parse import urlparse\n",
    "from multiprocessing import Pool\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import matplotlib.dates as mdates\n",
    "myFmt = mdates.DateFormatter('%d')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predicted Unconditional Weight Histogram for experiment ID #1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = '/root/data/temp/results_557ec1732d8bc8bc66951d2ea4e69b935d69b111_model_lateral_only_horizontal_vertical_constraints_research-exp-id-01-vikingfjord-20190628-20190630.h5'\n",
    "f = '/root/data/temp/results_557ec1732d8bc8bc66951d2ea4e69b935d69b111_model_lateral_only_horizontal_vertical_constraints_research-exp-id-03-vikingfjord-20190709-20190710.h5'\n",
    "df = pd.read_hdf(f, 'table')\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(20, 10))\n",
    "mask = (df.estimated_biomass_g > -2000) & (df.estimated_biomass_g < 20000)\n",
    "plt.hist(df[mask].estimated_biomass_g, bins=20, color='blue', label='4 eigenvectors', alpha=1.0)\n",
    "plt.axvline(6440, color='red')\n",
    "plt.title('Predicted biomass distribution for Waiting Pen Experiment ID #1')\n",
    "plt.xlabel('Predicted weight (g)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create features for lateral filter </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rms_error_m'] = np.nan\n",
    "\n",
    "rms_error_ms, coeffs = [], []\n",
    "horizontal_angles, vertical_angles = [], []\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        # fit plane based on well-behaved points\n",
    "        X, y = [], []\n",
    "        for body_part in ['UPPER_LIP', 'HYPURAL_PLATE', 'ADIPOSE_FIN', 'ANAL_FIN']:\n",
    "            wkp = row.world_keypoints[body_part]\n",
    "            X.append([\n",
    "                wkp[0],\n",
    "                wkp[2]\n",
    "            ])\n",
    "            y.append(wkp[1])\n",
    "\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        coeffs.append(reg.coef_)\n",
    "        vertical_angles.append(np.arctan(reg.coef_[0]) * 180.0 / np.pi)\n",
    "        horizontal_angles.append(np.arctan(reg.coef_[1]) * 180.0 / np.pi)\n",
    "        \n",
    "        # test plane\n",
    "        X, y = [], []\n",
    "        for body_part, wkp in row.world_keypoints.items():\n",
    "            X.append([\n",
    "                wkp[0],\n",
    "                wkp[2]\n",
    "            ])\n",
    "            y.append(wkp[1])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        rms_error_m = np.linalg.norm(reg.predict(X) - y) / y.shape[0]\n",
    "        rms_error_ms.append(rms_error_m)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        rms_error_ms.append(None)\n",
    "        horizontal_angles.append(None)\n",
    "        vertical_angles.append(None)\n",
    "\n",
    "df['rms_error_m'] = rms_error_ms\n",
    "df['horizontal_angle'] = horizontal_angles\n",
    "df['vertical_angle'] = vertical_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predicted Unconditional / Conditional Histograms Overlayed </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "hard_outlier_mask = (df.estimated_biomass_g < 0) | (df.estimated_biomass_g > 20000)\n",
    "good_annotation_mask = df.rms_error_m < 0.1\n",
    "lateral_mask = (df.horizontal_angle.abs() < 40) & (df.vertical_angle.abs() < 20)\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(20, 10))\n",
    "# plt.hist(df[~hard_outlier_mask].estimated_biomass_g, bins=20, color='blue', label='unconditional', alpha=0.5)\n",
    "plt.hist(df[~hard_outlier_mask & good_annotation_mask & lateral_mask].estimated_biomass_g, bins=20, color='red', label='conditional', alpha=0.5)\n",
    "plt.axvline(5710, color='red')\n",
    "plt.title('Predicted biomass distribution for Waiting Pen Experiment ID #1')\n",
    "plt.xlabel('Predicted weight (g)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~hard_outlier_mask & good_annotation_mask & lateral_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~hard_outlier_mask & good_annotation_mask & lateral_mask].estimated_biomass_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.horizontal_angle)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('rms_error_m', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize Individual Cases </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "v = Visualizer(rds_access_utils=rds_access_utils, s3_access_utils=s3_access_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for idx, row in df.sample(100).sort_values('rms_error_m', ascending=False).iterrows():\n",
    "    print(row.id, row.rms_error_m)\n",
    "    v.load_data(row.id)\n",
    "    v.display_crops(overlay_keypoints=True, show_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.load_data(554319)\n",
    "v.display_crops(overlay_keypoints=True, show_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "v.load_data(558443)\n",
    "v.display_3d_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.rms_error_m, bins=100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Optical Sampling Bias </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_depth(wkps):\n",
    "    if wkps:\n",
    "        return np.mean(np.array([wkp[1] for wkp in wkps.values()]))\n",
    "    return None\n",
    "\n",
    "df['centroid_depth'] = df.world_keypoints.apply(lambda x: centroid_depth(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.centroid_depth)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "depths = list(np.arange(0.8, 2.0, 0.1))\n",
    "mean_rms_values = []\n",
    "for i in range(len(depths[:-1])):\n",
    "    mask = (df.centroid_depth > depths[i]) & (df.centroid_depth < depths[i+1])\n",
    "    mean_rms_value = df[mask].rms_error_m.mean()\n",
    "    mean_rms_values.append(mean_rms_value)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "x = np.arange(len(depths[:-1]))\n",
    "plt.bar(x, mean_rms_values)\n",
    "plt.xticks(x, [round(d, 2) for d in depths[:-1]])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rms_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "hard_outlier_mask = (df.estimated_biomass_g < -10000) | (df.estimated_biomass_g > 40000)\n",
    "plt.hist(df[~hard_outlier_mask & (df.centroid_depth > 1.5)].estimated_biomass_g, bins=100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[~hard_outlier_mask & (df.centroid_depth > 1.6) & (df.centroid_depth < 1.8)].estimated_biomass_g, bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~hard_outlier_mask & (df.centroid_depth < 1.0)].estimated_biomass_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation_accuracy(depth, baseline, theta_fov):\n",
    "    return baseline / (2*depth*np.tan((theta_fov / 2.0) * (np.pi / 180.0)))\n",
    "\n",
    "def overlapping_field_size(depth, baseline, theta_fov):\n",
    "    return 2*depth*np.tan((theta_fov / 2.0) * (np.pi / 180.0)) - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulation_accuracy(0.8, 0.2, 70.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulation_accuracy(0.8, 0.1, 55.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulation_accuracy(1.0, 0.3, 80.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_field_size(0.6, 0.25, 85.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.right_image_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'aquabyte-crops'\n",
    "left_key = 'environment=production/site-id=29/pen-id=17/date=2019-07-09/hour=13/at=2019-07-09T13:12:42.376387000Z/left_frame_crop_1006_1004_3354_1643.jpg'\n",
    "right_key = 'environment=production/site-id=29/pen-id=17/date=2019-07-09/hour=13/at=2019-07-09T13:12:42.376387000Z/right_frame_crop_782_1033_3010_1673.jpg'\n",
    "left_image_f = s3_access_utils.download_from_s3(bucket, left_key)\n",
    "right_image_f = s3_access_utils.download_from_s3(bucket, right_key)\n",
    "imageL = cv2.imread(left_image_f)\n",
    "imageR = cv2.imread(right_image_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "GOOD_PERC = 0.7\n",
    "\n",
    "sift = cv2.KAZE_create()\n",
    "img1 = enhance(imageL)\n",
    "img2 = enhance(imageR)\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < GOOD_PERCBGBBH*n.distance:\n",
    "        good.append(m)\n",
    "if len(good)>=MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mpld3\n",
    "# mpld3.disable_notebook()\n",
    "# mpld3.enable_notebook()\n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "# draw_params = dict(matchColor = (0,0,255), # draw matches in white color\n",
    "#                    singlePointColor = None,\n",
    "#                    matchesMask = matchesMask, # draw only inliers\n",
    "#                    flags = 4)\n",
    "# # print(draw_params)\n",
    "# img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "\n",
    "img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,False)\n",
    "img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,True)\n",
    "alpha = 0.3  # Transparency factor.\n",
    "img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(img3)\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "# mpld3.display(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
