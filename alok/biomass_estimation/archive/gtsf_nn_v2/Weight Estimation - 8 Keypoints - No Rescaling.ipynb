{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from aquabyte.data_loader import KeypointsDataset, NormalizeCentered2D, ToTensor, BODY_PARTS\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prepare GTSF dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints -> 'leftCrop' is not null\n",
    "    and b.keypoints -> 'rightCrop' is not null\n",
    "    and b.is_qa = false \n",
    "    and b.captured_at < '2019-09-19';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "df = df[~df.id.isin(blacklisted_keypoint_annotation_ids)]\n",
    "\n",
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def is_well_behaved(wkps, cutoff_depth=10.0):\n",
    "    if any([abs(wkp[1]) > cutoff_depth for wkp in wkps.values()]):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "is_well_behaved_mask = df.world_keypoints.apply(lambda x: is_well_behaved(x))\n",
    "df = df[is_well_behaved_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeCentered2D(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Transforms the 2D left and right keypoints such that:\n",
    "        (1) The center of the left image 2D keypoints is located at the center of the left image\n",
    "            (i.e. 2D translation)\n",
    "        (2) The left image keypoints are possibly flipped such that the upper-lip x-coordinate \n",
    "            is greater than the tail-notch coordinate. This is done to reduce the total number of \n",
    "            spatial orientations the network must learn from -> reduces the training size\n",
    "        (3) The left image keypoints are then rotated such that upper-lip is located on the x-axis.\n",
    "            As in (2), this is done to reduce the total number of spatial orientations the network \n",
    "            must learn from -> reduces the training size\n",
    "        (4) Rescale all left image keypoints by some random number between 'lo' and 'hi' args\n",
    "        (5) Apply Gaussian random noise \"jitter\" to each keypoint to mimic annotation error\n",
    "        (5) For all transformations above, the right image keypoint coordinates are accordingly\n",
    "            transformed such that the original disparity values are preserved for all keypoints\n",
    "            (or adjusted during rescaling event)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def flip_center_kps(self, left_kps, right_kps):\n",
    "\n",
    "        x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "        x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "        x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "\n",
    "        y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "        y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "        y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "\n",
    "        x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "        x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "        x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "\n",
    "        y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "        y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "        y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "\n",
    "        fc_left_kps, fc_right_kps = {}, {}\n",
    "        flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            if flip_factor > 0:\n",
    "                fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "                fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "            else:\n",
    "                fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "                fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "            fc_left_kps[bp] = fc_left_kp\n",
    "            fc_right_kps[bp] = fc_right_kp\n",
    "\n",
    "        return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "    def _rotate_cc(self, p, theta):\n",
    "        R = np.array([\n",
    "            [np.cos(theta), -np.sin(theta)],\n",
    "            [np.sin(theta), np.cos(theta)]\n",
    "        ])\n",
    "\n",
    "        rotated_kp = np.dot(R, p)\n",
    "        return rotated_kp\n",
    "\n",
    "\n",
    "    def rotate_kps(self, left_kps, right_kps):\n",
    "        upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "        theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "        r_left_kps, r_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            rotated_kp = self._rotate_cc(left_kps[bp], -theta)\n",
    "            r_left_kps[bp] = rotated_kp\n",
    "            disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "            r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "\n",
    "        return r_left_kps, r_right_kps\n",
    "\n",
    "\n",
    "    def scale_kps(self, left_kps, right_kps, factor):\n",
    "        s_left_kps, s_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            s_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "            s_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "\n",
    "        return s_left_kps, s_right_kps\n",
    "\n",
    "\n",
    "    def jitter_kps(self, left_kps, right_kps, jitter):\n",
    "        j_left_kps, j_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                       left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "            j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                        right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "\n",
    "        return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "\n",
    "    def modify_kps(self, left_kps, right_kps, factor, jitter, cm, rotate=True, center=False):\n",
    "        fc_left_kps, fc_right_kps = self.flip_center_kps(left_kps, right_kps)\n",
    "        if rotate:\n",
    "            r_left_kps, r_right_kps = self.rotate_kps(fc_left_kps, fc_right_kps)\n",
    "            s_left_kps, s_right_kps = self.scale_kps(r_left_kps, r_right_kps, factor)\n",
    "        else:\n",
    "            s_left_kps, s_right_kps = self.scale_kps(fc_left_kps, fc_right_kps, factor)\n",
    "        j_left_kps, j_right_kps  = self.jitter_kps(s_left_kps, s_right_kps, jitter)\n",
    "        j_left_kps_list, j_right_kps_list = [], []\n",
    "        if not center:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "        else:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0],\n",
    "                    'yFrame': j_left_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0],\n",
    "                    'yFrame': j_right_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "\n",
    "\n",
    "        modified_kps = {\n",
    "            'leftCrop': j_left_kps_list,\n",
    "            'rightCrop': j_right_kps_list\n",
    "        }\n",
    "\n",
    "        return modified_kps\n",
    "\n",
    "    \n",
    "    def __init__(self, lo=None, hi=None, jitter=0.0, rotate=True, center=False):\n",
    "        self.lo = lo\n",
    "        self.hi = hi\n",
    "        self.jitter = jitter\n",
    "        self.rotate = rotate\n",
    "        self.center = center\n",
    "    \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        keypoints, cm, stereo_pair_id, label = \\\n",
    "            sample['keypoints'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "        left_keypoints_list = keypoints['leftCrop']\n",
    "        right_keypoints_list = keypoints['rightCrop']\n",
    "        left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "        right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "        \n",
    "        factor = 1.0 \n",
    "        if self.lo and self.hi:\n",
    "            factor = np.random.uniform(low=self.lo, high=self.hi)\n",
    "            \n",
    "        jitter = np.random.uniform(high=self.jitter) * (1.0 / np.random.uniform(low=0.3, high=2.0))\n",
    "        \n",
    "        modified_kps = self.modify_kps(left_kps, right_kps, factor, jitter, cm, \n",
    "            rotate=self.rotate, center=self.center)\n",
    "\n",
    "        kp_input = {}\n",
    "        for idx, _ in enumerate(modified_kps['leftCrop']):\n",
    "            left_item, right_item = modified_kps['leftCrop'][idx], modified_kps['rightCrop'][idx]\n",
    "            bp = left_item['keypointType']\n",
    "            kp_input[bp] = [left_item['xFrame'], left_item['yFrame'], right_item['xFrame'], right_item['yFrame']]\n",
    "\n",
    "\n",
    "        transformed_sample = {\n",
    "            'kp_input': kp_input,\n",
    "            'modified_kps': modified_kps,\n",
    "            'label': label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'cm': cm,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask].head(10), transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=1.0, hi=1.0, jitter=0),\n",
    "                                                  NormalizedStabilityTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KeypointsDataset(df[test_mask].head(20), transform=transforms.Compose([\n",
    "                                                      NormalizeCentered2D(lo=1.0, hi=1.0, jitter=0),\n",
    "                                                      NormalizedStabilityTransform(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128, momentum=0.2)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'batch_25_no_rescaling_higher_bn_lr_v1'\n",
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, run_name, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "    # run on test set\n",
    "    else:\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            network.eval()\n",
    "            for i, data_batch in enumerate(test_dataloader):\n",
    "                X_batch, y_batch, kpid_batch = \\\n",
    "                    data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "                y_pred = network(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "    test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "    train_losses.append(train_loss_for_epoch)\n",
    "    test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "    # save current state of network\n",
    "    if write_outputs:\n",
    "        f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "        f_path = os.path.join(output_dir, f_name)\n",
    "        torch.save(network, f_path)\n",
    "    \n",
    "    # print current loss values\n",
    "    print('-'*20)\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "    print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(len(train_losses)), train_losses, color='blue', label='training loss')\n",
    "plt.plot(range(len(test_losses)), test_losses, color='orange', label='validation loss')\n",
    "plt.ylim([0, 0.01])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value (MSE)')\n",
    "plt.title('Loss curves (MSE - Adam optimizer)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                      NormalizeCentered2D(lo=1.0, hi=1.0, jitter=10),\n",
    "                                                      NormalizedStabilityTransform(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "oos_dataloader = DataLoader(oos_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, data_batch in enumerate(test_dataloader):\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "# print current loss values\n",
    "print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, data_batch in enumerate(oos_dataloader):\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        oos_running_loss += loss.item()\n",
    "\n",
    "oos_loss_for_epoch = oos_running_loss / len(oos_dataloader)\n",
    "# print current loss values\n",
    "print('Test Loss: {}'.format(oos_loss_for_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_dataset:\n",
    "    X = data['kp_input'].numpy()\n",
    "    plt.scatter(X[:, 0], X[:, 2])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask].head(10), transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=1.0, hi=1.0, jitter=0),\n",
    "                                                  NormalizedStabilityTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "#     # run on test set\n",
    "#     else:\n",
    "#         test_running_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             network.eval()\n",
    "#             for i, data_batch in enumerate(test_dataloader):\n",
    "#                 X_batch, y_batch, kpid_batch = \\\n",
    "#                     data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "#                 y_pred = network(X_batch)\n",
    "#                 loss = criterion(y_pred, y_batch)\n",
    "#                 test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "#     test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "#     train_losses.append(train_loss_for_epoch)\n",
    "#     test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "#     # save current state of network\n",
    "#     if write_outputs:\n",
    "#         f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "#         f_path = os.path.join(output_dir, f_name)\n",
    "#         torch.save(network, f_path)\n",
    "    \n",
    "#     # print current loss values\n",
    "#     print('-'*20)\n",
    "#     print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "#     print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
