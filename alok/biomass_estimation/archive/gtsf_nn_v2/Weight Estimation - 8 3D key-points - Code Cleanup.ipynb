{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import random\n",
    "import torch\n",
    "from aquabyte.data_loader import KeypointsDataset, NormalizeCentered2D, ToTensor, BODY_PARTS\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy, deepcopy\n",
    "import pyarrow.parquet as pq\n",
    "from scipy.spatial import Delaunay\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "\n",
    "def prepare_df(aggregate_df):\n",
    "    \n",
    "    # use QA'ed entries, and only use Cogito entries when QA data is unavailable\n",
    "    qa_df = aggregate_df[aggregate_df.is_qa == True]\n",
    "    cogito_df = aggregate_df[(aggregate_df.is_qa != True) & \\\n",
    "                             ~(aggregate_df.left_image_url.isin(qa_df.left_image_url))]\n",
    "    df = pd.concat([qa_df, cogito_df], axis=0)\n",
    "    \n",
    "    # add world keypoints\n",
    "    df['world_keypoints'] = df.apply(lambda x: get_world_keypoints(x), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints -> 'leftCrop' is not null\n",
    "    and b.keypoints -> 'rightCrop' is not null\n",
    "    and b.is_qa = false\n",
    "    and b.captured_at < '2019-09-20';\n",
    "\"\"\"\n",
    "aggregate_df = rds_access_utils.extract_from_database(query)\n",
    "df = prepare_df(aggregate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_hull(p, hull):\n",
    "    hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "def get_raw_3D_coordinates(keypoints, cm):\n",
    "    wkps = pixel2world([item for item in keypoints['leftCrop'] if item['keypointType'] != 'BODY'], \n",
    "                       [item for item in keypoints['rightCrop'] if item['keypointType'] != 'BODY'],\n",
    "                       cm)\n",
    "    \n",
    "    # compute BODY world keypoint coordinates\n",
    "    if 'BODY' in [item['keypointType'] for item in keypoints['leftCrop']]:\n",
    "        left_item = [item for item in keypoints['leftCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "        right_item = [item for item in keypoints['rightCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "        disps = np.abs(left_item['xFrame'] - right_item['xFrame'])\n",
    "        focal_length_pixel = cm[\"focalLengthPixel\"]\n",
    "        baseline = cm[\"baseline\"]\n",
    "        depths = focal_length_pixel * baseline / np.array(disps)\n",
    "\n",
    "        pixel_count_width = cm[\"pixelCountWidth\"]\n",
    "        pixel_count_height = cm[\"pixelCountHeight\"]\n",
    "        sensor_width = cm[\"imageSensorWidth\"]\n",
    "        sensor_height = cm[\"imageSensorHeight\"]\n",
    "        focal_length = cm[\"focalLength\"]\n",
    "\n",
    "        image_center_x = pixel_count_width / 2.0\n",
    "        image_center_y = pixel_count_height / 2.0\n",
    "        x = left_item['xFrame']\n",
    "        y = left_item['yFrame']\n",
    "        px_x = x - image_center_x\n",
    "        px_z = image_center_y - y\n",
    "\n",
    "        sensor_x = px_x * (sensor_width / pixel_count_width)\n",
    "        sensor_z = px_z * (sensor_height / pixel_count_height)\n",
    "\n",
    "        world_y = depths\n",
    "        world_x = (world_y * sensor_x) / focal_length\n",
    "        world_z = (world_y * sensor_z) / focal_length\n",
    "        wkps['BODY'] = np.column_stack([world_x, world_y, world_z])\n",
    "        \n",
    "    \n",
    "    all_wkps = [list(wkps[bp]) for bp in BODY_PARTS]\n",
    "    if 'BODY' in wkps.keys():\n",
    "        body_wkps = random.sample([list(wkp) for wkp in list(wkps['BODY'])], 500)\n",
    "        all_wkps.extend(body_wkps)\n",
    "    return np.array(all_wkps)\n",
    "    \n",
    "\n",
    "def _generate_rotation_matrix(n, theta):\n",
    "\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0]**2*(1-np.cos(theta)), \n",
    "        n[0]*n[1]*(1-np.cos(theta)) - n[2]*np.sin(theta),\n",
    "        n[0]*n[2]*(1-np.cos(theta)) + n[1]*np.sin(theta)\n",
    "    ], [\n",
    "        n[1]*n[0]*(1-np.cos(theta)) + n[2]*np.sin(theta),\n",
    "        np.cos(theta) + n[1]**2*(1-np.cos(theta)),\n",
    "        n[1]*n[2]*(1-np.cos(theta)) - n[0]*np.sin(theta),\n",
    "    ], [\n",
    "        n[2]*n[0]*(1-np.cos(theta)) - n[1]*np.sin(theta),\n",
    "        n[2]*n[1]*(1-np.cos(theta)) + n[0]*np.sin(theta),\n",
    "        np.cos(theta) + n[2]**2*(1-np.cos(theta))\n",
    "    ]])\n",
    "    \n",
    "    return R\n",
    "\n",
    "def normalize_3D_coordinates(wkps):\n",
    "    \n",
    "    # translate keypoints such that tail notch is at origin\n",
    "    wkps = wkps - 0.5*(np.max(wkps[:8], axis=0) + np.min(wkps[:8], axis=0))\n",
    "\n",
    "    # perform rotation\n",
    "    upper_lip_idx = BODY_PARTS.index('UPPER_LIP')\n",
    "    \n",
    "    n = np.array([0, 1, 0])\n",
    "    theta = np.arctan(wkps[upper_lip_idx][2] / wkps[upper_lip_idx][0])\n",
    "    R = _generate_rotation_matrix(n, theta)\n",
    "    wkps = np.dot(R, wkps.T).T\n",
    "    \n",
    "    # perform reflecton if necessary\n",
    "    tail_notch_idx = BODY_PARTS.index('TAIL_NOTCH')\n",
    "    if wkps[upper_lip_idx][0] < wkps[tail_notch_idx][0]:\n",
    "        R = np.array([\n",
    "            [-1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        wkps = np.dot(R, wkps.T).T\n",
    "    \n",
    "    return wkps\n",
    "    \n",
    "    \n",
    "    \n",
    "def construct_point_cloud(keypoints, cm):\n",
    "    wkps = get_raw_3D_coordinates(keypoints, cm)\n",
    "    wkps = normalize_3D_coordinates(wkps)\n",
    "    wkps[:, 1] = wkps[:, 1] + 0.5\n",
    "    norm_wkps = np.column_stack([0.5 * wkps[:, 0] / wkps[:, 1], 0.5 * wkps[:, 2] / wkps[:, 1], 0.05 / wkps[:, 1]])\n",
    "    \n",
    "    return norm_wkps\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Neural Network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedCentered3D(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        keypoints, cm, stereo_pair_id, label = \\\n",
    "            sample['keypoints'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "    \n",
    "        wkps = construct_point_cloud(keypoints, cm)\n",
    "        normalized_label = label * 1e-4\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': wkps,\n",
    "            'label': normalized_label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'cm': cm,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "\n",
    "        return transformed_sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        x, label, stereo_pair_id = \\\n",
    "            sample['kp_input'], sample.get('label'), sample.get('stereo_pair_id')\n",
    "        \n",
    "        if sample.get('single_point_inference'):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        kp_input_tensor = torch.from_numpy(x).float()\n",
    "        \n",
    "        tensorized_sample = {\n",
    "            'kp_input': kp_input_tensor\n",
    "        }\n",
    "\n",
    "        if label:\n",
    "            label_tensor = torch.from_numpy(np.array([label])).float() if label else None\n",
    "            tensorized_sample['label'] = label_tensor\n",
    "\n",
    "        if stereo_pair_id:\n",
    "            tensorized_sample['stereo_pair_id'] = stereo_pair_id\n",
    "\n",
    "        return tensorized_sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask], transform=transforms.Compose([\n",
    "                                                  NormalizedCentered3D(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                      NormalizedCentered3D(),\n",
    "                                                      ToTensor()\n",
    "                                                  ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'batch_25_no_rescaling_v1'\n",
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, run_name, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "    # run on test set\n",
    "    else:\n",
    "        test_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            network.eval()\n",
    "            for i, data_batch in enumerate(test_dataloader):\n",
    "                X_batch, y_batch, kpid_batch = \\\n",
    "                    data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "                y_pred = network(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "    test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "    train_losses.append(train_loss_for_epoch)\n",
    "    test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "    # save current state of network\n",
    "    if write_outputs:\n",
    "        f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "        f_path = os.path.join(output_dir, f_name)\n",
    "        torch.save(network, f_path)\n",
    "    \n",
    "    # print current loss values\n",
    "    print('-'*20)\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "    print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wkps = data['kp_input'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# get x, y, and z lists\n",
    "\n",
    "x_values = all_wkps[:,0]\n",
    "y_values = all_wkps[:,1]\n",
    "z_values = all_wkps[:,2]\n",
    "\n",
    "ax.scatter(x_values, y_values, z_values)\n",
    "\n",
    "# Create cubic bounding box to simulate equal aspect ratio\n",
    "max_range = np.array([x_values.max()-x_values.min(), y_values.max()-y_values.min(), z_values.max()-z_values.min()]).max()\n",
    "Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(x_values.max()+x_values.min())\n",
    "Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(y_values.max()+y_values.min())\n",
    "Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(z_values.max()+z_values.min())\n",
    "# Comment or uncomment following both lines to test the fake bounding box:\n",
    "for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "    ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = df[df.id == 710764].keypoints.iloc[0]\n",
    "cm = df[df.id == 710764].camera_metadata.iloc[0]\n",
    "wkps = pixel2world(kps['leftCrop'], kps['rightCrop'], cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance(wkps['UPPER_LIP'], wkps['EYE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance(all_wkps[3], all_wkps[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    'keypoints': df.keypoints.iloc[0],\n",
    "    'stereo_pair_id': 0,\n",
    "    'cm': df.camera_metadata.iloc[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array([[1, 2, 3], [4, 5, 6]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_keypoints_list = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    X_keypoints = np.array([[item['xFrame'], item['yFrame']] for item in row.keypoints['leftCrop']])\n",
    "    X_body = np.array(row.matches)\n",
    "    is_valid = in_hull(X_body[:, :2], X_keypoints)\n",
    "    X_body = X_body[np.where(is_valid)]\n",
    "    \n",
    "    keypoints = deepcopy(row.keypoints)\n",
    "    left_keypoints, right_keypoints = keypoints['leftCrop'], keypoints['rightCrop']\n",
    "    left_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 0],\n",
    "        'yFrame': X_body[:, 1]\n",
    "    }\n",
    "    \n",
    "    right_item = {\n",
    "        'keypointType': 'BODY',\n",
    "        'xFrame': X_body[:, 2],\n",
    "        'yFrame': X_body[:, 3]\n",
    "    }\n",
    "    \n",
    "    left_keypoints.append(left_item)\n",
    "    right_keypoints.append(right_item)\n",
    "    modified_keypoints = {\n",
    "        'leftCrop': left_keypoints,\n",
    "        'rightCrop': right_keypoints\n",
    "    }\n",
    "\n",
    "    modified_keypoints_list.append(modified_keypoints)\n",
    "\n",
    "df['old_keypoints'] = df.keypoints\n",
    "df['keypoints'] = modified_keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf_fish_identifiers = list(df.fish_id.unique())\n",
    "train_size = int(0.8 * len(gtsf_fish_identifiers))\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (df.captured_at < '2019-09-10')\n",
    "train_mask = date_mask & df.fish_id.isin(fish_ids)\n",
    "test_mask = date_mask & ~df.fish_id.isin(fish_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(df[train_mask], transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                  WorldKeypointTransform(),\n",
    "                                                  PrismTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=25, shuffle=True, num_workers=1)\n",
    "\n",
    "test_dataset = KeypointsDataset(df[test_mask], transform=transforms.Compose([\n",
    "                                                  NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10),\n",
    "                                                  WorldKeypointTransform(),\n",
    "                                                  PrismTransform(),\n",
    "                                                  ToTensor()\n",
    "                                              ]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=25, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_outputs = False\n",
    "\n",
    "# establish output directory where model .pb files will be written\n",
    "if write_outputs:\n",
    "    dt_now = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    output_base = '/root/data/alok/biomass_estimation/results/neural_network'\n",
    "    output_dir = os.path.join(output_base, dt_now)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "# instantiate neural network\n",
    "network = Network()\n",
    "epochs = 1000\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# track train and test losses\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "seed = 0\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    np.random.seed(seed)\n",
    "    seed += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data_batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch, kpid_batch = \\\n",
    "            data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "        y_pred = network(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(running_loss / i)\n",
    "            \n",
    "#     # run on test set\n",
    "#     else:\n",
    "#         test_running_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             network.eval()\n",
    "#             for i, data_batch in enumerate(test_dataloader):\n",
    "#                 X_batch, y_batch, kpid_batch = \\\n",
    "#                     data_batch['kp_input'], data_batch['label'], data_batch['stereo_pair_id']\n",
    "#                 y_pred = network(X_batch)\n",
    "#                 loss = criterion(y_pred, y_batch)\n",
    "#                 test_running_loss += loss.item()\n",
    "\n",
    "    train_loss_for_epoch = running_loss / len(train_dataloader)\n",
    "#     test_loss_for_epoch = test_running_loss / len(test_dataloader)\n",
    "#     train_losses.append(train_loss_for_epoch)\n",
    "#     test_losses.append(test_loss_for_epoch)\n",
    "    \n",
    "#     # save current state of network\n",
    "#     if write_outputs:\n",
    "#         f_name = 'nn_epoch_{}.pb'.format(str(epoch).zfill(3))\n",
    "#         f_path = os.path.join(output_dir, f_name)\n",
    "#         torch.save(network, f_path)\n",
    "    \n",
    "#     # print current loss values\n",
    "#     print('-'*20)\n",
    "#     print('Epoch: {}'.format(epoch))\n",
    "    print('Train Loss: {}'.format(train_loss_for_epoch))\n",
    "#     print('Test Loss: {}'.format(test_loss_for_epoch))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
