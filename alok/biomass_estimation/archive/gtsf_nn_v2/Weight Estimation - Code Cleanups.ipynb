{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from research.weight_estimation.akpd_scorer import generate_confidence_score\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from research.weight_estimation.visualize import Visualizer, _normalize_world_keypoints\n",
    "from research.weight_estimation.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from research.weight_estimation.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from keras.models import load_model\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from research.weight_estimation.data_loader import KeypointsDataset, NormalizeCentered2D, ToTensor, BODY_PARTS\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy, deepcopy\n",
    "from scipy.spatial import Delaunay\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy, deepcopy\n",
    "import json, os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from research.weight_estimation.optics import pixel2world\n",
    "from research.weight_estimation.akpd_scorer import generate_confidence_score\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from research.gtsf_data.body_parts import BodyParts\n",
    "import pyarrow.parquet as pq\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "BODY_PARTS = BodyParts().get_core_body_parts()\n",
    "\n",
    "class GTSFDataset(object):\n",
    "\n",
    "    def __init__(self, start_date, end_date, akpd_scorer_url):\n",
    "        self.s3_access_utils = S3AccessUtils('/root/data')\n",
    "        self.df = self.generate_raw_df(start_date, end_date)\n",
    "        self.prepare_df(akpd_scorer_url)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_raw_df(start_date, end_date):\n",
    "        rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "        query = f\"\"\"\n",
    "            select * from research.fish_metadata a left join keypoint_annotations b\n",
    "            on a.left_url = b.left_image_url \n",
    "            where b.keypoints -> 'leftCrop' is not null\n",
    "            and b.keypoints -> 'rightCrop' is not null\n",
    "            and b.captured_at between '{start_date}' and '{end_date}';\n",
    "        \"\"\"\n",
    "        df = rds_access_utils.extract_from_database(query)\n",
    "        print('Raw dataframe loaded!')\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_world_keypoints(row):\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "\n",
    "    def prepare_df(self, akpd_scorer_path, add_template_matching_keypoints=True):\n",
    "        # use QA'ed entries, and only use Cogito entries when QA data is unavailable\n",
    "        qa_df = self.df[self.df.is_qa == True]\n",
    "        cogito_df = self.df[(self.df.is_qa != True) & ~(self.df.left_image_url.isin(qa_df.left_image_url))]\n",
    "        self.df = pd.concat([qa_df, cogito_df], axis=0)\n",
    "        print('Dataset preparation beginning...')\n",
    "\n",
    "        # add 3D spatial information\n",
    "        self.df['world_keypoints'] = self.df.apply(lambda x: self.get_world_keypoints(x), axis=1)\n",
    "        self.df['median_depth'] = self.df.world_keypoints.apply(lambda x: np.median([wkp[1] for wkp in x.values()]))\n",
    "        print('3D spatial information added!')\n",
    "        \n",
    "        self.add_akpd_scores(akpd_scorer_path)\n",
    "        if add_template_matching_keypoints:\n",
    "            self.add_template_matching_keypoints()\n",
    "        self.convert_wkps_to_matrix_form()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def in_hull(p, hull):\n",
    "        hull = Delaunay(hull)\n",
    "        return hull.find_simplex(p)>=0\n",
    "\n",
    "\n",
    "    def add_template_matching_keypoints(self):\n",
    "        print('Adding template matching body keypoints...')\n",
    "\n",
    "        # load data\n",
    "        gen = self.s3_access_utils.get_matching_s3_keys(\n",
    "            'aquabyte-research', \n",
    "            prefix='template-matching/2019-12-05T02:50:57', \n",
    "            suffixes=['.parquet']\n",
    "        )\n",
    "\n",
    "        keys = [key for key in gen]\n",
    "        f = self.s3_access_utils.download_from_s3('aquabyte-research', keys[0])\n",
    "        pdf = pd.read_parquet(f)\n",
    "        pdf['homography'] = pdf.homography_and_matches.apply(lambda x: np.array(x[0].tolist(), dtype=np.float))\n",
    "        pdf['matches'] = pdf.homography_and_matches.apply(lambda x: np.array(x[1].tolist(), dtype=np.int) if len(x) > 1 else None)\n",
    "\n",
    "        # merge with existing dataframe\n",
    "        self.df = pd.merge(self.df, pdf[['left_image_url', 'homography', 'matches']], how='inner', on='left_image_url')\n",
    "\n",
    "        # generate list of modified keypoints\n",
    "        modified_keypoints_list = []\n",
    "        count = 0\n",
    "        for idx, row in self.df.iterrows():\n",
    "            if count % 100 == 0:\n",
    "                print(count)\n",
    "            count += 1\n",
    "            X_keypoints = np.array([[item['xFrame'], item['yFrame']] for item in row.keypoints['leftCrop']])\n",
    "            X_body = np.array(row.matches)\n",
    "            is_valid = self.in_hull(X_body[:, :2], X_keypoints)\n",
    "            X_body = X_body[np.where(is_valid)]\n",
    "            \n",
    "            keypoints = deepcopy(row.keypoints)\n",
    "            left_keypoints, right_keypoints = keypoints['leftCrop'], keypoints['rightCrop']\n",
    "            left_item = {'keypointType': 'BODY', 'xFrame': X_body[:, 0], 'yFrame': X_body[:, 1]}\n",
    "            right_item = {'keypointType': 'BODY', 'xFrame': X_body[:, 2], 'yFrame': X_body[:, 3]}\n",
    "            \n",
    "            left_keypoints.append(left_item)\n",
    "            right_keypoints.append(right_item)\n",
    "            modified_keypoints = {'leftCrop': left_keypoints, 'rightCrop': right_keypoints}\n",
    "            modified_keypoints_list.append(modified_keypoints)\n",
    "\n",
    "        # add modified keypoints information to dataframe\n",
    "        self.df['old_keypoints'] = self.df.keypoints\n",
    "        self.df['keypoints'] = modified_keypoints_list\n",
    "        self.df = self.df[self.df.keypoints.apply(lambda x: x['leftCrop'][-1]['xFrame'].shape[0]) > 500]\n",
    "\n",
    "\n",
    "    def add_akpd_scores(self, akpd_scorer_url):\n",
    "        print('Adding AKPD scores...')\n",
    "        # load neural network weights\n",
    "        akpd_scorer_path, _, _ = self.s3_access_utils.download_from_url(akpd_scorer_url)\n",
    "        akpd_scorer_network = load_model(akpd_scorer_path)\n",
    "\n",
    "        akpd_scores = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            input_sample = {\n",
    "                'keypoints': row.keypoints,\n",
    "                'cm': row.camera_metadata,\n",
    "                'stereo_pair_id': row.id,\n",
    "                'single_point_inference': True\n",
    "            }\n",
    "            akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "            akpd_scores.append(akpd_score)\n",
    "        self.df['akpd_score'] = akpd_scores\n",
    "\n",
    "    def convert_wkps_to_matrix_form(self):\n",
    "        print('Converting world keypoints to matrix form...')\n",
    "        keypoint_arr_list = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            keypoints, cm = row.keypoints, row.camera_metadata\n",
    "            keypoint_arr = self.get_keypoint_arr(keypoints, cm)\n",
    "            keypoint_arr_list.append(keypoint_arr)\n",
    "        self.df['keypoint_arr'] = keypoint_arr_list\n",
    "\n",
    "    @staticmethod\n",
    "    def get_raw_3D_coordinates(keypoints, cm):\n",
    "        wkps = pixel2world([item for item in keypoints['leftCrop'] if item['keypointType'] != 'BODY'],\n",
    "                           [item for item in keypoints['rightCrop'] if item['keypointType'] != 'BODY'],\n",
    "                           cm)\n",
    "        all_wkps = [list(wkps[bp]) for bp in BODY_PARTS]\n",
    "\n",
    "        # compute BODY world keypoint coordinates\n",
    "        if 'BODY' in [item['keypointType'] for item in keypoints['leftCrop']]:\n",
    "            left_item = [item for item in keypoints['leftCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "            right_item = [item for item in keypoints['rightCrop'] if item['keypointType'] == 'BODY'][0]\n",
    "            disps = np.abs(left_item['xFrame'] - right_item['xFrame'])\n",
    "            focal_length_pixel = cm[\"focalLengthPixel\"]\n",
    "            baseline = cm[\"baseline\"]\n",
    "            depths = focal_length_pixel * baseline / np.array(disps)\n",
    "\n",
    "            pixel_count_width = cm[\"pixelCountWidth\"]\n",
    "            pixel_count_height = cm[\"pixelCountHeight\"]\n",
    "            sensor_width = cm[\"imageSensorWidth\"]\n",
    "            sensor_height = cm[\"imageSensorHeight\"]\n",
    "            focal_length = cm[\"focalLength\"]\n",
    "\n",
    "            image_center_x = pixel_count_width / 2.0\n",
    "            image_center_y = pixel_count_height / 2.0\n",
    "            x = left_item['xFrame']\n",
    "            y = left_item['yFrame']\n",
    "            px_x = x - image_center_x\n",
    "            px_z = image_center_y - y\n",
    "\n",
    "            sensor_x = px_x * (sensor_width / pixel_count_width)\n",
    "            sensor_z = px_z * (sensor_height / pixel_count_height)\n",
    "\n",
    "            world_y = depths\n",
    "            world_x = (world_y * sensor_x) / focal_length\n",
    "            world_z = (world_y * sensor_z) / focal_length\n",
    "            wkps['BODY'] = np.column_stack([world_x, world_y, world_z])\n",
    "\n",
    "            body_wkps = random.sample([list(wkp) for wkp in list(wkps['BODY'])], 500)\n",
    "            all_wkps.extend(body_wkps)\n",
    "        return np.array(all_wkps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_rotation_matrix(n, theta):\n",
    "\n",
    "        R = np.array([[\n",
    "            np.cos(theta) + n[0] ** 2 * (1 - np.cos(theta)),\n",
    "            n[0] * n[1] * (1 - np.cos(theta)) - n[2] * np.sin(theta),\n",
    "            n[0] * n[2] * (1 - np.cos(theta)) + n[1] * np.sin(theta)\n",
    "        ], [\n",
    "            n[1] * n[0] * (1 - np.cos(theta)) + n[2] * np.sin(theta),\n",
    "            np.cos(theta) + n[1] ** 2 * (1 - np.cos(theta)),\n",
    "            n[1] * n[2] * (1 - np.cos(theta)) - n[0] * np.sin(theta),\n",
    "        ], [\n",
    "            n[2] * n[0] * (1 - np.cos(theta)) - n[1] * np.sin(theta),\n",
    "            n[2] * n[1] * (1 - np.cos(theta)) + n[0] * np.sin(theta),\n",
    "            np.cos(theta) + n[2] ** 2 * (1 - np.cos(theta))\n",
    "        ]])\n",
    "\n",
    "        return R\n",
    "\n",
    "    def normalize_3D_coordinates(self, wkps):\n",
    "\n",
    "        # translate keypoints such that medoid is at origin\n",
    "        wkps = wkps - 0.5 * (np.max(wkps[:8], axis=0) + np.min(wkps[:8], axis=0))\n",
    "\n",
    "        # perform rotation\n",
    "        upper_lip_idx = BODY_PARTS.index('UPPER_LIP')\n",
    "\n",
    "        n = np.array([0, 1, 0])\n",
    "        theta = np.arctan(wkps[upper_lip_idx][2] / wkps[upper_lip_idx][0])\n",
    "        R = self._generate_rotation_matrix(n, theta)\n",
    "        wkps = np.dot(R, wkps.T).T\n",
    "\n",
    "        # perform reflecton if necessary\n",
    "        tail_notch_idx = BODY_PARTS.index('TAIL_NOTCH')\n",
    "        if wkps[upper_lip_idx][0] < wkps[tail_notch_idx][0]:\n",
    "            R = np.array([\n",
    "                [-1, 0, 0],\n",
    "                [0, 1, 0],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "            wkps = np.dot(R, wkps.T).T\n",
    "\n",
    "        return wkps\n",
    "\n",
    "    def get_keypoint_arr(self, keypoints, cm):\n",
    "        dorsal_fin_idx, pelvic_fin_idx = BODY_PARTS.index('DORSAL_FIN'), BODY_PARTS.index('PELVIC_FIN')\n",
    "        wkps = self.get_raw_3D_coordinates(keypoints, cm)\n",
    "        norm_wkps = self.normalize_3D_coordinates(wkps)\n",
    "        if any([item['keypointType'] == 'BODY' for item in keypoints['leftCrop']]):\n",
    "            body_norm_wkps = norm_wkps[8:, :]\n",
    "            mid_point = 0.5 * (norm_wkps[dorsal_fin_idx] + norm_wkps[pelvic_fin_idx])\n",
    "            idx = np.argmin(np.linalg.norm(body_norm_wkps[:, [0, 2]] - np.array([mid_point[0], mid_point[2]]), axis=1))\n",
    "            body_wkp = body_norm_wkps[idx]\n",
    "            keypoint_arr = np.vstack([norm_wkps[:8, :], body_wkp])\n",
    "            return keypoint_arr\n",
    "        else:\n",
    "            return norm_wkps\n",
    "\n",
    "    def get_prepared_dataset(self):\n",
    "        return self.df\n",
    "\n",
    "\n",
    "akpd_scorer_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/keypoint-detection-scorer/akpd_scorer_model_TF.h5'\n",
    "gtsf_dataset = GTSFDataset('2019-03-01', '2020-03-30', akpd_scorer_url)\n",
    "df = gtsf_dataset.get_prepared_dataset()\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps.max(axis=0), wkps.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(wkps.shape[0] - 1):\n",
    "    for j in range(i+1, wkps.shape[0]):\n",
    "        print(euclidean_distance(wkps[i], wkps[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_1 in range(len(BODY_PARTS) - 1):\n",
    "    for idx_2 in range(idx_1+1, len(BODY_PARTS)):\n",
    "        wkps_dict = df.world_keypoints.iloc[0]\n",
    "        bp_1, bp_2 = BODY_PARTS[idx_1], BODY_PARTS[idx_2]\n",
    "        d = euclidean_distance(wkps_dict[bp_1], wkps_dict[bp_2])\n",
    "        print('{}-{}: {}'.format(bp_1, bp_2, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "\n",
    "def prepare_df(aggregate_df):\n",
    "    \n",
    "    # use QA'ed entries, and only use Cogito entries when QA data is unavailable\n",
    "    qa_df = aggregate_df[aggregate_df.is_qa == True]\n",
    "    cogito_df = aggregate_df[(aggregate_df.is_qa != True) & \\\n",
    "                             ~(aggregate_df.left_image_url.isin(qa_df.left_image_url))]\n",
    "    df = pd.concat([qa_df, cogito_df], axis=0)\n",
    "    \n",
    "    # add world keypoints\n",
    "    df['world_keypoints'] = df.apply(lambda x: get_world_keypoints(x), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints -> 'leftCrop' is not null\n",
    "    and b.keypoints -> 'rightCrop' is not null\n",
    "    and b.is_qa = false\n",
    "    and b.captured_at < '2019-09-20';\n",
    "\"\"\"\n",
    "aggregate_df = rds_access_utils.extract_from_database(query)\n",
    "df = prepare_df(aggregate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.world_keypoints.apply(lambda x: np.median([wkp[1] for wkp in x.values()])))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['median_depth'] = df.world_keypoints.apply(lambda x: np.median([wkp[1] for wkp in x.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# load neural network weights\n",
    "akpd_scorer_network = load_model('/root/data/alok/biomass_estimation/playground/akpd_scorer_model_TF.h5') # make this better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_akpd_score(row_id, ann, cm):\n",
    "    \n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': ann,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': row_id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "    return akpd_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akpd_scores = []\n",
    "for idx, row in df.iterrows():\n",
    "    akpd_score = generate_akpd_score(row.id, row.keypoints, row.camera_metadata)\n",
    "    akpd_scores.append(akpd_score)\n",
    "df['akpd_score'] = akpd_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_clause = ''\n",
    "for idx, row in df.loc[df.akpd_score < 1e-4, ['id', 'akpd_score']].iterrows():\n",
    "    kpid = row.id\n",
    "    where_clause += f' OR id = {int(kpid)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for idx, row in df.loc[df.akpd_score < 1e-5, ['id', 'akpd_score']].iterrows():\n",
    "    kpid = row.id\n",
    "    ids.append(kpid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.fish_id=='190808-d20dc94e-fc76-4ffb-a4f5-f296d9ac368d'].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_research_sql_credentials = json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS']))\n",
    "rds_access_utils = RDSAccessUtils(prod_research_sql_credentials)\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "visualizer = Visualizer(s3_access_utils, rds_access_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_annotation_id = 507806\n",
    "visualizer.load_data(keypoint_annotation_id)\n",
    "visualizer.display_crops(overlay_keypoints=True, show_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_annotation_id = 648822\n",
    "visualizer.load_data(keypoint_annotation_id)\n",
    "visualizer.display_crops(overlay_keypoints=True, show_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{item['keypointType']: [item['xFrame'], item['yFrame']] for item in df[df.id == 635713].keypoints.iloc[0]['leftCrop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{item['keypointType']: [item['xFrame'], item['yFrame']] for item in df[df.id == 635713].keypoints.iloc[0]['rightCrop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 10000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    ann_c = row.keypoints\n",
    "    ann_dict_left_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['leftCrop']}\n",
    "    ann_dict_right_kps_c = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann_c['rightCrop']}\n",
    "    these_diffs = []\n",
    "    for bp in BODY_PARTS:\n",
    "        diff = ann_dict_left_kps_c[bp][1] - ann_dict_right_kps_c[bp][1]\n",
    "        these_diffs.append(diff)\n",
    "    diffs.append(np.mean(these_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diffs'] = diffs\n",
    "df.index = pd.to_datetime(df.captured_at)\n",
    "df.diffs.resample('D', how=lambda x: x.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
