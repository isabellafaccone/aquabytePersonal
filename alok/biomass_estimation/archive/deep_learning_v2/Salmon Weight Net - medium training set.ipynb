{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> In this notebook, we will implement a neural network that regresses volume against segmentation + depth map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/github/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from biomass_utils.points_of_interest import get_point_cloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready\n",
    "\n",
    "data_path_base = '/root/data/blender_v3'\n",
    "depth_map_dir = '{}/{}'.format(data_path_base, 'depth_map')\n",
    "segmentation_dir = '{}/{}'.format(data_path_base, 'mask')\n",
    "annotation_dir = '{}/{}'.format(data_path_base, 'annotations')\n",
    "\n",
    "number_key = lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "side_key = lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[0]\n",
    "all_segmentation_paths = sorted(glob.glob('{}/*.npy'.format(segmentation_dir)), key=number_key)\n",
    "segmentation_paths = [p for p in all_segmentation_paths if side_key(p) == 'left'] # we are working with left frame only\n",
    "depth_map_paths = sorted(glob.glob('{}/*.npy'.format(depth_map_dir)), key=number_key)\n",
    "annotation_paths = sorted(glob.glob('{}/*.json'.format(annotation_dir)), key=number_key) \n",
    "complete_data_list = zip(segmentation_paths, depth_map_paths, annotation_paths)\n",
    "\n",
    "\n",
    "TRAINING_SIZE = 500\n",
    "train_data_list = [v for i, v in enumerate(complete_data_list) if i < TRAINING_SIZE]\n",
    "test_data_list = [v for i, v in enumerate(complete_data_list) if i > TRAINING_SIZE]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_values, j_values = np.where(np.load(segmentation_paths[0]) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CLASSES = 10\n",
    "# def get_volume_class_from_numeric_value(volume):\n",
    "#     x = np.zeros(NUM_CLASSES)\n",
    "#     volume_class = int(round(volume / (10000/NUM_CLASSES)))\n",
    "#     x[volume_class] = 1\n",
    "#     return x\n",
    "\n",
    "sm = cm.ScalarMappable(cmap='hot')\n",
    "sm.set_clim(vmin=0, vmax=20)\n",
    "def convert_to_scaled_rgb_image(segmentation_mask, depth_map, annotation):    \n",
    "    projected_depth_map = get_point_cloud(depth_map, annotation['focal_length'], \n",
    "                                          annotation['sensor_height'], \n",
    "                                          annotation['sensor_width'])[:,:,1]\n",
    "    cleaned_depth_map = segmentation_mask * projected_depth_map\n",
    "    i_values, j_values = np.where(segmentation_mask > 0)\n",
    "    \n",
    "    \n",
    "    rgb_image = sm.to_rgba(cleaned_depth_map, bytes=True)[:,:,:3]\n",
    "    \n",
    "    scaled_rgb_image = np.array(Image.fromarray(rgb_image).resize((224, 224)))\n",
    "    return scaled_rgb_image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "a= convert_to_scaled_rgb_image(np.load(segmentation_paths[idx]), \n",
    "                               np.load(depth_map_paths[idx]).T, \n",
    "                               json.load(open(annotation_paths[idx], 'rb')))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_list, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, min((i+1)*BATCH_SIZE, len(data_list)))):\n",
    "            segmentation_mask = np.load(data_list[j][0])\n",
    "            depth_map = np.load(data_list[j][1]).T\n",
    "            annotation = json.load(open(data_list[j][2], 'rb'))\n",
    "            scaled_depth_map = convert_to_scaled_rgb_image(segmentation_mask, depth_map, annotation)\n",
    "            \n",
    "#             volume_class = get_volume_class_from_numeric_value(annotation['volume'])\n",
    "            x_batch[ind, ...] = scaled_depth_map / 255.0\n",
    "            y_batch[ind] = annotation['volume']\n",
    "            \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights=None, include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(1, name='predictions')(vgg16.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=vgg16.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "steps_per_epoch = int(len(train_data_list)/BATCH_SIZE)\n",
    "gen = generator(train_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))\n",
    "scores = model.evaluate_generator(eval_gen, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))\n",
    "predictions = model.predict_generator(eval_gen, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values = np.array([])\n",
    "for i in range(120*25):\n",
    "    annotation = json.load(open(test_data_list[i][2], 'rb'))\n",
    "    ground_truth_values = np.append(ground_truth_values, annotation['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ground_truth_values.mean() - predictions[:,0].mean())/(ground_truth_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
