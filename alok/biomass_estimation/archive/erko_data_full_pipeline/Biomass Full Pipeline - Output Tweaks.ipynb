{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load annotations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import skimage.io\n",
    "\n",
    "LIB_DIRECTORY = '/root/alok/repos/cv_research/lib/'\n",
    "sys.path.insert(0, os.path.join(LIB_DIRECTORY, 'maskrcnn'))\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mcoco.coco as coco\n",
    "# import mextra.utils as extra_utils\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "LIB_DIRECTORY = '/root/alok/repos/cv_research/lib/'\n",
    "sys.path.insert(0, LIB_DIRECTORY)\n",
    "\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "BASE_DIR = '/root/data/models/erko/mask_rcnn_instance_segmentation'\n",
    "DATA_DIR = '/root/data/erko/'\n",
    "WEIGHTS_DIR = os.path.join(BASE_DIR, \"weights\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"logs\", \"body_part_segmentation_20181031_21H02\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = '/root/alok/data/images/annotation_file_test_set.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = json.load(open(annotation_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize the Results </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annotations(image_id):    \n",
    "    image_data = coco.loadImgs([image_id])[0]\n",
    "    image_file_path = image_data['local_path']\n",
    "    annotation_ids = coco.getAnnIds(imgIds=[image_id])\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "    # load and display instance annotations\n",
    "    image = skimage.io.imread(image_file_path)\n",
    "    f, ax = plt.subplots(1, figsize=(20, 20))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    coco.showAnns(annotations)\n",
    "    \n",
    "    # display bounding boxes\n",
    "    for ann in annotations:\n",
    "        bbox = ann['bbox']\n",
    "        rectangle = Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "        ax.add_patch(rectangle)\n",
    "#         category_id = ann['category_id']\n",
    "        category_id = ann['id']\n",
    "        ax.text(bbox[1], bbox[0] - 10, category_id, fontsize=16, color='w')\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_annotations(527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_annotations(2222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get biomass estimates </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define some helper functions (most of this code is adapted from cv_algorithms)\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "FOCAL_LENGTH = 0.0107\n",
    "BASELINE = 0.135\n",
    "PIXEL_SIZE_M = 3.45 * 1e-6\n",
    "FOCAL_LENGTH_PIXEL = FOCAL_LENGTH / PIXEL_SIZE_M\n",
    "IMAGE_SENSOR_WIDTH = 0.01412\n",
    "IMAGE_SENSOR_HEIGHT = 0.01035\n",
    "PIXEL_COUNT_WIDTH = 4096\n",
    "PIXEL_COUNT_HEIGHT = 3000\n",
    "COST_THRESHOLD = 100.0  # another magic number\n",
    "\n",
    "# TODO (@Alok): this is hardcoded - not good, should come directly from coco file\n",
    "CATEGORIES = [\n",
    "    {'id': 1, 'name': 'salmon'},\n",
    "    {'id': 2, 'name': 'Head'},\n",
    "    {'id': 3, 'name': 'Caudal Fin'},\n",
    "    {'id': 4, 'name': 'Dorsal Fin'},\n",
    "    {'id': 5, 'name': 'Adipose Fin'},\n",
    "    {'id': 6, 'name': 'Anal Fin'},\n",
    "    {'id': 7, 'name': 'Pelvic Fin'},\n",
    "    {'id': 8, 'name': 'Pectoral Fin'},\n",
    "    {'id': 9, 'name': 'Eye'}\n",
    "]\n",
    "\n",
    "WHOLE_FISH = 'salmon'\n",
    "\n",
    "# TODO (@Alok): this is hardcoded - not good, should come from a file\n",
    "BODY_PARTS_REQUIRED = ['Head', 'Dorsal Fin', 'Anal Fin']\n",
    "\n",
    "MODEL_PATH = '/root/data/models/biomass/model.pickle'\n",
    "COMPONENTS_PATH = '/root/data/models/biomass/components.npy'\n",
    "IQRS_PATH = '/root/data/models/biomass/iqrs.pkl'\n",
    "\n",
    "\n",
    "def convert_to_world_point(x, y, d):\n",
    "    \"\"\" from pixel coordinates to world coordinates \"\"\"\n",
    "    \n",
    "    image_center_x = PIXEL_COUNT_HEIGHT / 2.0  \n",
    "    image_center_y = PIXEL_COUNT_WIDTH / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (IMAGE_SENSOR_WIDTH / 4096)\n",
    "    sensor_z = px_z * (IMAGE_SENSOR_HEIGHT / 3000)\n",
    "\n",
    "    # d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / FOCAL_LENGTH\n",
    "    world_z = (world_y * sensor_z) / FOCAL_LENGTH\n",
    "    return np.array([world_x, world_y, world_z])\n",
    "\n",
    "\n",
    "def depth_from_disp(disp):\n",
    "    depth = FOCAL_LENGTH_PIXEL*BASELINE / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "\n",
    "def get_fish_detections(annotations, categories, whole_fish=\"salmon\"):\n",
    "    \n",
    "    \"\"\" Get fish detections -- i.e. get all whole fish and body parts corresponding to that whole fish in a single frame \"\"\"\n",
    "    \n",
    "    whole_fish_id = [cat for cat in categories if cat['name'] == whole_fish][0]['id']\n",
    "    fish = []\n",
    "    body_parts = []\n",
    "\n",
    "    # first we separate whole salmon from body parts and give a unique identifier\n",
    "    for annotation in annotations:\n",
    "        if annotation['category_id'] == whole_fish_id:\n",
    "            fish.append(annotation)\n",
    "        else:\n",
    "            body_parts.append(annotation)\n",
    "\n",
    "    # second we match body parts with whole salmon\n",
    "    # @TODO (Thomas) this is not great because it does not take edges cases into account.\n",
    "    for part in body_parts:\n",
    "        bbox = part['bbox']\n",
    "        part_centroid = [np.mean([bbox[0], bbox[2]]), np.mean([bbox[1], bbox[3]])]\n",
    "        for f in fish:\n",
    "            bbox = f['bbox']\n",
    "            if bbox[0] < part_centroid[0] < bbox[2] and bbox[1] < part_centroid[1] < bbox[3]:\n",
    "                part['fish_ann_id'] = f['id']\n",
    "                break\n",
    "            \n",
    "    # @TODO (Alok) this is redudant work here -- merge this with the part above\n",
    "    fish_detections = []\n",
    "    for f in fish:\n",
    "        detection = {\n",
    "            'fish': f,\n",
    "            'body_parts': []\n",
    "        }\n",
    "        for part in body_parts:\n",
    "            if part.get('fish_ann_id') == f['id']:\n",
    "                detection['body_parts'].append(part)\n",
    "        fish_detections.append(detection)\n",
    "        \n",
    "    return fish_detections\n",
    "\n",
    "\n",
    "def get_stereo_fish_detections(left_fish_detections, right_fish_detections, categories, whole_fish=\"salmon\"):\n",
    "    \n",
    "    \"\"\"match the left and right fish detections to return a list of stereo fish detections \"\"\"\n",
    "    \n",
    "    # get the salmon category id\n",
    "    whole_fish_id = [cat for cat in categories if cat['name'] == whole_fish][0]['id']\n",
    "\n",
    "    # let's use x1, x2 to match bboxes\n",
    "    left_bottom_top_edge_locations = []\n",
    "    left_ids = []\n",
    "    for detection in left_fish_detections:\n",
    "        f = detection['fish']\n",
    "        assert f['category_id'] == whole_fish_id, 'Annotation should be a whole fish but is a body part'\n",
    "        bbox = f['bbox']\n",
    "        bottom_top_edge_location = [bbox[2], bbox[0]]\n",
    "        left_ids.append(f['id'])\n",
    "        left_bottom_top_edge_locations.append(bottom_top_edge_location)\n",
    "\n",
    "    right_bottom_top_edge_locations = []\n",
    "    right_ids = []\n",
    "    for detection in right_fish_detections:\n",
    "        f = detection['fish']\n",
    "        assert f['category_id'] == whole_fish_id, 'Annotation should be a whole fish but is a body part'\n",
    "        bbox = f['bbox']\n",
    "        bottom_top_edge_location = [bbox[2], bbox[0]]\n",
    "        right_ids.append(f['id'])\n",
    "        right_bottom_top_edge_locations.append(bottom_top_edge_location)\n",
    "\n",
    "    # euclidean distance in (x1, x2) space\n",
    "    cost_matrix = euclidean_distances(left_bottom_top_edge_locations, right_bottom_top_edge_locations)\n",
    "    \n",
    "    # hungarian algorithm to minimize weights in bipartite graph\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    stereo_fish_detections = []\n",
    "    for (r, c) in zip(row_ind, col_ind):\n",
    "        if cost_matrix[r, c] < COST_THRESHOLD:\n",
    "            left_fish_detection = [l for l in left_fish_detections if l['fish']['id'] == left_ids[r]][0]\n",
    "            right_fish_detection = [r for r in right_fish_detections if r['fish']['id'] == right_ids[c]][0]\n",
    "            \n",
    "            stereo_fish_detections.append({\n",
    "                'left': left_fish_detection,\n",
    "                'right': right_fish_detection\n",
    "            })\n",
    "    \n",
    "    return stereo_fish_detections\n",
    "\n",
    "\n",
    "def weight_estimator(left_matched_parts, right_matched_parts, required_categories, model, components, iqrs):\n",
    "    left_category_ids = [ann['category_id'] for ann in left_matched_parts]\n",
    "    right_category_ids = [ann['category_id'] for ann in right_matched_parts]\n",
    "    \n",
    "    required_body_part_ids = sorted([cat['id'] for cat in required_categories])\n",
    "    \n",
    "    left_valid = all([body_part in left_category_ids for body_part in required_body_part_ids])\n",
    "    right_valid = all([body_part in right_category_ids for body_part in required_body_part_ids])\n",
    "    \n",
    "    if left_valid and right_valid:\n",
    "        \"\"\"take left and right body parts and calculates the weights\"\"\"\n",
    "        \n",
    "        # create dataset that will contain pairwise distances\n",
    "        distances = [str(c) + str(k) for (i, c) in enumerate(required_body_part_ids) for k in required_body_part_ids[i + 1:]]\n",
    "        dataset = {}\n",
    "        for d in distances:\n",
    "            dataset[d] = []\n",
    "\n",
    "        # calculate disparities & world coordinates\n",
    "        world_coordinates = {}\n",
    "        for cat in required_categories:\n",
    "            \n",
    "            # calculate left centroid   \n",
    "            left_part = [part for part in left_matched_parts if part['category_id'] == cat['id']][0]\n",
    "            seg = left_part['segmentation'][0]\n",
    "            poly = np.array(seg).reshape((int(len(seg) / 2), 2))\n",
    "            p = [(r[0], r[1]) for r in poly]\n",
    "            left_mask = Image.new('L', (4096, 3000), 0)\n",
    "            ImageDraw.Draw(left_mask).polygon(p, outline=1, fill=1)\n",
    "            left_mask = np.array(left_mask)\n",
    "            x, y = np.nonzero(left_mask)\n",
    "            left_centroid = [np.mean(x), np.mean(y)]\n",
    "\n",
    "            # calculate right centroid\n",
    "            right_part = [part for part in right_matched_parts if part['category_id'] == cat['id']][0]\n",
    "            seg = right_part['segmentation'][0]\n",
    "            poly = np.array(seg).reshape((int(len(seg) / 2), 2))\n",
    "            p = [(r[0], r[1]) for r in poly]\n",
    "            right_mask = Image.new('L', (4096, 3000), 0)\n",
    "            ImageDraw.Draw(right_mask).polygon(p, outline=1, fill=1)\n",
    "            right_mask = np.array(right_mask)\n",
    "            x, y = np.nonzero(right_mask)\n",
    "            right_centroid = [np.mean(x), np.mean(y)]\n",
    "\n",
    "            # calculate disparity\n",
    "            disparities = np.abs(left_centroid[1] - right_centroid[1])\n",
    "            depth = depth_from_disp(disparities)\n",
    "            world_coordinates[str(cat['id'])] = convert_to_world_point(left_centroid[0], left_centroid[1], depth)\n",
    "\n",
    "        # now calculate the pairwise distances\n",
    "        for pair in dataset.keys():\n",
    "            cat0, cat1 = pair[0], pair[1]\n",
    "            dist = np.linalg.norm(world_coordinates[cat0] - world_coordinates[cat1])\n",
    "            dataset[pair].append(dist)\n",
    "        \n",
    "        # TODO (@Thomas) probably no reasons to use pandas here\n",
    "        df = pd.DataFrame(dataset)\n",
    "        for col in df.columns.tolist():\n",
    "            df[col] = df[col] / iqrs[col]\n",
    "        \n",
    "        pidx = np.indices((df.shape[1], df.shape[1])).reshape(2, -1)\n",
    "        lcol = pd.MultiIndex.from_product([df.columns, df.columns],  names=[df.columns.name, df.columns.name])\n",
    "        X = pd.DataFrame(df.values[:, pidx[0]] * df.values[:, pidx[1]],  columns=lcol)\n",
    "\n",
    "        # load pca components\n",
    "        newX = np.dot(X, components.T)\n",
    "        weight = float(np.squeeze(model.predict(newX)))\n",
    "        return weight\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = coco.getImgIds()\n",
    "images = coco.loadImgs(image_ids)\n",
    "stereo_frame_pairs = {}\n",
    "for image in images:\n",
    "    local_path = image['local_path']\n",
    "    sfp_id = int(local_path.split('/')[-3])\n",
    "    side = 'left' if 'left' in local_path else 'right'\n",
    "    if sfp_id not in list(stereo_frame_pairs.keys()):\n",
    "        stereo_frame_pairs[sfp_id] = {}\n",
    "    stereo_frame_pairs[sfp_id][side] = image['id']\n",
    "    \n",
    "stereo_frame_pairs = list(stereo_frame_pairs.values())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.load(MODEL_PATH)\n",
    "components = np.load(COMPONENTS_PATH)\n",
    "iqrs = pickle.load(open(IQRS_PATH, 'rb'))\n",
    "\n",
    "output_directory = './biomass_service_output'\n",
    "\n",
    "for i, stereo_frame_pair in enumerate(stereo_frame_pairs):\n",
    "    left_image_id = stereo_frame_pair['left']\n",
    "    left_image = coco.loadImgs([left_image_id])[0]\n",
    "    left_image_path = left_image['local_path']\n",
    "    left_annotation_ids = coco.getAnnIds(imgIds=[left_image_id])\n",
    "    left_annotations = coco.loadAnns(left_annotation_ids)\n",
    "    \n",
    "    right_image_id = stereo_frame_pair['right']\n",
    "    right_image = coco.loadImgs([right_image_id])[0]\n",
    "    right_image_path = right_image['local_path']\n",
    "    right_annotation_ids = coco.getAnnIds(imgIds=[right_image_id])\n",
    "    right_annotations = coco.loadAnns(right_annotation_ids)\n",
    "    required_categories = [cat for cat in CATEGORIES if cat['name'] in BODY_PARTS_REQUIRED]\n",
    "    \n",
    "    \n",
    "    left_fish_detections = get_fish_detections(left_annotations, CATEGORIES, whole_fish=WHOLE_FISH)\n",
    "    right_fish_detections = get_fish_detections(right_annotations, CATEGORIES, whole_fish=WHOLE_FISH)\n",
    "    \n",
    "    stereo_fish_detections = []\n",
    "    if left_fish_detections and right_fish_detections:\n",
    "        stereo_fish_detections = get_stereo_fish_detections(left_fish_detections, right_fish_detections, CATEGORIES)\n",
    "        for detection in stereo_fish_detections:\n",
    "            left_body_parts = detection['left']['body_parts']\n",
    "            right_body_parts = detection['right']['body_parts']\n",
    "            if left_body_parts and right_body_parts:\n",
    "                weight = weight_estimator(left_body_parts, right_body_parts, required_categories, model, components, iqrs)\n",
    "                print(weight)\n",
    "                detection['biomass'] = weight\n",
    "                    \n",
    "    # determine which left and right fish detections were not matched\n",
    "    matched_fish_detection_ids = []\n",
    "    for detection in stereo_fish_detections:\n",
    "        matched_fish_detection_ids.append(detection['left']['fish']['id'])\n",
    "        matched_fish_detection_ids.append(detection['right']['fish']['id'])\n",
    "    \n",
    "    all_stereo_fish_detections = []\n",
    "    for detection in left_fish_detections:\n",
    "        if detection['fish']['id'] not in matched_fish_detection_ids:\n",
    "            all_stereo_fish_detections.append({\n",
    "                'left': detection,\n",
    "                'right': None\n",
    "            })\n",
    "    for detection in right_fish_detections:\n",
    "        if detection['fish']['id'] not in matched_fish_detection_ids:\n",
    "            all_stereo_fish_detections.append({\n",
    "                'left': None,\n",
    "                'right': detection\n",
    "            })\n",
    "    \n",
    "    all_stereo_fish_detections.extend(stereo_fish_detections)\n",
    "    \n",
    "    stereo_fish_detections_to_output = []\n",
    "    left_im, right_im = Image.open(left_image_path), Image.open(right_image_path)\n",
    "    for detection in all_stereo_fish_detections:\n",
    "        sfd = {\n",
    "            'left_crop_path': None,\n",
    "            'left_annotation_json': None,\n",
    "            'right_crop_path': None,\n",
    "            'right_annotation_json': None,\n",
    "            'biomass': None\n",
    "        }\n",
    "        if detection.get('left'):\n",
    "            left_fish_detection = detection['left']\n",
    "            \n",
    "            # crop and save fish detection\n",
    "            min_x, min_y, max_x, max_y = left_fish_detection['fish']['bbox']\n",
    "            left_crop_basename = 'image_{}_{}_{}_{}.jpg'.format(min_x, min_y, max_x, max_y)\n",
    "            left_crop_path = os.path.join(output_directory, left_crop_basename)\n",
    "            left_crop = left_im.crop((min_y, min_x, max_y, max_x))\n",
    "            \n",
    "            left_crop.save(left_crop_path)\n",
    "            \n",
    "            sfd['left_crop_path'] = left_crop_path\n",
    "            sfd['left_annotation_json'] = left_fish_detection\n",
    "                        \n",
    "        if detection.get('right'):\n",
    "            right_fish_detection = detection['right']\n",
    "            \n",
    "            # crop and save fish detection\n",
    "            min_x, min_y, max_x, max_y = right_fish_detection['fish']['bbox']\n",
    "            right_crop_basename = 'image_{}_{}_{}_{}.jpg'.format(min_x, min_y, max_x, max_y)\n",
    "            right_crop_path = os.path.join(output_directory, right_crop_basename)\n",
    "            right_crop = right_im.crop((min_y, min_x, max_y, max_x))\n",
    "            right_crop.save(right_crop_path)\n",
    "            \n",
    "            sfd['right_crop_path'] = right_crop_path\n",
    "            sfd['right_annotation_json'] = right_fish_detection\n",
    "        \n",
    "        sfd['biomass'] = detection.get('biomass')\n",
    "        stereo_fish_detections_to_output.append(sfd)\n",
    "        print(len(stereo_fish_detections_to_output))\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.squeeze(weights))\n",
    "plt.xlabel('Biomass (grams)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_fish_detections_to_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not x.get('b'):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
