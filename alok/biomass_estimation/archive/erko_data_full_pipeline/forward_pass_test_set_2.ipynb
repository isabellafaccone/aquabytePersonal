{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "LIB_DIRECTORY = '/root/alok/repos/cv_research/lib/'\n",
    "sys.path.insert(0, LIB_DIRECTORY)\n",
    "\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load relevant file paths for left & right frames and bbox predictions\n",
    "\n",
    "data_directory_base = '/root/alok/data/images'\n",
    "stereo_frame_pairs_directory = os.path.join(data_directory_base, 'rectified_stereo_frame_pairs_test_set')\n",
    "left_image_file_paths = glob.glob('{}/{}/*/input/')\n",
    "\n",
    "# left_image_file_paths, right_image_file_paths = [], []\n",
    "# for directory_name in os.listdir(stereo_frame_pairs_directory):\n",
    "#     directory_path = os.path.join(stereo_frame_pairs_directory, directory_name)\n",
    "#     left_image_file_path = os.path.join(directory_path, 'input', 'left_frame.jpg')\n",
    "#     right_image_file_path = os.path.join(directory_path, 'input', 'right_frame.jpg')\n",
    "#     left_image_file_paths.append(left_image_file_path)\n",
    "#     right_image_file_paths.append(right_image_file_path)\n",
    "    \n",
    "# all_image_path = left_image_file_paths + right_image_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(all_image_path[:], columns=['image path'])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Loader </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    Load a dataset for target estimation\n",
    "    \n",
    "    Args:\n",
    "       - dataframe: DataFrame of image path\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataframe.iloc[:, 0][index]\n",
    "        img = skimage.io.imread(img_path)\n",
    "        \n",
    "        return img, img_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - MaskRCNN forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "sys.path.insert(0, os.path.join(LIB_DIRECTORY, 'maskrcnn'))\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mcoco.coco as coco\n",
    "# import mextra.utils as extra_utils\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "BASE_DIR = '/root/data/models/erko/mask_rcnn_instance_segmentation'\n",
    "DATA_DIR = '/root/data/erko/'\n",
    "WEIGHTS_DIR = os.path.join(BASE_DIR, \"weights\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"logs\", \"body_part_segmentation_20181112_21H31\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_body_part_segmentation_0117.h5\")\n",
    "print(COCO_MODEL_PATH)\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "rpn_anchor_template = (1, 2, 4, 8, 16) # anchor sizes in pixels\n",
    "rpn_anchor_scales = tuple(i * (image_size // 16) for i in rpn_anchor_template)\n",
    "\n",
    "class FishConfig(Config):\n",
    "    \"\"\"Configuration for training on the shapes dataset.\n",
    "    \"\"\"\n",
    "    # name your experiments here\n",
    "    NAME = \"full\"\n",
    "\n",
    "    # Train on 1 GPU and 2 images per GPU. Put multiple images on each\n",
    "    # GPU if the images are small. Batch size is 2 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 10  # background + 3 shapes (triangles, circles, and squares)\n",
    "\n",
    "    # Use smaller images for faster training. \n",
    "    IMAGE_MAX_DIM = image_size\n",
    "    IMAGE_MIN_DIM = image_size\n",
    "    \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = rpn_anchor_scales\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    VALIDATION_STEPS = 300\n",
    "    \n",
    "config = FishConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = COCO_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [{u'id': 1, u'name': u'F', u'supercategory': u'F'},\n",
    "    {u'id': 2, u'name': u'Head', u'supercategory': u'Head'},\n",
    "    {u'id': 3, u'name': u'Caudal Fin', u'supercategory': u'Caudal Fin'},\n",
    "    {u'id': 4, u'name': u'Dorsal Fin', u'supercategory': u'Dorsal Fin'},\n",
    "    {u'id': 5, u'name': u'Adipose Fin', u'supercategory': u'Adipose Fin'},\n",
    "    {u'id': 6, u'name': u'Anal Fin', u'supercategory': u'Anal Fin'},\n",
    "    {u'id': 7, u'name': u'Pelvic Fin', u'supercategory': u'Pelvic Fin'},\n",
    "    {u'id': 8, u'name': u'Pectoral Fin', u'supercategory': u'Pectoral Fin'},\n",
    "    {u'id': 9, u'name': u'Eye', u'supercategory': u'Eye'},\n",
    "    {u'id': 10, u'name': u'Body', u'supercategory': u'Body'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(FishConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "\n",
    "# model_path = '/root/data/models/erko/mask_rcnn_instance_segmentation/logs/full_20181002_19H09/mask_rcnn_full_0097.h5'\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Forward pass all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import NamedTemporaryFile\n",
    "from pycocotools.coco import COCO\n",
    "from cococreatortools import * \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO = {\n",
    "    \"description\": \"Fish data\",\n",
    "    \"url\": \"https://github.com/waspinator/pycococreator\",\n",
    "    \"version\": \"0.1.0\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"thossler\",\n",
    "    \"date_created\": datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "        \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'name': 'salmon',\n",
    "        'supercategory': 'fish',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = {\"info\": INFO, \"licenses\": LICENSES, \"categories\": CATEGORIES, \"images\": [], \"annotations\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_generator)\n",
    "segmentation_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in tqdm(range(len(data_generator))):\n",
    "    original_image, img_path = data_generator[image_id]\n",
    "    height,width,_ = original_image.shape\n",
    "    print(img_path)\n",
    "    if original_image is not None:\n",
    "        print(image_id)\n",
    "        \n",
    "        results = model.detect([original_image], verbose=1)[0]\n",
    "\n",
    "        # create the coco stuff\n",
    "        image_info = create_image_info(image_id, img_path, [width, height])\n",
    "        coco_output['images'].append(image_info)\n",
    "\n",
    "        # loop through all the fish detected\n",
    "        detections_number = len(results['class_ids'])\n",
    "        for k in range(detections_number):\n",
    "            # print(segmentation_id)\n",
    "            category_info = {'id': int(results['class_ids'][k])}\n",
    "            binary_mask = results['masks'][..., k]\n",
    "            annotation_info = create_annotation_info(segmentation_id, image_id, category_info, binary_mask,\n",
    "                                                     [width, height], bounding_box=results['rois'][k, ...], tolerance=2)\n",
    "            if annotation_info is not None:\n",
    "                coco_output[\"annotations\"].append(annotation_info)\n",
    "            segmentation_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = '/root/alok/data/annotation_file_test_set.json'\n",
    "with open(annotation_file, 'w') as f:\n",
    "    json.dump(coco_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = '/root/alok/data/images/annotation_file_test_set.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize the Results </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_annotations(image_id):    \n",
    "    image_data = coco.loadImgs([image_id])[0]\n",
    "    image_file_path = image_data['local_path']\n",
    "    annotation_ids = coco.getAnnIds(imgIds=[image_id])\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "    # load and display instance annotations\n",
    "    image = skimage.io.imread(image_file_path)\n",
    "    f, ax = plt.subplots(1, figsize=(20, 20))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    coco.showAnns(annotations)\n",
    "    \n",
    "    # display bounding boxes\n",
    "    for ann in annotations:\n",
    "        bbox = ann['bbox']\n",
    "        rectangle = Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "        ax.add_patch(rectangle)\n",
    "#         category_id = ann['category_id']\n",
    "        category_id = ann['id']\n",
    "        ax.text(bbox[1], bbox[0] - 10, category_id, fontsize=16, color='w')\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_annotations(527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_annotations(2222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Statistical Analysis of Body Part Segmentations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coco_bbox(bbox):\n",
    "    x1, y1, x2, y2 = bbox[1], bbox[0], bbox[3], bbox[2]\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def get_centroid_from_coco_bbox(bbox):\n",
    "    centroid_x = bbox[1] + 0.5 * (bbox[3] - bbox[1])\n",
    "    centroid_y = bbox[0] + 0.5 * (bbox[2] - bbox[0])\n",
    "    return (centroid_x, centroid_y)\n",
    "\n",
    "def determine_if_body_part_falls_inside_detection(centroid, bounding_box):\n",
    "    return (bounding_box[0] <= centroid[0] <= bounding_box[2]) and (bounding_box[1] <= centroid[1] <= bounding_box[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = 10\n",
    "FULL_FISH_CATEGORY_ID = 1\n",
    "\n",
    "'''\n",
    "For each fish detection, determine the body part annotations that correspond to it\n",
    "'''\n",
    "\n",
    "image_ids = coco.getImgIds()\n",
    "images = coco.loadImgs(image_ids)\n",
    "stereo_frame_pair_ids = [int(image['local_path'].split('/')[-3]) for image in images]\n",
    "fish_detections = []\n",
    "unmatched_body_parts = []\n",
    "for image_id, image, stereo_frame_pair_id in zip(image_ids, images, stereo_frame_pair_ids):\n",
    "    fish_detections_in_image = []\n",
    "    annotation_ids = coco.getAnnIds(imgIds=[image_id])\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    full_fish_annotations = [ann for ann in annotations if ann['category_id'] == FULL_FISH_CATEGORY_ID]\n",
    "    for full_fish_annotation in full_fish_annotations:\n",
    "        fish_detection = {\n",
    "            'stereo_frame_pair_id': stereo_frame_pair_id,\n",
    "            'side': 'left' if 'left' in image['local_path'] else 'right',\n",
    "            'full_fish_annotation': full_fish_annotation, \n",
    "            'body_part_annotations': []\n",
    "        }\n",
    "        fish_detection['bounding_box'] = transform_coco_bbox(full_fish_annotation['bbox'])\n",
    "        fish_detections_in_image.append(fish_detection)\n",
    "    \n",
    "    body_part_annotations = [ann for ann in annotations if ann['category_id'] != FULL_FISH_CATEGORY_ID]\n",
    "    for body_part_annotation in body_part_annotations:\n",
    "        body_part_centroid = get_centroid_from_coco_bbox(body_part_annotation['bbox'])\n",
    "        body_part_matched_to_fish_detection = False\n",
    "        for fish_detection in fish_detections_in_image:\n",
    "            body_part_inside_detection = \\\n",
    "                determine_if_body_part_falls_inside_detection(body_part_centroid, fish_detection['bounding_box'])\n",
    "            if body_part_inside_detection:\n",
    "                fish_detection['body_part_annotations'].append(body_part_annotation)\n",
    "                body_part_matched_to_fish_detection = True\n",
    "        if not body_part_matched_to_fish_detection:\n",
    "            unmatched_body_parts.append(body_part_annotation)\n",
    "    fish_detections.extend(fish_detections_in_image)\n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images: {}'.format(len(image_ids)))\n",
    "print('Number of fish detected per image: {}'.format(len(fish_detections) / float(len(image_ids))))\n",
    "\n",
    "body_part_annotation_counts = {i: 0 for i in range(1, NUM_CATEGORIES)}\n",
    "total_body_part_count = 0\n",
    "number_of_fish_with_all_body_parts_detected = 0\n",
    "for fish_detection in fish_detections:\n",
    "    for body_part_annotation in fish_detection['body_part_annotations']:\n",
    "        body_part_annotation_counts[body_part_annotation['category_id']] += 1\n",
    "    total_body_part_count += len(fish_detection['body_part_annotations'])\n",
    "    if total_body_part_count == NUM_CATEGORIES - 1:\n",
    "        number_of_fish_with_all_body_parts_detected += 1\n",
    "        \n",
    "for i in range(1, NUM_CATEGORIES):\n",
    "    if i != FULL_FISH_CATEGORY_ID:\n",
    "        body_part_frequency = body_part_annotation_counts[i] / float(len(fish_detections))\n",
    "        print('Frequency of body part #{} across fish detections: {}'.format(i, body_part_frequency))    \n",
    "        \n",
    "print('Average number of body parts detection per fish detection: {}'.format(float(total_body_part_count) / len(fish_detections)))\n",
    "print('Percentage of fish detections with all body parts detected: {}'.format(float(number_of_fish_with_all_body_parts_detected) / len(fish_detections)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate frequency breakdown by combination of body parts </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "\n",
    "for fish_detection in fish_detections:\n",
    "    combination = []\n",
    "    for body_part_annotation in fish_detection['body_part_annotations']:\n",
    "        combination.append(body_part_annotation['category_id'])\n",
    "    combination = sorted(list(set(combination)))\n",
    "    combinations.append(combination)\n",
    "\n",
    "combinations = list(set([','.join([str(i) for i in c]) for c in combinations]))[1:]\n",
    "\n",
    "combination_frequencies = {x: 0 for x in combinations}\n",
    "\n",
    "for combination in combinations:\n",
    "    for fish_detection in fish_detections:\n",
    "        body_part_annotations = [ann['category_id'] for ann in fish_detection['body_part_annotations']]\n",
    "        if all([c in body_part_annotations for c in [int(i) for i in combination.split(',')]]):\n",
    "            combination_frequencies[combination] += float(1) / len(fish_detections)\n",
    "    \n",
    "frequencies = []\n",
    "named_combinations = []\n",
    "unique_combinations = list(combination_frequencies.keys())\n",
    "for combination in unique_combinations:\n",
    "    named_combination = []\n",
    "    for c in [int(i) for i in combination.split(',')]:\n",
    "        named_combination.append(CATS[c])\n",
    "    frequencies.append(combination_frequencies[combination])\n",
    "    named_combinations.append(', '.join(named_combination))\n",
    "\n",
    "df = pd.DataFrame({'combination': named_combinations, 'frequency': frequencies})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Determine left-right matches (approach 1) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_matching_1(left_fish_detections, right_fish_detections):\n",
    "    left_bounding_boxes = [fish['bounding_box'] for fish in left_fish_detections]\n",
    "    right_bounding_boxes = [fish['bounding_box'] for fish in right_fish_detections]\n",
    "    \n",
    "    left_centroids, left_ids = [], []\n",
    "    for fish in left_fish_detections:\n",
    "        bbox = fish['bounding_box']\n",
    "        centroid = [0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])]\n",
    "        left_centroids.append(centroid)\n",
    "        left_ids.append(fish['full_fish_annotation']['id'])\n",
    "        \n",
    "    right_centroids, right_ids = [], []\n",
    "    for fish in right_fish_detections:\n",
    "        bbox = fish['bounding_box']\n",
    "        centroid = [0.5 * (bbox[0] + bbox[2]), 0.5 * (bbox[1] + bbox[3])]\n",
    "        right_centroids.append(centroid)\n",
    "        right_ids.append(fish['full_fish_annotation']['id'])\n",
    "        \n",
    "    for fish in left_fish_detections:\n",
    "        bbox = fish['bounding_box']\n",
    "        print(bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "        \n",
    "    for fish in right_fish_detections:\n",
    "        bbox = fish['bounding_box']\n",
    "        print(bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_iou(bbox_1, bbox_2):\n",
    "    bbox_1_length = bbox_1[2] - bbox_1[0]\n",
    "    bbox_1_height = bbox_1[3] - bbox_1[1]\n",
    "    bbox_2_length = bbox_2[2] - bbox_2[0]\n",
    "    bbox_2_height = bbox_2[3] - bbox_2[1]\n",
    "\n",
    "    a = min(bbox_2[2] - bbox_1[0], bbox_1[2] - bbox_2[0], bbox_1_length, bbox_2_length)\n",
    "    a = max(a, 0)\n",
    "    b = min(bbox_2[3] - bbox_1[1], bbox_1[3] - bbox_2[1], bbox_1_height, bbox_2_height)\n",
    "    b = max(b, 0)\n",
    "\n",
    "    intersection = a*b\n",
    "    area_1 = bbox_1_length * bbox_1_height\n",
    "    area_2 = bbox_2_length * bbox_2_height\n",
    "    union = area_1 + area_2 - intersection\n",
    "    iou = float(intersection) / union\n",
    "    return iou\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_matching_2(left_fish_detections, right_fish_detections):\n",
    "    for left_fish in left_fish_detections:\n",
    "        \n",
    "        left_fish_id = left_fish['full_fish_annotation']['id']\n",
    "        left_bbox = left_fish['bounding_box']\n",
    "        \n",
    "        for right_fish in right_fish_detections:\n",
    "            right_fish_id = right_fish['full_fish_annotation']['id']\n",
    "            right_bbox = right_fish['bounding_box']\n",
    "            if right_bbox[0] < left_bbox[0]:\n",
    "                translated_right_bbox = (\n",
    "                    left_bbox[0], \n",
    "                    right_bbox[1], \n",
    "                    right_bbox[2] - (right_bbox[0] - left_bbox[0]), \n",
    "                    right_bbox[3]\n",
    "                )\n",
    "                bbox_iou = get_bbox_iou(left_bbox, translated_right_bbox)\n",
    "                print(left_fish_id, right_fish_id, bbox_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_frame_pairs = {stereo_frame_pair_id: {'left_fish_detections': [], 'right_fish_detections': []} for stereo_frame_pair_id in list(set(stereo_frame_pair_ids))}\n",
    "for fish_detection in fish_detections:\n",
    "    stereo_frame_pair_id, side = fish_detection['stereo_frame_pair_id'], fish_detection['side']\n",
    "    stereo_frame_pairs[stereo_frame_pair_id]['{}_fish_detections'.format(side)].append(fish_detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stereo_frame_pair_id in list(stereo_frame_pairs.keys()):\n",
    "    \n",
    "    left_fish_detections = stereo_frame_pairs[stereo_frame_pair_id]['left_fish_detections']\n",
    "    right_fish_detections = stereo_frame_pairs[stereo_frame_pair_id]['right_fish_detections']\n",
    "    \n",
    "    if left_fish_detections and right_fish_detections:\n",
    "        print('Left image id: {}'.format(left_fish_detections[0]['full_fish_annotation']['image_id']))\n",
    "        print('Right image id: {}'.format(right_fish_detections[0]['full_fish_annotation']['image_id']))\n",
    "        left_right_matching(left_fish_detections, right_fish_detections)\n",
    "        print('')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['class_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/small_pen_data_collection/body_parts_detection_20181017.json', 'w') as f:\n",
    "    json.dump(coco_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
