{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTSF phase: biomass prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are forecasting the weights by finding the closest blender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the volumes created with blender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load blender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/data/alok/blender_data/volumes_all.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.array(data[\"dimensions\"])[:, 1], data[\"volume\"])\n",
    "# plt.ylabel(\"Volume (cm^3)\")\n",
    "# plt.xlabel(\"Length (mm)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"volume\"])\n",
    "plt.title(\"Blender volume histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pairwise distances from blender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = data[\"mapping\"]\n",
    "reverse_mapping = data[\"reverse_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_parts = max(list(mapping.values()))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"volume\":[]}\n",
    "dataset_np = []\n",
    "kfactors = []\n",
    "for (coord, vol) in zip(data[\"coordinates\"], data[\"volume\"]):\n",
    "    row = []\n",
    "    for k in range(number_of_parts):\n",
    "        v = coord[reverse_mapping[str(k)]]\n",
    "        for k0 in range(k+1, number_of_parts):\n",
    "            v0 = coord[reverse_mapping[str(k0)]]\n",
    "            dist = np.sqrt((v[2]-v0[2])**2 + (v[1]-v0[1])**2)\n",
    "            cname = \"{}-{}\".format(k, k0)\n",
    "            row.append(dist)\n",
    "            if cname not in dataset:\n",
    "                dataset[cname] = []\n",
    "            dataset[cname].append(dist)\n",
    "    dataset_np.append(row)\n",
    "    dataset[\"volume\"].append(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the gtsf data\n",
    "\n",
    "Loading the gtsf data points and creating the pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfiles = [\"/root/data/gtsf_phase_I/2019-02-26/2019-02-26_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-02-27/2019-02-27_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-01/2019-03-01_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-04/2019-03-04_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-05/2019-03-05_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-06/2019-03-06_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-11/2019-03-11_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-13/2019-03-13_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-14/2019-03-14_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-18/2019-03-18_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-19/2019-03-19_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-21/2019-03-21_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-25/2019-03-25_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-27/2019-03-27_cogito_annotations.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for jsonpath in jsonfiles:\n",
    "    with open(jsonpath, \"r\") as f:\n",
    "        jfile = json.load(f)\n",
    "        annotations += jfile\n",
    "print(\"Number of annotations: {}\".format(len(annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the local path for ease and rename the body parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotations:\n",
    "    local_path = os.path.join(\"/root/data/gtsf_phase_I/\", \n",
    "                  \"/\".join(ann[\"Labeled Data\"].split(\"/\")[7:]))\n",
    "    ann[\"local_path\"] = local_path\n",
    "    if not os.path.isfile(local_path):\n",
    "        print(\"missing image!!\")\n",
    "    for body_part in ann[\"Label\"].keys():\n",
    "        new_body_part = \"_\".join(body_part.replace(\":\", \"\").split()).upper()\n",
    "        ann[\"Label\"][new_body_part] = ann[\"Label\"].pop(body_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ground truth weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table, select, func, and_, insert, delete, update, or_\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_credentials = json.load(open(os.environ[\"SQL_CREDENTIALS\"]))\n",
    "\n",
    "sql_engine = create_engine(\n",
    "    \"postgresql://{}:{}@{}:{}/{}\".format(sql_credentials[\"user\"], sql_credentials[\"password\"],\n",
    "                                         sql_credentials[\"host\"], sql_credentials[\"port\"],\n",
    "                                         sql_credentials[\"database\"]))\n",
    "\n",
    "metadata = MetaData()\n",
    "gtsf = Table('gtsf_data_collections', metadata, autoload=True, autoload_with=sql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "for ann in annotations:\n",
    "    timestamp = ann[\"local_path\"].split(\"/\")[-3]\n",
    "    ann[\"timestamp\"] = timestamp\n",
    "    timestamps.append(ann[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query over all the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select([gtsf.c.ground_truth_metadata,\n",
    "                gtsf.c.gtsf_fish_identifier]).select_from(gtsf).where(gtsf.c.gtsf_fish_identifier.in_(timestamps))\n",
    "connection = sql_engine.connect()\n",
    "q = connection.execute(query)\n",
    "results = [(eval(r[0]), r[1]) for r in q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the morphologic information to the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(r[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotations:\n",
    "    for r in results:\n",
    "        if r[1] == ann[\"timestamp\"]:\n",
    "            ann[\"weight\"] = r[0][\"data\"][\"weight\"]\n",
    "            ann[\"breath\"] = r[0][\"data\"][\"breath\"]\n",
    "            ann[\"length\"] = r[0][\"data\"][\"length\"]\n",
    "            ann[\"width\"] = r[0][\"data\"][\"width\"]\n",
    "            ann[\"kfactor\"] = 10**5*ann[\"weight\"] / ann[\"length\"]**3\n",
    "            ann[\"species\"] = r[0][\"data\"].get(\"species\", \"salmon\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ann for ann in annotations if ann[\"kfactor\"] < 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactor = np.array([ann[\"kfactor\"] for ann in annotations if ann[\"species\"] == \"salmon\"])\n",
    "plt.hist(kfactor)\n",
    "plt.title(\"K factor distribution of GTSF data\")\n",
    "plt.xlabel(\"K factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D to 3D \n",
    "\n",
    "Move from 2d pixel coordinates to 3d world coordinates. First, need to create pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating pairs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs per timestamp\n",
    "pairs = {}\n",
    "for ann in annotations:\n",
    "    if ann[\"species\"] != \"salmon\":\n",
    "        continue\n",
    "    if ann[\"kfactor\"] < 0.3:\n",
    "        continue\n",
    "    timestamp = ann[\"timestamp\"]\n",
    "    side = os.path.basename(ann[\"local_path\"]).split(\"_\")[0]\n",
    "    ann[\"side\"] = side\n",
    "    if timestamp not in pairs:\n",
    "        pairs[timestamp] = {}\n",
    "    pairs[timestamp][side] = ann\n",
    "\n",
    "full_pairs = [k for (k, v)in pairs.items() if \"left\" in v and \"right\" in v]\n",
    "print(\"Number of full pairs: {}\".format(len(full_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = np.random.choice(full_pairs)\n",
    "left_ann = pairs[timestamp][\"left\"]\n",
    "right_ann = pairs[timestamp][\"right\"]\n",
    "\n",
    "# load images\n",
    "left_im = cv2.imread(left_ann[\"local_path\"])\n",
    "right_im = cv2.imread(right_ann[\"local_path\"])\n",
    "\n",
    "# load keypoints\n",
    "left_keypoints = [(v[0][\"geometry\"][\"x\"], v[0][\"geometry\"][\"y\"]) for v in left_ann[\"Label\"].values()]\n",
    "left_keypoints = np.array(left_keypoints)\n",
    "right_keypoints = [(v[0][\"geometry\"][\"x\"], v[0][\"geometry\"][\"y\"]) for v in right_ann[\"Label\"].values()]\n",
    "right_keypoints = np.array(right_keypoints)\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(left_im)\n",
    "ax[0].scatter(left_keypoints[:, 0], left_keypoints[:, 1])\n",
    "ax[1].imshow(right_im)\n",
    "ax[1].scatter(right_keypoints[:, 0], right_keypoints[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the keypoints and create world coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import depth_from_disp, convert_to_world_point, load_keypoints, euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = False\n",
    "new_shape = (512, 512)\n",
    "height_ratio = new_shape[0] / 3000.0\n",
    "width_ratio = new_shape[1] / 4096.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducing....jittering\n",
    "jitter = False\n",
    "jitter_max = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_array(array):\n",
    "    # randomly pick what part to jitter\n",
    "    size = array.shape[0]\n",
    "    coin = np.random.rand(size)\n",
    "    coin = np.round(coin)\n",
    "    \n",
    "    delta = np.random.randint(-jitter_max, jitter_max, size=size)\n",
    "    array = array + delta*coin\n",
    "    return array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = {}\n",
    "for ts in full_pairs:\n",
    "    # load annotations\n",
    "    left_ann = pairs[ts][\"left\"]\n",
    "    right_ann = pairs[ts][\"right\"]\n",
    "    \n",
    "    left_keypoints = load_keypoints(left_ann, mapping)\n",
    "    right_keypoints = load_keypoints(right_ann, mapping)\n",
    "    if jitter:\n",
    "        left_keypoints[:, 0] = jitter_array(left_keypoints[:, 0])\n",
    "        left_keypoints[:, 1] = jitter_array(left_keypoints[:, 1])\n",
    "        right_keypoints[:, 0] = jitter_array(right_keypoints[:, 0])\n",
    "        right_keypoints[:, 1] = jitter_array(right_keypoints[:, 1])\n",
    "    if rescale:\n",
    "        left_keypoints = left_keypoints * np.array([width_ratio, height_ratio])\n",
    "        left_keypoints = np.array(left_keypoints, dtype=np.uint8)\n",
    "        right_keypoints = right_keypoints * np.array([width_ratio, height_ratio])\n",
    "        right_keypoints = np.array(right_keypoints, dtype=np.uint8)\n",
    "        \n",
    "    # calculate disparities\n",
    "    disparities = left_keypoints[:, 0] - right_keypoints[:, 0]\n",
    "    # print(disparities)\n",
    "    # compute world key point\n",
    "    world_keypoints = {}\n",
    "    for (i, d) in enumerate(disparities):\n",
    "        depth = depth_from_disp(d)\n",
    "        world_coord = convert_to_world_point(left_keypoints[i, 0], left_keypoints[i, 1], depth)\n",
    "        world_keypoints[list(mapping.keys())[i]] = world_coord\n",
    "    world[ts] = world_keypoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot world coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(left_keypoints[:, 0], left_keypoints[:, 1])\n",
    "# for i in range(number_of_parts):\n",
    "#     plt.text(left_keypoints[i, 0], left_keypoints[i, 1], list(mapping.keys())[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for (k, v) in world['190226010005'].items():\n",
    "    plt.scatter(v[0], v[2])\n",
    "    plt.text(v[0]+0.003, v[2]+0.003, k)\n",
    "    plt.axis(\"scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "\n",
    "First, let's calculate the pairwise distances for the gtsf data. Second let's find the closest Blender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions_average = []\n",
    "ground_truth = []\n",
    "\n",
    "for ts in world:\n",
    "    # load keypoints\n",
    "    world_keypoints = world[ts]\n",
    "    # calculate distances\n",
    "    measurements= []\n",
    "    for k in range(number_of_parts):\n",
    "        v = world_keypoints[reverse_mapping[str(k)]]\n",
    "        for k0 in range(k+1, number_of_parts):\n",
    "            v0 = world_keypoints[reverse_mapping[str(k0)]]\n",
    "            dist = euclidean_distance(v, v0)*1000 # mm to m\n",
    "            measurements.append(dist)\n",
    "    \n",
    "    # find closest blender volume\n",
    "    # calculate l1 distance\n",
    "    diff = np.nanmean(np.abs(np.array(df)[:, :-1] - measurements), axis=1)\n",
    "    closest = np.argsort(diff)\n",
    "    idx = 10\n",
    "    closest5 = np.array(df)[closest[:idx], -1]\n",
    "    print(\"closest volumes\", closest5)\n",
    "    print(\"standard dev:\", np.std(closest5))\n",
    "    print(\"estimated length\", measurements[13])\n",
    "    closest_length = np.array(list(df[\"2-3\"].iloc()[closest[:idx]]))\n",
    "    kfactor = 10**5*closest5 / closest_length**3\n",
    "    print(\"closest length\", closest_length)\n",
    "    print(\"closest kfactor\", kfactor)\n",
    "    print(\"closest height\", list(df[\"4-6\"].iloc()[closest[:idx]]))\n",
    "    print(\"#\"*50)\n",
    "    pred_volume = np.array(df)[closest[0], -1]\n",
    "    predictions.append(pred_volume)\n",
    "    predictions_average.append(np.mean(closest5))\n",
    "    \n",
    "    # ground truth\n",
    "    ground_truth_weight = [ann[\"weight\"] for ann in annotations if ann[\"timestamp\"] == ts][0]\n",
    "    ground_truth_kfactor = [ann[\"kfactor\"] for ann in annotations if ann[\"timestamp\"] == ts][0]\n",
    "    ground_truth.append([ground_truth_weight, ground_truth_kfactor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions_average = np.array(predictions_average)\n",
    "ground_truth = np.array(ground_truth)\n",
    "gt_weight = ground_truth[:, 0]\n",
    "gt_kfactor = ground_truth[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OLD CODE**\n",
    "\n",
    "Quick OLS. \n",
    "\n",
    "$\\hat{\\beta} = (X^{T}X)^{-1}X^{T}Y$\n",
    "\n",
    "(just for Alok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = ground_truth[:, np.newaxis]\n",
    "# ground_truth.shape\n",
    "# A = np.linalg.inv(np.matmul(ground_truth.transpose(), ground_truth))\n",
    "# B = np.matmul(ground_truth.transpose(), predictions)\n",
    "# coeff = 1 / (A*B)\n",
    "# print(\"Reg coeff: {}\".format(coeff))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot([0, 5000], [0, 5000], \"--\", c=\"r\", linewidth=2)\n",
    "# plt.scatter(ground_truth, predictions*coeff)\n",
    "# #plt.scatter(ground_truth, predictions)\n",
    "# plt.xlabel(\"Ground truth weight\")\n",
    "# plt.ylabel(\"Predicted weight\")\n",
    "# plt.axis(\"scaled\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear reg New code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[:, np.newaxis]\n",
    "reg = LinearRegression().fit(predictions, gt_weight)\n",
    "print(reg.coef_, reg.intercept_)\n",
    "print(\"R2 : {}\".format(reg.score(predictions, gt_weight)))\n",
    "predictions = np.squeeze(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 5000], [0, 5000], \"--\", c=\"r\", linewidth=2)\n",
    "plt.scatter(gt_weight, predictions*reg.coef_ + reg.intercept_, c=gt_kfactor)\n",
    "#plt.scatter(ground_truth, predictions)\n",
    "plt.xlabel(\"Ground truth weight\")\n",
    "plt.ylabel(\"Predicted weight\")\n",
    "plt.colorbar()\n",
    "plt.clim([0.8, 1.6])\n",
    "plt.axis(\"scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_predictions = predictions*reg.coef_ + reg.intercept_\n",
    "error = fitted_predictions-gt_weight\n",
    "print(\"Average absolute error: {}\".format(np.nanmean(np.abs(error))))\n",
    "print(\"Average error: {}\".format(np.nanmean(error)))\n",
    "# error5 = predictions_average-ground_truth\n",
    "#print(\"Average absolute error5: {}\".format(np.nanmean(np.abs(error5))))\n",
    "relative_error = ((fitted_predictions-gt_weight) / gt_weight)*100\n",
    "print(\"Average relative error: {} %\".format(np.nanmean(relative_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.kde import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = gaussian_kde(error)\n",
    "dist_space = np.linspace( min(error), max(error), 100 )\n",
    "plt.hist(error, bins=20, density=True)\n",
    "plt.plot( dist_space, kde(dist_space) )\n",
    "plt.title(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = gaussian_kde(relative_error)\n",
    "dist_space = np.linspace( min(relative_error), max(relative_error), 100 )\n",
    "plt.hist(relative_error, bins=20, density=True)\n",
    "plt.plot( dist_space, kde(dist_space) )\n",
    "plt.title(\"Relative Error (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentile plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.arange(0, 101, 5)\n",
    "percentiles = np.percentile(np.abs(relative_error), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(percentiles, values)\n",
    "plt.yticks(np.arange(0,101,5))\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xlabel(\"Absolute relative error (%)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KS test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = norm.fit(fitted_predictions)\n",
    "print(\"Mean: {}, Standard deviation: {}\".format(mean, std))\n",
    "plt.hist(fitted_predictions, bins=20, normed=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(fitted_predictions, norm(loc=mean, scale=std).cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.squeeze(predictions)\n",
    "# all_errors = []\n",
    "# for i in np.arange(0.1, 1.0, 0.1):\n",
    "#     predictions = predictions[:, np.newaxis]\n",
    "#     test_size = i\n",
    "#     print(test_size)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(predictions, ground_truth, test_size=test_size)\n",
    "#     X_test= np.squeeze(X_test)\n",
    "    \n",
    "#     plt.scatter(X_train, y_train)\n",
    "#     plt.scatter(X_test, y_test)\n",
    "#     plt.axis(\"scaled\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     reg = LinearRegression().fit(X_train, y_train)\n",
    "#     print(reg.coef_, reg.intercept_)\n",
    "#     print(\"R2 : {}\".format(reg.score(X_train, y_train)))\n",
    "#     predictions = np.squeeze(predictions)\n",
    "    \n",
    "    \n",
    "#     fitted_X_test = X_test*reg.coef_ + reg.intercept_\n",
    "#     error = fitted_X_test-y_test\n",
    "#     print(\"Average absolute error: {}\".format(np.nanmean(np.abs(error))))\n",
    "#     print(\"Average error: {}\".format(np.nanmean(error)))\n",
    "#     relative_error = ((fitted_X_test-y_test) / y_test)*100\n",
    "#     print(\"Average relative error: {} %\".format(np.nanmean(relative_error)))\n",
    "#     all_errors.append(np.nanmean(relative_error))\n",
    "#     print(\"#\"*50)\n",
    "# plt.plot(np.arange(0.1, 1.0, 0.1)*100 , all_errors)\n",
    "# plt.ylabel(\"Test set average relative error\")\n",
    "# plt.xlabel(\"Test set size (% of total pop)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(predictions)\n",
    "all_errors = []\n",
    "all_relative_errors = []\n",
    "for i in range(1000):\n",
    "    predictions = predictions[:, np.newaxis]\n",
    "    test_size = i\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictions, gt_weight, test_size=0.2)\n",
    "    X_test= np.squeeze(X_test)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    # print(reg.coef_, reg.intercept_)\n",
    "    # print(\"R2 : {}\".format(reg.score(X_train, y_train)))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    \n",
    "    \n",
    "    fitted_X_test = X_test*reg.coef_ + reg.intercept_\n",
    "    error = fitted_X_test-y_test\n",
    "    relative_error = ((fitted_X_test-y_test) / y_test)*100\n",
    "    all_errors.append(np.nanmean(error))\n",
    "    all_relative_errors.append(np.nanmean(relative_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_errors)\n",
    "plt.xlabel(\"Average error distribution\")\n",
    "plt.show()\n",
    "plt.hist(all_relative_errors)\n",
    "plt.xlabel(\"Average relative error distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "errors_means = []\n",
    "kfactors = []\n",
    "\n",
    "for i in range(1000):\n",
    "    predictions = predictions[:, np.newaxis]\n",
    "    test_size = i\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictions, ground_truth, test_size=0.2)\n",
    "    X_test = np.squeeze(X_test)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, y_train[:, 0])\n",
    "    predictions = np.squeeze(predictions)\n",
    "    \n",
    "    fitted_X_test = X_test*reg.coef_ + reg.intercept_\n",
    "    error_mean = np.mean(fitted_X_test) - np.mean(y_test[:, 0])\n",
    "    error = fitted_X_test - y_test[:, 0]\n",
    "    errors_means.append(error_mean)\n",
    "    errors.append(error)\n",
    "    kfactors.append(y_test[:, 1])\n",
    "#     relative_error = ((fitted_X_test-y_test) / y_test)*100\n",
    "#     all_errors.append(np.nanmean(error))\n",
    "#     all_relative_errors.append(np.nanmean(relative_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error = $\\hat{\\mu} - \\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(errors_means)\n",
    "plt.title(\"Error on mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "absolute error as a function of k factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, 1001)\n",
    "abs_error = np.abs(errors[idx])\n",
    "plt.scatter(kfactors[idx], abs_error)\n",
    "plt.xlabel(\"K factor\")\n",
    "plt.ylabel(\"absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more error stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "# isolate 50% of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictions, gt_weight, test_size=0.5)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.squeeze(X_test)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "fitted_X_test = X_test*reg.coef_ + reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 260, 50):\n",
    "    predictions = predictions[:, np.newaxis]\n",
    "    test_size = i\n",
    "    tmp = []\n",
    "    for j in range(100):\n",
    "        random_idx = np.random.choice(range(len(X_test)), size=i, replace=False)\n",
    "        fitted_X_test_subset = fitted_X_test[random_idx]\n",
    "        y_test_subset = y_test[random_idx]\n",
    "\n",
    "        # error = fitted_X_test - y_test[:, 0]\n",
    "        # relative_error = np.abs(((fitted_X_test-y_test_subset) / y_test_subset)*100)\n",
    "        err = (np.mean(fitted_X_test) - np.mean(y_test_subset))*100 / np.mean(y_test_subset)\n",
    "        err = np.abs(err)\n",
    "        tmp.append(err)\n",
    "        # tmp.append(np.mean(relative_error))\n",
    "    errors.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(50, 260, 50):\n",
    "    values = np.arange(0, 101, 5)\n",
    "    percentiles = np.percentile(errors[c], values)\n",
    "    plt.plot(values, percentiles, label=\"Sample size {}\".format(i))\n",
    "    c += 1\n",
    "    \n",
    "plt.xticks(np.arange(0,101,5))\n",
    "plt.yticks(np.arange(0, 9, 1))\n",
    "plt.xlabel(\"Percentage\")\n",
    "# plt.ylabel(\"Mean Absolute relative error (%)\")\n",
    "plt.grid()\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
