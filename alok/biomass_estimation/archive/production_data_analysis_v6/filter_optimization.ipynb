{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from research.utils.datetime_utils import get_dates_in_range\n",
    "from research.weight_estimation.population_metrics import PopulationMetricsEstimator\n",
    "from research.utils.data_generation_utils import extract_biomass_data\n",
    "from research.utils.image_utils import Picture\n",
    "from research.utils.data_access_utils import S3AccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filter_mask(df, start_date, end_date, start_hour, end_hour, kf_cutoff):\n",
    "    # generate filter mask\n",
    "    date_mask = (df.date >= start_date) & (df.date <= end_date)\n",
    "    if start_hour < end_hour:\n",
    "        hour_mask = (df.hour >= start_hour) & (df.hour <= end_hour)\n",
    "    else:\n",
    "        hour_mask = (df.hour >= start_hour) | (df.hour <= end_hour)\n",
    "    kf_mask = (df.estimated_k_factor >= kf_cutoff)\n",
    "    mask = date_mask & hour_mask & kf_mask\n",
    "    return mask\n",
    "\n",
    "\n",
    "def generate_pme(df, start_date, end_date, start_hour, end_hour, kf_cutoff, akpd_score_cutoff=0.99):\n",
    "    mask = generate_filter_mask(df, start_date, end_date, start_hour, end_hour, kf_cutoff)\n",
    "\n",
    "    # get filtered set of biomass computations\n",
    "    biomass_computations = list(zip(df[mask].date.values,\n",
    "                                    df.loc[mask, 'estimated_weight_g'].values,\n",
    "                                    df[mask].estimated_k_factor.values))\n",
    "\n",
    "    # generate population metrics estimator\n",
    "    if biomass_computations:\n",
    "        return PopulationMetricsEstimator(biomass_computations)\n",
    "    return None\n",
    "\n",
    "def not_none_mean(x):\n",
    "    return np.mean([i for i in x if i is not None])\n",
    "    \n",
    "\n",
    "def generate_metrics_for_filter(df, start_date, end_date, start_hour, end_hour, kf_cutoff):\n",
    "    pme = generate_pme(df, start_date, end_date, start_hour, end_hour, kf_cutoff)\n",
    "    mean_dc, mean_kpi, final_smart_average = None, None, None\n",
    "    dates = get_dates_in_range(start_date, end_date)\n",
    "    if pme:\n",
    "        kpis, dcs, smart_avgs = [], [], []\n",
    "        for date in dates:\n",
    "            metrics = pme.generate_smart_metrics_on_date(date)\n",
    "            kpis.append(metrics.get('biomass_kpi'))\n",
    "            dcs.append(metrics.get('distribution_consistency'))\n",
    "            smart_avgs.append(metrics.get('smart_average_weight'))\n",
    "\n",
    "        # compute mean kpi, mean distribution consistency, and final smart average\n",
    "        mean_kpi = not_none_mean(kpis)\n",
    "        mean_dc = not_none_mean(dcs)\n",
    "        final_smart_average = smart_avgs[-1]\n",
    "\n",
    "    return mean_dc, mean_kpi, final_smart_average\n",
    "\n",
    "\n",
    "def generate_optimized_filters(df, start_date, end_date, start_hours, end_hours, kf_cutoffs):\n",
    "\n",
    "    analysis_data = defaultdict(list)\n",
    "    for start_hour in start_hours:\n",
    "        for end_hour in end_hours:\n",
    "            print(start_hour, end_hour)\n",
    "            for kf_cutoff in kf_cutoffs:\n",
    "                mean_dc, mean_kpi, final_smart_avg = generate_metrics_for_filter(df, start_date, end_date, start_hour,\n",
    "                                                                            end_hour, kf_cutoff)\n",
    "\n",
    "                # add to data\n",
    "                analysis_data['mean_kpi'].append(mean_kpi)\n",
    "                analysis_data['mean_dc'].append(mean_dc)\n",
    "                analysis_data['smart_avg'].append(final_smart_avg)\n",
    "                analysis_data['start_hour'].append(start_hour)\n",
    "                analysis_data['end_hour'].append(end_hour)\n",
    "                analysis_data['kf_cutoff'].append(kf_cutoff)\n",
    "\n",
    "    analysis_df = pd.DataFrame(analysis_data)\n",
    "    return analysis_df\n",
    "\n",
    "\n",
    "def generate_global_optimum_filter(pen_id, start_date, end_date, akpd_score_cutoff=0.99):\n",
    "    # generate df\n",
    "    print('Extract raw biomass data...')\n",
    "    df = extract_biomass_data(pen_id, start_date, end_date, min_akpd_score=akpd_score_cutoff)\n",
    "    print('Extraction Complete!')\n",
    "\n",
    "    # perform coarse grid search\n",
    "    print('Performing Coarse Grid Search...')\n",
    "    start_hours = np.arange(0, 24, 1)\n",
    "    end_hours = np.arange(0, 24, 1)\n",
    "    min_kf_cutoff = .05 * int(df.estimated_k_factor.min() / .05)\n",
    "    max_kf = 1.3\n",
    "    kf_cutoffs = np.arange(min_kf_cutoff, max_kf, 0.05)\n",
    "\n",
    "    # get best values from coarse grid search\n",
    "    analysis_df = generate_optimized_filters(df, start_date, end_date, start_hours, end_hours, kf_cutoffs)\n",
    "    best_row = analysis_df.sort_values('mean_kpi', ascending=False).iloc[0]\n",
    "    best_start_hour, best_end_hour, best_kf_cutoff = best_row.start_hour, best_row.end_hour, best_row.kf_cutoff\n",
    "    print(f'Coarse grid search complete with best start hour of {best_start_hour}, '\n",
    "          f'best end hour of {best_end_hour}, best kf cutoff of {best_kf_cutoff}')\n",
    "\n",
    "    # performe fine grid search in local neighborhood of best values above\n",
    "    lo_start_hr, hi_start_hr = max(best_start_hour-1, 0), min(best_start_hour+1, 24)\n",
    "    lo_end_hr, hi_end_hr = max(best_end_hour-1, 0), min(best_end_hour+1, 24)\n",
    "    lo_kf, hi_kf = best_kf_cutoff - 0.1, best_kf_cutoff + 0.01\n",
    "    \n",
    "    start_hours = np.arange(lo_start_hr, hi_start_hr, 1)\n",
    "    end_hours = np.arange(lo_end_hr, hi_end_hr, 1)\n",
    "    kf_cutoffs = np.arange(lo_kf, hi_kf, 0.005)\n",
    "    analysis_df = generate_optimized_filters(df, start_date, end_date, start_hours, end_hours, kf_cutoffs)\n",
    "    best_row = analysis_df.sort_values('mean_kpi', ascending=False).iloc[0]\n",
    "    best_start_hour, best_end_hour, best_kf_cutoff = best_row.start_hour, best_row.end_hour, best_row.kf_cutoff\n",
    "    return best_start_hour, best_end_hour, best_kf_cutoff\n",
    "\n",
    "\n",
    "def main():\n",
    "    pen_id = 1\n",
    "    start_date = '2020-06-15'\n",
    "    end_date = '2020-06-29'\n",
    "    best_start_hour, best_end_hour, best_kf_cutoff = generate_global_optimum_filter(pen_id, start_date, end_date)\n",
    "    print(f'Best Start Hour: {best_start_hour}')\n",
    "    print(f'Best End Hour: {best_end_hour}')\n",
    "    print(f'Best KF Cutoff: {best_kf_cutoff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 108\n",
    "start_date = '2020-05-07'\n",
    "end_date = '2020-05-17'\n",
    "df = extract_biomass_data(pen_id, start_date, end_date, min_akpd_score=0.99)\n",
    "\n",
    "start_hour, end_hour, kf_cutoff = 17, 14, 1.25\n",
    "pme = generate_pme(df, start_date, end_date, start_hour, end_hour, kf_cutoff)\n",
    "dates = get_dates_in_range(start_date, end_date)\n",
    "if pme:\n",
    "    kpis, dcs, smart_avgs = [], [], []\n",
    "    for date in dates:\n",
    "        metrics = pme.generate_smart_metrics_on_date(date)\n",
    "        kpis.append(metrics.get('biomass_kpi'))\n",
    "        dcs.append(metrics.get('distribution_consistency'))\n",
    "        smart_avgs.append(metrics.get('smart_average_weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'date': dates, 'smart_average': smart_avgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5387-5544)/5544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
