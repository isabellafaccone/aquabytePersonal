{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, compute_local_growth_rate, \\\n",
    "    generate_smart_individual_values\n",
    "from report_generation.report_generator import gen_pm_base\n",
    "from report_generation.report_generator import generate_ts_data, SamplingFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load data and generate AKPD scores / weight estimates </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data')\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/data_dump_1.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-06-from-2019-10-25-to-2019-11-01.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-07-from-2019-11-01-to-2019-11-08.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-08-from-2019-11-08-to-2019-11-15.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-09-from-2019-11-15-to-2019-11-22.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-10-from-2019-11-22-to-2019-11-29.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-11-from-2019-11-29-to-2019-12-06.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-12-from-2019-12-06-to-2019-12-13.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-13-from-2019-12-13-to-2019-12-20.csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/pen=61/biomass.csv-61-14-from-2019-12-20-to-2019-12-27.csv')\n",
    "])    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['estimated_weight_g'] = df['weight']\n",
    "df['estimated_k_factor'] = 0.0\n",
    "df.index = pd.to_datetime(df.captured_at)\n",
    "df['hour'] = df.index.hour\n",
    "df['date'] = df.index.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.estimated_weight_g.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SamplingFilter = namedtuple('SamplingFilter', 'start_hour end_hour kf_cutoff akpd_score_cutoff')\n",
    "\n",
    "sampling_filter = SamplingFilter(\n",
    "    start_hour=0,\n",
    "    end_hour=24,\n",
    "    kf_cutoff=0.0,\n",
    "    akpd_score_cutoff=0.95\n",
    ")\n",
    "\n",
    "pm_base = gen_pm_base(df[df.akpd_score > 0.01], sampling_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = generate_smart_avg_weight(pm_base, '2020-02-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_local_growth_rate(pm_base, '2019-09-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_smart_avg_weight(pm_base, '2019-09-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, _ = generate_smart_individual_values(pm_base, '2019-12-05', 3, True, True, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights * (1.0108**-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in weights:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(weights, bucket_cutoffs):\n",
    "    dist = {}\n",
    "    count = 0\n",
    "    for low, high in zip(bucket_cutoffs, bucket_cutoffs[1:]):\n",
    "        bucket = f'{round(1e-3 * low, 1)}-{round(1e-3 * high, 1)}'\n",
    "        bucket_count = weights[(weights >= low) & (weights < high)].shape[0]\n",
    "        dist[bucket] = bucket_count\n",
    "        count += bucket_count\n",
    "    \n",
    "    dist = {k: round(100 * v / count, 1) for k, v in dist.items()}\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_distribution(weights, np.arange(0, 5000, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(list(dist.keys()), list(dist.values()))\n",
    "plt.xlabel('Weight Bucket (kg)')\n",
    "plt.ylabel('Frequency (%)')\n",
    "plt.title('Weight Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_smart_avg_weight(pm_base, '2019-12-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RDSAccessUtils()\n",
    "query = \"\"\"\n",
    "    select * from prod.biomass_computations\n",
    "    where pen_id=61\n",
    "    and group_id='61'\n",
    "    and captured_at between '2020-02-05' and '2020-02-15';\n",
    "\"\"\"\n",
    "\n",
    "df = rds.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('captured_at', ascending=True)\n",
    "df.index = pd.to_datetime(df.captured_at)\n",
    "df['hour'] = df.index.hour\n",
    "df['date'] = df.index.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_filter = SamplingFilter(\n",
    "    start_hour=0,\n",
    "    end_hour=24,\n",
    "    kf_cutoff=0.0,\n",
    "    akpd_score_cutoff=0.01\n",
    ")\n",
    "\n",
    "pm_base = gen_pm_base(df[df.akpd_score > 0.01], sampling_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_local_growth_rate(pm_base, '2020-02-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, _ = generate_smart_individual_values(pm_base, '2020-02-11', 3, True, True, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_distribution(weights, np.arange(0, 12000, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(list(dist.keys()), list(dist.values()))\n",
    "plt.xlabel('Weight Bucket (kg)')\n",
    "plt.ylabel('Frequency (%)')\n",
    "plt.title('Weight Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Union\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from population_metrics.population_metrics_base import generate_pm_base, PopulationMetricsBase, ValidationError\n",
    "from research.utils.datetime_utils import add_days, day_difference, get_dates_in_range\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This module contains functions for computing daily local growth rate. Ask Alok for more \n",
    "context behind mathematical formulation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def compute_growth_rate(X: np.ndarray, y: np.ndarray, n: np.ndarray, decay: float = 0.1) \\\n",
    "        -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Computes growth rate given input log-weight, day number, and sample size information.\n",
    "    Args:\n",
    "        X: numpy array representing day number (i.e. day difference between date and today)\n",
    "        y: numpy array representing log of average weights\n",
    "        n: numpy array representing raw daily sample sizes\n",
    "        decay: exponential decay factor applied to data for dates not equal to today\n",
    "    Returns:\n",
    "        growth_rate: daily growth rate (exponential)\n",
    "        error_magnitude_pct: RMS of error percentages (important for computing trend stability)\n",
    "    \"\"\"\n",
    "\n",
    "    sample_weights = np.multiply(n, np.exp(-decay * np.abs(X.squeeze())))\n",
    "    reg = LinearRegression().fit(X, y, sample_weight=sample_weights)\n",
    "    growth_rate = reg.coef_[0]\n",
    "    y_pred = reg.predict(X)\n",
    "    error_magnitude_pct = np.average(((np.exp(y) - np.exp(y_pred)) / np.exp(y_pred))**2,\n",
    "                                        weights=sample_weights)**0.5\n",
    "\n",
    "    return float(growth_rate), float(error_magnitude_pct)\n",
    "\n",
    "\n",
    "def generate_regression_input(pm_base: PopulationMetricsBase, date: str,\n",
    "                              incorporate_future: bool, window: int = 7,\n",
    "                              min_days_required: int = 4) -> Tuple:\n",
    "    \"\"\"Returns inputs for performing growth rate regression and does data validation in the process.\"\"\"\n",
    "\n",
    "    if incorporate_future:\n",
    "        min_end, max_end = date, add_days(date, window // 2)\n",
    "        possible_end_dates = \\\n",
    "            sorted([date for date in get_dates_in_range(min_end, max_end) if date in pm_base.unique_dates])\n",
    "        end = possible_end_dates[-1] if possible_end_dates else date\n",
    "    else:\n",
    "        end = date\n",
    "\n",
    "    start = add_days(end, -window)\n",
    "    \n",
    "    included_dates = sorted([date for date in get_dates_in_range(start, end) if date in pm_base.unique_dates])\n",
    "    if len(included_dates) < min_days_required:\n",
    "        raise ValidationError('Insufficient data found for computing growth rate!')\n",
    "        \n",
    "    start_idx = pm_base.unique_dates.index(included_dates[0])\n",
    "    end_idx = pm_base.unique_dates.index(included_dates[-1]) + 1\n",
    "    X = np.array([day_difference(d, date) for d in pm_base.unique_dates[start_idx:end_idx]]).reshape(-1, 1)\n",
    "    y = np.log(np.array(pm_base.average_weights[start_idx:end_idx]))\n",
    "    n = np.array(pm_base.sample_sizes[start_idx:end_idx])\n",
    "    \n",
    "    return X, y, n\n",
    "\n",
    "\n",
    "def compute_local_growth_rate(pm_base: PopulationMetricsBase, date: str, incorporate_future: bool = True) \\\n",
    "        -> Union[float, None]:\n",
    "    \"\"\"Computes local growth rate on given date. \"\"\"\n",
    "    print('hey')\n",
    "    try:\n",
    "        X, y, n = generate_regression_input(pm_base, date, incorporate_future)\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return None\n",
    "    growth_rate, _ = compute_growth_rate(X, y, n)\n",
    "    return growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "import numpy as np\n",
    "from population_metrics.population_metrics_base import PopulationMetricsBase, ValidationError\n",
    "from population_metrics.raw_metrics import get_raw_sample_size, get_raw_weight_values, get_raw_kf_values\n",
    "from population_metrics.growth_rate import compute_local_growth_rate\n",
    "from population_metrics.confidence_metrics import generate_trend_stability, get_raw_and_historical_weights\n",
    "from research.utils.datetime_utils import add_days, day_difference, get_dates_in_range\n",
    "\n",
    "\"\"\"\n",
    "This module contains functions for computing daily level smart features - for example, smart growth rate,\n",
    "smart distribution, smart average, smart k-factor, smart sample-size, and smart standard deviation. \n",
    "Ask Alok for more context behind mathematical formulation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_included_dates(pm_base: PopulationMetricsBase, date: str,\n",
    "                       max_day_difference: int, incorporate_future: bool) -> List:\n",
    "    \"\"\"\n",
    "    Gets list of dates that fall into window corresponding to max_day_difference. Window\n",
    "    is affected by whether or not incorporate_future is set to True.\n",
    "    \"\"\"\n",
    "\n",
    "    start = add_days(date, -max_day_difference)\n",
    "    end = add_days(date, max_day_difference if incorporate_future else 0)\n",
    "    included_dates = sorted([date for date in get_dates_in_range(start, end) if date in pm_base.unique_dates])\n",
    "    if not included_dates:\n",
    "        raise ValidationError('No raw biomass data found in window!')\n",
    "    return included_dates\n",
    "\n",
    "\n",
    "def get_smart_growth_rate(pm_base: PopulationMetricsBase, date: str,\n",
    "                          incorporate_future: bool = True, apply_growth_rate: bool = True,\n",
    "                          trend_stability_threshold: float = 0.9) -> float:\n",
    "    \"\"\"Get local growth rate adjustment to use for smart average computation.\"\"\"\n",
    "    raw_sample_size = get_raw_sample_size(pm_base, date)\n",
    "    growth_rate_for_smart_metrics = 0.0\n",
    "    if apply_growth_rate:\n",
    "        try:\n",
    "            growth_rate = compute_local_growth_rate(pm_base, date, incorporate_future=incorporate_future)\n",
    "            trend_stability = generate_trend_stability(pm_base, date, incorporate_future=incorporate_future)\n",
    "            if raw_sample_size and trend_stability and trend_stability > trend_stability_threshold:\n",
    "                growth_rate_for_smart_metrics = growth_rate\n",
    "        except ValidationError as err:\n",
    "            print(str(err))\n",
    "    return growth_rate_for_smart_metrics\n",
    "\n",
    "\n",
    "def generate_smart_individual_values(pm_base: PopulationMetricsBase, date: str, max_day_difference: int,\n",
    "                                     incorporate_future: bool, apply_growth_rate: bool,\n",
    "                                     trend_stability_threshold: float) -> Tuple:\n",
    "    \"\"\"\n",
    "    Generate smart individual values for weight and k-factor on given date.\n",
    "    Args:\n",
    "        pm_base: PopulationMetricsBase instance\n",
    "        date: the date to compute smart individual values for\n",
    "        max_day_difference: what is the maximum day difference of dates in the window?\n",
    "        incorporate_future: should future data be incorporated?\n",
    "        apply_growth_rate: should we apply a growth rate adjustment?\n",
    "        trend_stability_threshold: if apply_growth_rate is True, what minimum trend_stability_threshold\n",
    "                                   should we mandate for growth rate adjustment?\n",
    "    Returns:\n",
    "        adj_weights: growth rate adjusted individual weights in window\n",
    "        kfs: individual k-factor values in window\n",
    "    \"\"\"\n",
    "    \n",
    "    # validate data\n",
    "    included_dates = get_included_dates(pm_base, date, max_day_difference, incorporate_future)\n",
    "\n",
    "    # compute local growth rate to use for smart average\n",
    "    growth_rate_for_smart_metrics = get_smart_growth_rate(pm_base, date, incorporate_future=incorporate_future,\n",
    "                                                          apply_growth_rate=apply_growth_rate,\n",
    "                                                          trend_stability_threshold=trend_stability_threshold)\n",
    "\n",
    "    # get adjusted weights and kfs for smart metrics\n",
    "    adj_weights, kfs = [], []\n",
    "    for d in included_dates:\n",
    "\n",
    "        # extend adjusted weights list for this date\n",
    "        weights_for_date = get_raw_weight_values(pm_base, d)\n",
    "        day_diff = day_difference(d, date)\n",
    "        adj_weights_for_date = np.array(weights_for_date) * np.exp(-day_diff * growth_rate_for_smart_metrics)\n",
    "        adj_weights.extend(adj_weights_for_date)\n",
    "\n",
    "        # extend k-factor list for this date\n",
    "        kfs_for_date = get_raw_kf_values(pm_base, d)\n",
    "        kfs.extend(kfs_for_date)\n",
    "\n",
    "    return np.array(adj_weights), np.array(kfs)\n",
    "\n",
    "\n",
    "def generate_smart_avg_weight(pm_base: PopulationMetricsBase, date: str, max_day_difference: int = 3,\n",
    "                              incorporate_future: bool = True, apply_growth_rate: bool = True,\n",
    "                              trend_stability_threshold: float = 0.9) -> Union[float, None]:\n",
    "    \"\"\"Generates smart average weight on given date.\"\"\"\n",
    "    try:\n",
    "        adj_weights, _ = generate_smart_individual_values(pm_base, date, max_day_difference, incorporate_future,\n",
    "                                                          apply_growth_rate, trend_stability_threshold)\n",
    "        return float(np.mean(adj_weights))\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_smart_distribution(pm_base: PopulationMetricsBase, date: str, max_day_difference: int = 3,\n",
    "                                incorporate_future: bool = True, apply_growth_rate=True,\n",
    "                                trend_stability_threshold: float = 0.9, bucket_size: int = 100) -> Union[Dict, None]:\n",
    "    \"\"\"Generates smart distribution on given date.\"\"\"\n",
    "    try:\n",
    "        adj_weights, kfs = generate_smart_individual_values(pm_base, date, max_day_difference, incorporate_future,\n",
    "                                                            apply_growth_rate, trend_stability_threshold)\n",
    "        # convert None values to nan\n",
    "        kfs = np.array([val if val else np.nan for val in kfs])\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return None\n",
    "\n",
    "    smart_distribution = dict()\n",
    "    bucket_size_kg = 1e-3 * bucket_size\n",
    "    buckets = [round(x, 2) for x in np.arange(0.0, 1e-3 * np.max(adj_weights), bucket_size_kg)]\n",
    "    for b in buckets:\n",
    "        low, high = 1e3 * b, 1e3 * (b + bucket_size_kg)\n",
    "        mask = (adj_weights >= low) & (adj_weights < high)\n",
    "        count = adj_weights[mask].shape[0]\n",
    "        kfs_for_bucket = kfs[mask]\n",
    "        mean_kf = np.mean(kfs_for_bucket)\n",
    "        smart_distribution[str(b)] = {\n",
    "            'count': count,\n",
    "            'avgKFactor': None if np.isnan(mean_kf) else mean_kf\n",
    "        }\n",
    "\n",
    "    return smart_distribution\n",
    "\n",
    "\n",
    "def generate_smart_avg_kf(pm_base: PopulationMetricsBase, date: str, max_day_difference: int = 3,\n",
    "                          incorporate_future: bool = True, apply_growth_rate: bool = True,\n",
    "                          trend_stability_threshold: float = 0.9) -> Union[float, None]:\n",
    "    \"\"\"Generates smart average k-factor on given date.\"\"\"\n",
    "    try:\n",
    "        _, kfs = generate_smart_individual_values(pm_base, date, max_day_difference,\n",
    "                                                  incorporate_future, apply_growth_rate,\n",
    "                                                  trend_stability_threshold)\n",
    "\n",
    "        kfs = [val for val in kfs if val]\n",
    "        mean_kf = np.mean(kfs)\n",
    "        smart_avg_kf = None if np.isnan(mean_kf) else float(mean_kf)\n",
    "        return smart_avg_kf\n",
    "\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_smart_standard_deviation(pm_base: PopulationMetricsBase, date: str, max_day_difference: int = 3,\n",
    "                                      incorporate_future: bool = True, apply_growth_rate: bool = True,\n",
    "                                      trend_stability_threshold: float = 0.9) -> Union[float, None]:\n",
    "    \"\"\"Generates smart standard deviation on given date.\"\"\"\n",
    "    try:\n",
    "        adj_weights, _ = generate_smart_individual_values(pm_base, date, max_day_difference, incorporate_future,\n",
    "                                                          apply_growth_rate, trend_stability_threshold)\n",
    "        return float(np.std(adj_weights))\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_smart_sample_size(pm_base: PopulationMetricsBase, date: str, max_day_difference: int = 3,\n",
    "                          incorporate_future: bool = True, apply_growth_rate: bool = True,\n",
    "                          trend_stability_threshold: float = 0.9) -> int:\n",
    "    \"\"\"Generates smart sample size on given date.\"\"\"\n",
    "    try:\n",
    "        adj_weights, _ = generate_smart_individual_values(pm_base, date, max_day_difference, incorporate_future,\n",
    "                                                          apply_growth_rate, trend_stability_threshold)\n",
    "        return len(adj_weights)\n",
    "    except ValidationError as err:\n",
    "        print(str(err))\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
