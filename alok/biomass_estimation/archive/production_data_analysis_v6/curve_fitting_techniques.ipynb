{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from filter_optimization.filter_optimization_task import _add_date_hour_columns\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select * from prod.biomass_computations\n",
    "    where pen_id=56\n",
    "    and captured_at between '2020-08-21' and '2020-08-30'\n",
    "    and akpd_score >= 0.9\n",
    "\"\"\"\n",
    "\n",
    "df = rds.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _add_date_hour_columns(df)\n",
    "hour_mask = (df.hour >= 7) & (df.hour <= 15)\n",
    "akpd_mask = (df.akpd_score > 0.99)\n",
    "kf_mask = (df.estimated_k_factor > 1.135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[hour_mask & akpd_mask].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[hour_mask].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[kf_mask & akpd_mask].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[akpd_mask].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Histogram of weights below minimum acceptable weight </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hour_mask = (df.hour >= 7) & (df.hour <= 15)\n",
    "akpd_mask = (df.akpd_score > 0.99)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df.estimated_weight_g, bins=100)\n",
    "plt.hist(df[hour_mask].estimated_weight_g, bins=100, color='red')\n",
    "plt.axvline(1120, color='red', linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Curve fitting on part of distribution </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from filter_optimization.filter_optimization_task import NoDataException, SamplingFilter, generate_filter_mask, \\\n",
    "     extract_biomass_data\n",
    "from population_metrics.population_metrics_base import generate_pm_base, PopulationMetricsBase\n",
    "from population_metrics.growth_rate import compute_local_growth_rate\n",
    "from population_metrics.raw_metrics import get_raw_kf_values, generate_raw_average_weight, get_raw_sample_size\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values, \\\n",
    "     generate_smart_distribution, generate_smart_avg_kf, get_smart_sample_size, get_smart_growth_rate, \\\n",
    "     generate_smart_standard_deviation\n",
    "from population_metrics.confidence_metrics import generate_trend_stability, generate_distribution_consistency, \\\n",
    "     compute_biomass_kpi, get_raw_and_historical_weights\n",
    "from research.utils.datetime_utils import get_dates_in_range\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "\n",
    "def gen_pm_base(df: pd.DataFrame, sampling_filter: SamplingFilter) -> PopulationMetricsBase:\n",
    "    \"\"\"\n",
    "    Returns PopulationMetricsBase instance given input biomass computations\n",
    "    data-frame (see README for more details) and SamplingFilter instance.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = generate_filter_mask(df, sampling_filter)\n",
    "\n",
    "    # get filtered set of biomass computations\n",
    "    biomass_computations = list(zip(df[mask].date.values,\n",
    "                                    df.loc[mask, 'estimated_weight_g'].values,\n",
    "                                    df[mask].estimated_k_factor.values))\n",
    "\n",
    "    # generate population metrics estimator\n",
    "    if not biomass_computations:\n",
    "        raise NoDataException('No data found for given filter!')\n",
    "    return generate_pm_base(biomass_computations)\n",
    "\n",
    "\n",
    "def generate_ts_data(df: pd.DataFrame, sampling_filter: SamplingFilter) -> defaultdict:\n",
    "    \"\"\"\n",
    "    Given input data-frame of biomass computations and SamplingFilter instance,\n",
    "    generates time-series data for different raw metrics, smart metrics, growth rate metrics,\n",
    "    and confidence metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    pm_base = gen_pm_base(df, sampling_filter)\n",
    "    start_date, end_date = pm_base.unique_dates[0], pm_base.unique_dates[-1]\n",
    "    dates = get_dates_in_range(start_date, end_date)\n",
    "    ts_data = defaultdict(list)\n",
    "    ts_data['date'].extend(dates)\n",
    "    for date in dates:\n",
    "\n",
    "        # raw metrics\n",
    "        raw_average_weight = generate_raw_average_weight(pm_base, date)\n",
    "        raw_sample_size = get_raw_sample_size(pm_base, date)\n",
    "\n",
    "        # growth rate metrics\n",
    "        growth_rate = compute_local_growth_rate(pm_base, date)\n",
    "\n",
    "        # confidence metrics\n",
    "        distribution_consistency = generate_distribution_consistency(pm_base, date)\n",
    "        kpi = compute_biomass_kpi(pm_base, date)\n",
    "\n",
    "        # smart metrics\n",
    "        smart_average_weight = generate_smart_avg_weight(pm_base, date)\n",
    "        smart_average_kf = generate_smart_avg_kf(pm_base, date)\n",
    "        smart_sample_size = get_smart_sample_size(pm_base, date)\n",
    "        smart_growth_rate = get_smart_growth_rate(pm_base, date)\n",
    "\n",
    "        ts_data['raw_average_weight'].append(raw_average_weight)\n",
    "        ts_data['raw_sample_size'].append(raw_sample_size)\n",
    "        ts_data['growth_rate'].append(growth_rate)\n",
    "        ts_data['distribution_consistency'].append(distribution_consistency)\n",
    "        ts_data['kpi'].append(kpi)\n",
    "        ts_data['smart_average_weight'].append(smart_average_weight)\n",
    "        ts_data['smart_average_kf'].append(smart_average_kf)\n",
    "        ts_data['smart_sample_size'].append(smart_sample_size)\n",
    "        ts_data['smart_growth_rate'].append(smart_growth_rate)\n",
    "\n",
    "    return ts_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id, start_date, end_date = 60, '2020-08-15', '2020-08-25'\n",
    "sampling_filter = SamplingFilter(start_hour=7, end_hour=15, kf_cutoff=1.135, akpd_score_cutoff=0.95)\n",
    "df = extract_biomass_data(pen_id, start_date, end_date, sampling_filter.akpd_score_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_base = gen_pm_base(df, sampling_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_weights, _ = generate_smart_individual_values(pm_base, '2020-08-24', 3, True, True, 0.9)\n",
    "weights = 0.83 * round_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.optimize import fmin_slsqp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def func(p, r, xa, xb):\n",
    "    return truncnorm.nnlf(p, r)\n",
    "\n",
    "\n",
    "def constraint(p, r, xa, xb):\n",
    "    a, b, loc, scale = p\n",
    "    return np.array([a*scale + loc - xa, b*scale + loc - xb])\n",
    "\n",
    "\n",
    "# xa, xb = 3000, 6000\n",
    "\n",
    "# Generate some data to work with.\n",
    "\n",
    "lo, hi = 2500, 6000\n",
    "mask = (weights > lo) & (weights < hi)\n",
    "vals = weights[mask]\n",
    "\n",
    "u, sigma = np.mean(vals), np.std(vals)\n",
    "xa, xb = (lo - u) / sigma, (hi - u) / sigma\n",
    "r = (vals - np.mean(vals)) / np.std(vals)\n",
    "\n",
    "loc_guess = 0\n",
    "scale_guess = 1\n",
    "\n",
    "a_guess = (xa - loc_guess)/scale_guess\n",
    "b_guess = (xb - loc_guess)/scale_guess\n",
    "p0 = [a_guess, b_guess, loc_guess, scale_guess]\n",
    "\n",
    "par = fmin_slsqp(func, p0, f_eqcons=constraint, args=(r, xa, xb),\n",
    "                 iprint=True, iter=1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "cf_mean, cf_std = sigma * par[2] + u, sigma * par[3]\n",
    "x = np.linspace(0, 10000, 1000)\n",
    "ax.plot(x, 0.83 * norm.pdf(x, cf_mean, cf_std), 'k--', lw=1, alpha=1.0, label='norm fit')\n",
    "ax.hist(weights, bins=15, density=True, histtype='stepfilled', alpha=0.3)\n",
    "ax.legend(shadow=True)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "cohort_name = 'vikane_pen_id_60_2020-08-05_2020-08-30'\n",
    "\n",
    "s3_dir = os.path.join(\n",
    "    'https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets',\n",
    "    cohort_name\n",
    ")\n",
    "\n",
    "ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata.json')\n",
    "ground_truth_f, _, _ = s3.download_from_url(ground_truth_metadata_url)\n",
    "ground_truth_metadata = json.load(open(ground_truth_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_cutoffs = np.arange(0, 10000, 1000)\n",
    "pred_distribution = {}\n",
    "for low_weight, high_weight in zip(bucket_cutoffs, bucket_cutoffs[1:]):\n",
    "    bucket = '{}-{}'.format(low_weight, high_weight)\n",
    "    pct = norm.cdf(high_weight, cf_mean, cf_std) - norm.cdf(low_weight, cf_mean, cf_std)\n",
    "    pred_distribution[bucket] = round(100 * pct, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cf_mean - 3515) / 3515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xmin = -2\n",
    "xmax = 4\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, truncnorm.pdf(x, *par),\n",
    "        'k--', lw=1, alpha=1.0, label='truncnorm fit')\n",
    "ax.hist(r, bins=15, density=True, histtype='stepfilled', alpha=0.3)\n",
    "ax.legend(shadow=True)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] * norm.pdf(x, cf_mean, cf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
