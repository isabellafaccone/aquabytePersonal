{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import datetime as dt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "from research.utils.datetime_utils import add_days, get_dates_in_range\n",
    "from research.weight_estimation.population_metrics import PopulationMetricsEstimator\n",
    "from research.weight_estimation.keypoint_utils.keypoint_transformations import get_raw_3d_coordinates\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Establish Useful Functions for smart average calcualtion </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        credentials = json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS']))\n",
    "        self.rds_access_utils = RDSAccessUtils(credentials)\n",
    "        self.df = None\n",
    "\n",
    "    def query_from_db(self, pen_id, start_date=None, end_date=None, min_akpd_score=0.99):\n",
    "        if not end_date:\n",
    "            end_date = dt.datetime.strftime(dt.datetime.now(), '%Y-%m-%d')\n",
    "        if not start_date:\n",
    "            start_date = add_days(end_date, -30 * 6)\n",
    "        query = \"\"\"\n",
    "            SELECT * FROM\n",
    "            prod.biomass_computations bc\n",
    "            WHERE bc.pen_id={}\n",
    "            AND bc.akpd_score >= {}\n",
    "            AND bc.captured_at between '{}' and '{}'\n",
    "            AND bc.estimated_weight_g > 0.0\n",
    "        \"\"\".format(pen_id, min_akpd_score, start_date, end_date)\n",
    "\n",
    "        print('Executing query...')\n",
    "        print(query)\n",
    "        self.df = self.rds_access_utils.extract_from_database(query)\n",
    "        print('Query complete!')\n",
    "        self.df = self.df.loc[:, ~self.df.columns.duplicated()]\n",
    "        self.df.rename(columns={'estimated_weight_g': 'estimated_weight_g_0'}, inplace=True)\n",
    "\n",
    "\n",
    "    def preprocess_df(self):\n",
    "        self.df.index = list(range(self.df.shape[0]))\n",
    "        self.df = self.df.sort_values('captured_at').copy(deep=True)\n",
    "        self.df.index = pd.to_datetime(self.df.captured_at)\n",
    "        dates = self.df.index.date.astype(str)\n",
    "        self.df['date'] = dates\n",
    "        self.df['estimated_k_factor'] = 1e5 * self.df['estimated_weight_g_0'] / (self.df['estimated_length_mm']**3)\n",
    "        self.df['hour'] = self.df.index.hour\n",
    "\n",
    "\n",
    "    # generate default data-frame to use on start-up\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    \n",
    "def generate_pme(df, start_date, end_date, start_hour, end_hour, low_kf, high_kf):\n",
    "    date_mask = (df.date >= start_date) & (df.date <= end_date)\n",
    "    if start_hour < end_hour:\n",
    "        hour_mask = (df.hour >= start_hour) & (df.hour <= end_hour)\n",
    "    else:\n",
    "        hour_mask = (df.hour >= start_hour) | (df.hour <= end_hour)\n",
    "    kf_mask = (df.estimated_k_factor >= low_kf) & (df.estimated_k_factor <= high_kf)\n",
    "    \n",
    "    mask = date_mask & hour_mask & kf_mask & (df.akpd_score > 0.99)\n",
    "    biomass_computations = list(zip(df[mask].date.values,\n",
    "                                    df.loc[mask, 'estimated_weight_g_0'].values,\n",
    "                                    df[mask].estimated_k_factor.values))\n",
    "    if biomass_computations:\n",
    "        return PopulationMetricsEstimator(biomass_computations)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPI = log (sample size * dist_consistency^20) / np.log(500 * 0.9^20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_analysis_df(df, pen_id, start_date, end_date):\n",
    "    \n",
    "\n",
    "\n",
    "    start_hours = np.arange(0, 24, 1)\n",
    "    end_hours = np.arange(0, 24, 1)\n",
    "    low_kfs = np.arange(0.9, 1.3, 0.01)\n",
    "\n",
    "    analysis_data = defaultdict(list)\n",
    "    dates = get_dates_in_range(start_date, end_date)\n",
    "    for start_hour in start_hours:\n",
    "        print(start_hour)\n",
    "        for end_hour in end_hours:\n",
    "            for low_kf in low_kfs:\n",
    "                if start_hour >= end_hour:\n",
    "                    continue\n",
    "                pme = generate_pme(df, start_date, end_date, start_hour, end_hour, low_kf)\n",
    "                if not pme:\n",
    "                    continue\n",
    "                kpis, dcs, smart_avgs = [], [], []\n",
    "                for date in dates:\n",
    "                    metrics = pme.generate_smart_metrics_on_date(date)\n",
    "                    if metrics.get('raw_sample_size') and metrics.get('distribution_consistency'):\n",
    "                        kpi = np.log(metrics.get('raw_sample_size') * metrics.get('distribution_consistency')**20) / np.log(500 * 0.9**20)\n",
    "                        kpis.append(kpi)\n",
    "                        dcs.append(metrics.get('distribution_consistency'))\n",
    "                    if date == dates[-1]:\n",
    "                        smart_avgs.append(metrics['smart_average_weight'])\n",
    "\n",
    "                # compute mean kpi\n",
    "                mean_kpi = np.mean(kpis)\n",
    "                mean_dc = np.mean(dcs)\n",
    "\n",
    "                # add to data\n",
    "                analysis_data['mean_kpi'].append(mean_kpi)\n",
    "                analysis_data['mean_dc'].append(mean_dc)\n",
    "                analysis_data['smart_avg'].append(smart_avgs[-1])\n",
    "                analysis_data['start_hour'].append(start_hour)\n",
    "                analysis_data['end_hour'].append(end_hour)\n",
    "                analysis_data['low_kf'].append(low_kf)\n",
    "\n",
    "\n",
    "    analysis_df = pd.DataFrame(analysis_data)\n",
    "    return analysis_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id, start_date, end_date = 88, '2020-02-25', '2020-03-06'\n",
    "dg = DataGenerator()\n",
    "dg.query_from_db(pen_id, start_date=start_date, end_date=end_date)\n",
    "dg.preprocess_df()\n",
    "df = dg.get_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hours = np.arange(0, 24, 1)\n",
    "end_hours = np.arange(0, 24, 1)\n",
    "# start_hours = [0]\n",
    "# end_hours = [24]\n",
    "low_kfs = np.arange(0.8, 1.5, 0.05)\n",
    "high_kfs = [3.0]\n",
    "\n",
    "analysis_data = defaultdict(list)\n",
    "dates = get_dates_in_range(start_date, end_date)\n",
    "for start_hour in start_hours:\n",
    "    print(start_hour)\n",
    "    for end_hour in end_hours:\n",
    "        for low_kf in low_kfs:\n",
    "            for high_kf in high_kfs:\n",
    "                if start_hour >= end_hour:\n",
    "                    continue\n",
    "                pme = generate_pme(df, start_date, end_date, start_hour, end_hour, low_kf, high_kf)\n",
    "                if not pme:\n",
    "                    continue\n",
    "                kpis, dcs, smart_avgs, smart_kfs, raw_sample_sizes = [], [], [], [], []\n",
    "                for date in dates:\n",
    "                    metrics = pme.generate_smart_metrics_on_date(date)\n",
    "                    if metrics.get('raw_sample_size') and metrics.get('distribution_consistency'):\n",
    "                        kpi = np.log(metrics.get('raw_sample_size') * metrics.get('distribution_consistency')**20) / np.log(500 * 0.9**20)\n",
    "                        kpis.append(kpi)\n",
    "                        dcs.append(metrics.get('distribution_consistency'))\n",
    "                        raw_sample_sizes.append(metrics.get('raw_sample_size'))\n",
    "                    if date == dates[-1]:\n",
    "                        smart_avgs.append(metrics['smart_average_weight'])\n",
    "                        smart_kfs.append(np.mean(metrics['kfs']))\n",
    "\n",
    "\n",
    "                # compute mean kpi\n",
    "                mean_kpi = np.mean(kpis)\n",
    "                mean_dc = np.mean(dcs)\n",
    "                total_sample_size = np.sum(raw_sample_sizes)\n",
    "\n",
    "                # add to data\n",
    "                analysis_data['mean_kpi'].append(mean_kpi)\n",
    "                analysis_data['mean_dc'].append(mean_dc)\n",
    "                analysis_data['smart_avg'].append(smart_avgs[-1])\n",
    "                analysis_data['smart_kf'].append(smart_kfs[-1])\n",
    "                analysis_data['total_sample_size'].append(total_sample_size)\n",
    "                analysis_data['start_hour'].append(start_hour)\n",
    "                analysis_data['end_hour'].append(end_hour)\n",
    "                analysis_data['low_kf'].append(low_kf)\n",
    "                analysis_data['high_kf'].append(high_kf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pme = generate_pme(df, '2020-06-11', '2020-06-22', 0, 24, 1.065, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pme.generate_smart_metrics_on_date('2020-06-21', max_day_difference=3, apply_growth_rate=True, incorporate_future=True, bucket_size=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist = {}\n",
    "kf_breakdown = {}\n",
    "count = 0\n",
    "for k in list(metrics['smart_distribution'].keys()):\n",
    "    key = '{}-{}'.format(str(k), str(float(k)+1))\n",
    "    w_dist[key] = metrics['smart_distribution'][k]['count']\n",
    "    kf_breakdown[key] = metrics['smart_distribution'][k]['avgKFactor']\n",
    "    count += metrics['smart_distribution'][k]['count']\n",
    "w_dist = {k: 100 * float(v) / count for k, v in w_dist.items()}\n",
    "w_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(metrics['kfs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "analysis_df.sort_values('mean_kpi', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(analysis_df.low_kf == analysis_df.low_kf.min())].sort_values('mean_kpi', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(analysis_df.start_hour == 0) & (analysis_df.end_hour == 23) & (analysis_df.low_kf == analysis_df.low_kf.min())].sort_values('mean_kpi', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.sort_values('mean_kpi', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "axes[0].plot(analysis_df.low_kf, analysis_df.mean_kpi)\n",
    "axes[0].set_xlabel('K-factor cutoff')\n",
    "axes[0].set_ylabel('Biomass KPI')\n",
    "axes[1].plot(analysis_df.low_kf, analysis_df.smart_avg)\n",
    "axes[2].plot(analysis_df.low_kf, analysis_df.total_sample_size)\n",
    "[ax.grid() for ax in axes]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = generate_analysis_df(88, '2020-02-26', '2020-03-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(2, 1, figsize=(15, 15))\n",
    "axes[0].plot(analysis_df.low_kf, analysis_df.mean_dc)\n",
    "axes[1].plot(analysis_df.low_kf, analysis_df.smart_avg)\n",
    "[ax.grid() for ax in axes]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = generate_analysis_df(66, '2020-06-05', '2020-06-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(2, 1, figsize=(15, 15))\n",
    "axes[0].plot(analysis_df.low_kf, analysis_df.mean_kpi)\n",
    "axes[1].plot(analysis_df.low_kf, analysis_df.smart_avg)\n",
    "[ax.grid() for ax in axes]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = generate_analysis_df(83, '2020-05-25', '2020-06-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(2, 1, figsize=(15, 15))\n",
    "axes[0].plot(analysis_df.low_kf, analysis_df.mean_kpi)\n",
    "axes[1].plot(analysis_df.low_kf, analysis_df.smart_avg)\n",
    "[ax.grid() for ax in axes]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/data/alok/biomass_estimation/playground/imr_pen_id_61_2019-11-15_2019-12-15_20200520_model_keras_reduced_jitter.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(np.log(1 - df.akpd_score))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.akpd_score > 0.99, '20200520_model_keras_reduced_jitter_estimated_weight_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/data/alok/biomass_estimation/playground/pen_66_2020-06-05_2020-06-12_0_1759_nn_epoch_798.csv')\n",
    "# df = pd.read_csv('/root/data/alok/biomass_estimation/playground/pen_88_2020-02-28_2020-03-06_combined_nn_epoch_798.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99)].shape, df[(df.post_refinement_akpd_score > 0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99) | (df.post_refinement_akpd_score > 0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score > 0.99)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99)].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score >= 0.9) & (df.post_refinement_akpd_score >= 0.99)].nn_epoch_798_estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.post_refinement_akpd_score >= 0.99].estimated_weight_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "original_weights = df[df.akpd_score > 0.99].estimated_weight_g.values\n",
    "original_weight = np.mean(original_weights)\n",
    "\n",
    "adj_set = df[(df.post_refinement_akpd_score >= 0.99)].nn_epoch_798_estimated_weight_g.values\n",
    "non_adj_set = df[(df.akpd_score >= 0.99) & (df.post_refinement_akpd_score < 0.99)].estimated_weight_g.values\n",
    "new_weights = np.array(list(adj_set) + list(non_adj_set))\n",
    "print(len(new_weights))\n",
    "new_weight = np.mean(new_weights)\n",
    "\n",
    "print('Average weight without AKPR: {}'.format(original_weight))\n",
    "print('Average weight with AKPR: {}'.format(new_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(original_weights, bins=5, color='blue', alpha=0.7)\n",
    "plt.hist(new_weights, bins=5, color='red', alpha=0.7)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_hist, new_hist = {}, {}\n",
    "bin_labels, original_freqs, new_freqs = [], [], []\n",
    "bin_edges = np.arange(0, 10000, 1000)\n",
    "for idx in range(len(bin_edges) - 1):\n",
    "    low_edge, high_edge = bin_edges[idx], bin_edges[idx + 1]\n",
    "    bin_label = '{}-{}'.format(low_edge, high_edge)\n",
    "    \n",
    "    original_mask = (original_weights >= low_edge) & (original_weights < high_edge)\n",
    "    original_count = np.sum(original_mask)\n",
    "    \n",
    "    new_mask = (new_weights >= low_edge) & (new_weights < high_edge)\n",
    "    new_count = np.sum(new_mask)\n",
    "    \n",
    "    bin_labels.append(bin_label)\n",
    "    original_freqs.append(original_count)\n",
    "    new_freqs.append(new_count)\n",
    "    \n",
    "original_freqs = np.array(original_freqs) / np.sum(original_freqs)\n",
    "new_freqs = np.array(new_freqs) / np.sum(new_freqs)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.bar(list(range(len(bin_labels))), original_freqs, tick_label=bin_labels, alpha=0.5, color='blue', label='without AKPR')\n",
    "ax.bar(list(range(len(bin_labels))), new_freqs, tick_label=bin_labels, alpha=0.5, color='red', label='with AKPR')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.weight_estimation.keypoint_utils.keypoint_transformations import get_raw_3d_coordinates\n",
    "\n",
    "pre_depths = []\n",
    "post_depths = []\n",
    "for idx, row in df.iterrows():\n",
    "    pre_ann = json.loads(row.annotation.replace(\"'\", '\"'))\n",
    "    post_ann = json.loads(row.post_refinement_akpd.replace(\"'\", '\"'))\n",
    "    cm = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "    \n",
    "    pre_kp_arr = get_raw_3d_coordinates(pre_ann, cm)\n",
    "    pre_depth = np.median(pre_kp_arr[:, 1])\n",
    "    \n",
    "    post_kp_arr = get_raw_3d_coordinates(post_ann, cm)\n",
    "    post_depth = np.median(post_kp_arr[:, 1])\n",
    "    \n",
    "    pre_depths.append(pre_depth)\n",
    "    post_depths.append(post_depth)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score < 0.99)].pre_depth, bins=20, color='blue', alpha=0.8)\n",
    "plt.hist(df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score > 0.99)].pre_depth, bins=20, color='red', alpha=0.8)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_depth'] = pre_depths\n",
    "df['post_depth'] = post_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.akpd_score > 0.99].pre_depth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score < 0.99)].pre_depth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score > 0.99)].pre_depth.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score < 0.99)].pre_depth, bins=20, color='blue', alpha=0.8)\n",
    "plt.hist(df[(df.akpd_score > 0.99) & (df.post_refinement_akpd_score > 0.99)].pre_depth, bins=20, color='red', alpha=0.8)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.image_utils import Picture\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "\n",
    "image_url = 'https://aquabyte-frames-resized-inbound.s3-eu-west-1.amazonaws.com/environment=production/site-id=59/pen-id=95/date=2020-06-25/hour=10/at=2020-06-25T10:48:55.901597000Z/left_frame.resize_512_512.jpg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = Picture(s3_access_utils=S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS']))), image_url=image_url)\n",
    "picture.enhance()\n",
    "picture.get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture.get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'https://aquabyte-frames-resized-inbound.s3-eu-west-1.amazonaws.com/environment=production/site-id=59/pen-id=95/date=2020-06-25/hour=10/at=2020-06-25T10:56:38.558207000Z/left_frame.resize_512_512.jpg'\n",
    "\n",
    "picture = Picture(s3_access_utils=S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS']))), image_url=image_url)\n",
    "picture.get_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture.enhance()\n",
    "picture.get_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
