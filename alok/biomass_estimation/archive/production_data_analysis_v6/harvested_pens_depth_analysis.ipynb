{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "from research.utils.datetime_utils import add_days, day_difference\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values, ValidationError\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = [\n",
    "    'seglberget_pen_id_66_2020-05-13_2020-06-13',\n",
    "    'bolaks_pen_id_88_2020-02-28_2020-03-10',\n",
    "    'langoy_pen_id_108_2020-05-07_2020-05-17',\n",
    "    'tittelsnes_pen_id_37_2020-06-10_2020-06-24',\n",
    "    'aplavika_pen_id_95_2020-07-10_2020-07-26',\n",
    "    'kjeppevikholmen_pen_id_5_2019-06-18_2019-07-02',\n",
    "    'silda_pen_id_86_2020-07-02_2020-07-19',\n",
    "    'vikane_pen_id_60_2020-08-10_2020-08-30',\n",
    "    'eldviktaren_pen_id_164_2020-09-21_2020-10-08',\n",
    "    'habranden_pen_id_100_2020-08-10_2020-08-31',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'dale_pen_id_143_2020-10-07_2020-10-21',\n",
    "    'djubawik_pen_id_153_2020-11-10_2020-11-26',\n",
    "    'leivsethamran_pen_id_165_2020-10-18_2020-11-13',\n",
    "    'movikodden_pen_id_114_2020-11-03_2020-11-25',\n",
    "    'movikodden_pen_id_167_2020-10-13_2020-10-30',\n",
    "    'slapoya_pen_id_116_2020-10-18_2020-11-08',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'varholmen_pen_id_151_2020-10-02_2020-10-17',\n",
    "    'varholmen_pen_id_186_2020-10-18_2020-11-02'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_date_hour_columns(df):\n",
    "    df.index = pd.to_datetime(df.captured_at)\n",
    "    df['date'] = df.index.date\n",
    "    df['hour'] = df.index.hour\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'test'\n",
    "\n",
    "ROOT_DIR = '/root/data/alok/biomass_estimation/playground'\n",
    "dfs, gt_metadatas = {}, {}\n",
    "for cohort_name in cohort_names:\n",
    "    print(cohort_name)\n",
    "    s3_dir = os.path.join(\n",
    "        'https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets',\n",
    "        cohort_name\n",
    "    )\n",
    "\n",
    "    ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata.json')\n",
    "    ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata.json')\n",
    "    ground_truth_f = os.path.join(ROOT_DIR, ground_truth_key_base)\n",
    "    s3.download_from_url(ground_truth_metadata_url, custom_location=ground_truth_f)\n",
    "    gt_metadata = json.load(open(ground_truth_f))\n",
    "    gt_metadatas[cohort_name] = gt_metadata\n",
    "    \n",
    "    data_url = os.path.join(s3_dir, 'annotation_dataset.csv')\n",
    "    data_f, _, _= s3.download_from_url(data_url)\n",
    "    df = pd.read_csv(data_f)\n",
    "    df = _add_date_hour_columns(df)\n",
    "    dfs[cohort_name] = df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Conduct depth analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_estimation.utils import get_left_right_keypoint_arrs, convert_to_world_point_arr, CameraMetadata\n",
    "\n",
    "for cohort_name, df in dfs.items():\n",
    "    print(cohort_name)\n",
    "    depths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, camera_metadata = json.loads(row.annotation.replace(\"'\", '\"')), json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        X = convert_to_world_point_arr(*get_left_right_keypoint_arrs(ann), cm)\n",
    "        median_depth = np.median(X[:, 1])\n",
    "        depths.append(median_depth)\n",
    "\n",
    "    df['depth'] = depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 15))\n",
    "idx = 0\n",
    "for cohort_name, df in dfs.items():\n",
    "    row, col = idx // 5, idx % 5\n",
    "    axes[row][col].hist(df[df.akpd_score > 0.9].depth.values, bins=20)\n",
    "    axes[row][col].grid()\n",
    "    axes[row][col].set_title(cohort_name)\n",
    "    idx += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(30, 25))\n",
    "idx = 0\n",
    "\n",
    "working_distances = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "depth_of_field = 0.4\n",
    "\n",
    "for cohort_name, df in dfs.items():\n",
    "    print(cohort_name)\n",
    "    dates = sorted(df.date.unique())\n",
    "    akpd_mask = df.akpd_score > 0.9\n",
    "    \n",
    "    mean_sample_sizes, tenth_pct_sample_sizes = [], []\n",
    "    for working_distance in working_distances:\n",
    "        depth_range_mask = (df.depth >= working_distance - 0.5*depth_of_field) & (df.depth <= working_distance + 0.5*depth_of_field)\n",
    "        sample_sizes = []\n",
    "        for date in dates:\n",
    "            date_mask = df.date == date\n",
    "            sample_size = df[date_mask & depth_range_mask & akpd_mask].shape[0]\n",
    "            sample_sizes.append(sample_size)\n",
    "        \n",
    "        mean_sample_size = np.mean(sample_sizes)\n",
    "        tenth_pct_sample_size = np.percentile(sample_sizes, 10)\n",
    "        mean_sample_sizes.append(mean_sample_size)\n",
    "        tenth_pct_sample_sizes.append(tenth_pct_sample_size)\n",
    "            \n",
    "    row, col = idx // 5, idx % 5\n",
    "    axes[row][col].plot(working_distances, mean_sample_sizes, color='blue')\n",
    "    axes[row][col].grid()\n",
    "    axes[row][col].set_title('{};{};{}'.format('_'.join(cohort_name.split('_')[:4]), \n",
    "                                               round(df[akpd_mask].estimated_weight_g.mean()), \n",
    "                                               round(df[akpd_mask].estimated_weight_g.resample('D').agg(lambda x: x.shape[0]).mean())))\n",
    "    axes[row][col].set_xlabel('Working Distance (m)')\n",
    "    axes[row][col].set_ylabel('Samples in Active Depth Range')\n",
    "    idx += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Simulation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def length_from_weight(weight):\n",
    "    return (weight**(1/3.0)) / 2.36068 * random.gauss(1.0, 0.05)\n",
    "\n",
    "class Fish:\n",
    "    \n",
    "    def __init__(self, weight_mean, weight_cov, speed_factor_mean, speed_factor_std, \n",
    "                 min_depth, max_depth, max_y_coordinate=3.0):\n",
    "        self.weight = max(random.gauss(weight_mean, weight_mean * weight_cov), 0.1)\n",
    "        self.length = length_from_weight(self.weight)\n",
    "        self.height = 0.3 * self.length\n",
    "        self.depth = random.uniform(min_depth, max_depth)\n",
    "        self.speed = self.length * max(0.3, random.gauss(speed_factor_mean, speed_factor_std))\n",
    "        self.is_sampled = False\n",
    "        self.position = [-10, self.depth, random.uniform(-max_y_coordinate, max_y_coordinate)]\n",
    "        \n",
    "    def update_position(self, delta_t):\n",
    "        delta_x = self.speed * delta_t\n",
    "        self.position[0] += delta_x\n",
    "        \n",
    "    def get_position(self):\n",
    "        return self.position\n",
    "        \n",
    "        \n",
    "class Camera:\n",
    "    \n",
    "    def __init__(self, position, fov_degrees, aspect_ratio=0.75):\n",
    "        self.position = position\n",
    "        self.fov = fov_degrees * np.pi / 180.0\n",
    "        self.vfov = 2 * np.arctan(np.tan(self.fov / 2) * aspect_ratio)\n",
    "        self.pixel_width = 1000\n",
    "        self.pixel_height = int(self.pixel_width * aspect_ratio)\n",
    "        self.focal_length_pixel = (self.pixel_width / 2) / np.tan(self.fov / 2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def gen_p_capture(depth, a=1.0, b=2.5, default_p=1.0):\n",
    "        if depth < a:\n",
    "            return default_p\n",
    "        else:\n",
    "            return max(default_p * (b - depth) / (b - a), 0)\n",
    "        \n",
    "    def contains(self, fish):\n",
    "        fish_position = fish.get_position()\n",
    "        fish_segment_at_depth = (fish_position[0] - fish.length / 2.0, fish_position[0] + fish.length / 2.0)\n",
    "        field_size = 2 * fish_position[1] * np.tan(self.fov / 2.0)\n",
    "        field_center = self.position[0]\n",
    "        field_segment_at_depth = (field_center - field_size / 2.0, field_center + field_size / 2.0)\n",
    "        inside_horizontal_field = (fish_segment_at_depth[0] > field_segment_at_depth[0]) and \\\n",
    "            (fish_segment_at_depth[1] < field_segment_at_depth[1])\n",
    "        \n",
    "        vertical_fish_segment_at_depth = (fish_position[2] - fish.height / 2.0, fish_position[2] + fish.height / 2.0)\n",
    "        vertical_field_segment_at_depth = (-fish_position[1] * np.tan(self.vfov / 2.0), fish_position[1] * np.tan(self.vfov / 2.0))\n",
    "        inside_vertical_field = (vertical_fish_segment_at_depth[0] > vertical_field_segment_at_depth[0]) and \\\n",
    "            (vertical_fish_segment_at_depth[1] < vertical_field_segment_at_depth[1])\n",
    "        \n",
    "        if inside_horizontal_field and inside_vertical_field:\n",
    "            return random.random() < self.gen_p_capture(fish_position[1])\n",
    "        return False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "sm = cm.ScalarMappable(cmap=cm.get_cmap('Reds'), norm=Normalize(vmin=0.3, vmax=3.0))\n",
    "\n",
    "def spawn_fish(fishes, avg_weight):\n",
    "    fish = Fish(avg_weight, 0.2, 0.7, 0.15, 0.3, 3.0)\n",
    "    fishes.append(fish)\n",
    "    \n",
    "    \n",
    "def move_fish(t, t_new, fishes):\n",
    "    delta_t = t_new - t\n",
    "    for fish in fishes:\n",
    "        fish.update_position(delta_t)\n",
    "        \n",
    "    fishes = [fish for fish in fishes if fish.get_position()[0] < 10.0]\n",
    "    return fishes\n",
    "    \n",
    "\n",
    "def check_if_fully_visible(fish, left_camera, right_camera):\n",
    "    return left_camera.contains(fish) and right_camera.contains(fish)\n",
    "    \n",
    "    \n",
    "def trigger_capture(fishes, sampled_fishes, left_camera, right_camera, remove_dups=True):\n",
    "    for fish in fishes:\n",
    "        is_visible = check_if_fully_visible(fish, left_camera, right_camera)\n",
    "        if is_visible:\n",
    "            fish.is_sampled = True\n",
    "            sampled_fishes.append(fish)\n",
    "            \n",
    "    if remove_dups:\n",
    "        fishes = [fish for fish in fishes if fish.is_sampled == False]\n",
    "    return fishes\n",
    "            \n",
    "    \n",
    "\n",
    "def get_pixel_bbox(fish, camera):\n",
    "    x_pixel = fish.position[0] * camera.focal_length_pixel / fish.position[1] + camera.pixel_width / 2.0\n",
    "    y_pixel = -(fish.position[2] * camera.focal_length_pixel / fish.position[1]) + camera.pixel_height / 2.0\n",
    "    length_pixel = fish.length * camera.focal_length_pixel / fish.position[1]\n",
    "    height_pixel = fish.height * camera.focal_length_pixel / fish.position[1]\n",
    "    bbox = [x_pixel-length_pixel/2.0, y_pixel-height_pixel/2.0, x_pixel+length_pixel/2.0, y_pixel+height_pixel/2.0]\n",
    "    return [int(x) for x in bbox]\n",
    "    \n",
    "    \n",
    "def draw_frame(fishes, left_camera, right_camera):\n",
    "    im = Image.new('RGB', (left_camera.pixel_width, left_camera.pixel_height))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    for fish in reversed(sorted(fishes, key=lambda x: x.depth)):\n",
    "        bbox = get_pixel_bbox(fish, left_camera)\n",
    "        color = sm.to_rgba(fish.depth, bytes=True)\n",
    "        draw.ellipse(tuple(bbox), fill=color[:3])\n",
    "    return np.array(im)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(FOV, FPS, avg_weight, aspect_ratio=0.75, reduction_factor=1.0):\n",
    "    fishes = []\n",
    "    sampled_fishes = []\n",
    "    left_camera = Camera((0, 0, 0), FOV, aspect_ratio=aspect_ratio)\n",
    "    right_camera = Camera((0.105, 0, 0), FOV, aspect_ratio=aspect_ratio)\n",
    "\n",
    "    capture_times = list(np.arange(0, 100000, 1.0 / FPS))\n",
    "    fish_spawn_times = list(np.cumsum(np.random.exponential(0.5, int(100000 * reduction_factor))))\n",
    "\n",
    "    t = 0\n",
    "    while len(capture_times) > 0 and len(fish_spawn_times) > 0:\n",
    "        event_type = np.argmin([capture_times[0], fish_spawn_times[0]])\n",
    "        if event_type == 0:\n",
    "            t_new = capture_times[0]\n",
    "            fishes = move_fish(t, t_new, fishes)\n",
    "            fishes = trigger_capture(fishes, sampled_fishes, left_camera, right_camera, remove_dups=True)\n",
    "            t = t_new\n",
    "            del capture_times[0]\n",
    "        elif event_type == 1:\n",
    "            t_new = fish_spawn_times[0]\n",
    "            fishes = move_fish(t, t_new, fishes)\n",
    "            spawn_fish(fishes, avg_weight)\n",
    "            t = t_new\n",
    "            del fish_spawn_times[0]\n",
    "\n",
    "        if len(capture_times) % 100000 == 0:\n",
    "            print(len(capture_times))\n",
    "\n",
    "    return sampled_fishes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Camera((0, 0, 0), 80, aspect_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_fishes_comparison_dict = defaultdict(dict)\n",
    "\n",
    "for cohort_name, df in dfs.items():\n",
    "    print(cohort_name)\n",
    "    \n",
    "    akpd_mask = df.akpd_score > 0.9\n",
    "    avg_weight = df[akpd_mask].estimated_weight_g.mean() * 1e-3\n",
    "    daily_sample_size = df[akpd_mask].estimated_weight_g.resample('D').agg(lambda x: x.shape[0]).mean()\n",
    "    \n",
    "    sampled_fishes = generate_samples(54, 0.6, avg_weight)\n",
    "    print('Sampled fishes generated!')\n",
    "    reduction_factor = float(daily_sample_size) / len(sampled_fishes)\n",
    "    \n",
    "    adjusted_sampled_fishes = generate_samples(54, 0.6, avg_weight, reduction_factor=reduction_factor)\n",
    "    print('Adjusted samples generated!')\n",
    "    adjusted_sampled_fishes_new = generate_samples(80, 8.0, avg_weight, reduction_factor=reduction_factor)\n",
    "    print('New adjusted samples generated!')\n",
    "    \n",
    "    sampled_fishes_comparison_dict[cohort_name]['sampled_fishes'] = adjusted_sampled_fishes\n",
    "    sampled_fishes_comparison_dict[cohort_name]['new_sampled_fishes'] = adjusted_sampled_fishes_new\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * np.arctan(np.tan(80 * np.pi/180 / 2) * 0.75) * 180.0/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * np.arctan(np.tan(self.fov / 2) * aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishes = sampled_fishes_comparison_dict['djubawik_pen_id_153_2020-11-10_2020-11-26']['sampled_fishes']\n",
    "fishes_2 = sampled_fishes_comparison_dict['djubawik_pen_id_153_2020-11-10_2020-11-26']['new_sampled_fishes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_distances = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "depth_of_field = 0.4\n",
    "s1s, s2s = [], []\n",
    "\n",
    "for working_distance in working_distances:\n",
    "    lo, hi = working_distance - 0.5*depth_of_field, working_distance + 0.5*depth_of_field\n",
    "    s1 = len([f for f in fishes if f.depth > lo and f.depth < hi])\n",
    "    s2 = len([f for f in fishes_2 if f.depth > lo and f.depth < hi])\n",
    "    \n",
    "    s1s.append(s1)\n",
    "    s2s.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y / x if x > 0 else None for x, y in zip(s1s, s2s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_projection_factor_dict(sampled_fishes_comparison_dict['djubawik_pen_id_153_2020-11-10_2020-11-26'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rad(degrees):\n",
    "    return degrees * np.pi / 180.0\n",
    "\n",
    "def calculate_focal_length(fov, sensor_width=0.01412):\n",
    "    focal_length = (0.5 * sensor_width) / np.arctan(convert_to_rad(fov) / 2.0)\n",
    "    return focal_length\n",
    "    \n",
    "def get_depth_of_field(fov, working_distance, f_number=2.8, base_circle_of_confusion=0.0000107*3):\n",
    "    focal_length = calculate_focal_length(fov)\n",
    "    circle_of_confusion = base_circle_of_confusion * np.tan(convert_to_rad(54) / 2.0) / np.tan(convert_to_rad(fov) / 2.0)\n",
    "    dof = 2 * working_distance**2 * f_number * circle_of_confusion / (focal_length**2)\n",
    "    return dof\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_depth_of_field(80, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_factor_dict(sampled_fishes_comparison):\n",
    "    \n",
    "    sampled_fishes = sampled_fishes_comparison['sampled_fishes']\n",
    "    sampled_fishes_new = sampled_fishes_comparison['new_sampled_fishes']\n",
    "    working_distances = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "    depth_of_field = 0.4\n",
    "    projection_factor_dict = {}\n",
    "\n",
    "    for working_distance in working_distances:\n",
    "        lo, hi = working_distance - 0.5*depth_of_field, working_distance + 0.5*depth_of_field\n",
    "        s1 = len([f for f in fishes if f.depth > lo and f.depth < hi])\n",
    "        s2 = len([f for f in fishes_2 if f.depth > lo and f.depth < hi])\n",
    "        projection_factor = s2 / s1 if s1 > 0 else 1.0\n",
    "        projection_factor_dict[working_distance] = projection_factor\n",
    "    \n",
    "    return projection_factor_dict\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projected_sample_size(sampled_fishes_comparison, working_distance):\n",
    "    sampled_fishes = sampled_fishes_comparison['new_sampled_fishes']\n",
    "    depth_of_field = 0.4\n",
    "    lo, hi = working_distance - 0.5*depth_of_field, working_distance + 0.5*depth_of_field\n",
    "    s = len([f for f in sampled_fishes if f.depth > lo and f.depth < hi])\n",
    "    return s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(30, 25))\n",
    "idx = 0\n",
    "\n",
    "working_distances = [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "depth_of_field = 0.4\n",
    "\n",
    "for cohort_name, df in dfs.items():\n",
    "    print(cohort_name)\n",
    "    dates = sorted(df.date.unique())\n",
    "    akpd_mask = df.akpd_score > 0.9\n",
    "    \n",
    "#     projection_factor_dict = get_projection_factor_dict(sampled_fishes_comparison_dict[cohort_name])\n",
    "    \n",
    "    mean_sample_sizes, tenth_pct_sample_sizes = [], []\n",
    "    projected_mean_sample_sizes, projected_tenth_pct_sample_sizes = [], []\n",
    "    for working_distance in working_distances:\n",
    "        \n",
    "        projected_sample_size = get_projected_sample_size(sampled_fishes_comparison_dict[cohort_name], working_distance)\n",
    "        \n",
    "        depth_of_field = get_depth_of_field(80, working_distance)\n",
    "        depth_range_mask = (df.depth >= working_distance - 0.5*depth_of_field) & (df.depth <= working_distance + 0.5*depth_of_field)\n",
    "        sample_sizes, projected_sample_sizes = [], []\n",
    "        for date in dates:\n",
    "            date_mask = df.date == date\n",
    "            sample_size = df[date_mask & depth_range_mask & akpd_mask].shape[0]\n",
    "            sample_sizes.append(sample_size)\n",
    "            projected_sample_sizes.append(projected_sample_size)\n",
    "        \n",
    "        mean_sample_size = np.mean(sample_sizes)\n",
    "        tenth_pct_sample_size = np.percentile(sample_sizes, 20)\n",
    "        projected_mean_sample_size = np.mean(projected_sample_sizes)\n",
    "        projected_tenth_pct_sample_size = np.percentile(projected_sample_sizes, 20)\n",
    "        \n",
    "        mean_sample_sizes.append(mean_sample_size)\n",
    "        tenth_pct_sample_sizes.append(tenth_pct_sample_size)\n",
    "        projected_mean_sample_sizes.append(projected_mean_sample_size)\n",
    "        projected_tenth_pct_sample_sizes.append(projected_tenth_pct_sample_size)\n",
    "            \n",
    "    row, col = idx // 5, idx % 5\n",
    "    axes[row][col].plot(working_distances, projected_tenth_pct_sample_sizes, color='blue')\n",
    "    axes[row][col].axhline(500, color='red', linestyle='--', label='KPI requirement')\n",
    "    axes[row][col].grid()\n",
    "    axes[row][col].set_title('{}: {}'.format('_'.join(cohort_name.split('_')[:4]), \n",
    "                                               round(df[akpd_mask].estimated_weight_g.mean())))\n",
    "    axes[row][col].set_xlabel('Working Distance (m)')\n",
    "    axes[row][col].set_ylabel('Samples in Active Depth Range')\n",
    "    axes[row][col].legend()\n",
    "    idx += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampled_fishes_comparison_dict['seglberget_pen_id_66_2020-05-13_2020-06-13']['sampled_fishes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampled_fishes_comparison_dict['seglberget_pen_id_66_2020-05-13_2020-06-13']['new_sampled_fishes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 15))\n",
    "idx = 0\n",
    "for cohort_name, df in dfs.items():\n",
    "    row, col = idx // 5, idx % 5\n",
    "    depths = [f.depth for f in sampled_fishes_comparison_dict[cohort_name]['sampled_fishes']]\n",
    "    axes[row][col].hist(depths, bins=20)\n",
    "    axes[row][col].grid()\n",
    "    axes[row][col].set_title(cohort_name)\n",
    "    idx += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 15))\n",
    "idx = 0\n",
    "for cohort_name, df in dfs.items():\n",
    "    row, col = idx // 5, idx % 5\n",
    "    \n",
    "    depths = [f.depth for f in sampled_fishes_comparison_dict[cohort_name]['sampled_fishes']]\n",
    "    axes[row][col].hist(df[df.akpd_score > 0.9].depth.values, bins=20, density=True, alpha=0.5)\n",
    "    axes[row][col].hist(depths, bins=20, density=True, alpha=0.5)\n",
    "    axes[row][col].grid()\n",
    "    axes[row][col].set_title(cohort_name)\n",
    "    idx += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.arctan((np.tan(80*0.5 * np.pi / 180)**2 + ((3000.0 / 4096) * np.tan(80*0.5 * np.pi / 180))**2)**.5) * 180.0/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfs.keys())[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = list(dfs.values())[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.depth > 0.5) & (tdf.depth < 1.0)\n",
    "tdf[mask].akpd_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.depth > 1.0) & (tdf.depth < 1.5)\n",
    "tdf[mask].akpd_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.depth > 1.5) & (tdf.depth < 2.0)\n",
    "tdf[mask].akpd_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
