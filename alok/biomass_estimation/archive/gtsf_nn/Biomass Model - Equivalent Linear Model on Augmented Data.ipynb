{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aquabyte.accuracy_metrics import AccuracyMetricsGenerator\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from research.fish_metadata a left join keypoint_annotations b\n",
    "    on a.left_url = b.left_image_url \n",
    "    where b.keypoints is not null\n",
    "    and (b.is_qa = false or b.captured_at > '2019-09-19');\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_keypoint_annotation_ids = [\n",
    "    606484, \n",
    "    635806, \n",
    "    637801, \n",
    "    508773, \n",
    "    640493, \n",
    "    639409, \n",
    "    648536, \n",
    "    507003,\n",
    "    706002,\n",
    "    507000,\n",
    "    709298,\n",
    "    714073,\n",
    "    719239\n",
    "]\n",
    "\n",
    "df = df[~df.id.isin(blacklisted_keypoint_annotation_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Apend world keypoints to this data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = sorted([\n",
    "    'TAIL_NOTCH',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE',\n",
    "    'UPPER_PRECAUDAL_PIT', \n",
    "    'LOWER_PRECAUDAL_PIT',\n",
    "    'HYPURAL_PLATE'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_behaved(wkps, cutoff_depth=10.0):\n",
    "    if any([abs(wkp[1]) > cutoff_depth for wkp in wkps.values()]):\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def flip_center_kps(left_kps, right_kps):\n",
    "    \n",
    "    x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "    x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "    x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "    \n",
    "    y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "    y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "    y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "    \n",
    "    x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "    x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "    x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "    \n",
    "    y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "    y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "    y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "        \n",
    "    fc_left_kps, fc_right_kps = {}, {}\n",
    "    flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "    for bp in BODY_PARTS:\n",
    "        left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "        if flip_factor > 0:\n",
    "            fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "            fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "        else:\n",
    "            fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "            fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "        fc_left_kps[bp] = fc_left_kp\n",
    "        fc_right_kps[bp] = fc_right_kp\n",
    "        \n",
    "    return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "def _rotate_cc(p, theta):\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "    \n",
    "    rotated_kp = np.dot(R, p)\n",
    "    return rotated_kp\n",
    "\n",
    "\n",
    "def rotate_kps(left_kps, right_kps):\n",
    "    upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    r_left_kps, r_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        rotated_kp = _rotate_cc(left_kps[bp], -theta)\n",
    "        r_left_kps[bp] = rotated_kp\n",
    "        disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "        r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "        \n",
    "    return r_left_kps, r_right_kps\n",
    "\n",
    "\n",
    "def translate_kps(left_kps, right_kps, factor):\n",
    "    t_left_kps, t_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "        t_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "        t_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "    \n",
    "    return t_left_kps, t_right_kps\n",
    "\n",
    "\n",
    "def jitter_kps(left_kps, right_kps, jitter):\n",
    "    j_left_kps, j_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                   left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "        j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                    right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "    \n",
    "    return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "\n",
    "def modify_kps(left_kps, right_kps, factor, jitter, cm):\n",
    "    fc_left_kps, fc_right_kps = flip_center_kps(left_kps, right_kps)\n",
    "    r_left_kps, r_right_kps = rotate_kps(fc_left_kps, fc_right_kps)\n",
    "    t_left_kps, t_right_kps = translate_kps(r_left_kps, r_right_kps, factor)\n",
    "    j_left_kps, j_right_kps  = jitter_kps(t_left_kps, t_right_kps, jitter)\n",
    "    j_left_kps_list, j_right_kps_list = [], []\n",
    "    for bp in BODY_PARTS:\n",
    "        l_item = {\n",
    "            'keypointType': bp,\n",
    "            'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "            'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "        }\n",
    "        \n",
    "        r_item = {\n",
    "            'keypointType': bp,\n",
    "            'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "            'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "        }\n",
    "        \n",
    "        j_left_kps_list.append(l_item)\n",
    "        j_right_kps_list.append(r_item)\n",
    "        \n",
    "    modified_kps = {\n",
    "        'leftCrop': j_left_kps_list,\n",
    "        'rightCrop': j_right_kps_list\n",
    "    }\n",
    "    \n",
    "    return modified_kps\n",
    "\n",
    "\n",
    "def process_df(df, n_factors=1, jitters=[0, 10, 20], low=0.3, high=2, oos=False, network=None):\n",
    "    features_data = defaultdict(list)\n",
    "    \n",
    "    row_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        keypoints = row.keypoints\n",
    "        left_keypoints_list = keypoints.get('leftCrop')\n",
    "        right_keypoints_list = keypoints.get('rightCrop')\n",
    "        cm = row.camera_metadata\n",
    "        if left_keypoints_list and right_keypoints_list:\n",
    "            wkps = pixel2world(left_keypoints_list, right_keypoints_list, cm)\n",
    "            left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "            right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "            if well_behaved(wkps):\n",
    "                for n in range(n_factors):\n",
    "                    factor = 1.0 if n_factors == 1 else np.random.uniform(low=low, high=high)\n",
    "                    for jitter in jitters:\n",
    "                        trials = 3 if jitter > 0 else 1\n",
    "                        for t in range(trials):\n",
    "                            modified_kps = modify_kps(left_kps, right_kps, factor, jitter, cm)\n",
    "                            modified_wkps = pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)\n",
    "\n",
    "                            for i in range(len(BODY_PARTS)-1):\n",
    "                                for j in range(i+1, len(BODY_PARTS)):\n",
    "                                    d = euclidean_distance(modified_wkps[BODY_PARTS[i]], \n",
    "                                                           modified_wkps[BODY_PARTS[j]])\n",
    "                                    features_data['{0}-{1}'.format(i, j)].append(d)\n",
    "                            \n",
    "                            features_data['weight'].append(row.weight)\n",
    "                            features_data['captured_at'].append(row.captured_at)\n",
    "                            features_data['gtsf_fish_identifier'].append(row.fish_id)\n",
    "                            features_data['keypoint_annotation_id'].append(row.id)\n",
    "                            features_data['world_keypoints'].append(modified_wkps)\n",
    "        if row_count % 1000 == 0:\n",
    "            print('Percentage complete: {}'.format(row_count / df.shape[0]))\n",
    "        row_count += 1\n",
    "                            \n",
    "    \n",
    "    return features_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data = process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all features\n",
    "\n",
    "body_parts_subset = sorted([\n",
    "    'HYPURAL_PLATE',\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'UPPER_LIP',\n",
    "    'EYE'\n",
    "])\n",
    "\n",
    "body_part_indices = [BODY_PARTS.index(bp) for bp in body_parts_subset]\n",
    "\n",
    "pairwise_distance_columns = ['{0}-{1}'.format(x, y) for x, y in list(combinations(body_part_indices, 2))]\n",
    "interaction_columns_quadratic = []\n",
    "interaction_columns_cubic = []\n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        col1 = pairwise_distance_columns[i]\n",
    "        col2 = pairwise_distance_columns[j]\n",
    "        interaction_column = '{},{}'.format(col1, col2)\n",
    "        features_df[interaction_column] = features_df[col1] * features_df[col2]\n",
    "        interaction_columns_quadratic.append(interaction_column)\n",
    "        \n",
    "for i in range(len(pairwise_distance_columns)):\n",
    "    for j in range(i, len(pairwise_distance_columns)):\n",
    "        for k in range(j, len(pairwise_distance_columns)):\n",
    "            col1 = pairwise_distance_columns[i]\n",
    "            col2 = pairwise_distance_columns[j]\n",
    "            col3 = pairwise_distance_columns[k]\n",
    "            interaction_column = '{},{},{}'.format(col1, col2, col3)\n",
    "            features_df[interaction_column] = features_df[col1] * features_df[col2] * features_df[col3]\n",
    "            interaction_columns_cubic.append(interaction_column)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Linear Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "i = 0\n",
    "for idx, row in features_df.iterrows():\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "    count = features_df[features_df.gtsf_fish_identifier == row.gtsf_fish_identifier].shape[0]\n",
    "    if count > 1:\n",
    "        weights.append(1.0 / count ** 0.5)\n",
    "#         weights.append(1.0 / count)\n",
    "    else:\n",
    "        weights.append(1)\n",
    "        \n",
    "features_df['w'] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_mask(df, train_frac, randomize=True):\n",
    "    x = np.zeros((df.shape[0]), dtype=bool)\n",
    "    x[:int(train_frac * df.shape[0])] = True\n",
    "    np.random.shuffle(x)\n",
    "    mask = pd.Series(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def generate_oos_score(features_df, mask, train_size, num_eigenvectors):\n",
    "    np.random.seed(0)\n",
    "    columns = pairwise_distance_columns + interaction_columns_quadratic + interaction_columns_cubic\n",
    "\n",
    "    X_train = features_df.loc[mask, columns].values\n",
    "    y_train = features_df.loc[mask, 'weight'].values\n",
    "    w_train = features_df.loc[mask, 'w'].values\n",
    "    X_test = features_df.loc[~mask, columns].values\n",
    "    y_test = features_df.loc[~mask, 'weight'].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_normalized = scaler.transform(X_train)\n",
    "\n",
    "    pca = PCA(n_components=min(X_train_normalized.shape[0], X_train_normalized.shape[1]))\n",
    "    pca.fit(X_train_normalized)\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
    "    idx = num_eigenvectors\n",
    "\n",
    "    pca = PCA(n_components=idx+1)\n",
    "    pca.fit(X_train_normalized)\n",
    "    X_train_transformed = pca.transform(X_train_normalized)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    X_test_transformed = pca.transform(X_test_normalized)\n",
    "\n",
    "    reg = LinearRegression().fit(X_train_transformed, y_train, sample_weight=w_train)\n",
    "    score = reg.score(X_test_transformed, y_test)\n",
    "\n",
    "    y_pred = reg.predict(pca.transform(scaler.transform(features_df[columns].values)))\n",
    "    features_df['prediction'] = y_pred\n",
    "    features_df['error'] = features_df.prediction - features_df.weight\n",
    "    features_df['error_pct'] = features_df.error / features_df.weight\n",
    "    features_df['abs_error_pct'] = features_df.error_pct.abs()\n",
    "\n",
    "    model = {\n",
    "    'mean': scaler.mean_,\n",
    "    'std': scaler.scale_,\n",
    "    'PCA_components': pca.components_,\n",
    "    'reg_coef': reg.coef_,\n",
    "    'reg_intercept': reg.intercept_,\n",
    "    'body_parts': body_parts_subset   \n",
    "    }\n",
    "    \n",
    "\n",
    "    return mask, model, score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num eigenvectors = 20\n",
    "\n",
    "train_size = 2000\n",
    "gtsf_fish_identifiers = list(features_df.gtsf_fish_identifier.unique())\n",
    "fish_ids = random.sample(gtsf_fish_identifiers, train_size)\n",
    "date_mask = (features_df.captured_at < '2019-09-01') \n",
    "mask = date_mask & features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "mask, model, score = generate_oos_score(features_df, mask, 2000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "amg = AccuracyMetricsGenerator()\n",
    "test_mask = date_mask & ~features_df.gtsf_fish_identifier.isin(fish_ids)\n",
    "amg.set_data(mask, features_df.prediction.values, features_df.weight.values, w=features_df.w.values, test_mask=test_mask)\n",
    "amg.plot_predictions_vs_ground_truth(impose_bounds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.display_train_test_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "amg = AccuracyMetricsGenerator()\n",
    "test_mask = ~date_mask\n",
    "amg.set_data(mask, features_df.prediction.values, features_df.weight.values, w=features_df.w.values, test_mask=test_mask)\n",
    "amg.plot_predictions_vs_ground_truth(impose_bounds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amg.display_train_test_accuracy_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mask = features_df.captured_at < '2019-09-10'\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sc = ax.scatter(features_df[~mask].weight.values, features_df[~mask].prediction.values, c=features_df[~mask].depth.values)\n",
    "plt.colorbar(sc)\n",
    "plt.plot([0, 5e3], [0, 5e3], color='red')\n",
    "plt.xlim([0, 5e3])\n",
    "plt.ylim([0, 2e4])\n",
    "plt.xlabel('Ground truth weight (grams)')\n",
    "plt.ylabel('Predicted weight (grams)')\n",
    "plt.title('Prediction vs. Ground Truth: fish far away from camera, Linear PCA')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
