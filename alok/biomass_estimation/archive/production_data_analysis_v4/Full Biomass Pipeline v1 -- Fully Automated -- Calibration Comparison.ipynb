{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.akpd_scorer import generate_confidence_score\n",
    "from keras.models import load_model\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKPD(object):\n",
    "\n",
    "    def __init__(self, aws_credentials):\n",
    "        self.client = boto3.client(\n",
    "            \"sagemaker-runtime\", \n",
    "            region_name=\"eu-west-1\", \n",
    "            aws_access_key_id=aws_credentials['aws_access_key_id'], \n",
    "            aws_secret_access_key=aws_credentials['aws_secret_access_key']\n",
    "        \n",
    "        )\n",
    "\n",
    "    def predict_keypoints(self, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, camera_metadata):\n",
    "        body = [{\n",
    "            'leftCropUrl': left_crop_url,\n",
    "            'rightCropUrl': right_crop_url,\n",
    "            'leftCropMetadata': left_crop_metadata,\n",
    "            'rightCropMetadata': right_crop_metadata,\n",
    "            'cameraMetadata': camera_metadata,\n",
    "            'id': 1\n",
    "        }]\n",
    "\n",
    "        body_str = json.dumps(body).replace(\"'\", '\"')\n",
    "\n",
    "        resp = self.client.invoke_endpoint(EndpointName='auto-keypoints', ContentType='application/json', Body=body_str)\n",
    "        akpd_keypoints_str = resp['Body'].read()\n",
    "        akpd_keypoints = json.loads(akpd_keypoints_str.decode(\"utf-8\"))\n",
    "        return akpd_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate first DF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM\n",
    "    prod.crop_annotation cas\n",
    "    INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "    WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "    AND cas.annotation is not null\n",
    "    AND cas.pen_id=61\n",
    "    AND cas.group_id='staging-b2-orig-61'\n",
    "    AND cas.captured_at between '2019-09-13' and '2019-09-21';\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "aws_credentials = json.load(open(os.environ['AWS_CREDENTIALS']))\n",
    "akpd = AKPD(aws_credentials)\n",
    "\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n",
    "akpd_scorer_network = load_model('/root/data/alok/biomass_estimation/playground/akpd_scorer_model_TF.h5') # make this better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Function to generate weight prediction and confidence score </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, akpd_keypoints, cm):\n",
    "    \n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "\n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    akpd_weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    \n",
    "    return akpd_score, akpd_weight_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_score_dict = {}\n",
    "\n",
    "args = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata,\n",
    "    cm = row.camera_metadata\n",
    "    akpd_keypoints = row.annotation\n",
    "    row_id = idx\n",
    "    akpd_score, akpd_weight_prediction = generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, akpd_keypoints, cm)\n",
    "    weight_score_dict[row_id] = {\n",
    "        'akpd_score': akpd_score,\n",
    "        'akpd_weight_prediction': akpd_weight_prediction,\n",
    "    }\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['akpd_weight'], df['akpd_score'] = np.nan, np.nan\n",
    "for idx, row in df.iterrows():\n",
    "    if idx in weight_score_dict.keys():\n",
    "        df.at[idx, 'akpd_weight'] = weight_score_dict[idx]['akpd_weight_prediction']\n",
    "        df.at[idx, 'akpd_score'] = weight_score_dict[idx]['akpd_score']\n",
    "\n",
    "df.index = pd.to_datetime(df.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.akpd_score > 0.9].akpd_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Second DF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    SELECT * FROM\n",
    "    prod.crop_annotation cas\n",
    "    INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "    WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "    AND cas.annotation is not null\n",
    "    AND cas.pen_id=61\n",
    "    AND cas.group_id='staging-61'\n",
    "    AND cas.captured_at between '2019-09-13' and '2019-09-21';\n",
    "\"\"\"\n",
    "\n",
    "df2 = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_score_dict = {}\n",
    "\n",
    "args = []\n",
    "count = 0\n",
    "for idx, row in df2.iterrows():\n",
    "    left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata,\n",
    "    cm = row.camera_metadata\n",
    "    akpd_keypoints = row.annotation\n",
    "    row_id = idx\n",
    "    akpd_score, akpd_weight_prediction = generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, akpd_keypoints, cm)\n",
    "    weight_score_dict[row_id] = {\n",
    "        'akpd_score': akpd_score,\n",
    "        'akpd_weight_prediction': akpd_weight_prediction,\n",
    "    }\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.captured_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.akpd_score > 0.9].akpd_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3045-3070)/3070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['akpd_weight'], df2['akpd_score'] = np.nan, np.nan\n",
    "for idx, row in df2.iterrows():\n",
    "    if idx in weight_score_dict.keys():\n",
    "        df2.at[idx, 'akpd_weight'] = weight_score_dict[idx]['akpd_weight_prediction']\n",
    "        df2.at[idx, 'akpd_score'] = weight_score_dict[idx]['akpd_score']\n",
    "\n",
    "df2.index = pd.to_datetime(df2.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.annotation and 'rightCrop' in row.annotation:\n",
    "        return pixel2world(row.annotation['leftCrop'], row.annotation['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df2['world_keypoints'] = df2.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "df['dist'] = df.world_keypoints.apply(lambda x: euclidean_distance(x['ANAL_FIN'], x['EYE']))\n",
    "df2['dist'] = df2.world_keypoints.apply(lambda x: euclidean_distance(x['ANAL_FIN'], x['EYE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, keypoints, weights2, keypoints2 = [], [], [], []\n",
    "dists, dists2 = [], []\n",
    "for idx, row in df.iterrows():\n",
    "    url = row.left_crop_url\n",
    "    f_name = os.path.basename(url)\n",
    "    search_url = url.replace('s3-eu-west-1.amazonaws.com/aquabyte-crops/environment=production', \n",
    "                             'aquabyte-crops.s3.eu-west-1.amazonaws.com/environment=staging')\n",
    "    if df2.left_crop_url.str.contains(f_name).any() and row.akpd_score > 0.9:\n",
    "        row2 = df2[df2.left_crop_url.str.contains(f_name)]\n",
    "        score2 = row2.akpd_score.iloc[0]\n",
    "        if score2 > 0.9:\n",
    "            weight2 = row2.akpd_weight.iloc[0]\n",
    "            weights.append(row.akpd_weight)\n",
    "            weights2.append(weight2)\n",
    "            keypoints.append(row.annotation)\n",
    "            keypoints2.append(row2.annotation.iloc[0])\n",
    "            dists.append(row.dist)\n",
    "            dists2.append(row2.dist.iloc[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(dists) - np.array(dists2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(np.array(dists) - np.array(dists2))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in np.array(dists) - np.array(dists2)][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df[(df.akpd_weight > 2302.56) & (df.akpd_weight < 2302.57)]\n",
    "x2 = df2[(df2.akpd_weight > 2683.95) & (df2.akpd_weight < 2683.96)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.right_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYE TRIANGULATION\n",
    "kps_left = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x1.annotation.iloc[0]['leftCrop']}\n",
    "kps_right = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x1.annotation.iloc[0]['rightCrop']}\n",
    "bp = 'EYE'\n",
    "\n",
    "x_left = kps_left[bp][0]\n",
    "y_left = kps_left[bp][1]\n",
    "x_right = kps_right[bp][0]\n",
    "y_right = kps_right[bp][1]\n",
    "x_left_frame = x_left + x1.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x1.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x1.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x1.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x1.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_a = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_a)\n",
    "\n",
    "# ANAL FIN TRIANGULATION\n",
    "\n",
    "bp = 'ANAL_FIN'\n",
    "\n",
    "x_left = kps_left[bp][0]\n",
    "y_left = kps_left[bp][1]\n",
    "x_right = kps_right[bp][0]\n",
    "y_right = kps_right[bp][1]\n",
    "x_left_frame = x_left + x1.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x1.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x1.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x1.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x1.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_b = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_b)\n",
    "\n",
    "print(euclidean_distance(world_coordinates_a, world_coordinates_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYE TRIANGULATION\n",
    "kps_left = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x2.annotation.iloc[0]['leftCrop']}\n",
    "kps_right = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x2.annotation.iloc[0]['rightCrop']}\n",
    "bp = 'EYE'\n",
    "\n",
    "x_left = kps_left[bp][0]\n",
    "y_left = kps_left[bp][1]\n",
    "x_right = kps_right[bp][0]\n",
    "y_right = kps_right[bp][1]\n",
    "x_left_frame = x_left + x2.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x2.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x2.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x2.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x2.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_a = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_a)\n",
    "\n",
    "# ANAL FIN TRIANGULATION\n",
    "\n",
    "bp = 'ANAL_FIN'\n",
    "\n",
    "x_left = kps_left[bp][0]\n",
    "y_left = kps_left[bp][1]\n",
    "x_right = kps_right[bp][0]\n",
    "y_right = kps_right[bp][1]\n",
    "x_left_frame = x_left + x2.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x2.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x2.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x2.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x2.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_b = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_b)\n",
    "\n",
    "print(euclidean_distance(world_coordinates_a, world_coordinates_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.right_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYE TRIANGULATION\n",
    "kps_left = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x1.annotation.iloc[0]['leftCrop']}\n",
    "kps_right = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x1.annotation.iloc[0]['rightCrop']}\n",
    "bp = 'EYE'\n",
    "\n",
    "x_left = 1707\n",
    "y_left = 190\n",
    "x_right = 1710\n",
    "y_right = 196\n",
    "x_left_frame = x_left + x1.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x1.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x1.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x1.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "print(disp)\n",
    "cm = x1.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_a = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_a)\n",
    "\n",
    "# ANAL FIN TRIANGULATION\n",
    "\n",
    "bp = 'ANAL_FIN'\n",
    "\n",
    "x_left = 677\n",
    "y_left = 494\n",
    "x_right = 669\n",
    "y_right = 502\n",
    "x_left_frame = x_left + x1.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x1.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x1.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x1.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x1.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_b = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_b)\n",
    "\n",
    "print(euclidean_distance(world_coordinates_a, world_coordinates_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYE TRIANGULATION\n",
    "kps_left = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x2.annotation.iloc[0]['leftCrop']}\n",
    "kps_right = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in x2.annotation.iloc[0]['rightCrop']}\n",
    "bp = 'EYE'\n",
    "\n",
    "x_left = 1691\n",
    "y_left = 192\n",
    "x_right = 1697\n",
    "y_right = 194\n",
    "x_left_frame = x_left + x2.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x2.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x2.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x2.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "print(disp)\n",
    "cm = x2.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_a = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_a)\n",
    "\n",
    "# ANAL FIN TRIANGULATION\n",
    "\n",
    "bp = 'ANAL_FIN'\n",
    "\n",
    "x_left = 674\n",
    "y_left = 490\n",
    "x_right = 664\n",
    "y_right = 499\n",
    "x_left_frame = x_left + x2.left_crop_metadata.iloc[0]['x_coord']\n",
    "y_left_frame = y_left + x2.left_crop_metadata.iloc[0]['y_coord']\n",
    "x_right_frame = x_right + x2.right_crop_metadata.iloc[0]['x_coord']\n",
    "y_right_frame = y_right + x2.right_crop_metadata.iloc[0]['y_coord']\n",
    "disp = abs(x_right_frame - x_left_frame)\n",
    "cm = x2.camera_metadata.iloc[0]\n",
    "depth = depth_from_disp(disp, cm)\n",
    "world_coordinates_b = convert_to_world_point(x_left_frame, y_left_frame, depth, cm)\n",
    "print(world_coordinates_b)\n",
    "\n",
    "print(euclidean_distance(world_coordinates_a, world_coordinates_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part = 'UPPER_LIP'\n",
    "d_diffs = []\n",
    "for kps, kps2 in zip(keypoints, keypoints2):\n",
    "    left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in kps['leftCrop']}\n",
    "    right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in kps['rightCrop']}\n",
    "    left_kps2 = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in kps2['leftCrop']}\n",
    "    right_kps2 = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in kps2['rightCrop']}\n",
    "    d = left_kps[body_part][0] - right_kps[body_part][0]\n",
    "    d2 = left_kps2[body_part][0] - right_kps2[body_part][0]\n",
    "    d_diffs.append(d - d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
