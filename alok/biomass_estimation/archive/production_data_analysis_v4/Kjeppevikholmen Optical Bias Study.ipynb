{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Kjeppevikholmen Optical Sampling Bias Study </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from aquabyte.visualize import Visualizer\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "import pytz\n",
    "from PIL import Image\n",
    "import datetime as dt\n",
    "import dateutil\n",
    "from urllib.parse import urlparse\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Manager, Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Optical Sampling Bias Study </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Simulate FOVs of all sizes, and for each one get the average crop width / crop height / crop area. For FOVs smaller than the current one, get the average bimoass as well </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where pen_id=5\n",
    "    and is_qa=FALSE\n",
    "    and captured_at between '2019-06-26' and '2019-06-30';\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = '2019-06-26', '2019-06-27'\n",
    "s3_path_components = urlparse(df.left_image_url.iloc[0]).path.lstrip('/').split('/')\n",
    "bucket, key = s3_path_components[0], os.path.join(*s3_path_components[1:])\n",
    "inbound_bucket = 'aquabyte-frames-resized-inbound'\n",
    "s3_folder = key[:key.index(start_date) + len(start_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = s3_access_utils.get_matching_s3_keys(inbound_bucket, s3_folder, suffixes=['capture.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for key in generator:\n",
    "    if len(keys) % 1000 == 0:\n",
    "        print(len(keys))\n",
    "    keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key_dirs = sorted(list(set([os.path.dirname(f) for f in keys])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_s3_key_dir(s3_key_dir):\n",
    "    global shared_list\n",
    "    crop_metadata_f = s3_access_utils.download_from_s3(inbound_bucket, os.path.join(s3_key_dir, 'crops.json'))\n",
    "    crop_metadata = json.load(open(crop_metadata_f))\n",
    "    for ann in crop_metadata['annotations']:\n",
    "        bbox = ann['bbox']\n",
    "        x_lower, y_lower, x_upper, y_upper = bbox[1], bbox[0], bbox[3], bbox[2]\n",
    "        x_lower = round(max(x_lower * (4096 / 512) - 50, 0))\n",
    "        y_lower = round(max(y_lower * (3000 / 512) - 50, 0))\n",
    "        x_upper = round(min(x_upper * (4096 / 512) + 50, 4096))\n",
    "        y_upper = round(min(y_upper * (3000 / 512) + 50, 3000))\n",
    "        shared_list.append([x_lower, y_lower, x_upper, y_upper])\n",
    "        \n",
    "    if len(shared_list) % 100 == 0:\n",
    "        print(len(shared_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "shared_list = manager.list()\n",
    "pool = Pool(20)\n",
    "pool.map(process_s3_key_dir, s3_key_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fov_cutoffs(fov, cm):\n",
    "    fov = fov * np.pi / 180.0\n",
    "    field_size_px = 2*cm['focalLengthPixel'] * np.tan(fov / 2.0)\n",
    "    min_cutoff = (cm['pixelCountWidth'] - field_size_px) / 2.0\n",
    "    max_cutoff = (cm['pixelCountWidth'] + field_size_px) / 2.0\n",
    "    return min_cutoff, max_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = list(np.arange(10, 55, 1))\n",
    "mean_widths = []\n",
    "cm = df.camera_metadata.iloc[0]\n",
    "for fov in fovs:\n",
    "    min_cutoff, max_cutoff = get_fov_cutoffs(fov, cm)\n",
    "    mask = np.where((X[:, 0] > min_cutoff) & (X[:, 2] < max_cutoff))\n",
    "    mean_widths.append((X[mask, 2] - X[mask, 0]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, mean_widths)\n",
    "plt.title('Empirical Optical Sampling Bias')\n",
    "plt.xlabel('Percetange of single camera FOV in stereo overlap region')\n",
    "plt.ylabel('Mean Crop Width')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_HEIGH_PX = 3000\n",
    "pct_coverages = np.arange(0.2, 1, 0.01)\n",
    "mean_heights = []\n",
    "for pct in pct_coverages:\n",
    "    upper_y = round(pct * FULL_HEIGH_PX)\n",
    "    mask = np.where((X[:, 3] < upper_y) & (X[:, 3] - X[:, 1] < 800))\n",
    "    mean_heights.append((X[mask, 3] - X[mask, 1]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(pct_coverages, mean_heights)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Weight Based Optical Sampling Bias Study </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Get weight dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from aquabyte.visualize import Visualizer\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "import pytz\n",
    "from PIL import Image\n",
    "import datetime as dt\n",
    "import dateutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where pen_id=5\n",
    "    and keypoints -> 'leftCrop' is not null\n",
    "    and keypoints -> 'rightCrop' is not null\n",
    "    and captured_at between '2019-06-23' and '2019-06-30'\n",
    "    and is_qa=FALSE;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight(row_id, keypoints, cm):\n",
    "    \n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': row_id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    return weight_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    weight = generate_weight(row.id, row.keypoints, row.camera_metadata)\n",
    "    weights.append(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'] = weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fov_cutoffs(fov, cm):\n",
    "    fov = fov * np.pi / 180.0\n",
    "    field_size_px = 2*cm['focalLengthPixel'] * np.tan(fov / 2.0)\n",
    "    min_cutoff = (cm['pixelCountWidth'] - field_size_px) / 2.0\n",
    "    max_cutoff = (cm['pixelCountWidth'] + field_size_px) / 2.0\n",
    "    return min_cutoff, max_cutoff\n",
    "\n",
    "def is_preserved(keypoints, min_cutoff, max_cutoff):\n",
    "    min_x_left = min([item['xFrame'] for item in keypoints['leftCrop']])\n",
    "    max_x_left = max([item['xFrame'] for item in keypoints['leftCrop']])\n",
    "    min_x_right = min([item['xFrame'] for item in keypoints['rightCrop']])\n",
    "    max_x_right = max([item['xFrame'] for item in keypoints['rightCrop']])\n",
    "    \n",
    "    if (min_x_left < min_cutoff) or (min_x_right < min_cutoff) or (max_x_left > max_cutoff) or (max_x_right > max_cutoff):\n",
    "        return False\n",
    "    return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = list(np.arange(10, 55, 1))\n",
    "for fov in fovs:\n",
    "    min_cutoff, max_cutoff = get_fov_cutoffs(fov, df.camera_metadata.iloc[0])\n",
    "    is_preserved_list = []\n",
    "    for idx, row in df.iterrows():\n",
    "        keypoints = row.keypoints\n",
    "        is_preserved_list.append(is_preserved(keypoints, min_cutoff, max_cutoff))\n",
    "\n",
    "    df['is_preserved_{}'.format(fov)] = is_preserved_list\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weight_means, sample_sizes = [], []\n",
    "for fov in fovs:\n",
    "    mask = (df['is_preserved_{}'.format(fov)] == True) & (df.centroid_depth > 1.6)\n",
    "    pred_weight_means.append(df[mask].weight.mean())\n",
    "    sample_sizes.append(df[mask].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, pred_weight_means, s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(fovs, (np.array(pred_weight_means) - df.weight.mean()) / df.weight.mean(), s=80)\n",
    "plt.xlabel('Field of View (degrees)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Weight-Based Study (Depth) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_depth(wkps):\n",
    "    if wkps:\n",
    "        return np.median(np.array([wkp[1] for wkp in wkps.values()]))\n",
    "    return None\n",
    "\n",
    "df['centroid_depth'] = df.world_keypoints.apply(lambda x: centroid_depth(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "depths = list(np.arange(0.6, 2.2, 0.1))\n",
    "est_weights = []\n",
    "for i in range(len(depths[:-1])):\n",
    "    mask = (df.centroid_depth > depths[i]) & (df.centroid_depth < depths[i+1])\n",
    "    est_weights.append(df[mask].weight.mean())\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "x = np.arange(len(depths[:-1]))\n",
    "plt.bar(x, est_weights)\n",
    "plt.xticks(x, [round(d, 2) for d in depths[:-1]])\n",
    "plt.title('Empirlcal Optical Samling Bias')\n",
    "plt.xlabel('Distance from camera (m)')\n",
    "plt.ylabel('Estimated biomass (g)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df[(df.centroid_depth > 0) & (df.centroid_depth < 3.0) & (df.weight > 7000) & (df.weight < 8000)].centroid_depth, bins=10)\n",
    "plt.title\n",
    "plt.xlabel('Distance from Camera (m)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(20, 20))\n",
    "weights_list = list(np.arange(0, 9000, 1000))\n",
    "for i, weight in enumerate(weights_list[:-1]):\n",
    "    row = int(i / 2)\n",
    "    col = i % 2\n",
    "    mask = (df.weight > weights_list[i]) & (df.weight < weights_list[i+1])\n",
    "    ax = axes[row, col]\n",
    "    ax.hist(df[mask].centroid_depth, bins=10)\n",
    "    ax.set_xlim([0, 2.5])\n",
    "    ax.set_title('Depth distribution for {}g to {}g bucket'.format(weights_list[i], weights_list[i+1]))\n",
    "    ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
