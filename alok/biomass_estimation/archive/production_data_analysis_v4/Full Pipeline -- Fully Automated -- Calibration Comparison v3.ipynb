{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.akpd_scorer import generate_confidence_score\n",
    "from keras.models import load_model\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_access_utils = S3AccessUtils('/root/data')\n",
    "# rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "# df1 = pd.read_csv('/root/data/alok/biomass_estimation/playground/biomass.csv-61-00-from-2019-09-13-to-2019-09-23.csv')\n",
    "# df1.index = pd.to_datetime(df1.captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM\n",
    "    prod.crop_annotation cas\n",
    "    INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "    WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "    AND cas.annotation is not null\n",
    "    AND cas.pen_id=61\n",
    "    AND cas.group_id='staging-61'\n",
    "    AND cas.captured_at between '2019-09-13' and '2019-09-21';\n",
    "\"\"\"\n",
    "\n",
    "df1 = rds_access_utils.extract_from_database(query)\n",
    "aws_credentials = json.load(open(os.environ['AWS_CREDENTIALS']))\n",
    "akpd = AKPD(aws_credentials)\n",
    "\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n",
    "akpd_scorer_network = load_model('/root/data/alok/biomass_estimation/playground/akpd_scorer_model_TF.h5') # make this better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, akpd_keypoints, cm):\n",
    "    \n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "\n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    akpd_weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    \n",
    "    return akpd_score, akpd_weight_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_score_dict = {}\n",
    "\n",
    "args = []\n",
    "count = 0\n",
    "for idx, row in df1.iterrows():\n",
    "    left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata,\n",
    "    cm = row.camera_metadata\n",
    "    akpd_keypoints = row.annotation\n",
    "    row_id = idx\n",
    "    akpd_score, akpd_weight_prediction = generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, akpd_keypoints, cm)\n",
    "    weight_score_dict[row_id] = {\n",
    "        'akpd_score': akpd_score,\n",
    "        'akpd_weight_prediction': akpd_weight_prediction,\n",
    "    }\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, akpd_scores = [], []\n",
    "for idx, row in df1.iterrows():\n",
    "    if idx in weight_score_dict.keys():\n",
    "        weight = weight_score_dict[idx]['akpd_weight_prediction']\n",
    "        weights.append(weight)\n",
    "        akpd_score = weight_score_dict[idx]['akpd_score']\n",
    "        akpd_scores.append(akpd_score)\n",
    "    else:\n",
    "        weights.append(None)\n",
    "        akpd_scores.append(None)\n",
    "\n",
    "df1['weight'] = weights\n",
    "df1['akpd_score'] = akpd_scores\n",
    "df1.index = pd.to_datetime(df1.captured_at)\n",
    "df1['ts'] = df1.captured_at\n",
    "df1 = df1.sort_values('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate Other DF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "df2 = pd.read_csv('/root/data/alok/biomass_estimation/playground/61_sample.biomass_output-CORE-404.1f.csv')\n",
    "df2.index = pd.to_datetime(df2.captured_at)\n",
    "df2['ts'] = df2.captured_at\n",
    "df2 = df2.sort_values('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df1.captured_at < '2019-09-21'\n",
    "df1[mask & (df1.akpd_score > 0.9)].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df2.captured_at < '2019-09-21'\n",
    "df2[mask & (df2.akpd_score > 0.9)].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.left_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1 = df1.copy(deep=True)\n",
    "tdf2 = df2.copy(deep=True)\n",
    "tdf1['adj_left_crop_url'] = tdf1.left_crop_url.apply(lambda x: x.replace('https://aquabyte-crops.s3.eu-west-1.amazonaws.com/environment=staging/', \n",
    "                                                                         'https://s3-eu-west-1.amazonaws.com/aquabyte-crops-test/environment=production/'))\n",
    "common_urls = list(set(tdf1.adj_left_crop_url).intersection(set(tdf2.left_crop_url)))\n",
    "tdf1 = tdf1[tdf1.adj_left_crop_url.isin(common_urls)].copy(deep=True)\n",
    "tdf2 = tdf2[tdf2.left_crop_url.isin(common_urls)].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf1.akpd_score > 0.9) & (tdf2.akpd_score > 0.9)\n",
    "tdf1[mask].weight - tdf2[mask].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tdf1[mask].weight - tdf2[mask].weight, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(tdf2[mask].annotation.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = 'PELVIC_FIN'\n",
    "disps1 = []\n",
    "for idx, row in tdf1[mask].iterrows():\n",
    "    ann = row.annotation\n",
    "    left_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['leftCrop']}\n",
    "    right_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['rightCrop']}\n",
    "    disp = left_kps[bp][0] - right_kps[bp][0]\n",
    "    disps1.append(disp)\n",
    "    \n",
    "disps2 = []\n",
    "for idx, row in tdf2[mask].iterrows():\n",
    "    ann = json.loads(row.annotation)\n",
    "    left_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['leftCrop']}\n",
    "    right_kps = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['rightCrop']}\n",
    "    disp = left_kps[bp][0] - right_kps[bp][0]\n",
    "    disps2.append(disp)\n",
    "    \n",
    "print(np.mean(np.array(disps1) - np.array(disps2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = df1.camera_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = {\n",
    "    'focalLengthPixel': 3995.5062171346935,\n",
    "    'pixelCountWidth': 4096,\n",
    "    'pixelCountHeight': 3000,\n",
    "    'imageSensorWidth': 0.01412,\n",
    "    'imageSensorHeight': 0.01035,\n",
    "    'baseline': 0.10152658650444619,\n",
    "    'focalLength': 3995.5062171346935 * 3.45e-6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp1, bp2 = 'UPPER_LIP', 'EYE'\n",
    "tdf1.loc[mask, 'world_keypoints'] = tdf1[mask].annotation.apply(lambda x: pixel2world(x['leftCrop'], \n",
    "                                                  x['rightCrop'], cm1))\n",
    "\n",
    "tdf1.loc[mask, 'length'] = tdf1[mask].world_keypoints.apply(lambda x: euclidean_distance(x[bp1], x[bp2]))\n",
    "\n",
    "tdf2.loc[mask, 'world_keypoints'] = tdf2[mask].annotation.apply(lambda x: pixel2world(json.loads(x)['leftCrop'], \n",
    "                                                  json.loads(x)['rightCrop'], cm1))\n",
    "tdf2.loc[mask, 'length'] = tdf2[mask].world_keypoints.apply(lambda x: euclidean_distance(x[bp1], x[bp2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tdf1[mask].length - tdf2[mask].length).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(tdf1[mask].length - tdf2[mask].length, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(params_file):\n",
    "    params = json.load(open(params_file))\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "\n",
    "    imageSize = (4096, 3000)\n",
    "    \n",
    "    # perform rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, None, None, None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "    \n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "    \n",
    "    return left_maps, right_maps, cameraMatrix1, distCoeffs1, R1, P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1[mask].camera_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_params_f = '/root/data/alok/biomass_estimation/playground/2020-01-14T00_00_00Z_L40013180_R40029775_stereo-parameters.json'\n",
    "circular_params_f = '/root/data/alok/biomass_estimation/playground/EstimatedStereoCamParams_L40013180_R40029775.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m, right_maps_m, cameraMatrix1_m, distCoeffs1_m, R1_m, P1_m = load_params(matlab_params_f)\n",
    "left_maps_c, right_maps_c, cameraMatrix1_c, distCoeffs1_c, R1_c, P1_c = load_params(circular_params_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.undistortPoints(np.array([[left_maps_m[0][923, 294]]]).astype(float), cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = left_maps[0][923, 294] - right_maps[0][923, 294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf2.loc[mask, 'left_crop_metadata_m'] = tdf1[mask].left_crop_metadata\n",
    "tdf2.loc[mask, 'right_crop_metadata_m'] = tdf1[mask].right_crop_metadata\n",
    "new_anns = []\n",
    "for idx, row in tdf2[mask].iterrows():\n",
    "    captured_at = row.captured_at\n",
    "    left_crop_metadata = row.left_crop_metadata_m\n",
    "    right_crop_metadata = row.right_crop_metadata_m\n",
    "    crop_x_coords = {'leftCrop': left_crop_metadata['x_coord'], 'rightCrop': right_crop_metadata['x_coord']}\n",
    "    crop_y_coords = {'leftCrop': left_crop_metadata['y_coord'], 'rightCrop': right_crop_metadata['y_coord']}\n",
    "    \n",
    "    ann = json.loads(row.annotation)\n",
    "    new_ann = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann[side]:\n",
    "            bp = item['keypointType']\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            maps = left_maps_c if side == 'leftCrop' else right_maps_c\n",
    "            x_new, y_new = cv2.undistortPoints(np.array([[maps[0][y, x]]]).astype(float), \n",
    "                                cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "            new_ann[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new,\n",
    "                'xCrop': x_new - crop_x_coords[side],\n",
    "                'yCrop': y_new - crop_y_coords[side]\n",
    "            })\n",
    "    new_anns.append(new_ann)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp1, bp2 = 'UPPER_LIP', 'PELVIC_FIN'\n",
    "tdf1.loc[mask, 'world_keypoints'] = tdf1[mask].annotation.apply(lambda x: pixel2world(x['leftCrop'], \n",
    "                                                  x['rightCrop'], cm1))\n",
    "\n",
    "tdf1.loc[mask, 'length'] = tdf1[mask].world_keypoints.apply(lambda x: euclidean_distance(x[bp1], x[bp2]))\n",
    "\n",
    "tdf2.loc[mask, 'world_keypoints'] = tdf2[mask].annotation.apply(lambda x: pixel2world(json.loads(x)['leftCrop'], \n",
    "                                                  json.loads(x)['rightCrop'], cm1))\n",
    "tdf2.loc[mask, 'length'] = tdf2[mask].world_keypoints.apply(lambda x: euclidean_distance(x[bp1], x[bp2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_world_keypoints = [pixel2world(x['leftCrop'], x['rightCrop'], cm1) for x in new_anns]\n",
    "tdf2.loc[mask, 'new_length'] = [euclidean_distance(x[bp1], x[bp2]) for x in new_world_keypoints]\n",
    "tdf2.loc[mask, 'new_anns'] = new_anns\n",
    "tdf2.loc[mask, 'new_world_keypoints'] = new_world_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(tdf2[mask].length.values - tdf2[mask].new_length.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get circular + matlab crop urls and annotations\n",
    "ts = tdf2[mask & ((tdf2.length - tdf2.new_length).abs() > 0.02)].captured_at.iloc[0]\n",
    "left_crop_url_c = tdf2[mask & ((tdf2.length - tdf2.new_length).abs() > 0.02)].left_crop_url.iloc[0]\n",
    "right_crop_url_c = tdf2[mask & ((tdf2.length - tdf2.new_length).abs() > 0.02)].right_crop_url.iloc[0]\n",
    "ann_c = json.loads(tdf2[mask & ((tdf2.length - tdf2.new_length).abs() > 0.02)].annotation.iloc[0])\n",
    "\n",
    "left_crop_url_m = tdf1[mask & (tdf1.captured_at == ts)].left_crop_url.iloc[0]\n",
    "right_crop_url_m = tdf1[mask & (tdf1.captured_at == ts)].right_crop_url.iloc[0]\n",
    "ann_m = tdf2[mask & ((tdf2.length - tdf2.new_length).abs() > 0.02)].new_anns.iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_crop_url, right_crop_url, ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image_f, bucket, left_image_key = s3_access_utils.download_from_url(left_crop_url)\n",
    "    right_image_f, _, right_image_key = s3_access_utils.download_from_url(right_crop_url)\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    print(right_image.shape)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    \n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['leftCrop']}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['rightCrop']}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_crops(left_crop_url_c, right_crop_url_c, ann_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_crops(left_crop_url_m, right_crop_url_m, ann_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.left_crop_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.left_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFrame, yFrame = [1794 + 2718 - 2519, 297 + 1903 - 383]\n",
    "print(xFrame, yFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsTemp = np.array([], dtype='float32')\n",
    "rtemp = ttemp = np.array([0,0,0], dtype='float32')\n",
    "ptsOut = cv2.undistortPoints(np.array([yFrame, xFrame]).astype(float), cameraMatrix1_m, distCoeffs1_m)\n",
    "ptsTemp = cv2.convertPointsToHomogeneous( ptsOut );\n",
    "output = cv2.projectPoints( ptsTemp, rtemp, ttemp, cameraMatrix1, distCoeffs1_m, ptsOut );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.iloc[0].base_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0][yFrame, xFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf1.left_crop_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0][xFrame, yFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.undistortPoints(np.array([[1981, 1806]]).astype(float), cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1743 + 238, 286+1520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0][1806, 1981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0][1981, 1806]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM\n",
    "    prod.crop_annotation cas\n",
    "    INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "    WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "    AND cas.annotation is not null\n",
    "    AND cas.pen_id=88\n",
    "    AND cas.captured_at between '2020-02-20' and '2020-02-21';\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "aws_credentials = json.load(open(os.environ['AWS_CREDENTIALS']))\n",
    "akpd = AKPD(aws_credentials)\n",
    "\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n",
    "akpd_scorer_network = load_model('/root/data/alok/biomass_estimation/playground/akpd_scorer_model_TF.h5') # make this better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.left_crop_url.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.camera_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.left_crop_metadata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_params_f = '/root/data/alok/biomass_estimation/playground/2020-02-19T03_42_04.748042000Z_L40039154_R40012648_stereo-parameters.json'\n",
    "left_maps_m, right_maps_m, cameraMatrix1_m, distCoeffs1_m, R1_m, P1_m = load_params(matlab_params_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFrame = 1217 + 1577\n",
    "yFrame = 2024 + 781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_maps_m[0][yFrame, xFrame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1200 + 1604, 764 + 2036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
