{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> In this notebook, we will implement a neural network that regresses volume against segmentation + depth map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/github/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "# from biomass_utils.points_of_interest import get_point_cloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready\n",
    "\n",
    "data_path_base = '/root/data/blender_v3'\n",
    "image_dir = '{}/{}'.format(data_path_base, 'stereo_images')\n",
    "depth_map_dir = '{}/{}'.format(data_path_base, 'depth_map')\n",
    "segmentation_dir = '{}/{}'.format(data_path_base, 'mask')\n",
    "annotation_dir = '{}/{}'.format(data_path_base, 'annotations')\n",
    "\n",
    "number_key = lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "side_key = lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[0]\n",
    "all_image_paths = sorted(glob.glob('{}/*.png'.format(image_dir)), key=number_key)\n",
    "image_paths = [p for p in all_image_paths if side_key(p) == 'left'] # we are working with left frame only\n",
    "all_segmentation_paths = sorted(glob.glob('{}/*.npy'.format(segmentation_dir)), key=number_key)\n",
    "segmentation_paths = [p for p in all_segmentation_paths if side_key(p) == 'left'] # we are working with left frame only\n",
    "depth_map_paths = sorted(glob.glob('{}/*.npy'.format(depth_map_dir)), key=number_key)\n",
    "annotation_paths = sorted(glob.glob('{}/*.json'.format(annotation_dir)), key=number_key) \n",
    "complete_data_list = zip(image_paths, segmentation_paths, depth_map_paths, annotation_paths)\n",
    "\n",
    "\n",
    "TRAINING_SIZE = 500\n",
    "train_data_list = [v for i, v in enumerate(complete_data_list) if i < TRAINING_SIZE]\n",
    "test_data_list = [v for i, v in enumerate(complete_data_list) if i > TRAINING_SIZE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = cm.ScalarMappable(cmap='hot')\n",
    "sm.set_clim(vmin=0, vmax=20)\n",
    "\n",
    "def convert_to_gradient_image(image_array, segmentation_mask, depth_map, annotation):    \n",
    "    projected_depth_map = get_point_cloud(depth_map, annotation['focal_length'], \n",
    "                                          annotation['sensor_height'], \n",
    "                                          annotation['sensor_width'])[:,:,1]\n",
    "    cleaned_depth_map = segmentation_mask * projected_depth_map\n",
    "    rgb_depth_map = sm.to_rgba(cleaned_depth_map, bytes=True)[:,:,:3]\n",
    "    image_array = image_array\n",
    "    image_array = np.dstack([image_array, np.ones((image_array.shape[0], image_array.shape[1], 1))*255]).astype('uint8')\n",
    "    rgb_depth_map = np.dstack([rgb_depth_map, np.ones((rgb_depth_map.shape[0], rgb_depth_map.shape[1], 1))*170]).astype('uint8')\n",
    "    composite_image = Image.alpha_composite(Image.fromarray(image_array), Image.fromarray(rgb_depth_map))\n",
    "    composite_image = composite_image * np.dstack([segmentation_mask, segmentation_mask, segmentation_mask, segmentation_mask])\n",
    "    composite_image = composite_image[:,:,:3]\n",
    "    return Image.fromarray(composite_image).resize((224, 224))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 29\n",
    "a = convert_to_gradient_image(np.array(Image.open(image_paths[idx]))[:,:,:3],\n",
    "                                 np.load(segmentation_paths[idx]),\n",
    "                                 np.load(depth_map_paths[idx]).T, \n",
    "                                 json.load(open(annotation_paths[idx], 'rb')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_list, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, min((i+1)*BATCH_SIZE, len(data_list)))):\n",
    "            image_array = np.array(Image.open(data_list[j][0]))[:,:,:3]\n",
    "            segmentation_mask = np.load(data_list[j][1])\n",
    "            depth_map = np.load(data_list[j][2]).T\n",
    "            annotation = json.load(open(data_list[j][3], 'rb'))\n",
    "            four_channel_input = convert_to_gradient_image(image_array, segmentation_mask, depth_map, annotation)\n",
    "            x_batch[ind, ...] = four_channel_input\n",
    "            y_batch[ind] = annotation['volume']\n",
    "            print(data_list[j])\n",
    "            \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights=None, include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(1, name='predictions')(vgg16.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=vgg16.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "steps_per_epoch = int(len(train_data_list)/BATCH_SIZE)\n",
    "gen = generator(train_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, np.inf, BATCH_SIZE, (224, 224, 3))\n",
    "scores = model.evaluate_generator(eval_gen, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, np.inf, BATCH_SIZE, (224, 224, 3))\n",
    "predictions = model.predict_generator(eval_gen, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values = np.array([])\n",
    "for i in range(120*25):\n",
    "    annotation = json.load(open(test_data_list[i][3], 'rb'))\n",
    "    ground_truth_values = np.append(ground_truth_values, annotation['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ground_truth_values.mean() - predictions[:,0].mean())/(ground_truth_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ground_truth_values, predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile((abs(ground_truth_values - predictions[:,0])/ground_truth_values), 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(open(annotation_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
