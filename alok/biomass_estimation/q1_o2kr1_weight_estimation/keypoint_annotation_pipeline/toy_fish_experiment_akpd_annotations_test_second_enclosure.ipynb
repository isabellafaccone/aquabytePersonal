{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../q1_o2kr2_dataset_annotations/')\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "import uuid\n",
    "from construct_fish_detection_dataset_o2kr2 import establish_plali_connection, insert_into_plali\n",
    "from rectification import rectify\n",
    "from weight_estimation.weight_estimator import WeightEstimator, CameraMetadata\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get raw images from toy fish experiment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'environment=production/site-id=55/pen-id=97/date=2021-02-24/hour=13'\n",
    "suffixes = ['frame.jpg']\n",
    "keygen = s3.get_matching_s3_keys('aquabyte-images-raw', prefix, suffixes=suffixes)\n",
    "keys = []\n",
    "for key in keygen:\n",
    "    keys.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pair_dict = defaultdict(dict)\n",
    "for key in keys:\n",
    "    dirname = os.path.dirname(key)\n",
    "    if 'left' in key:\n",
    "        image_pair_dict[dirname]['left'] = key\n",
    "    elif 'right' in key:\n",
    "        image_pair_dict[dirname]['right'] = key\n",
    "    else:\n",
    "        raise Exception('Key not valid')\n",
    "        \n",
    "image_pairs = []\n",
    "for dirname in sorted(list(image_pair_dict.keys())):\n",
    "    keys = image_pair_dict[dirname]\n",
    "    try:\n",
    "        image_pairs.append((keys['left'], keys['right']))\n",
    "    except KeyError as err:\n",
    "        print(err)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Check frames </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url):\n",
    "    image_s3_url = image_url\n",
    "    url_components = image_s3_url.replace('s3://', '').split('/')\n",
    "    bucket = url_components[0]\n",
    "    key = os.path.join(*url_components[1:])\n",
    "    image_f = s3.download_from_s3(bucket, key)\n",
    "    return image_f\n",
    "\n",
    "\n",
    "def plot_stereo_image(left_image_f, right_image_f):\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    \n",
    "    # show left image\n",
    "    left_im = cv2.imread(left_image_f)\n",
    "    left_im = cv2.cvtColor(left_im, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(left_im)\n",
    "    \n",
    "    # show right image\n",
    "    right_im = cv2.imread(right_image_f)\n",
    "    right_im = cv2.cvtColor(right_im, cv2.COLOR_BGR2RGB)\n",
    "    axes[1].imshow(right_im)\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for left_key, right_key in image_pairs:\n",
    "    print(idx)\n",
    "    idx += 1\n",
    "    \n",
    "    left_full_res_frame_s3_url, right_full_res_frame_s3_url = [os.path.join('s3://', 'aquabyte-images-raw', key) for key in (left_key, right_key)]\n",
    "    left_frame_s3_url, right_frame_s3_url = [x.replace('.jpg', '.resize_512_512.jpg') for x in (left_full_res_frame_s3_url, right_full_res_frame_s3_url)]\n",
    "    \n",
    "    # download left image\n",
    "    left_image_f = download_image(left_frame_s3_url)\n",
    "    right_image_f = download_image(right_frame_s3_url)\n",
    "    \n",
    "    # plot image\n",
    "    plot_stereo_image(left_image_f, right_image_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Rectify raw images and upload to s3 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_s3_url(s3_url):\n",
    "    url_components = s3_url.replace('s3://', '').split('/')\n",
    "    bucket = url_components[0]\n",
    "    key = os.path.join(*url_components[1:])\n",
    "    f = s3.download_from_s3(bucket, key)\n",
    "    return f, bucket, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_rectified_s3_urls, right_image_rectified_s3_urls = [], []\n",
    "stereo_parameters_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40020313_R40013177/2021-02-25T12%3A11%3A24.770071000Z_L40020313_R40013177_stereo-parameters.json'.replace('%3A', ':')\n",
    "count = 0\n",
    "\n",
    "for left_key, right_key in image_pairs:\n",
    "    \n",
    "    # get unrectified full resolution frames\n",
    "    left_full_res_frame_s3_url, right_full_res_frame_s3_url = [os.path.join('s3://', 'aquabyte-images-raw', key) for key in (left_key, right_key)]\n",
    "    left_full_res_frame_f, _, left_full_res_frame_key = download_from_s3_url(left_full_res_frame_s3_url)\n",
    "    right_full_res_frame_f, _, right_full_res_frame_key = download_from_s3_url(right_full_res_frame_s3_url)\n",
    "    stereo_parameters_f, _, _ = s3.download_from_url(stereo_parameters_url)\n",
    "    \n",
    "    # rectify into full resolution stereo frame pair and save to disk\n",
    "    left_image_rectified, right_image_rectified = rectify(left_full_res_frame_f, right_full_res_frame_f, stereo_parameters_f)\n",
    "    left_image_rectified_f = os.path.join(os.path.dirname(left_full_res_frame_f), 'left_frame.rectified.jpg')\n",
    "    right_image_rectified_f = os.path.join(os.path.dirname(right_full_res_frame_f), 'right_frame.rectified.jpg')\n",
    "    cv2.imwrite(left_image_rectified_f, left_image_rectified)\n",
    "    cv2.imwrite(right_image_rectified_f, right_image_rectified)\n",
    "    \n",
    "    # upload rectified stereo frame pairs to s3\n",
    "    left_rectified_full_res_frame_key = left_full_res_frame_key.replace('.jpg', '.rectified.jpg')\n",
    "    right_rectified_full_res_frame_key = right_full_res_frame_key.replace('.jpg', '.rectified.jpg')\n",
    "    s3.s3_client.upload_file(left_image_rectified_f, 'aquabyte-images-raw', left_rectified_full_res_frame_key)\n",
    "    s3.s3_client.upload_file(right_image_rectified_f, 'aquabyte-images-raw', right_rectified_full_res_frame_key)\n",
    "    \n",
    "    # append to url lists\n",
    "    left_image_rectified_s3_url = os.path.join('s3://', 'aquabyte-images-raw', left_rectified_full_res_frame_key)\n",
    "    right_image_rectified_s3_url = os.path.join('s3://', 'aquabyte-images-raw', right_rectified_full_res_frame_key)\n",
    "    left_image_rectified_s3_urls.append(left_image_rectified_s3_url)\n",
    "    right_image_rectified_s3_urls.append(right_image_rectified_s3_url)\n",
    "    \n",
    "    print(count)\n",
    "    count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Insert into PLALI for key-point annotation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_into_plali_records(image_url_pairs, workflow_id):\n",
    "\n",
    "    values_to_insert = []\n",
    "    for idx, image_url_pair in enumerate(image_url_pairs):\n",
    "        id = str(uuid.uuid4())\n",
    "        images = set(image_url_pair)\n",
    "        metadata = {}\n",
    "        priority = float(idx) / len(image_url_pairs)\n",
    "\n",
    "        values = {\n",
    "            'id': id,\n",
    "            'workflow_id': workflow_id,\n",
    "            'images': images,\n",
    "            'metadata': metadata,\n",
    "            'priority': priority\n",
    "        }\n",
    "\n",
    "        values_to_insert.append(values)\n",
    "\n",
    "    return values_to_insert\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_pairs = list(zip(left_image_rectified_s3_urls, right_image_rectified_s3_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_ID = '00000000-0000-0000-0000-000000000056'\n",
    "values_to_insert = process_into_plali_records(image_url_pairs, WORKFLOW_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PLALI_SQL_CREDENTIALS'] = '/run/secrets/plali_sql_credentials.json'\n",
    "engine, sql_metadata = establish_plali_connection()\n",
    "\n",
    "n = 10\n",
    "count = 0\n",
    "for chunk in chunker(values_to_insert, n):\n",
    "    insert_into_plali(chunk, engine, sql_metadata)\n",
    "    \n",
    "    count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.images.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Calculate weights </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Parse annotations into standard form </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PLALI_SQL_CREDENTIALS'] = '/run/secrets/plali_sql_credentials.json'\n",
    "rds = RDSAccessUtils(json.load(open(os.environ['PLALI_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from plali.plali_annotations x\n",
    "    inner join \n",
    "    ( select a.id as plali_image_id, a.images, a.metadata, b.id as workflow_id, b.name from plali.plali_images a\n",
    "    inner join plali.plali_workflows b\n",
    "    on a.workflow_id = b.id ) y\n",
    "    on x.plali_image_id = y.plali_image_id\n",
    "    where workflow_id = '00000000-0000-0000-0000-000000000056';\n",
    "\"\"\"\n",
    "\n",
    "annotated_df = rds.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationFormatError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "anns = []\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    try:\n",
    "        raw_ann = row.annotation\n",
    "        if 'skipReasons' in raw_ann:\n",
    "            raise AnnotationFormatError\n",
    "\n",
    "        ann = {'leftCrop': [], 'rightCrop': []}\n",
    "\n",
    "        for side in ['leftCrop', 'rightCrop']:\n",
    "            for raw_item in row.annotation[side]['annotation']['annotations']:\n",
    "                if 'xCrop' not in raw_item or 'yCrop' not in raw_item:\n",
    "                    raise AnnotationFormatError\n",
    "                item = {\n",
    "                    'xCrop': raw_item['xCrop'],\n",
    "                    'yCrop': raw_item['yCrop'],\n",
    "                    'xFrame': raw_item['xCrop'],\n",
    "                    'yFrame': raw_item['yCrop'],\n",
    "                    'keypointType': raw_item['category']\n",
    "                }\n",
    "                \n",
    "                ann[side].append(item)\n",
    "\n",
    "        if any([len(ann[side]) != 11 for side in ['leftCrop', 'rightCrop']]):\n",
    "            raise AnnotationFormatError\n",
    "        \n",
    "        anns.append(ann)\n",
    "        \n",
    "    except AnnotationFormatError as err:\n",
    "        anns.append(None)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['ann'] = anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Check annotations / disparity values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is not None:\n",
    "        left_mean_x = np.mean([item['xFrame'] for item in ann['leftCrop']])\n",
    "        right_mean_x = np.mean([item['xFrame'] for item in ann['rightCrop']])\n",
    "        print(left_mean_x - right_mean_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Compute weights </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_parameters_url = 'https://aquabyte-stereo-parameters.s3-eu-west-1.amazonaws.com/L40020313_R40013177/2021-02-25T12%3A11%3A24.770071000Z_L40020313_R40013177_stereo-parameters.json'.replace('%3A', ':')\n",
    "stereo_parameters_f, _, _ = s3.download_from_url(stereo_parameters_url)\n",
    "\n",
    "stereo_params = json.load(open(stereo_parameters_f))\n",
    "camera_metadata = {\n",
    "    'focalLengthPixel': stereo_params['CameraParameters1']['FocalLength'][0],\n",
    "    'baseline': abs(stereo_params['TranslationOfCamera2'][0] / 1e3),\n",
    "    'focalLength': stereo_params['CameraParameters1']['FocalLength'][0] * 3.45e-6,\n",
    "    'pixelCountWidth': 4096,\n",
    "    'pixelCountHeight': 3000,\n",
    "    'imageSensorWidth': 0.01412,\n",
    "    'imageSensorHeight': 0.01035\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb')\n",
    "kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/trained_models/2020-08-08T000000/kf_predictor_v2.pb')\n",
    "weight_estimator = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "pred_weights = []\n",
    "\n",
    "count = 0\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is not None:\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        weight, _, _ = weight_estimator.predict(ann, cm)\n",
    "        pred_weights.append(weight)\n",
    "    else:\n",
    "        pred_weights.append(None)\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['weight'] = pred_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, ann, overlay_keypoints=True, show_labels=True):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    \n",
    "    left_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['leftCrop']}\n",
    "    right_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in ann['rightCrop']}\n",
    "    \n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.images.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx, row in annotated_df.iterrows():\n",
    "    ann = row.ann\n",
    "    if ann is None:\n",
    "        continue\n",
    "    \n",
    "    left_image_s3_url = row.images[0]\n",
    "    right_image_s3_url = row.images[1]\n",
    "    left_image_key = os.path.join(*left_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    right_image_key = os.path.join(*right_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    left_image_f = s3.download_from_s3('aquabyte-images-raw', left_image_key)\n",
    "    right_image_f = s3.download_from_s3('aquabyte-images-raw', right_image_key)\n",
    "    \n",
    "    \n",
    "    display_crops(left_image_f, right_image_f, ann)\n",
    "    \n",
    "    if count > 10:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate video </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DIR = '/root/data/s3'\n",
    "OUTPUT_BASE_DIR = '/root/data/alok/biomass_estimation/playground/toy_fish_video_second_enclosure'\n",
    "WIDTH = 512\n",
    "\n",
    "def stitch_frames(left_thumbnail_f, right_thumbnail_f, weight):\n",
    "\n",
    "    # open images and metadata files\n",
    "    left_im = Image.open(left_thumbnail_f)\n",
    "    right_im = Image.open(right_thumbnail_f)\n",
    "\n",
    "    # stitch images\n",
    "    result = Image.new('RGB', (2 * WIDTH, WIDTH))\n",
    "    result.paste(im=left_im, box=(0, 0))\n",
    "    result.paste(im=right_im, box=(WIDTH, 0))\n",
    "\n",
    "    # write timestamp on stitched image\n",
    "    result_draw = ImageDraw.Draw(result)\n",
    "#     selected_font = \"arial.ttf\"\n",
    "#     font_size = 30\n",
    "#     font = ImageFont.truetype(selected_font, font_size)\n",
    "    result_draw.text((0, 0), '{} g'.format(str(weight)), (255, 255, 255))\n",
    "\n",
    "    output_f = left_thumbnail_f.replace(S3_DIR, OUTPUT_BASE_DIR).replace('left_', 'stereo_')\n",
    "    if not os.path.exists(os.path.dirname(output_f)):\n",
    "        os.makedirs(os.path.dirname(output_f))\n",
    "    result.save(output_f)\n",
    "    return output_f\n",
    "    \n",
    "\n",
    "def stitch_frames_into_video(image_fs, video_f):\n",
    "    im = cv2.imread(image_fs[0])\n",
    "    height, width, layers = im.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video = cv2.VideoWriter(video_f, fourcc, 1, (width, height), True)\n",
    "    for idx, image_f in enumerate(image_fs):\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "        im = cv2.imread(image_f, cv2.IMREAD_COLOR)\n",
    "        video.write(im)\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~annotated_df.ann.isnull()\n",
    "output_fs = []\n",
    "for idx, row in annotated_df[mask].iterrows():\n",
    "    ann = row.ann\n",
    "    left_image_s3_url = row.images[0]\n",
    "    right_image_s3_url = row.images[1]\n",
    "    weight = round(row.weight, 2)\n",
    "    left_image_key = os.path.join(*left_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    right_image_key = os.path.join(*right_image_s3_url.replace('s3://', '').split('/')[1:])\n",
    "    left_thumbnail_key, right_thumbnail_key = [x.replace('.rectified.jpg', '.resize_512_512.jpg') for x in (left_image_key, right_image_key)\n",
    "                                              ]\n",
    "    left_thumbnail_f = s3.download_from_s3('aquabyte-images-raw', left_thumbnail_key)\n",
    "    right_thumbnail_f = s3.download_from_s3('aquabyte-images-raw', right_thumbnail_key)\n",
    "    \n",
    "    output_f = stitch_frames(left_thumbnail_f, right_thumbnail_f, weight)\n",
    "    output_fs.append(output_f)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_frames_into_video(sorted(output_fs), '/root/data/alok/biomass_estimation/playground/toy_fish_video_second_enclosure/video_second_enclosure.avi')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(annotated_df.weight.values, bins=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.weight.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
