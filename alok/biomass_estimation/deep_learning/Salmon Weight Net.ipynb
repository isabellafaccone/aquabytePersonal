{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> In this notebook, we will implement a neural network that regresses volume against segmentation + depth map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_base = '/root/data/blender_v3'\n",
    "depth_map_dir = '{}/{}'.format(data_path_base, 'depth_map')\n",
    "segmentation_dir = '{}/{}'.format(data_path_base, 'mask')\n",
    "annotation_dir = '{}/{}'.format(data_path_base, 'annotations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready\n",
    "number_key = lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "side_key = lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[0]\n",
    "all_segmentation_paths = sorted(glob.glob('{}/*.npy'.format(segmentation_dir)), key=number_key)\n",
    "segmentation_paths = [p for p in all_segmentation_paths if side_key(p) == 'left'] # we are working with left frame only\n",
    "depth_map_paths = sorted(glob.glob('{}/*.npy'.format(depth_map_dir)), key=number_key)\n",
    "data_dict = dict(zip(map(number_key, segmentation_paths), zip(segmentation_paths, depth_map_paths)))\n",
    "\n",
    "# get labels\n",
    "annotation_paths = sort(glob.glob('{}/*npy'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/data/blender_v3/mask/left_2.npy\n",
      "/root/data/blender_v3/depth_map/depth_map_2.npy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(file_paths, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            # pick a random image\n",
    "            f = np.random.choice(file_paths)\n",
    "            random_x = np.random.randint(0, 1500-img_size)\n",
    "            random_y = np.random.randint(0, 1500-img_size)\n",
    "            xb = np.array(Image.open(f))[random_x:random_x+img_size, random_y:random_y+img_size, :]\n",
    "            ftruth = f.replace('images', 'labels')\n",
    "            ftruth = ftruth[:-1]\n",
    "            yb = np.expand_dims(np.array(Image.open(ftruth))[random_x:random_x+img_size, random_y:random_y+img_size, 0], axis=2)\n",
    "            yb[yb==255]=1\n",
    "            if np.random.random() < 0.5:\n",
    "                xb = flip_axis(xb, 1)\n",
    "                yb = flip_axis(yb, 1)\n",
    "            if np.random.random() < 0.5:\n",
    "                xb = flip_axis(xb, 0)\n",
    "                yb = flip_axis(yb, 0)\n",
    "            if np.random.random() < 0.5:\n",
    "                xb = xb.swapaxes(1, 0)\n",
    "                yb = yb.swapaxes(1, 0)\n",
    "            x_batch[ind,...] = xb\n",
    "            y_batch[ind,...] = yb\n",
    "        # bunch of augmentation\n",
    "\n",
    "        x_batch = seq.augment_images(x_batch)\n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-80-193799cf1049>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-193799cf1049>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    X = np.empty((self.batch_size, *self.dim, self.n_channels))\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1, n_classes=10, shuffle=True):\n",
    "        # Initialization\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            segmentation_path, depth_map_path = data_dict[ID]\n",
    "            X[i,] = np.dstack([np.load(segmentation_path), np.load(depth_map_path)])\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        , 15.56217384],\n",
       "        [ 0.        , 15.55384636],\n",
       "        [ 0.        , 15.54553795],\n",
       "        ...,\n",
       "        [ 0.        ,  7.60877419],\n",
       "        [ 0.        ,  7.59293795],\n",
       "        [ 0.        ,  7.57719374]],\n",
       "\n",
       "       [[ 0.        , 15.57263088],\n",
       "        [ 0.        , 15.56428337],\n",
       "        [ 0.        , 15.55595398],\n",
       "        ...,\n",
       "        [ 0.        ,  7.60196686],\n",
       "        [ 0.        ,  7.58615208],\n",
       "        [ 0.        ,  7.57042789]],\n",
       "\n",
       "       [[ 0.        , 15.58313084],\n",
       "        [ 0.        , 15.57476234],\n",
       "        [ 0.        , 15.56641293],\n",
       "        ...,\n",
       "        [ 0.        ,  7.59516335],\n",
       "        [ 0.        ,  7.5793705 ],\n",
       "        [ 0.        ,  7.56366825]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        , 13.88478756],\n",
       "        [ 0.        , 13.87733078],\n",
       "        [ 0.        , 13.86989117],\n",
       "        ...,\n",
       "        [ 0.        ,  7.5951705 ],\n",
       "        [ 0.        ,  7.57937717],\n",
       "        [ 0.        ,  7.56367493]],\n",
       "\n",
       "       [[ 0.        , 13.87543201],\n",
       "        [ 0.        , 13.86799431],\n",
       "        [ 0.        , 13.86057281],\n",
       "        ...,\n",
       "        [ 0.        ,  7.60197353],\n",
       "        [ 0.        ,  7.58615923],\n",
       "        [ 0.        ,  7.57043552]],\n",
       "\n",
       "       [[ 0.        , 13.86611366],\n",
       "        [ 0.        , 13.85869503],\n",
       "        [ 0.        , 13.8512907 ],\n",
       "        ...,\n",
       "        [ 0.        ,  7.60878229],\n",
       "        [ 0.        ,  7.59294605],\n",
       "        [ 0.        ,  7.57720089]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack([np.load(segmentation_paths[0]).T, np.load(depth_map_paths[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
