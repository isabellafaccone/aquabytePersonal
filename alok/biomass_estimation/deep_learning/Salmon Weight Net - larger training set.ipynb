{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> In this notebook, we will implement a neural network that regresses volume against segmentation + depth map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/github/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from biomass_utils.points_of_interest import get_point_cloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready\n",
    "\n",
    "data_path_base = '/root/data/blender_v3'\n",
    "depth_map_dir = '{}/{}'.format(data_path_base, 'depth_map')\n",
    "segmentation_dir = '{}/{}'.format(data_path_base, 'mask')\n",
    "annotation_dir = '{}/{}'.format(data_path_base, 'annotations')\n",
    "\n",
    "number_key = lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "side_key = lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[0]\n",
    "all_segmentation_paths = sorted(glob.glob('{}/*.npy'.format(segmentation_dir)), key=number_key)\n",
    "segmentation_paths = [p for p in all_segmentation_paths if side_key(p) == 'left'] # we are working with left frame only\n",
    "depth_map_paths = sorted(glob.glob('{}/*.npy'.format(depth_map_dir)), key=number_key)\n",
    "annotation_paths = sorted(glob.glob('{}/*.json'.format(annotation_dir)), key=number_key) \n",
    "complete_data_list = zip(segmentation_paths, depth_map_paths, annotation_paths)\n",
    "\n",
    "\n",
    "TRAINING_SIZE = 2000\n",
    "train_data_list = [v for i, v in enumerate(complete_data_list) if i < TRAINING_SIZE]\n",
    "test_data_list = [v for i, v in enumerate(complete_data_list) if i > TRAINING_SIZE]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_values, j_values = np.where(np.load(segmentation_paths[0]) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CLASSES = 10\n",
    "# def get_volume_class_from_numeric_value(volume):\n",
    "#     x = np.zeros(NUM_CLASSES)\n",
    "#     volume_class = int(round(volume / (10000/NUM_CLASSES)))\n",
    "#     x[volume_class] = 1\n",
    "#     return x\n",
    "\n",
    "sm = cm.ScalarMappable(cmap='hot')\n",
    "sm.set_clim(vmin=0, vmax=20)\n",
    "def convert_to_scaled_rgb_image(segmentation_mask, depth_map, annotation):    \n",
    "    projected_depth_map = get_point_cloud(depth_map, annotation['focal_length'], \n",
    "                                          annotation['sensor_height'], \n",
    "                                          annotation['sensor_width'])[:,:,1]\n",
    "    cleaned_depth_map = segmentation_mask * projected_depth_map\n",
    "    i_values, j_values = np.where(segmentation_mask > 0)\n",
    "    \n",
    "    \n",
    "    rgb_image = sm.to_rgba(cleaned_depth_map, bytes=True)[:,:,:3]\n",
    "    \n",
    "    scaled_rgb_image = np.array(Image.fromarray(rgb_image).resize((224, 224)))\n",
    "    return scaled_rgb_image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb041363ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0385c90d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "a= convert_to_scaled_rgb_image(np.load(segmentation_paths[idx]), \n",
    "                               np.load(depth_map_paths[idx]).T, \n",
    "                               json.load(open(annotation_paths[idx], 'rb')))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_list, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, min((i+1)*BATCH_SIZE, len(data_list)))):\n",
    "            segmentation_mask = np.load(data_list[j][0])\n",
    "            depth_map = np.load(data_list[j][1]).T\n",
    "            annotation = json.load(open(data_list[j][2], 'rb'))\n",
    "            scaled_depth_map = convert_to_scaled_rgb_image(segmentation_mask, depth_map, annotation)\n",
    "            \n",
    "#             volume_class = get_volume_class_from_numeric_value(annotation['volume'])\n",
    "            x_batch[ind, ...] = scaled_depth_map / 255.0\n",
    "            y_batch[ind] = annotation['volume']\n",
    "            \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"pr..., inputs=Tensor(\"in...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights=None, include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(1, name='predictions')(vgg16.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=vgg16.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.adam(lr=0.0001, decay=0.1)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "steps_per_epoch = int(len(train_data_list)/BATCH_SIZE)\n",
    "gen = generator(train_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 226s 3s/step - loss: 1817.9600 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 1227.8991 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 965.5394 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 681.1551 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 483.7914 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 417.4607 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 393.1342 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 377.9204 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 367.5664 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 168s 2s/step - loss: 360.6414 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 170s 2s/step - loss: 356.2451 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 352.3564 - acc: 5.0000e-04\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 348.4835 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 344.9575 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 340.9712 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 337.6493 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 334.7786 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 331.8209 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 329.8926 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 327.3979 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 325.1359 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 323.6645 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 321.1653 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 319.2323 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 316.9424 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 315.2937 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 313.7601 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 311.6523 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 310.1692 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 308.4634 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 306.8310 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 305.0483 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 303.8167 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 302.3633 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 301.1137 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 299.8623 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 298.3906 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 297.2436 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 296.1114 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 295.1095 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 293.9077 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 292.6518 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 291.4627 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 290.5792 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 289.6957 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 288.5659 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 287.5483 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 286.6369 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 285.6393 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 284.5988 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 283.6288 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 282.7814 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 281.6898 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 280.9441 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 280.0133 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 279.2504 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 278.3657 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 277.5485 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 276.6383 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 275.8118 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 274.9537 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 274.1603 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 273.2843 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 272.6063 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 271.7598 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 270.9828 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 270.2148 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 269.5469 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 268.6430 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 267.9991 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 267.1595 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 266.4620 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 265.7395 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 168s 2s/step - loss: 264.9966 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 264.2728 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 263.6405 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 262.9388 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 262.3964 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 261.5865 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 260.8741 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 260.2123 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 259.4988 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 258.7226 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 258.1806 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 257.4831 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 256.8367 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 256.3408 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 255.7723 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 255.1155 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 254.5155 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 253.8693 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 253.2119 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 252.5830 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 252.0673 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 251.4099 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 250.8264 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 250.1693 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 249.4374 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 248.9830 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 167s 2s/step - loss: 248.4060 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb014041c50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cb5734703930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "eval_gen = generator(test_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))\n",
    "scores = model.evaluate_generator(eval_gen, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[345.81402587890625, 0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 3))\n",
    "predictions = model.predict_generator(eval_gen, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values = np.array([])\n",
    "for i in range(100*25):\n",
    "    annotation = json.load(open(test_data_list[i][2], 'rb'))\n",
    "    ground_truth_values = np.append(ground_truth_values, annotation['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2068.00994581, 1983.57114122, 5667.58181159, 2049.77426155,\n",
       "       1528.27865757, 1679.62820886, 1947.34439018,  684.62315282,\n",
       "       2434.38040172, 5113.82745715, 8486.68708593, 7273.50315184,\n",
       "       3423.50665138, 6234.69380593, 3862.53731828, 6785.19899183,\n",
       "       3708.29718001, 7386.69905305, 5573.30013394, 5137.94349751,\n",
       "       2104.43053116, 7616.8387957 , 4965.50153042, 1031.97936857,\n",
       "        653.68714871,  795.52886466, 4588.47304829, 1055.92267465,\n",
       "       2831.32756492, 2327.26298245, 3519.36642167, 8371.00638618,\n",
       "       3409.9339579 , 2145.05276732,  641.34302622, 2712.55266872,\n",
       "       7792.95574693, 2475.12041666,  411.3280957 , 2891.24525597,\n",
       "        414.19034068, 1166.19174925,  415.51776598, 3304.26350106,\n",
       "        764.68483052, 5550.34090059,  706.34773551, 2391.911852  ,\n",
       "       1171.72532551,  862.73221058, 1208.00440943, 2103.96966803,\n",
       "       3018.69930411, 1784.1289841 , 5950.56608098, 3310.11119381,\n",
       "       5423.55895446, 4088.90170256, 8093.99164143, 2328.52493205,\n",
       "        625.89236912, 7395.85289639,  740.82330201,  412.64455375,\n",
       "       3639.46883259, 4942.21327941, 1244.12649471, 5409.60336072,\n",
       "        906.01412532,  761.74357958, 7037.24368083, 5995.10171988,\n",
       "       4048.26230026, 4939.36656144, 2577.69977649, 7194.46500515,\n",
       "       1093.74444606, 1260.13081939, 6078.36225979, 4277.64530231,\n",
       "       1970.32043205, 3071.12707516,  781.93119684, 2551.58674203,\n",
       "       8311.67353593, 1083.72037487, 1169.28654176, 2963.83370297,\n",
       "       5667.56750647, 1415.86202752, 1290.95750858, 1303.13724144,\n",
       "       8445.82118597, 4799.03337951, 6240.54030659,  791.53463803,\n",
       "       5820.74477467, 5505.62501724, 1764.43513175,  542.10581819,\n",
       "       3285.51521684, 3178.40876483, 7098.41616892, 1540.60442182,\n",
       "       1603.15508857, 4731.69681721, 4550.8014806 ,  653.04043828,\n",
       "       3068.75767121,  515.22966542, 2088.30675878, 3086.22064082,\n",
       "       1942.31995682, 2341.89473131, 6989.14177667, 8584.87072221,\n",
       "       1509.0720136 , 3609.52488823, 1606.15081815,  450.88150133,\n",
       "       6030.57077664, 4480.43747904, 2151.24235233,  670.71059364,\n",
       "       4051.82379716])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3089.0618"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032213283684685616"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ground_truth_values.mean() - predictions[:,0].mean())/(ground_truth_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
