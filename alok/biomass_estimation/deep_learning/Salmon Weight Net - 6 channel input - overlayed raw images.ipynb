{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> In this notebook, we will implement a neural network that regresses volume against segmentation + depth map </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/alok/github/cv_research/alok')\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.backend import tf as ktf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from biomass_utils.points_of_interest import get_point_cloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready\n",
    "\n",
    "data_path_base = '/root/data/blender_v3'\n",
    "image_dir = '{}/{}'.format(data_path_base, 'stereo_images')\n",
    "annotation_dir = '{}/{}'.format(data_path_base, 'annotations')\n",
    "\n",
    "number_key = lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "side_key = lambda x: os.path.splitext(os.path.basename(x))[0].split('_')[0]\n",
    "all_image_paths = sorted(glob.glob('{}/*.png'.format(image_dir)), key=number_key)\n",
    "left_image_paths = [p for p in all_image_paths if side_key(p) == 'left'] \n",
    "right_image_paths = [p for p in all_image_paths if side_key(p) == 'right']\n",
    "annotation_paths = sorted(glob.glob('{}/*.json'.format(annotation_dir)), key=number_key) \n",
    "complete_data_list = zip(left_image_paths, right_image_paths, annotation_paths)\n",
    "\n",
    "\n",
    "TRAINING_SIZE = 500\n",
    "train_data_list = [v for i, v in enumerate(complete_data_list) if i < TRAINING_SIZE]\n",
    "test_data_list = [v for i, v in enumerate(complete_data_list) if i > TRAINING_SIZE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_six_channel_input(left_image_array, right_image_array, annotation):    \n",
    "    \n",
    "    left_image = Image.fromarray(left_image_array)\n",
    "    resized_left_image = left_image.resize((224, 224))\n",
    "    normalized_left_image_array = np.array(resized_left_image) / 255.0\n",
    "    \n",
    "    right_image = Image.fromarray(right_image_array)\n",
    "    resized_right_image = right_image.resize((224, 224))\n",
    "    normalized_right_image_array = np.array(resized_right_image) / 255.0\n",
    "    \n",
    "    six_channel_input = np.dstack([normalized_left_image_array, normalized_right_image_array])\n",
    "    \n",
    "    return six_channel_input\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "a = convert_to_four_channel_input(np.array(Image.open(image_paths[idx]))[:,:,:3],\n",
    "                                 np.load(segmentation_paths[idx]),\n",
    "                                 np.load(depth_map_paths[idx]).T, \n",
    "                                 json.load(open(annotation_paths[idx], 'rb')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_list, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, min((i+1)*BATCH_SIZE, len(data_list)))):\n",
    "            left_image_array = np.array(Image.open(data_list[j][0]))[:,:,:3]\n",
    "            right_image_array = np.array(Image.open(data_list[j][1]))[:,:,:3]\n",
    "            annotation = json.load(open(data_list[j][2], 'rb'))\n",
    "            six_channel_input = convert_to_six_channel_input(left_image_array, right_image_array, annotation)\n",
    "            x_batch[ind, ...] = six_channel_input\n",
    "            y_batch[ind] = annotation['volume']\n",
    "            \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model with all layers (with top)\n",
    "vgg16 = VGG16(weights=None, include_top=True, input_shape=(224, 224, 6))\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(1, name='predictions')(vgg16.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=vgg16.input, output=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.adam(lr=0.0005, decay=0.1)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "steps_per_epoch = int(len(train_data_list)/BATCH_SIZE)\n",
    "gen = generator(train_data_list, steps_per_epoch, BATCH_SIZE, (224, 224, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen, steps_per_epoch=steps_per_epoch, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gen = generator(test_data_list, np.inf, BATCH_SIZE, (224, 224, 6))\n",
    "predictions = model.predict_generator(eval_gen, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values = np.array([])\n",
    "for i in range(50*25):\n",
    "    annotation = json.load(open(test_data_list[i][2], 'rb'))\n",
    "    ground_truth_values = np.append(ground_truth_values, annotation['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ground_truth_values.mean() - predictions[:,0].mean())/(ground_truth_values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ground_truth_values, predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(ground_truth_values - predictions[:,0])/ground_truth_values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
