{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('/root/data/small_pen_data_collection/dataset_13k_pairs.csv')\n",
    "# original_df = original_df.filter(original_df.columns.tolist()[1:-1]).dropna()\n",
    "original_df = original_df.filter(original_df.columns.tolist()[1:-1])\n",
    "original_df['fish_id'] = 1\n",
    "fish_counter = 1\n",
    "for biomass in original_df.ground_truth.unique():\n",
    "    mask = original_df.ground_truth == biomass\n",
    "    original_df.ix[mask, 'fish_id'] = fish_counter\n",
    "    fish_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(original_df.ix[original_df.fish_id == 2, '34'].dropna(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Define all possible features we care about </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_convolution_features(df, primary_features):\n",
    "    convolution_features = []\n",
    "    for i in range(len(primary_features)):\n",
    "        for j in range(i, len(primary_features)):\n",
    "            pair_1 = primary_features[i]\n",
    "            pair_2 = primary_features[j]\n",
    "            conv_feature = '{},{}'.format(pair_1, pair_2)\n",
    "            df[conv_feature] = df[pair_1] * df[pair_2]\n",
    "            convolution_features.append(conv_feature)\n",
    "    return convolution_features\n",
    "\n",
    "def add_square_features(df, primary_features):\n",
    "    square_features = []\n",
    "    for feature in primary_features:\n",
    "        square_feature = '{},{}'.format(feature, feature)\n",
    "        df[square_feature] = df[feature]**2\n",
    "        square_features.append(square_feature)\n",
    "    return square_features\n",
    "\n",
    "def add_cubic_features(df, primary_features):\n",
    "    cubic_features = []\n",
    "    for feature in primary_features:\n",
    "        cubic_feature = '{},{},{}'.format(feature, feature, feature)\n",
    "        df[cubic_feature] = df[feature]**3\n",
    "        cubic_features.append(cubic_feature)\n",
    "    return cubic_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features list\n",
    "\n",
    "df = original_df.copy(deep=True)\n",
    "primary_features = df.columns.tolist()[:-2]\n",
    "# square_features = add_square_features(df, primary_features)\n",
    "# cubic_features = add_cubic_features(df, primary_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Forward Stepwise Selection using AIC score as main criterion for evaluating model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = primary_features + square_features + cubic_features\n",
    "features = primary_features\n",
    "target = 'ground_truth'\n",
    "feature_subset = []\n",
    "rank = 1\n",
    "while True:\n",
    "    aic_dict = {}\n",
    "    for feature in features:\n",
    "        if feature in feature_subset:\n",
    "            continue\n",
    "        X_train = df[feature_subset + [feature]]\n",
    "        y_train = df[target]\n",
    "        model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "        aic_dict[feature] = model.aic\n",
    "    best_feature = min(aic_dict, key=aic_dict.get)\n",
    "    print('Feature ranked #{}: {}'.format(rank, best_feature))\n",
    "    feature_subset.append(best_feature)        \n",
    "    rank += 1\n",
    "    if rank > 10:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We will probably end up using only '46', '26', and '24' and variants of those features so that we can restrict ourselves to only having to detect three body parts </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run cross validation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df, features, target='ground_truth', test_fraction=0.2, random_seed=None):\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "    N = df.shape[0]\n",
    "    shuffled_fish_ids = df.fish_id.unique()\n",
    "    np.random.shuffle(shuffled_fish_ids)\n",
    "    tdfs = []\n",
    "    train_sample_size = 0\n",
    "    for i, fish_id in enumerate(shuffled_fish_ids):\n",
    "        mask = df.fish_id == fish_id\n",
    "        tdf = df[mask].copy(deep=True)\n",
    "        tdfs.append(tdf)\n",
    "        if train_sample_size < (1 - test_fraction) * N:\n",
    "            train_sample_size += tdf.shape[0]\n",
    "    shuffled_df = pd.concat(tdfs, axis=0)\n",
    "    shuffled_df.index = range(shuffled_df.shape[0])\n",
    "    shuffled_df = shuffled_df[features + [target]].copy(deep=True)\n",
    "    train_df = shuffled_df.iloc[:train_sample_size].copy(deep=True)\n",
    "    test_df = shuffled_df.iloc[train_sample_size:].copy(deep=True)\n",
    "    \n",
    "    \n",
    "    X_train = train_df[features]\n",
    "    Y_train = train_df[target]\n",
    "    X_test = test_df[features]\n",
    "    Y_test = test_df[target]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(df, features, N=10, test_fraction=0.2):\n",
    "    mae_list = []\n",
    "    mse_list = []\n",
    "    error_means = []\n",
    "    for i in range(N):\n",
    "        X_train, Y_train, X_test, Y_test = get_train_test_split(df, features, test_fraction=test_fraction)\n",
    "        model = sm.OLS(Y_train, sm.add_constant(X_train)).fit()\n",
    "        \n",
    "        predictions = model.predict(sm.add_constant(X_test))\n",
    "        errors = (predictions - Y_test)/Y_test\n",
    "        \n",
    "        absolute_errors = np.abs(errors)\n",
    "        mae = absolute_errors.mean()\n",
    "        squared_errors = errors ** 2\n",
    "        mse = squared_errors.mean()\n",
    "        mae_list.append(mae)\n",
    "        mse_list.append(mse)\n",
    "        error_means.append(np.mean(predictions - Y_test)/np.mean(Y_test))\n",
    "    return mse_list, mae_list, error_means\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['24', '24,24', '24,24,24', '46', '46,46', '46,46,46', '26', '26,26', '26,26,26']\n",
    "mse_list, mae_list, error_means = perform_cross_validation(df, features)\n",
    "print('Average percentage deviation from true mean: {}'.format(np.mean(np.abs(error_means))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train final model and save it </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[features]\n",
    "y_train = df[target]\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "model.save('/root/alok/data/models/filtered_feature_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Bryton's stuff below </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_train = np.squeeze(X_train)\n",
    "\n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(y_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "#print(df.isna().sum())\n",
    "\n",
    "new_df = df.drop(columns=[])\n",
    "#new_df = df.drop(columns=['14', '24', '34', '45', '46', '47']) \n",
    "#new_df = new_df.drop(columns=['16', '26', '36', '56', '67']) # '46', \n",
    "\n",
    "print(new_df.isna().sum())\n",
    "\n",
    "new_df = new_df.dropna(subset=new_df.columns[1:-2])\n",
    "\n",
    "print(new_df.shape)\n",
    "\n",
    "\n",
    "my_mean = new_df.mean()\n",
    "#my_sd = np.std(new_df, axis=0)\n",
    "\n",
    "#print(my_mean)\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "my_columns = new_df.columns[1:-2]\n",
    "\n",
    "print(my_columns)\n",
    "\n",
    "norm_df = new_df.copy()\n",
    "\n",
    "for x in my_columns:\n",
    "    my_mean = new_df[x].median()\n",
    "    my_std = new_df[x].std()\n",
    "    my_iqr = stats.iqr(new_df[x])\n",
    "    \n",
    "    means.append(my_mean)\n",
    "    stds.append(my_std)\n",
    "    \n",
    "    #print(my_mean)\n",
    "    #print(my_std)\n",
    "    #print((new_df[x] - my_mean) / my_std)\n",
    "    \n",
    "    my_row = new_df[x].copy()\n",
    "    new_df[x] = my_row / my_iqr\n",
    "    norm_df[x] = (my_row - my_mean) / my_std\n",
    "    \n",
    "#norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = new_df.loc[:, new_df.columns[1]:new_df.columns[-3]]\n",
    "my_norm_df = norm_df.loc[:, new_df.columns[1]:new_df.columns[-3]]\n",
    "\n",
    "array_subset = (np.abs(my_norm_df) > 1.5).any(axis=1) == False\n",
    "\n",
    "print('Keeping %i of %i' % (np.sum(array_subset), my_norm_df.shape[0]))\n",
    "\n",
    "my_df = my_df.loc[array_subset, :]\n",
    "\n",
    "#Y = new_df['ground_truth']\n",
    "Y = new_df['ground_truth'][array_subset]\n",
    "print(my_df.shape)\n",
    "#my_df_X = np.hstack((my_df, my_df ** 2, my_df ** 3))\n",
    "pidx = np.indices((my_df.shape[1], my_df.shape[1])).reshape(2, -1)\n",
    "lcol = pd.MultiIndex.from_product([my_df.columns, my_df.columns],\n",
    "                                  names=[my_df.columns.name, my_df.columns.name])\n",
    "my_df_X = pd.DataFrame(my_df.values[:, pidx[0]] * my_df.values[:, pidx[1]],\n",
    "             columns=lcol)\n",
    "print(my_df_X.shape)\n",
    "#my_df_X = np.hstack(( my_df_X))\n",
    "\n",
    "# my_df_X = sm.add_constant(my_df_X)\n",
    "print(my_df_X.shape)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(my_df_X)\n",
    "newX = pca.transform(my_df_X)\n",
    "# new_X_compare = pca.fit_transform(my_df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(newX[:, 0], newX[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = pca.explained_variance_ratio_\n",
    "print(np.sum(eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "\n",
    "newX = np.dot(my_df_X, components.T)\n",
    "\n",
    "print(components.shape)\n",
    "\n",
    "newX\n",
    "\n",
    "#outlierIndices = np.where(newX[:,0] > 10)\n",
    "#my_indices = my_df.index[outlierIndices[0]]\n",
    "\n",
    "\n",
    "#my_df.loc[my_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(newX[:,0], Y)#plt.scatter(np.log(newX[:,0]),np.log(Y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myX = newX[:, 0]\n",
    "myX = newX\n",
    "myY = Y\n",
    "\n",
    "plt.scatter(newX[:, 0], Y)\n",
    "plt.show()\n",
    "\n",
    "# myX = sm.add_constant(myX)\n",
    "\n",
    "print(myX.shape)\n",
    "print(myY.shape)\n",
    "\n",
    "model = sm.OLS(myY, myX).fit()\n",
    "predictions = model.predict(myX) # make the predictions by the model\n",
    "\n",
    "print(model.params.shape)\n",
    "#print(model.summary())\n",
    "\n",
    "predY = predictions\n",
    "#predY = np.exp(predictions)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "error = predY - myY\n",
    "\n",
    "plt.scatter(Y, predY)\n",
    "\n",
    "res = model.resid\n",
    "fig = sm.qqplot(res, fit=True, line='45')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Error: %0.2f' % (np.median(np.abs(error)), ))\n",
    "print('Pct Error: %0.2f' % (np.median(np.abs(error) / myY * 100), ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/root/data/models/biomass/model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/root/data/models/biomass/components.npy', components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(list(Y)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_per_fish(dataframe, Y, test_size = 0.2):\n",
    "    nsamples = len(list(Y))\n",
    "    most_common_list = Counter(list(Y)).most_common()\n",
    "\n",
    "    np.random.shuffle(most_common_list)\n",
    "    \n",
    "    train_fish_ids = []\n",
    "    test_fish_ids = []\n",
    "    train_counter = 0\n",
    "    for mc in most_common_list:\n",
    "        train_counter += mc[1]\n",
    "        if train_counter < nsamples * (1 - test_size):\n",
    "            train_fish_ids.append(mc[0])\n",
    "        else:\n",
    "            test_fish_ids.append(mc[0])\n",
    "    # create the datasets\n",
    "    train_index = []\n",
    "    test_index = []\n",
    "    for (i, v) in enumerate(Y):\n",
    "        if v in train_fish_ids:\n",
    "            train_index.append(i)\n",
    "        else:\n",
    "            test_index.append(i)\n",
    "#     print(train_index)\n",
    "#     print(test_index)\n",
    "    X_train = dataframe.iloc[train_index, :]\n",
    "    Y_train = Y.iloc[train_index]\n",
    "    X_test = dataframe.iloc[test_index, :]\n",
    "    Y_test = Y.iloc[test_index]\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = cross_validation_per_fish(my_df_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getError(n_components, k):\n",
    "    errors = []\n",
    "    avg_errors = []\n",
    "    avg_errors_raw = []\n",
    "    error_pcts = []\n",
    "    \n",
    "    for i in range(k):\n",
    "#         X_train, X_test, y_train, y_test = cross_validation.train_test_split(my_df_X, Y, test_size=0.4)\n",
    "        X_train, X_test, y_train, y_test = cross_validation_per_fish(my_df_X, Y)\n",
    "        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        \n",
    "        pca.fit(X_train)\n",
    "        \n",
    "#         components = pca.components_ ### put this back in!\n",
    "        components = np.eye(X_train.shape[1])[:n_components,:]\n",
    "        newX = np.dot(X_train, components.T)\n",
    "\n",
    "        #newX = pca.fit_transform(X_train)\n",
    "        model = sm.OLS(y_train, newX).fit()\n",
    "        \n",
    "        newX_test = np.dot(X_test, components.T)\n",
    "        #X_test = pca.transform(X_test)\n",
    "        \n",
    "        predY = model.predict(newX_test)\n",
    "        error = predY - y_test\n",
    "\n",
    "        errors.append(np.median(np.abs(error)))\n",
    "        avg_errors.append(np.abs(np.mean(error)) / np.mean(y_test) * 100)\n",
    "        avg_errors_raw.append(np.mean(error) / np.mean(y_test) * 100)\n",
    "        error_pcts.append(np.median(np.abs(error) / y_test * 100))\n",
    "    \n",
    "    return (np.mean(errors), np.mean(avg_errors), avg_errors_raw, np.mean(error_pcts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getError(n_components, k):\n",
    "#     errors = []\n",
    "#     avg_errors = []\n",
    "#     avg_errors_raw = []\n",
    "#     error_pcts = []\n",
    "    \n",
    "#     for i in range(k):\n",
    "#         pca = PCA(n_components=n_components)\n",
    "\n",
    "#         pca.fit(my_df_X)\n",
    "\n",
    "#         components = pca.components_\n",
    "\n",
    "#         newX = np.dot(my_df_X, components.T)\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = cross_validation.train_test_split(newX, Y, test_size=0)\n",
    "\n",
    "#         myX = X_train\n",
    "#         myY = y_train\n",
    "#         model = sm.OLS(myY, myX).fit()\n",
    "        \n",
    "#         predY = model.predict(X_test) # make the predictions by the model\n",
    "\n",
    "#         error = predY - y_test\n",
    "\n",
    "#         errors.append(np.median(np.abs(error)))\n",
    "#         avg_errors.append(np.abs(np.mean(error)) / np.mean(y_test) * 100)\n",
    "#         avg_errors_raw.append(np.mean(error) / np.mean(y_test) * 100)\n",
    "#         error_pcts.append(np.median(np.abs(error) / y_test * 100))\n",
    "    \n",
    "#     return (np.mean(errors), np.mean(avg_errors), avg_errors_raw, np.mean(error_pcts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_eigens = [5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_eigens = [1, 2, 3, 5, 10, 15]\n",
    "# n_eigens = [1]\n",
    "\n",
    "errors = []\n",
    "avg_errors_raws = []\n",
    "\n",
    "for n_eigen in n_eigens:\n",
    "    myError = getError(n_eigen, 50)\n",
    "    errors.append(myError[3])\n",
    "    avg_errors_raws.append(myError[2])\n",
    "    \n",
    "    #print(myError)\n",
    "\n",
    "    print('Achieve %0.2f with %i eigenvectors' % (myError[1], n_eigen))\n",
    "    \n",
    "#print(avg_errors_raws[1])\n",
    "plt.plot(avg_errors_raws[3])\n",
    "plt.show()\n",
    "\n",
    "print(.4 * newX.shape[0])\n",
    "\n",
    "# plt.plot(n_eigens, errors)\n",
    "# plt.xlabel('Number of regressors')\n",
    "# plt.ylabel('Median error %')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extensions to this\n",
    "- Try different filtering based off of total norm of covariance of eigenvectors\n",
    "- More data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(np.squeeze(newX), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY, y_test = getError(1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(np.squeeze(newX), np.array(y_train)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.linregress(np.squeeze(newX), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((np.array(y_train) - 8 * np.squeeze(newX))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(newX, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(np.array(y_train), np.squeeze(newX)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(np.array(y_train), np.squeeze(newX), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.histogram(np.random.normal(loc=3000, scale=500, size=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test PCA Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in model, PCA components, and new dataframe\n",
    "\n",
    "model = sm.load('/root/data/models/biomass/model.pickle')\n",
    "components = np.load('/root/data/models/biomass/components.npy')\n",
    "iqrs = pickle.load(open('/root/data/models/biomass/iqrs.pkl', 'rb'))\n",
    "df = pd.read_csv('/root/data/small_pen_data_collection/dataset_13k_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['ground_truth'] = df['ground_truth']\n",
    "feature_remapping = {\n",
    "    '2': '1',\n",
    "    '3': '2',\n",
    "    '4': '3',\n",
    "    '5': '4',\n",
    "    '6': '5',\n",
    "    '7': '6',\n",
    "    '8': '7'\n",
    "}\n",
    "\n",
    "for column in df.columns.tolist():\n",
    "    part_1, part_2 = column[0], column[1]\n",
    "    if part_1 not in feature_remapping.keys() or part_2 not in feature_remapping.keys():\n",
    "        continue\n",
    "    remapped_part_1 = feature_remapping[part_1]\n",
    "    remapped_part_2 = feature_remapping[part_2]\n",
    "    f = '{}{}'.format(remapped_part_1, remapped_part_2)\n",
    "    new_df[f] = df[column] / iqrs[f]\n",
    "df = new_df.copy(deep=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[df.columns.tolist()[1:]]\n",
    "\n",
    "pidx = np.indices((df_X.shape[1], df_X.shape[1])).reshape(2, -1)\n",
    "lcol = pd.MultiIndex.from_product([df_X.columns, df_X.columns],  names=[df_X.columns.name, df_X.columns.name])\n",
    "X = pd.DataFrame(df_X.values[:, pidx[0]] * df_X.values[:, pidx[1]],  columns=lcol)\n",
    "\n",
    "newX = np.dot(X, components.T)\n",
    "predY = model.predict(newX)\n",
    "y = df.ground_truth.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y - predY) / np.mean(predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Feature Filtered Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in model, PCA components, and new dataframe\n",
    "\n",
    "model = sm.load('/root/alok/data/models/filtered_feature_model.pkl')\n",
    "df = pd.read_csv('/root/data/small_pen_data_collection/dataset_13k_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['ground_truth'] = df['ground_truth']\n",
    "feature_remapping = {\n",
    "    '2': '1',\n",
    "    '3': '2',\n",
    "    '4': '3',\n",
    "    '5': '4',\n",
    "    '6': '5',\n",
    "    '7': '6',\n",
    "    '8': '7'\n",
    "}\n",
    "\n",
    "for column in df.columns.tolist():\n",
    "    part_1, part_2 = column[0], column[1]\n",
    "    if part_1 not in feature_remapping.keys() or part_2 not in feature_remapping.keys():\n",
    "        continue\n",
    "    remapped_part_1 = feature_remapping[part_1]\n",
    "    remapped_part_2 = feature_remapping[part_2]\n",
    "    f = '{}{}'.format(remapped_part_1, remapped_part_2)\n",
    "    new_df[f] = df[column]\n",
    "df = new_df.copy(deep=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame()\n",
    "for feature in ['24', '46', '26']:\n",
    "    df_X[feature] = df[feature]\n",
    "    df_X['{},{}'.format(feature, feature)] = df[feature]**2 # add square features\n",
    "    df_X['{},{},{}'.format(feature, feature, feature)] = df[feature]**3 # add cubic features\n",
    "    \n",
    "y = df.ground_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(sm.add_constant(df_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
