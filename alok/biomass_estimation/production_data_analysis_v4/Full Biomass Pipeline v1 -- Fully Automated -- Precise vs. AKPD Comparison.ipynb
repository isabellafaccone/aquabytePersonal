{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "from multiprocessing import Pool, Manager\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.akpd import AKPD\n",
    "from aquabyte.template_matching import find_matches_and_homography\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.akpd_scorer import generate_confidence_score\n",
    "from keras.models import load_model\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKPD(object):\n",
    "\n",
    "    def __init__(self, aws_credentials):\n",
    "        self.client = boto3.client(\n",
    "            \"sagemaker-runtime\", \n",
    "            region_name=\"eu-west-1\", \n",
    "            aws_access_key_id=aws_credentials['aws_access_key_id'], \n",
    "            aws_secret_access_key=aws_credentials['aws_secret_access_key']\n",
    "        \n",
    "        )\n",
    "\n",
    "    def predict_keypoints(self, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, camera_metadata):\n",
    "        body = [{\n",
    "            'leftCropUrl': left_crop_url,\n",
    "            'rightCropUrl': right_crop_url,\n",
    "            'leftCropMetadata': left_crop_metadata,\n",
    "            'rightCropMetadata': right_crop_metadata,\n",
    "            'cameraMetadata': camera_metadata,\n",
    "            'id': 1\n",
    "        }]\n",
    "\n",
    "        body_str = json.dumps(body).replace(\"'\", '\"')\n",
    "\n",
    "        resp = self.client.invoke_endpoint(EndpointName='auto-keypoints', ContentType='application/json', Body=body_str)\n",
    "        akpd_keypoints_str = resp['Body'].read()\n",
    "        akpd_keypoints = json.loads(akpd_keypoints_str.decode(\"utf-8\"))\n",
    "        return akpd_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations where pen_id=61 and captured_at between '2019-09-13' and '2019-09-21'\n",
    "    and keypoints -> 'leftCrop' is not null\n",
    "    and keypoints -> 'rightCrop' is not null;\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "aws_credentials = json.load(open(os.environ['AWS_CREDENTIALS']))\n",
    "akpd = AKPD(aws_credentials)\n",
    "\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# initialize data transforms so that we can run inference with biomass neural network\n",
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')\n",
    "akpd_scorer_network = load_model('/root/data/alok/biomass_estimation/playground/akpd_scorer_model_TF.h5') # make this better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Function to generate weight prediction and confidence score </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, keypoints, cm):\n",
    "    \n",
    "    akpd_keypoints = akpd.predict_keypoints(left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, cm)\n",
    "\n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints[0],\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "\n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints[0],\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    akpd_weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    # run manual scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    manual_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "\n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    manual_weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    print(akpd_score, akpd_weight_prediction, manual_score, manual_weight_prediction)\n",
    "    return akpd_keypoints, akpd_score, akpd_weight_prediction, manual_score, manual_weight_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_score_dict = {}\n",
    "\n",
    "args = []\n",
    "for idx, row in df.head(1000).iterrows():\n",
    "    left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata,\n",
    "    cm = row.camera_metadata\n",
    "    keypoints = row.keypoints\n",
    "    row_id = idx\n",
    "    akpd_keypoints, akpd_score, akpd_weight_prediction, manual_score, manual_weight_prediction = generate_weight_score(row_id, left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata, keypoints, cm)\n",
    "    weight_score_dict[row_id] = {\n",
    "        'akpd_keypoints': akpd_keypoints,\n",
    "        'akpd_score': akpd_score,\n",
    "        'akpd_weight_prediction': akpd_weight_prediction,\n",
    "        'manual_score': manual_score,\n",
    "        'manual_weight_prediction': manual_weight_prediction\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['akpd_weight'], df['akpd_score'], df['manual_weight'], df['manual_score'] = np.nan, np.nan, np.nan, np.nan\n",
    "for idx, row in df.iterrows():\n",
    "    if idx in weight_score_dict.keys():\n",
    "        df.at[idx, 'akpd_weight'] = weight_score_dict[idx]['akpd_weight_prediction']\n",
    "        df.at[idx, 'akpd_score'] = weight_score_dict[idx]['akpd_score']\n",
    "        df.at[idx, 'manual_weight'] = weight_score_dict[idx]['manual_weight_prediction']\n",
    "        df.at[idx, 'manual_score'] = weight_score_dict[idx]['manual_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mask = df.akpd_score > 0.9\n",
    "df[score_mask].akpd_weight.mean(), df[score_mask].manual_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "mask = df.score > 0.8\n",
    "plt.hist(df[mask].weight, bins=10)\n",
    "plt.xlabel('Predicted weight (grams)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Predicted weight distribution for IMR - 11/09-11/13')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints, side='both', overlay_keypoints=True, show_labels=False):\n",
    "    assert side == 'left' or side == 'right' or side == 'both', \\\n",
    "        'Invalid side value: {}'.format(side)\n",
    "\n",
    "    if side == 'left' or side == 'right':\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        image_f = left_image_f if side == 'left' else right_image_f\n",
    "        keypoints = left_keypoints if side == 'left' else right_keypoints\n",
    "        image = plt.imread(image_f)\n",
    "        ax.imshow(image)\n",
    "\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in keypoints.items():\n",
    "#                 ax.scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                ax.scatter([kp[0]], [kp[1]], color='red', s=200, alpha=0.3)\n",
    "                if show_labels:\n",
    "                    ax.annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "        left_image = plt.imread(left_image_f)\n",
    "        right_image = plt.imread(right_image_f)\n",
    "        axes[0].imshow(left_image)\n",
    "        axes[1].imshow(right_image)\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in left_keypoints.items():\n",
    "#                 axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                axes[0].scatter([kp[0]], [kp[1]], color='red', s=200, alpha=0.3)\n",
    "                if show_labels:\n",
    "                    axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "            for bp, kp in right_keypoints.items():\n",
    "#                 axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                axes[1].scatter([kp[0]], [kp[1]], color='red', s=200, alpha=0.3)\n",
    "                if show_labels:\n",
    "                    axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 24\n",
    "row = df[mask].sort_values('weight', ascending=False).iloc[idx]\n",
    "\n",
    "left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "right_image_f, _, _ = s3_access_utils.download_from_url(right_crop_url)\n",
    "left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata,\n",
    "cm = row.camera_metadata\n",
    "row_id = idx\n",
    "\n",
    "# run AKPD\n",
    "akpd_keypoints = akpd.predict_keypoints(left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata)\n",
    "left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in akpd_keypoints[0]['leftCrop']}\n",
    "right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in akpd_keypoints[0]['rightCrop']}\n",
    "\n",
    "\n",
    "# run AKPD scoring network\n",
    "input_sample = {\n",
    "    'keypoints': akpd_keypoints[0],\n",
    "    'cm': cm,\n",
    "    'stereo_pair_id': row_id,\n",
    "    'single_point_inference': True\n",
    "}\n",
    "nomralized_centered_2D_kps = \\\n",
    "    normalize_centered_2D_transform_akpd.__call__(input_sample)\n",
    "\n",
    "akpd_normalized_kps = akpd_normalization_transform.__call__(nomralized_centered_2D_kps)\n",
    "tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "score = akpd_scorer_network(tensorized_kps['kp_input']).item()\n",
    "display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints, show_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3250 = 2070 * (1+r)**60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((3250/2070)**(1/63.0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2070*(1.00718)**(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
