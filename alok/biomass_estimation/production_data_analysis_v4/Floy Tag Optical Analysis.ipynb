{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Kjeppevikholmen Optical Analysis -- June Growth Trend </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from aquabyte.visualize import Visualizer\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "import json, os\n",
    "import cv2\n",
    "import torch\n",
    "import pytz\n",
    "from PIL import Image\n",
    "import datetime as dt\n",
    "import dateutil\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where pen_id=64\n",
    "    and keypoints -> 'leftCrop' is not null\n",
    "    and keypoints -> 'rightCrop' is not null\n",
    "    and is_qa=FALSE;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_centered_2D_transform_biomass = NormalizeCentered2D()\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# load neural network weights\n",
    "biomass_network = torch.load('/root/data/alok/biomass_estimation/results/neural_network/2019-11-08T00:13:09/nn_epoch_798.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight(row_id, keypoints, cm):\n",
    "    \n",
    "    # run biomass estimation\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': row_id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_biomass.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    weight_prediction = biomass_network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    \n",
    "    return weight_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    weight = generate_weight(row.id, row.keypoints, row.camera_metadata)\n",
    "    weights.append(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'] = weights\n",
    "# df = df.sort_values('captured_at', ascending=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['left_floy_tag'] = df.left_crop_metadata.apply(lambda x: x.get('floyTag'))\n",
    "df['right_floy_tag'] = df.right_crop_metadata.apply(lambda x: x.get('floyTag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.left_floy_tag == df.right_floy_tag) & (df.left_floy_tag.notnull())\n",
    "tag_mask = df.left_floy_tag == 'BWWW'\n",
    "df[mask & tag_mask].weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[mask & tag_mask].weight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_weight_gt = {\n",
    "    'BWWB': 2000,\n",
    "    'BBBW': 1750,\n",
    "    'BWBB': 810,\n",
    "    'BBWW': 1708,\n",
    "    'WBWB': 1950,\n",
    "    'BBBB': 1952,\n",
    "    'WBBB': 2044,\n",
    "    'WWWB': 1834,\n",
    "    'WWWW': 564,\n",
    "    'BWWW': 1778,\n",
    "    'BBWB': 1638,\n",
    "    'WWBB': 782,\n",
    "    'WBWW': 2442,\n",
    "    'WWBW': 1158,\n",
    "    'W'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data = defaultdict(list)\n",
    "mask = (df.left_floy_tag == df.right_floy_tag) & (df.left_floy_tag.notnull())\n",
    "for tag_id, gt_weight in tag_weight_gt.items():\n",
    "    tag_mask = df.left_floy_tag == tag_id\n",
    "    pred_weight = df[mask & tag_mask].weight.median()\n",
    "    pct_difference = (gt_weight - pred_weight)/gt_weight\n",
    "    analysis_data['pred_weight'].append(pred_weight)\n",
    "    analysis_data['ground_truth_weight'].append(gt_weight)\n",
    "    analysis_data['pct_difference'].append(pct_difference)\n",
    "analysis_df = pd.DataFrame(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.pct_difference = 100 * analysis_df.pct_difference\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.hist(analysis_df.pct_difference)\n",
    "ax.set_title('Percentage Difference Distribution in Floy Tag Data')\n",
    "ax.set_xlabel('Percentage Difference')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.captured_at.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.pct_difference.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
