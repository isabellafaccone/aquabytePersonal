{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer, _normalize_world_keypoints\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "from aquabyte.biomass_estimator import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from aquabyte.akpd_scorer import AKPDNormalizationTransform, AKPDScorerNetwork\n",
    "from aquabyte.akpd import AKPD\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load base dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where keypoints is not null\n",
    "    and keypoints -> 'leftCrop' is not null\n",
    "    and keypoints -> 'rightCrop' is not null\n",
    "    limit 100;\n",
    "\"\"\"\n",
    "good_df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where is_partial = TRUE\n",
    "    limit 100;\n",
    "\"\"\"\n",
    "bad_df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run Inference </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_credentials = json.load(open(os.environ['AWS_CREDENTIALS']))\n",
    "akpd_scorer_network = torch.load('/root/data/alok/biomass_estimation/playground/akpd_scorer_model.pb')\n",
    "akpd = AKPD(aws_credentials)\n",
    "\n",
    "normalize_centered_2D_transform_akpd = NormalizeCentered2D(rotate=False, center=True)\n",
    "akpd_normalization_transform = AKPDNormalizationTransform()\n",
    "to_tensor_transform = ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame()\n",
    "for idx, row in good_df.iterrows():\n",
    "    row_to_append = {}\n",
    "    keypoints = row.keypoints\n",
    "    left_keypoints, right_keypoints = keypoints['leftCrop'], keypoints['rightCrop']\n",
    "    left_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in left_keypoints}\n",
    "    right_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in right_keypoints}\n",
    "    \n",
    "    # append disparity values\n",
    "    for bp in BODY_PARTS:\n",
    "        row_to_append['disp_{}'.format(bp)] = left_keypoints_dict[bp][1] - right_keypoints_dict[bp][1]\n",
    "    \n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': idx,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    \n",
    "    # append AKPD score\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_akpd.__call__(input_sample)\n",
    "\n",
    "    akpd_normalized_kps = akpd_normalization_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "    score = akpd_scorer_network(tensorized_kps['kp_input']).item()\n",
    "    row_to_append['score'] = score\n",
    "    row_to_append['is_good'] = True\n",
    "    analysis_df = analysis_df.append(row_to_append, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in bad_df.iterrows():\n",
    "    row_to_append = {}\n",
    "    left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "    akpd_keypoints = akpd.predict_keypoints(left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata)[0]\n",
    "    left_keypoints, right_keypoints = akpd_keypoints['leftCrop'], akpd_keypoints['rightCrop']\n",
    "    left_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in left_keypoints}\n",
    "    right_keypoints_dict = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in right_keypoints}\n",
    "    for bp in BODY_PARTS:\n",
    "        row_to_append['disp_{}'.format(bp)] = left_keypoints_dict[bp][1] - right_keypoints_dict[bp][1]\n",
    "        \n",
    "    # run AKPD scoring network\n",
    "    input_sample = {\n",
    "        'keypoints': akpd_keypoints,\n",
    "        'cm': row.camera_metadata,\n",
    "        'stereo_pair_id': idx,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    \n",
    "    # append AKPD score\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform_akpd.__call__(input_sample)\n",
    "\n",
    "    akpd_normalized_kps = akpd_normalization_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "    score = akpd_scorer_network(tensorized_kps['kp_input']).item()\n",
    "    row_to_append['score'] = score\n",
    "    row_to_append['is_good'] = False\n",
    "    analysis_df = analysis_df.append(row_to_append, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Compute Original Precision / Recall </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "good_mask = analysis_df.is_good == True\n",
    "predicted_good_mask = analysis_df.score > threshold\n",
    "recall = analysis_df[good_mask & predicted_good_mask].shape[0] / analysis_df[good_mask].shape[0]\n",
    "precision = analysis_df[good_mask & predicted_good_mask].shape[0] / analysis_df[predicted_good_mask].shape[0]\n",
    "print('Original Precision: {}'.format(precision))\n",
    "print('Original Recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Compute New Precision / Recall </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[~good_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(good_max_y_deviations, 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bp in BODY_PARTS:\n",
    "    print('{}: {}'.format(bp, np.percentile(np.abs(y_deviation_values[bp]), 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints, side='both', overlay_keypoints=True, show_labels=False):\n",
    "    assert side == 'left' or side == 'right' or side == 'both', \\\n",
    "        'Invalid side value: {}'.format(side)\n",
    "\n",
    "    if side == 'left' or side == 'right':\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        image_f = left_image_f if side == 'left' else right_image_f\n",
    "        keypoints = left_keypoints if side == 'left' else right_keypoints\n",
    "        image = plt.imread(image_f)\n",
    "        ax.imshow(image)\n",
    "\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in keypoints.items():\n",
    "                ax.scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    ax.annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "        left_image = plt.imread(left_image_f)\n",
    "        right_image = plt.imread(right_image_f)\n",
    "        axes[0].imshow(left_image)\n",
    "        axes[1].imshow(right_image)\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in left_keypoints.items():\n",
    "                axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "            for bp, kp in right_keypoints.items():\n",
    "                axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = bad_df.copy(deep=True)\n",
    "idx = 21\n",
    "left_crop_url, right_crop_url = tdf.left_image_url.iloc[idx], tdf.right_image_url.iloc[idx]\n",
    "left_crop_metadata, right_crop_metadata = tdf.left_crop_metadata.iloc[idx], tdf.right_crop_metadata.iloc[idx]\n",
    "left_image_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "right_image_f, _, _= s3_access_utils.download_from_url(right_crop_url)\n",
    "akpd_keypoints = akpd.predict_keypoints(left_crop_url, right_crop_url, left_crop_metadata, right_crop_metadata)[0]\n",
    "left_keypoints_list, right_keypoints_list = akpd_keypoints['leftCrop'], akpd_keypoints['rightCrop']\n",
    "left_keypoints = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in left_keypoints_list}\n",
    "right_keypoints = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in right_keypoints_list}\n",
    "display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints, show_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run AKPD scoring network\n",
    "input_sample = {\n",
    "#     'keypoints': akpd_keypoints[0],\n",
    "    'keypoints': akpd_keypoints,\n",
    "    'cm': tdf.camera_metadata.iloc[idx],\n",
    "    'stereo_pair_id': idx,\n",
    "    'single_point_inference': True\n",
    "}\n",
    "nomralized_centered_2D_kps = \\\n",
    "    normalize_centered_2D_transform_akpd.__call__(input_sample)\n",
    "\n",
    "akpd_normalized_kps = akpd_normalization_transform.__call__(nomralized_centered_2D_kps)\n",
    "tensorized_kps = to_tensor_transform.__call__(akpd_normalized_kps)\n",
    "score = akpd_scorer_network(tensorized_kps['kp_input']).item()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X_batch in enumerate(bad_dataloader_train):\n",
    "    if i == 2:\n",
    "        print(X_batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "X = X_batch['kp_input'].numpy().squeeze()\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.scatter(X[:, 2], X[:, 3])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
