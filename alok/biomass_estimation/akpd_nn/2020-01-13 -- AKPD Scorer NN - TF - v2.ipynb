{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from weight_estimation.utils import CameraMetadata, get_ann_from_keypoint_arrs, get_left_right_keypoint_arrs, normalize_left_right_keypoint_arrs\n",
    "from weight_estimation.body_parts import core_body_parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load base dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "    select * from keypoint_annotations\n",
    "    where keypoints is not null\n",
    "    and keypoints -> 'leftCrop' is not null\n",
    "    and keypoints -> 'rightCrop' is not null\n",
    "    limit 10000;\n",
    "\"\"\"\n",
    "df = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Construct \"good\" and \"bad\" class </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_COUNT_WIDTH = 4096\n",
    "\n",
    "\n",
    "def convert_to_akpd_nn_input(ann):\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(ann)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X = np.hstack([X_left_norm, X_right_norm]) / PIXEL_COUNT_WIDTH\n",
    "    return X\n",
    "\n",
    "\n",
    "def perturb_ann(ann, p_perturbation=0.2, min_magnitude=30, max_magnitude=200):\n",
    "    \n",
    "    left_keypoints, right_keypoints = ann['leftCrop'], ann['rightCrop']\n",
    "    perturbed_left_keypoints = []\n",
    "    \n",
    "    # pick body parts to perturb (at least one)\n",
    "    indices = []\n",
    "    while len(indices) == 0:\n",
    "        indices = [x for x in range(len(core_body_parts)) if (random.random() < p_perturbation)]\n",
    "    \n",
    "    # apply perturbation\n",
    "    perturbed_left_keypoints, perturbed_right_keypoints = [], []\n",
    "    for idx, _ in enumerate(left_keypoints):\n",
    "        left_item, right_item = left_keypoints[idx], right_keypoints[idx]\n",
    "        left_perturbation_x, right_perturbation_x, left_perturbation_y, right_perturbation_y = \\\n",
    "            0.0, 0.0, 0.0, 0.0\n",
    "        if idx in indices:\n",
    "            case = np.random.choice([0, 1, 2], 1).item()\n",
    "            if case == 0:\n",
    "                left_perturbation_x = np.random.normal(0, np.random.uniform(low=min_magnitude, high=max_magnitude))\n",
    "                right_perturbation_x = np.random.normal(0, np.random.uniform(low=min_magnitude, high=max_magnitude))\n",
    "                left_perturbation_y = np.random.normal(0, np.random.uniform(low=min_magnitude, high=max_magnitude))\n",
    "                right_perturbation_y = np.random.normal(0, np.random.uniform(low=min_magnitude, high=max_magnitude))\n",
    "            elif case == 1:\n",
    "                x_magnitude = np.random.uniform(low=min_magnitude, high=max_magnitude)\n",
    "                y_magnitude = np.random.uniform(low=min_magnitude, high=max_magnitude)\n",
    "                left_perturbation_x = np.random.normal(0, x_magnitude)\n",
    "                right_perturbation_x = np.random.normal(0, abs(x_magnitude + np.random.normal(0, 20)))\n",
    "                left_perturbation_y = np.random.normal(0, y_magnitude)\n",
    "                right_perturbation_y = np.random.normal(0, abs(y_magnitude + np.random.normal(0, 20)))\n",
    "            else:\n",
    "                k = list(range(len(core_body_parts)))\n",
    "                k.remove(idx)\n",
    "                random_idx = np.random.choice(k, 1).item()\n",
    "                left_perturbation_x = left_keypoints[random_idx]['xFrame'] - left_item['xFrame'] + np.random.normal(0, 20)\n",
    "                left_perturbation_y = left_keypoints[random_idx]['yFrame'] - left_item['yFrame'] + np.random.normal(0, 20)\n",
    "                right_perturbation_x = right_keypoints[random_idx]['xFrame'] - right_item['xFrame'] + np.random.normal(0, 20)\n",
    "                right_perturbation_y = right_keypoints[random_idx]['yFrame'] - right_item['yFrame'] + np.random.normal(0, 20)\n",
    "\n",
    "        perturbed_left_item = {\n",
    "            'keypointType': left_item['keypointType'],\n",
    "            'xFrame': left_item['xFrame'] + left_perturbation_x,\n",
    "            'yFrame': left_item['yFrame'] + left_perturbation_y\n",
    "        }\n",
    "\n",
    "        perturbed_right_item = {\n",
    "            'keypointType': right_item['keypointType'],\n",
    "            'xFrame': right_item['xFrame'] + right_perturbation_x,\n",
    "            'yFrame': right_item['yFrame'] + right_perturbation_y\n",
    "        }\n",
    "        \n",
    "        perturbed_left_keypoints.append(perturbed_left_item)\n",
    "        perturbed_right_keypoints.append(perturbed_right_item)\n",
    "\n",
    "    perturbed_keypoints = {\n",
    "        'leftCrop': perturbed_left_keypoints,\n",
    "        'rightCrop': perturbed_right_keypoints\n",
    "    }\n",
    "    \n",
    "    return perturbed_keypoints\n",
    "        \n",
    "\n",
    "\n",
    "X_good_arr, X_bad_arr = [], []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    # construct \"good\" class\n",
    "    ann = row.keypoints\n",
    "    \n",
    "    X_good = convert_to_akpd_nn_input(ann)\n",
    "    X_good_arr.append(X_good)\n",
    "    \n",
    "    # construct \"bad\" class\n",
    "    ann_bad = perturb_ann(ann)\n",
    "    X_bad = convert_to_akpd_nn_input(ann_bad)\n",
    "    X_bad_arr.append(X_bad)\n",
    "    \n",
    "\n",
    "X_good_arr = np.array(X_good_arr)\n",
    "X_bad_arr = np.array(X_bad_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_good_arr[6]\n",
    "plt.scatter(x[:, 0], x[:, 1], color='blue')\n",
    "plt.scatter(x[:, 2], x[:, 3], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create train / val split </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct = 0.8\n",
    "\n",
    "X_good_train = X_good_arr[:int(len(X_good_arr) * train_pct)]\n",
    "X_good_val = X_good_arr[int(len(X_good_arr) * train_pct):]\n",
    "X_bad_train = X_bad_arr[:int(len(X_bad_arr) * train_pct)]\n",
    "X_bad_val = X_bad_arr[int(len(X_bad_arr) * train_pct):]\n",
    "\n",
    "X_train = np.vstack([X_good_train, X_bad_train])\n",
    "y_train = np.array([1] * len(X_good_train) + [0] * len(X_bad_train))\n",
    "shuffle_idx = np.array(range(len(X_train)))\n",
    "np.random.shuffle(shuffle_idx)\n",
    "X_train = X_train[shuffle_idx]\n",
    "y_train = y_train[shuffle_idx]\n",
    "\n",
    "X_val = np.vstack([X_good_val, X_bad_val])\n",
    "y_val = np.array([1] * len(X_good_val) + [0] * len(X_bad_val))\n",
    "shuffle_idx = np.array(range(len(X_val)))\n",
    "np.random.shuffle(shuffle_idx)\n",
    "X_val = X_val[shuffle_idx]\n",
    "y_val = y_val[shuffle_idx]\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(len(X_train), -1)\n",
    "X_val = X_val.reshape(len(X_val), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32,))\n",
    "\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=30,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test on Real Examples </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints, side='both', overlay_keypoints=True, show_labels=False):\n",
    "    assert side == 'left' or side == 'right' or side == 'both', \\\n",
    "        'Invalid side value: {}'.format(side)\n",
    "\n",
    "    if side == 'left' or side == 'right':\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        image_f = left_image_f if side == 'left' else right_image_f\n",
    "        keypoints = left_keypoints if side == 'left' else right_keypoints\n",
    "        image = plt.imread(image_f)\n",
    "        ax.imshow(image)\n",
    "\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in keypoints.items():\n",
    "                ax.scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    ax.annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "        left_image = plt.imread(left_image_f)\n",
    "        right_image = plt.imread(right_image_f)\n",
    "        axes[0].imshow(left_image)\n",
    "        axes[1].imshow(right_image)\n",
    "        if overlay_keypoints:\n",
    "            for bp, kp in left_keypoints.items():\n",
    "                axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "            for bp, kp in right_keypoints.items():\n",
    "                axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "                if show_labels:\n",
    "                    axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "query = \"\"\"\n",
    "        select * from prod.biomass_computations\n",
    "        where pen_id=144 and captured_at >= '2020-12-27' and captured_at <= '2021-01-12';\n",
    "    \"\"\"\n",
    "tdf = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akpd_scores = []\n",
    "count = 0\n",
    "for idx, row in tdf.iterrows():\n",
    "    \n",
    "    ann = row.annotation\n",
    "    X = convert_to_akpd_nn_input(ann)\n",
    "    score = model.predict(np.array(X.reshape(-1, 32)))[0][0]\n",
    "    akpd_scores.append(score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf[(tdf.estimated_weight_g > 10000) & (tdf.akpd_score > 0.1) & (tdf.akpd_score < 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "left_image_url = tdf.left_crop_url.iloc[idx]\n",
    "right_image_url = tdf.right_crop_url.iloc[idx]\n",
    "left_image_f, _, _ = s3.download_from_url(left_image_url)\n",
    "right_image_f, _, _ = s3.download_from_url(right_image_url)\n",
    "\n",
    "ann = tdf.annotation.iloc[idx]\n",
    "left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['leftCrop']}\n",
    "right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['rightCrop']}\n",
    "\n",
    "display_crops(left_image_f, right_image_f, left_keypoints, right_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.akpd_score.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['left_crop_area'] = tdf.left_crop_metadata.apply(lambda x: x['width'] * x['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.left_crop_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.arange(7000, 16000, 500)\n",
    "for low_lca, high_lca in zip(weights, weights[1:]):\n",
    "    mask = (tdf.estimated_weight_g > low_lca) & (tdf.estimated_weight_g < high_lca) & (tdf.akpd_score > 0.01)\n",
    "    print(tdf[mask].akpd_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
