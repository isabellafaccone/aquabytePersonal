{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from filter_optimization.filter_optimization_task import generate_sampling_filters, extract_biomass_data, \\\n",
    "    NoDataException, SamplingFilter, generate_pm_base, PopulationMetricsBase, generate_filter_mask, get_dates_in_range, \\\n",
    "    find_optimal_filter, gen_pm_base\n",
    "from population_metrics.population_metrics_base import generate_pm_base, PopulationMetricsBase\n",
    "from population_metrics.confidence_metrics import compute_biomass_kpi, generate_distribution_consistency\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values\n",
    "from population_metrics.raw_metrics import get_raw_sample_size\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 167\n",
    "start_date = '2020-10-18'\n",
    "end_date = '2020-10-25'\n",
    "akpd_score_cutoff = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_biomass_data(pen_id, start_date, end_date, akpd_score_cutoff)\n",
    "start_hours = [0]\n",
    "end_hours = [24]\n",
    "kf_cutoffs = np.arange(0.8, 1.5, 0.005)\n",
    "# kf_cutoffs = [1.25]\n",
    "sampling_filters = generate_sampling_filters(start_hours, end_hours, kf_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics_for_pm_base(pm_base: PopulationMetricsBase, dates: List[str]) -> float:\n",
    "    \"\"\"Generates mean biomass KPI given a PopulationMetricsBase instance and dates to consider.\"\"\"\n",
    "\n",
    "    kpis, sample_sizes, weights = [], [], []\n",
    "    for date in dates:\n",
    "        sample_size = get_raw_sample_size(pm_base, date)\n",
    "#         biomass_kpi = compute_biomass_kpi(pm_base, date)\n",
    "        biomass_kpi = generate_distribution_consistency(pm_base, date)\n",
    "        sample_sizes.append(sample_size)\n",
    "        weights.append(generate_smart_avg_weight(pm_base, date))\n",
    "        kpis.append(biomass_kpi)\n",
    "\n",
    "    # compute sample-size weighted kpi and final smart average\n",
    "    kpis = np.array([k if k else np.nan for k in kpis])\n",
    "    sample_sizes = np.array([s if s else np.nan for s in sample_sizes])\n",
    "    mean_kpi = np.nansum(kpis * sample_sizes) / np.nansum(sample_sizes)\n",
    "    return mean_kpi, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_filter(df: pd.DataFrame, sampling_filters: List[SamplingFilter]) -> SamplingFilter:\n",
    "    \"\"\"Finds optimal filter given data-frame of raw biomass computations and different sampling filters. \"\"\"\n",
    "\n",
    "    analysis_data = defaultdict(list)\n",
    "    for sampling_filter in sampling_filters:\n",
    "        print('Start hour: {}, End hour: {}, KF cutoff: {}'.format(\n",
    "            sampling_filter.start_hour, sampling_filter.end_hour, sampling_filter.kf_cutoff\n",
    "        ))\n",
    "        pm_base = gen_pm_base(df, sampling_filter)\n",
    "\n",
    "        if pm_base:\n",
    "            unique_dates = sorted(df.date.unique().tolist())\n",
    "            dates = get_dates_in_range(unique_dates[0], unique_dates[-1])\n",
    "            mean_kpi, weights = generate_metrics_for_pm_base(pm_base, dates)\n",
    "            \n",
    "        else:\n",
    "            mean_kpi = None\n",
    "\n",
    "        # add to data\n",
    "        analysis_data['mean_kpi'].append(mean_kpi)\n",
    "        analysis_data['start_hour'].append(sampling_filter.start_hour)\n",
    "        analysis_data['end_hour'].append(sampling_filter.end_hour)\n",
    "        analysis_data['kf_cutoff'].append(sampling_filter.kf_cutoff)\n",
    "        analysis_data['final_weight'].append(weights[-1])\n",
    "        analysis_data['akpd_score_cutoff'].append(sampling_filter.akpd_score_cutoff)\n",
    "\n",
    "    analysis_df = pd.DataFrame(analysis_data)\n",
    "    best_sampling_filter_params = analysis_df.sort_values('mean_kpi', ascending=False).iloc[0]\n",
    "\n",
    "    best_sampling_filter = SamplingFilter(\n",
    "        start_hour=float(best_sampling_filter_params.start_hour),\n",
    "        end_hour=float(best_sampling_filter_params.end_hour),\n",
    "        kf_cutoff=float(best_sampling_filter_params.kf_cutoff),\n",
    "        akpd_score_cutoff=float(best_sampling_filter_params.akpd_score_cutoff)\n",
    "    )\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_df, best_sampling_filter = find_optimal_filter(df, sampling_filters)\n",
    "analysis_df = find_optimal_filter(df, sampling_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(analysis_df.kf_cutoff, analysis_df.mean_kpi)\n",
    "\n",
    "plt.xlabel('KF Cutoff')\n",
    "plt.ylabel('Sample size weighted KPI')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(analysis_df.kf_cutoff, analysis_df.final_weight)\n",
    "plt.xlabel('KF Cutoff')\n",
    "plt.ylabel('Sample size weighted KPI')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (analysis_df.start_hour == 7) & (analysis_df.end_hour == 15)\n",
    "analysis_df.sort_values('mean_kpi', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm_base = gen_pm_base(df, SamplingFilter(start_hour=0, end_hour=24, kf_cutoff=0.0, akpd_score_cutoff=0.99))\n",
    "weights, kfs = generate_smart_individual_values(pm_base, '2020-08-30', 3, True, True, 0.9)\n",
    "pm_base = gen_pm_base(df, SamplingFilter(start_hour=0, end_hour=24, kf_cutoff=1.3, akpd_score_cutoff=0.99))\n",
    "weights_2, kfs_2 = generate_smart_individual_values(pm_base, '2020-08-30', 3, True, True, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(weights, bins=50)\n",
    "# plt.hist(weights_2, bins=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - 5794*.84 / 4949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.hour >= 19) | (df.hour <= 3)\n",
    "plt.figure(figsize=(20, 10))\n",
    "# plt.hist(df[mask].estimated_k_factor.values, bins=20, color='blue', alpha=0.7)\n",
    "plt.hist(df[~mask].estimated_k_factor.values, bins=20, color='red', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_filter = SamplingFilter(start_hour=4, end_hour=18, kf_cutoff=0.0, akpd_score_cutoff=0.99)\n",
    "pm_base = gen_pm_base(df, sampling_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_smart_avg_weight(pm_base, '2020-08-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.random.normal(60, 30, 10000)\n",
    "speed_ratios = np.random.normal(1.0, 0.2, 10000)\n",
    "speeds = speed_ratios * lengths\n",
    "depths = np.random.normal(120, 50, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_lengths = []\n",
    "for i in range(1000):\n",
    "    p = max(min((1.04 * depths[i] - lengths[i]) / speeds[i], 1), 0.1)\n",
    "    adj_lengths.extend([lengths[i]] * int(100 * p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup\n",
    "rng = np.random.RandomState(0)  # Seed RNG for replicability\n",
    "n = 100  # Number of samples to draw\n",
    "\n",
    "# Generate data\n",
    "x = lengt\n",
    "y = rng.standard_t(df=5, size=n)  # Sample 2: Y ~ t(5)\n",
    "\n",
    "# Quantile-quantile plot\n",
    "plt.figure()\n",
    "plt.scatter(np.sort(x), np.sort(y))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adj_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array(lengths)\n",
    "test2 = np.array(adj_lengths)\n",
    "\n",
    "#Calculate quantiles\n",
    "test1.sort()\n",
    "quantile_levels1 = np.arange(len(test1),dtype=float)/len(test1)\n",
    "\n",
    "test2.sort()\n",
    "quantile_levels2 = np.arange(len(test2),dtype=float)/len(test2)\n",
    "\n",
    "#Use the smaller set of quantile levels to create the plot\n",
    "quantile_levels = quantile_levels2\n",
    "\n",
    "#We already have the set of quantiles for the smaller data set\n",
    "quantiles2 = test2\n",
    "\n",
    "#We find the set of quantiles for the larger data set using linear interpolation\n",
    "quantiles1 = np.interp(quantile_levels,quantile_levels1,test1)\n",
    "\n",
    "#Plot the quantiles to create the qq plot\n",
    "pylab.plot(quantiles1,quantiles2)\n",
    "\n",
    "#Add a reference line\n",
    "maxval = max(test1[-1],test2[-1])\n",
    "minval = min(test1[0],test2[0])\n",
    "pylab.plot([minval,maxval],[minval,maxval],'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
