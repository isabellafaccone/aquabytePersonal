{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from aquabyte.data_access_utils import S3AccessUtils\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akpd_data_f = s3_access_utils.download_from_s3('aquabyte-annotations', 'akpd/type=data/date=2019-06-01/group=VERIFIED/group=VERIFIED.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pq.ParquetDataset(akpd_data_f).read()\n",
    "df = data.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Construct Features </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    return np.linalg.norm(p1-p2)\n",
    "\n",
    "def get_left_right_keypoints(keypoints):\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in keypoints['leftCrop']:\n",
    "        left_keypoints[item['keypointType']] = (item['xFrame'], item['yFrame'])\n",
    "        \n",
    "    for item in keypoints['rightCrop']:\n",
    "        right_keypoints[item['keypointType']] = (item['xFrame'], item['yFrame'])\n",
    "        \n",
    "    return left_keypoints, right_keypoints\n",
    "\n",
    "body_parts = sorted([\n",
    "    'UPPER_LIP',\n",
    "    'TAIL_NOTCH',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'ADIPOSE_FIN',\n",
    "    'EYE',\n",
    "    'DORSAL_FIN',\n",
    "    'ANAL_FIN'\n",
    "])\n",
    "\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "sides, manhattan_errors = [], []\n",
    "pairwise_distance_values = defaultdict(list)\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "    \n",
    "    gt_keypoints = json.loads(row.keypoints.decode('utf8').replace(\"'\", '\"'))\n",
    "    gt_left_keypoints, gt_right_keypoints = get_left_right_keypoints(gt_keypoints)\n",
    "    \n",
    "    pred_keypoints = json.loads(row.akpd.decode('utf8').replace(\"'\", '\"'))\n",
    "    pred_left_keypoints, pred_right_keypoints = {}, {}\n",
    "    pred_left_keypoints, pred_right_keypoints = get_left_right_keypoints(pred_keypoints)\n",
    "    \n",
    "    manhattan_error = row.leftError\n",
    "    sides.append('left')\n",
    "    manhattan_errors.append(manhattan_error)\n",
    "    \n",
    "    manhattan_error = row.rightError\n",
    "    sides.append('right')\n",
    "    manhattan_errors.append(manhattan_error)\n",
    "    \n",
    "    # get predicted pairwise distances\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            bp1, bp2 = body_parts[i], body_parts[j]\n",
    "            dist_left = euclidean_distance(np.array(pred_left_keypoints[bp1]), \n",
    "                                           np.array(pred_left_keypoints[bp2]))\n",
    "            dist_left /= euclidean_distance(np.array(pred_left_keypoints['UPPER_LIP']), \n",
    "                                            np.array(pred_left_keypoints['TAIL_NOTCH']))\n",
    "            \n",
    "            \n",
    "            pairwise_distance_values['{}-{}'.format(bp1, bp2)].append(dist_left)\n",
    "            \n",
    "            dist_right = euclidean_distance(np.array(pred_right_keypoints[bp1]), np.array(pred_right_keypoints[bp2]))\n",
    "            dist_right /= euclidean_distance(np.array(pred_right_keypoints['UPPER_LIP']),\n",
    "                                             np.array(pred_right_keypoints['TAIL_NOTCH']))\n",
    "            \n",
    "            pairwise_distance_values['{}-{}'.format(bp1, bp2)].append(dist_right)\n",
    "            \n",
    "            \n",
    "features_df = pd.DataFrame({\n",
    "    'side': sides,\n",
    "    'manhattan_errors': manhattan_errors,\n",
    "})\n",
    "\n",
    "for k, v in dict(pairwise_distance_values).items():\n",
    "\n",
    "    features_df[k] = v\n",
    "            \n",
    "        \n",
    "\n",
    "# json.loads(df.keypoints.iloc[0].decode('utf8').replace(\"'\", '\"'))['leftCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(len(body_parts)-1):\n",
    "    for j in range(i+1, len(body_parts)):\n",
    "        features.append('{}-{}'.format(body_parts[i], body_parts[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = features_df[features].values, (features_df.manhattan_errors < 20).values.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, clf.decision_function(X_test))\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.4\n",
    "y_pred = (p_test[:, 1] > t).astype(int)\n",
    "print(y_pred[y_test == 1].sum()/y_test.sum())\n",
    "print(y_pred[y_test == 1].sum()/y_pred.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Two Layer Neural Network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import math\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_right_keypoints(keypoints):\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in keypoints['leftCrop']:\n",
    "        left_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "        \n",
    "    for item in keypoints['rightCrop']:\n",
    "        right_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "        \n",
    "    return left_keypoints, right_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(point, angle, origin=(0, 0)):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return qx, qy\n",
    "\n",
    "\n",
    "def normalize_keypoints(keypoints, origin_bp = 'TAIL_NOTCH'):\n",
    "    # translation\n",
    "    for bp in body_parts:\n",
    "        keypoints[bp] = keypoints[bp] - keypoints[origin_bp]\n",
    "        keypoints[bp][1] = -keypoints[bp][1]\n",
    "    \n",
    "    # rotation & compression\n",
    "    angle = np.arctan(keypoints['UPPER_LIP'][1] / keypoints['UPPER_LIP'][0])\n",
    "    for bp in body_parts:\n",
    "        keypoints[bp] = rotate(keypoints[bp], -angle)\n",
    "        keypoints[bp] = keypoints[bp] / np.linalg.norm(keypoints['UPPER_LIP'])\n",
    "        \n",
    "    return keypoints\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Construct dataset to feed to network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = sorted([\n",
    "    'UPPER_LIP',\n",
    "    'TAIL_NOTCH',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'ADIPOSE_FIN',\n",
    "    'EYE',\n",
    "    'DORSAL_FIN',\n",
    "    'ANAL_FIN'\n",
    "])\n",
    "\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "X_values, manhattan_errors = [], []\n",
    "counter = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "    \n",
    "    pred_keypoints = json.loads(row.akpd.decode('utf8').replace(\"'\", '\"'))\n",
    "    pred_left_keypoints, pred_right_keypoints = get_left_right_keypoints(pred_keypoints)\n",
    "    pred_norm_left_keypoints = normalize_keypoints(pred_left_keypoints)\n",
    "    pred_norm_right_keypoints = normalize_keypoints(pred_right_keypoints)\n",
    "    \n",
    "    coords = []\n",
    "    for bp in body_parts:\n",
    "        coords.append(pred_norm_left_keypoints[bp])\n",
    "    \n",
    "    X_values.append(coords)\n",
    "    manhattan_errors.append(row.leftError)\n",
    "    \n",
    "    coords = []\n",
    "    for bp in body_parts:\n",
    "        coords.append(pred_norm_right_keypoints[bp])\n",
    "    \n",
    "    X_values.append(coords)\n",
    "    manhattan_errors.append(row.rightError)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.swapaxes(np.array(X_values), 1, 2)\n",
    "# y = (np.array(manhattan_errors) < 10).astype(int)\n",
    "y = (np.array(manhattan_errors) < 20).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(2, 8))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(8, activation='relu')(inputs)\n",
    "x = Dense(24, activation='relu')(x)\n",
    "x = Dense(24, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/root/data/temp/akpd_scorer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(np.array([X_train[0],]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import math\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "class AKPDPredictionScorer(object):\n",
    "    \n",
    "    def __init__(self, model_f, body_parts):\n",
    "        self.model = load_model(model_f)\n",
    "        self.body_parts = sorted(body_parts)\n",
    "\n",
    "    def _get_left_right_keypoints(self, keypoints):\n",
    "        left_keypoints, right_keypoints = {}, {}\n",
    "        for item in keypoints['leftCrop']:\n",
    "            left_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "\n",
    "        for item in keypoints['rightCrop']:\n",
    "            right_keypoints[item['keypointType']] = np.array([item['xFrame'], item['yFrame']])\n",
    "\n",
    "        return left_keypoints, right_keypoints\n",
    "\n",
    "    \n",
    "    def _rotate(self, point, angle, origin=(0, 0)):\n",
    "        \"\"\"\n",
    "        Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "        The angle should be given in radians.\n",
    "        \"\"\"\n",
    "        ox, oy = origin\n",
    "        px, py = point\n",
    "\n",
    "        qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "        qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "        return qx, qy\n",
    "\n",
    "\n",
    "    def _normalize_keypoints(self, keypoints, origin_bp='TAIL_NOTCH'):\n",
    "        # translation\n",
    "        for bp in body_parts:\n",
    "            keypoints[bp] = keypoints[bp] - keypoints[origin_bp]\n",
    "            keypoints[bp][1] = -keypoints[bp][1]\n",
    "\n",
    "        # rotation & compression\n",
    "        angle = np.arctan(keypoints['UPPER_LIP'][1] / keypoints['UPPER_LIP'][0])\n",
    "        for bp in body_parts:\n",
    "            keypoints[bp] = self._rotate(keypoints[bp], -angle)\n",
    "            keypoints[bp] = keypoints[bp] / np.linalg.norm(keypoints['UPPER_LIP'])\n",
    "\n",
    "        return keypoints\n",
    "    \n",
    "    def _generate_one_side_score(self, coords):\n",
    "        X = np.array([coords, ])\n",
    "        X = np.swapaxes(X, 1, 2)\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "\n",
    "\n",
    "    def get_confidence_score(self, pred_keypoints):\n",
    "\n",
    "        pred_left_keypoints, pred_right_keypoints = self._get_left_right_keypoints(pred_keypoints)\n",
    "        pred_norm_left_keypoints = self._normalize_keypoints(pred_left_keypoints)\n",
    "        pred_norm_right_keypoints = self._normalize_keypoints(pred_right_keypoints)\n",
    "\n",
    "        coords_left, coords_right = [], []\n",
    "        for bp in self.body_parts:\n",
    "            coords_left.append(pred_norm_left_keypoints[bp])\n",
    "            coords_right.append(pred_norm_right_keypoints[bp])\n",
    "            \n",
    "        left_score = self._generate_one_side_score(coords_left)[0][0]\n",
    "        right_score = self._generate_one_side_score(coords_right)[0][0]\n",
    "        return min(left_score, right_score)\n",
    "\n",
    "    \n",
    "\n",
    "pred_keypoints = {\"version\": 2, \"leftCrop\": [{\"xCrop\": 58, \"yCrop\": 367, \"xFrame\": 382, \"yFrame\": 959, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 232, \"yCrop\": 345, \"xFrame\": 556, \"yFrame\": 937, \"keypointType\": \"EYE\"}, {\"xCrop\": 724, \"yCrop\": 70, \"xFrame\": 1048, \"yFrame\": 662, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 1255, \"yCrop\": 150, \"xFrame\": 1579, \"yFrame\": 742, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 1426, \"yCrop\": 209, \"xFrame\": 1750, \"yFrame\": 801, \"keypointType\": \"UPPER_PRECAUDAL_PIT\"}, {\"xCrop\": 1525, \"yCrop\": 275, \"xFrame\": 1849, \"yFrame\": 867, \"keypointType\": \"HYPURAL_PLATE\"}, {\"xCrop\": 1623, \"yCrop\": 283, \"xFrame\": 1947, \"yFrame\": 875, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 1430, \"yCrop\": 328, \"xFrame\": 1754, \"yFrame\": 920, \"keypointType\": \"LOWER_PRECAUDAL_PIT\"}, {\"xCrop\": 1187, \"yCrop\": 423, \"xFrame\": 1511, \"yFrame\": 1015, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 900, \"yCrop\": 484, \"xFrame\": 1224, \"yFrame\": 1076, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 466, \"yCrop\": 462, \"xFrame\": 790, \"yFrame\": 1054, \"keypointType\": \"PECTORAL_FIN\"}], \"rightCrop\": [{\"xCrop\": 21, \"yCrop\": 392, \"xFrame\": 83, \"yFrame\": 961, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 185, \"yCrop\": 363, \"xFrame\": 247, \"yFrame\": 932, \"keypointType\": \"EYE\"}, {\"xCrop\": 708, \"yCrop\": 78, \"xFrame\": 770, \"yFrame\": 647, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 1261, \"yCrop\": 171, \"xFrame\": 1323, \"yFrame\": 740, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 1462, \"yCrop\": 228, \"xFrame\": 1524, \"yFrame\": 797, \"keypointType\": \"UPPER_PRECAUDAL_PIT\"}, {\"xCrop\": 1538, \"yCrop\": 294, \"xFrame\": 1600, \"yFrame\": 863, \"keypointType\": \"HYPURAL_PLATE\"}, {\"xCrop\": 1645, \"yCrop\": 302, \"xFrame\": 1707, \"yFrame\": 871, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 1445, \"yCrop\": 345, \"xFrame\": 1507, \"yFrame\": 914, \"keypointType\": \"LOWER_PRECAUDAL_PIT\"}, {\"xCrop\": 1198, \"yCrop\": 443, \"xFrame\": 1260, \"yFrame\": 1012, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 901, \"yCrop\": 523, \"xFrame\": 963, \"yFrame\": 1092, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 414, \"yCrop\": 481, \"xFrame\": 476, \"yFrame\": 1050, \"keypointType\": \"PECTORAL_FIN\"}]}\n",
    "body_parts = sorted([\n",
    "    'UPPER_LIP',\n",
    "    'TAIL_NOTCH',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'ADIPOSE_FIN',\n",
    "    'EYE',\n",
    "    'DORSAL_FIN',\n",
    "    'ANAL_FIN'\n",
    "])\n",
    "\n",
    "f = '/root/data/temp/akpd_scorer_model.h5'\n",
    "aps = AKPDPredictionScorer(f, body_parts)\n",
    "aps.get_confidence_score(pred_keypoints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Plot Precision / Recall </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = model.predict(X_test).flatten()\n",
    "thresholds = np.arange(0.0, 0.86, 0.01)\n",
    "precisions, recalls = [], []\n",
    "for t in thresholds:\n",
    "    y_pred = (p_test >= t).astype(int)\n",
    "    recall = y_pred[y_test == 1].sum()/y_test.sum()\n",
    "    precision = y_pred[y_test == 1].sum()/y_pred.sum()\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(precisions, recalls)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Plot Prioritizer Performance </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Plot actual prioritizier performance </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cache = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_test_split(X, np.array(list(range(X.shape[0]))), test_size=0.33, random_state=0)[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = (np.array(manhattan_errors)[idx] < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test_cache.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1500\n",
    "\n",
    "\n",
    "scores = list(zip(p_test, y_test))\n",
    "sorted_by_score = list(reversed(sorted(scores, key=lambda x: x[0])))\n",
    "perfectly_sorted = list(reversed(sorted(scores, key=lambda x: x[1])))\n",
    "randomly_shuffled = shuffle(scores)\n",
    "\n",
    "cum_randomly_shuffled = np.cumsum(np.array([x[1] for x in randomly_shuffled]))\n",
    "cum_sorted_by_score = np.cumsum(np.array([x[1] for x in sorted_by_score]))\n",
    "cum_perfectly_sorted = np.cumsum(np.array([x[1] for x in perfectly_sorted]))\n",
    "                                \n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(cum_randomly_shuffled, color='r', label='AKPD Prioritizer Inactive')\n",
    "plt.plot(cum_sorted_by_score, color='b', label='AKPD Prioritizer Active')\n",
    "plt.plot(cum_perfectly_sorted, color='g', label='Perfect Theoretical Performance')\n",
    "\n",
    "plt.hlines(cutoff, 0, 16000, linestyles='dashed', label='Required daily good image count: 1500')\n",
    "\n",
    "plt.title('AKPD Prioritizer Performance')\n",
    "plt.xlabel('Number of images analyzed')\n",
    "plt.ylabel('Number of good AKPD predictions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cum_sorted_by_score == 1500)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
