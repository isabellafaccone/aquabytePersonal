{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKPD SageMaker Interface\n",
    "import boto3\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from aquabyte.optics import pixel2world\n",
    "\n",
    "# load config\n",
    "import json\n",
    "\n",
    "config_path = '/root/data/bati/model/config.json' \n",
    "checkpoint_path = '/root/data/bati/model/model.pb'\n",
    "config = json.load(open(config_path))\n",
    "\n",
    "class FLAGS(object):\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = config[\"cpm_stages\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    crop = config[\"crop\"]\n",
    "    augmentation = None\n",
    "    \n",
    "import csv\n",
    "# /root/data/depth_values_gt_eye_depth.csv\n",
    "# /root/data/depth_values.csv\n",
    "with open('/root/data/depth_values_gt_eye_depth.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            #data.append([row[50],row[51],row[52],row[53],row[54],row[62],row[43]])\n",
    "            data.append([row[50],row[51],row[52],row[53],row[54],row[64],row[43]])\n",
    "            line_count += 1\n",
    "#     print(line_count)\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\", region_name=\"eu-west-1\", aws_access_key_id=\"AKIAUFQLGRHU7YGONOQO\", aws_secret_access_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "sum=0\n",
    "results=[]\n",
    "kps_all=[]\n",
    "est_depth=[]\n",
    "for i in range(len(data)):\n",
    "    imL=data[i][0]\n",
    "    imR=data[i][1]\n",
    "    lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "    rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "    meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "    body='[{\"leftCropUrl\": \"'+imL+'\", \"rightCropUrl\": \"'+imR+'\", \"leftCropMetadata\": {\"x_coord\": '+str(lco['x_coord'])+', \"y_coord\": '+str(lco['y_coord'])+'}, \"rightCropMetadata\": {\"x_coord\": '+str(rco['x_coord'])+', \"y_coord\": '+str(rco['y_coord'])+'}, \"id\": \"1\"}]'\n",
    "    resp = client.invoke_endpoint(EndpointName='auto-keypoints', ContentType='application/json', Body=body)\n",
    "    kp=resp['Body'].read()\n",
    "    kps=json.loads(kp.decode(\"utf-8\"))\n",
    "    kps_all.append(kps)\n",
    "    wp=pixel2world(kps[0]['leftCrop'], kps[0]['rightCrop'], meta)\n",
    "    diff=abs(float(data[i][5])-float(wp['EYE'][1]))\n",
    "    print((i,len(data), diff*1000))\n",
    "    sum+=diff\n",
    "    results.append(diff)\n",
    "    est_depth.append(float(wp['EYE'][1]))\n",
    "# print(lco['x_coord'])\n",
    "# print(rco)\n",
    "# print(meta)\n",
    "# print(data[0][5])\n",
    "# print(wp['EYE'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(float(data[i][5]))\n",
    "# print(float(wp['EYE'][1]))\n",
    "# kps=json.loads(kp.decode(\"utf-8\"))\n",
    "# # l_keypoints = load_keypoints(kps[0]['leftCrop'], FLAGS)\n",
    "# # r_keypoints = load_keypoints(kps[0]['rightCrop'], FLAGS)\n",
    "\n",
    "# wp=pixel2world(kps[0]['leftCrop'], kps[0]['rightCrop'], meta)\n",
    "# print(data[0][5])\n",
    "# print(wp['EYE'][1])\n",
    "# print(sum/(i+1))\n",
    "# print(i)\n",
    "# print(sum)\n",
    "# print(results)\n",
    "# plt.hist(np.array(results),bins=100)\n",
    "# plt.show()\n",
    "# print(data[0][5])\n",
    "print(FLAGS.keypoints_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(l_keypoints)\n",
    "# print(r_keypoints)\n",
    "# print(meta)\n",
    "# print(kps[0]['leftCrop'])\n",
    "# print(wp)\n",
    "# print(data[0][6])\n",
    "# print(kps_all[0])\n",
    "# print(kps_all[1])\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints(annotation, FLAGS, xoff, yoff, gtdata, leftCrop):\n",
    "    \"\"\"from prediction load keypoints\"\"\"\n",
    "    keypoints = []\n",
    "    gtkeypoints = []\n",
    "    labels = []\n",
    "    for i in range(FLAGS.joints):\n",
    "        valueX = annotation[i]['xFrame']\n",
    "        valueY = annotation[i]['yFrame']\n",
    "        keypoints.append([int(valueX-xoff), int(valueY-yoff)])  \n",
    "        labels.append(annotation[i]['keypointType'])\n",
    "        if leftCrop==True:\n",
    "            for j in range(FLAGS.joints):\n",
    "                if annotation[i]['keypointType']==gtdata['leftCrop'][j]['keypointType']:\n",
    "                    valueX = gtdata['leftCrop'][j]['xFrame']\n",
    "                    valueY = gtdata['leftCrop'][j]['yFrame']\n",
    "                    gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                    # print((annotation[i]['keypointType'], gtdata['leftCrop'][j]['keypointType']))\n",
    "                    break\n",
    "        else:\n",
    "            for j in range(FLAGS.joints):\n",
    "                if annotation[i]['keypointType']==gtdata['rightCrop'][j]['keypointType']:\n",
    "                    valueX = gtdata['rightCrop'][j]['xFrame']\n",
    "                    valueY = gtdata['rightCrop'][j]['yFrame']\n",
    "                    gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                    # print((annotation[i]['keypointType'], gtdata['rightCrop'][j]['keypointType']))\n",
    "                    break\n",
    "    keypoints = np.array(keypoints) \n",
    "    gtkeypoints = np.array(gtkeypoints) \n",
    "    return keypoints, gtkeypoints, labels\n",
    "\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "mean_dists=[]\n",
    "for i in range(len(data)):\n",
    "    imL=data[i][0]\n",
    "    imR=data[i][1]\n",
    "    lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "    rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "    gtdata=json.loads(data[i][6].replace(\"'\", '\"'))\n",
    "    keypointsL, gtkeypointsL, labelsL = load_keypoints(kps_all[i][0]['leftCrop'], FLAGS, lco['x_coord'], lco['y_coord'], gtdata, True)\n",
    "    keypointsR, gtkeypointsR, labelsR = load_keypoints(kps_all[i][0]['rightCrop'], FLAGS, rco['x_coord'], rco['y_coord'], gtdata, False)\n",
    "#     imageL = url_to_image(imL)\n",
    "#     imageR = url_to_image(imR)\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.imshow(imageL)\n",
    "#     plt.scatter(gtkeypointsL[:, 0], gtkeypointsL[:, 1], c=\"b\")\n",
    "#     plt.scatter(keypointsL[:, 0], keypointsL[:, 1], c=\"r\")\n",
    "#     plt.show()\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.imshow(imageR)\n",
    "#     plt.scatter(gtkeypointsR[:, 0], gtkeypointsR[:, 1], c=\"b\")\n",
    "#     plt.scatter(keypointsR[:, 0], keypointsR[:, 1], c=\"r\")\n",
    "#     plt.show()\n",
    "    man_dists=[]\n",
    "    for c in range(FLAGS.joints):\n",
    "        pred_kp = keypointsL[c,:]\n",
    "        gt_kp = gtkeypointsL[c,:]\n",
    "        man_distL = np.sum(np.abs(pred_kp - gt_kp))\n",
    "        man_dists.append(man_distL)\n",
    "        # print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL, labelsL[c]))\n",
    "        pred_kp = keypointsR[c,:]\n",
    "        gt_kp = gtkeypointsR[c,:]\n",
    "        man_distR = np.sum(np.abs(pred_kp - gt_kp))\n",
    "        man_dists.append(man_distR)\n",
    "        # print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR, labelsR[c]))\n",
    "    mean_dists.append(np.mean(man_dists))\n",
    "    print(\"Mean error for frame {} of {} is {} with depth error {}mm\".format(i, len(data), mean_dists[i], results[i]*1000))\n",
    "\n",
    "print(\"Mean error for all data is {}\".format(np.mean(mean_dists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtdata=json.loads(data[i][6].replace(\"'\", '\"'))\n",
    "# print(keypointsL)\n",
    "# print(gtkeypointsL)\n",
    "# print(gtdata['leftCrop'][0]['keypointType'])\n",
    "# print(keypointsR)\n",
    "# print(gtkeypointsR)\n",
    "print(\"Mean Manhattan error for all data is {} and median is {}\".format(np.mean(mean_dists),np.median(mean_dists)))\n",
    "print(\"Mean Depth error for all data is {}mm and median is {}mm\".format(np.mean(results)*1000,np.median(results)*1000))\n",
    "res=np.array(results)*1000\n",
    "plt.hist(res,bins=100)\n",
    "plt.show()\n",
    "plt.hist(np.array(mean_dists),bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-production research code evaluation\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "from models.nets import fish_test\n",
    "from utils import cpm_utils\n",
    "import numpy as np\n",
    "\n",
    "config_path = '/root/data/bati/model/config.json' # config_4_stage.json # config_bak.json (for deployed May model) # config.json\n",
    "checkpoint_path = '/root/data/bati/model/model_199.pb' # all-hi-res=model_49.pb #fish_test-6' #model_6.pb' # 25/199 for Sept all # 99 for Sept # 20 for May\n",
    "\n",
    "config = json.load(open(config_path))\n",
    "print(config)\n",
    "\n",
    "class FLAGS(object):\n",
    "    stages = 3\n",
    "    crop = False    \n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    augmentation = None\n",
    "    \n",
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, input_map=None,\n",
    "                                return_elements=None,\n",
    "                                name=\"\",\n",
    "                                op_dict=None,\n",
    "                                producer_op_list=None)\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "        for t in graph_nodes:\n",
    "            print(t.name)\n",
    "        return graph\n",
    "\n",
    "mod=load_pb(checkpoint_path)\n",
    "print(mod)\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.graph.as_default()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tf_device = '/gpu:0'\n",
    "with tf.device(tf_device):\n",
    "    model = mod\n",
    "\n",
    "print(model)\n",
    "print(FLAGS.model_path)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from utils.utils import DataGenerator, load_image_keypoints\n",
    "\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def image_resize(image, FLAGS):\n",
    "    height, width, _ = image.shape\n",
    "    ratio_width = width / FLAGS.input_size[0]\n",
    "    ratio_height = height / FLAGS.input_size[1]\n",
    "    image = cv2.resize(image, FLAGS.input_size)\n",
    "    image  = image / 255.0 - 0.5\n",
    "    image = image[np.newaxis, ...]\n",
    "    return image\n",
    "\n",
    "def load_gt_keypoints(FLAGS, xoff, yoff, gtdata, left):\n",
    "    \"\"\"from gt load keypoints\"\"\"\n",
    "    gtkeypoints = []\n",
    "    for i in range(FLAGS.joints):\n",
    "        for j in range(FLAGS.joints):\n",
    "            if left==True and FLAGS.keypoints_order[i]==gtdata['leftCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['leftCrop'][j]['xFrame']\n",
    "                valueY = gtdata['leftCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "            elif left==False and FLAGS.keypoints_order[i]==gtdata['rightCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['rightCrop'][j]['xFrame']\n",
    "                valueY = gtdata['rightCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "    gtkeypoints = np.array(gtkeypoints) \n",
    "    return gtkeypoints\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "GOOD_PERC = 0.7\n",
    "sift = cv2.KAZE_create()\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "# # manhattan distance\n",
    "# man_dists=[]\n",
    "# for c in range(8):\n",
    "#     hm = cv2.resize(final_stage_heatmap[..., c], (width, height))\n",
    "#     hm_max = np.where(hm == hm.max())\n",
    "#     pred_kp = np.array([hm_max[1][0], hm_max[0][0]])\n",
    "#     gt_kp = np.array(keypoints[c, :], dtype=np.uint32)\n",
    "#     man_dist = np.sum(np.abs(pred_kp - gt_kp))\n",
    "#     man_dists.append(man_dist)\n",
    "#     print(\"Manhattan distance between pred and gt {} for {}\".format(man_dist, FLAGS.keypoints_order[c]))\n",
    "# print(np.mean(man_dists))\n",
    "    \n",
    "config['input_name']='input_placeholder:0'\n",
    "config['output_name']='stage_3/mid_conv7/BiasAdd:0'\n",
    "\n",
    "np2_sum=0\n",
    "np2_results=[]\n",
    "np2_kps_all=[]\n",
    "np2_est_depth=[]\n",
    "np2_mean_dists=[]\n",
    "np2_ind_dists=[[] for i in range(FLAGS.joints)]\n",
    "for i in range(len(data)):\n",
    "    imL=data[i][0]\n",
    "    imR=data[i][1]\n",
    "    lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "    rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "    meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "    gtdata=json.loads(data[i][6].replace(\"'\", '\"'))\n",
    "    gtkeypointsL = load_gt_keypoints(FLAGS, lco['x_coord'], lco['y_coord'], gtdata, True)\n",
    "    gtkeypointsR = load_gt_keypoints(FLAGS, rco['x_coord'], rco['y_coord'], gtdata, False)\n",
    "\n",
    "    imageL = url_to_image(imL)\n",
    "    heightL, widthL, _ = imageL.shape\n",
    "    img_input = image_resize(imageL, FLAGS)\n",
    "    with tf.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "    \n",
    "    imageR = url_to_image(imR)\n",
    "    heightR, widthR, _ = imageR.shape\n",
    "    img_input = image_resize(imageR, FLAGS)\n",
    "    with tf.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "    \n",
    "    # SIFT matching\n",
    "    img1 = enhance(imageL)\n",
    "    img2 = enhance(imageR)\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < GOOD_PERC*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>=MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "    \n",
    "#     img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,False)\n",
    "#     img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,True)\n",
    "#     alpha = 0.3  # Transparency factor.\n",
    "#     img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(img3)\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    " \n",
    "    man_dists=[]\n",
    "    kpL = []\n",
    "    kpR = []    \n",
    "    kpL2R = []\n",
    "    kpR2L = [] \n",
    "    im1ps = []\n",
    "    im2ps = []\n",
    "    gtL2R = []\n",
    "    gtR2L = [] \n",
    "    gt1ps = []\n",
    "    gt2ps = []\n",
    "    Hx=M\n",
    "    Hy=np.linalg.inv(M)\n",
    "    for c in range(FLAGS.joints):\n",
    "        hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "        hm_maxL = list(np.where(hm == hm.max()))   \n",
    "        kpL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "        ptx=np.array([kpL[c][0],kpL[c][1],1])\n",
    "        zx=np.dot(Hx,ptx)\n",
    "        kpL2R.append([int(zx[0]/zx[2]), int(zx[1]/zx[2])]) \n",
    "        gtx=np.array([gtkeypointsL[c][0],gtkeypointsL[c][1],1])\n",
    "        gzx=np.dot(Hx,gtx)\n",
    "        gtL2R.append([int(gzx[0]/gzx[2]), int(gzx[1]/gzx[2])]) \n",
    "#         gt_kp = gtkeypointsL[c,:]\n",
    "#         man_distL = np.sqrt(pow(hm_maxL[1][0] - gt_kp[0],2)+pow(hm_maxL[0][0] - gt_kp[1],2))\n",
    "#         man_dists.append(man_distL)\n",
    "#         print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL[0], FLAGS.keypoints_order[c]))\n",
    "        hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "        hm_maxR = np.where(hm == hm.max())\n",
    "        kpR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "        pty=np.array([kpR[c][0],kpR[c][1],1])\n",
    "        zy=np.dot(Hy,pty)\n",
    "        kpR2L.append([int(zy[0]/zy[2]), int(zy[1]/zy[2])]) \n",
    "        gty=np.array([gtkeypointsR[c][0],gtkeypointsR[c][1],1])\n",
    "        gzy=np.dot(Hy,gty)\n",
    "        gtR2L.append([int(gzy[0]/gzy[2]), int(gzy[1]/gzy[2])])\n",
    "#         gt_kp = gtkeypointsR[c,:]\n",
    "#         man_distR = np.sqrt(pow(hm_maxR[1][0] - gt_kp[0],2)+pow(hm_maxR[0][0] - gt_kp[1],2))\n",
    "#         man_dists.append(man_distR)\n",
    "#         print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR[0], FLAGS.keypoints_order[c]))\n",
    "\n",
    "#         np2_ind_dists[c].append((man_distL+man_distR)/2)\n",
    "    \n",
    "        im1ps.append([int((kpL[c][0]+kpR2L[c][0])/2), int((kpL[c][1]+kpR2L[c][1])/2)]) \n",
    "        im2ps.append([int((kpR[c][0]+kpL2R[c][0])/2), int((kpR[c][1]+kpL2R[c][1])/2)]) \n",
    "        gt1ps.append([int((gtkeypointsL[c][0]+gtR2L[c][0])/2), int((gtkeypointsL[c][1]+kpR2L[c][1])/2)]) \n",
    "        gt2ps.append([int((gtkeypointsR[c][0]+gtL2R[c][0])/2), int((gtkeypointsR[c][1]+gtL2R[c][1])/2)]) \n",
    "        man_distL = np.sqrt(pow(im1ps[c][0] - gt1ps[c][0],2) + pow(im1ps[c][1] - gt1ps[c][1],2))\n",
    "        man_dists.append(man_distL)\n",
    "        # print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL, FLAGS.keypoints_order[c]))\n",
    "        man_distR = np.sqrt(pow(im2ps[c][0] - gt2ps[c][0],2) + pow(im2ps[c][1] - gt2ps[c][1],2))\n",
    "        man_dists.append(man_distR)\n",
    "        # print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR, FLAGS.keypoints_order[c]))\n",
    "        np2_ind_dists[c].append((man_distL+man_distR)/2)  \n",
    "\n",
    "    np2_mean_dists.append(np.mean(man_dists))\n",
    "    kpL = np.array(kpL) \n",
    "    kpR = np.array(kpR) \n",
    "    kpL2R = np.array(kpL2R) \n",
    "    kpR2L = np.array(kpR2L)\n",
    "    im1ps = np.array(im1ps)\n",
    "    im2ps = np.array(im2ps)\n",
    "    gt1ps = np.array(gt1ps)\n",
    "    gt2ps = np.array(gt2ps)\n",
    "    print(\"Mean error for frame {} of {} is {}\".format(i, len(data), np2_mean_dists[i]))\n",
    "    \n",
    "#     height, width, _ = imageL.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(imageL)\n",
    "# #     plt.scatter(gtkeypointsL[:, 0], gtkeypointsL[:, 1], c=\"b\")\n",
    "# #     plt.scatter(kpL[:, 0], kpL[:, 1], c=\"r\")\n",
    "# #     plt.scatter(kpR2L[:, 0], kpR2L[:, 1], c=\"g\")\n",
    "#     plt.scatter(gt1ps[:, 0], gt1ps[:, 1], c=\"b\")\n",
    "#     plt.scatter(im1ps[:, 0], im1ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     height, width, _ = imageR.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(imageR)\n",
    "# #     plt.scatter(gtkeypointsR[:, 0], gtkeypointsR[:, 1], c=\"b\")\n",
    "# #     plt.scatter(kpR[:, 0], kpR[:, 1], c=\"r\")\n",
    "# #     plt.scatter(kpL2R[:, 0], kpL2R[:, 1], c=\"g\")\n",
    "#     plt.scatter(gt2ps[:, 0], gt2ps[:, 1], c=\"b\")\n",
    "#     plt.scatter(im2ps[:, 0], im2ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "print(\"Mean error for all data is {}\".format(np.mean(np2_mean_dists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Manhattan error for all data is {} and median is {}\".format(np.mean(np2_mean_dists),np.median(np2_mean_dists)))\n",
    "plt.hist(np.array(np2_mean_dists),bins=100)\n",
    "plt.show()\n",
    "for i in range(FLAGS.joints):\n",
    "    plt.hist(np.array(np2_ind_dists[i]),bins=100)\n",
    "    print(\"Error distribution for {}\".format(FLAGS.keypoints_order[i]))\n",
    "    plt.show()\n",
    "# print(kpL)\n",
    "# print(gtkeypointsL)\n",
    "# print(M)\n",
    "# print(np.linalg.inv(M))\n",
    "# ptx=np.array([kpL[0][0],kpL[1][0],1])\n",
    "# z=np.matmul(M,ptx)\n",
    "# print(M)\n",
    "# print(z)\n",
    "# print(z[0]/z[2])\n",
    "# print(kpL[:,0])\n",
    "# print(kpR2L[:,0])\n",
    "# print(kpL[:,1])\n",
    "# print(kpR2L[:,1])\n",
    "# print(len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(image, clip_limit=3):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n",
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "# f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "# ax.imshow(imageL)\n",
    "# ax.axis(\"off\")\n",
    "# plt.show()\n",
    "    \n",
    "img1 = enhance(imageL)\n",
    "img2 = enhance(imageR)\n",
    "\n",
    "# f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "# ax.imshow(img1)\n",
    "# ax.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.KAZE_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good)>=MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    \n",
    "#     h,w,_ = img1.shape\n",
    "#     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "#     dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "#     img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    matchesMask = None\n",
    "    \n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !pip3 install mpld3\n",
    "\n",
    "import mpld3\n",
    "# mpld3.disable_notebook()\n",
    "# mpld3.enable_notebook()\n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "# draw_params = dict(matchColor = (0,0,255), # draw matches in white color\n",
    "#                    singlePointColor = None,\n",
    "#                    matchesMask = matchesMask, # draw only inliers\n",
    "#                    flags = 4)\n",
    "# # print(draw_params)\n",
    "# img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "\n",
    "img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,False)\n",
    "img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,True)\n",
    "alpha = 0.3  # Transparency factor.\n",
    "img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(img3)\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "# mpld3.display(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def column(matrix, i):\n",
    "#     return [row[i] for row in matrix]\n",
    "\n",
    "# a=np_ind_dists\n",
    "# print(a)\n",
    "# print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# dill.dump_session('akpd_notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
