{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from research.weight_estimation.population_metrics import PopulationMetricsEstimator\n",
    "import json\n",
    "import os\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "\n",
    "import psycopg2\n",
    "import boto3\n",
    "from research.weight_estimation.population_metrics import PopulationMetricsEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCHEDULE_BY_PEN = {\n",
    "    88: (7, 16),\n",
    "    66: (0, 24),\n",
    "}\n",
    "\n",
    "\n",
    "def get_db_params_from_aws():\n",
    "#     ssm = boto3.client('ssm', region_name='eu-west-1')\n",
    "#     host_param = ssm.get_parameter(Name='/DW_DB_RO_HOST', WithDecryption=True)\n",
    "#     host = host_param['Parameter']['Value']\n",
    "\n",
    "#     user_param = ssm.get_parameter(Name='/DW_DB_RO_USER', WithDecryption=True)\n",
    "#     user = user_param['Parameter']['Value']\n",
    "\n",
    "#     password_param = ssm.get_parameter(Name='/DW_DB_RO_PASSWORD', WithDecryption=True)\n",
    "#     password = password_param['Parameter']['Value']\n",
    "\n",
    "#     dbname_param = ssm.get_parameter(Name='/DW_DB_RO_NAME', WithDecryption=True)\n",
    "#     dbname = dbname_param['Parameter']['Value']\n",
    "\n",
    "    credentials = json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS']))\n",
    "    host, user, password, dbname = credentials['host'], credentials['user'], credentials['password'], \\\n",
    "                                   credentials['database']\n",
    "\n",
    "    print(\"Successfully retrieved DB params.\")\n",
    "    return host, user, password, dbname\n",
    "\n",
    "\n",
    "def get_data_from_db(pen_id, dates_to_include, akpd_score_cutoff=0.99):\n",
    "\n",
    "    # get sampling schedule by pen ID (default to 24 hour sampling if pen not available)\n",
    "    if pen_id in SCHEDULE_BY_PEN.keys():\n",
    "        hour_start, hour_end = SCHEDULE_BY_PEN[pen_id]\n",
    "    else:\n",
    "        hour_start, hour_end = 0, 24\n",
    "\n",
    "    date_list = '({})'.format(\", \".join([f\"'{d}'\" for d in dates_to_include]))\n",
    "    print(\"Connecting to DB...\")\n",
    "\n",
    "    host, user, password, dbname = get_db_params_from_aws()\n",
    "\n",
    "    res = []\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\"dbname=\"+dbname+\" user=\"+user+\" host=\"+host+\" password=\"+password)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        query = \"SELECT\\\n",
    "                to_char(captured_at, 'YYYY-MM-DD') AS date,\\\n",
    "                estimated_weight_g, estimated_length_mm\\\n",
    "                FROM prod.biomass_computations\\\n",
    "                WHERE\\\n",
    "                to_char(captured_at, 'YYYY-MM-DD') IN {0}\\\n",
    "                AND date_part('hour', captured_at) BETWEEN {1} AND {2}\\\n",
    "                AND pen_id = {3}\\\n",
    "                AND group_id IN ('{3}')\\\n",
    "                AND akpd_score > {4}\\\n",
    "                AND estimated_weight_g > 0\\\n",
    "                AND estimated_weight_g != double precision 'NaN'\\\n",
    "                ORDER BY date DESC\".format(date_list, hour_start, hour_end, pen_id, akpd_score_cutoff)\n",
    "        print(query)\n",
    "\n",
    "        # execute statement\n",
    "        cur.execute(query)\n",
    "\n",
    "        # fetch rows\n",
    "        rows = cur.fetchall()\n",
    "        for row in rows:\n",
    "            res.append(row)\n",
    "\n",
    "        cur.close()\n",
    "    except psycopg2.DatabaseError as error:\n",
    "        print(error)\n",
    "        print(\"COULD NOT CONNECT TO DB\")\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "    print(f\"Successfully retrieved from DB: {len(res)} rows\")\n",
    "    return res\n",
    "\n",
    "\n",
    "# flask app\n",
    "application = api = Flask(__name__)\n",
    "application.add_url_rule('/', 'index', (lambda: \"hi\"))\n",
    "\n",
    "\n",
    "def process_bcs(biomass_computations):\n",
    "    new_bcs = []\n",
    "    for bc in biomass_computations:\n",
    "        date, weight, length = bc\n",
    "        estimated_k_factor = 1e5 * (weight / (length**3)) if (weight and length) else None\n",
    "        new_bcs.append((date, weight, estimated_k_factor))\n",
    "    new_bcs = sorted(new_bcs, key=lambda x: x[0])\n",
    "    return new_bcs\n",
    "\n",
    "\n",
    "def generate_smart_metrics(data):\n",
    "    pen_id = data['penId']\n",
    "    dates_to_compute = sorted(list(data['datesToCompute']))\n",
    "    dates_to_include = sorted(list(data['datesToInclude']))\n",
    "\n",
    "    resp = {}\n",
    "\n",
    "    # Get data from DB\n",
    "    biomass_computations = get_data_from_db(pen_id, dates_to_include)\n",
    "    if not biomass_computations:\n",
    "        return resp\n",
    "\n",
    "    biomass_computations = process_bcs(biomass_computations)\n",
    "\n",
    "    # If any dates to compute pre-date first available date in dates to include, return None\n",
    "    first_available_date = biomass_computations[0][0]\n",
    "    if not all([first_available_date <= date for date in dates_to_compute]):\n",
    "        print('DATE IS BEFORE CAMERA DATA!')\n",
    "        return resp\n",
    "\n",
    "    pme = PopulationMetricsEstimator(biomass_computations)\n",
    "    \n",
    "    for date in dates_to_compute:\n",
    "        metrics = pme.generate_smart_metrics_on_date(date,\n",
    "                                                     max_day_difference=3,\n",
    "                                                     incorporate_future=True,\n",
    "                                                     apply_growth_rate=True)\n",
    "\n",
    "        # smart_sample_size is np.int64. Quick workaround to make json happy.\n",
    "        smart_sample_size = int(metrics['smart_sample_size'])\n",
    "        resp_for_date = dict(\n",
    "            weightMovingAvg=metrics['smart_average_weight'],\n",
    "            weightMovingDist=metrics['smart_distribution'],\n",
    "            movingKFactor=metrics['smart_average_kf'],\n",
    "            dailyGrowthRate=metrics['growth_rate'],\n",
    "            numMovingAvgBatiFish=smart_sample_size\n",
    "        )\n",
    "        resp[date] = resp_for_date\n",
    "\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"penId\": 23,\n",
    "    \"datesToCompute\": [\n",
    "        \"2020-04-18\",\n",
    "        \"2020-04-19\",\n",
    "        \"2020-04-20\",\n",
    "        \"2020-04-21\",\n",
    "        \"2020-04-22\",\n",
    "        \"2020-04-23\",\n",
    "        \"2020-04-24\",\n",
    "        \"2020-04-25\",\n",
    "        \"2020-04-26\",\n",
    "        \"2020-04-27\",\n",
    "        \"2020-04-28\",\n",
    "        \"2020-04-29\",\n",
    "        \"2020-04-30\",\n",
    "        \"2020-05-01\",\n",
    "        \"2020-05-02\",\n",
    "        \"2020-05-03\",\n",
    "        \"2020-05-04\",\n",
    "        \"2020-05-05\",\n",
    "        \"2020-05-06\",\n",
    "        \"2020-05-07\",\n",
    "        \"2020-05-08\",\n",
    "        \"2020-05-09\",\n",
    "        \"2020-05-10\",\n",
    "        \"2020-05-11\",\n",
    "        \"2020-05-12\",\n",
    "        \"2020-05-13\",\n",
    "        \"2020-05-14\",\n",
    "        \"2020-05-15\",\n",
    "        \"2020-05-16\",\n",
    "        \"2020-05-17\",\n",
    "        \"2020-05-18\"\n",
    "    ],\n",
    "    \"datesToInclude\": [\n",
    "        \"2020-04-04\",\n",
    "        \"2020-04-05\",\n",
    "        \"2020-04-06\",\n",
    "        \"2020-04-07\",\n",
    "        \"2020-04-08\",\n",
    "        \"2020-04-09\",\n",
    "        \"2020-04-10\",\n",
    "        \"2020-04-11\",\n",
    "        \"2020-04-12\",\n",
    "        \"2020-04-13\",\n",
    "        \"2020-04-14\",\n",
    "        \"2020-04-15\",\n",
    "        \"2020-04-16\",\n",
    "        \"2020-04-17\",\n",
    "        \"2020-04-18\",\n",
    "        \"2020-04-19\",\n",
    "        \"2020-04-20\",\n",
    "        \"2020-04-21\",\n",
    "        \"2020-04-22\",\n",
    "        \"2020-04-23\",\n",
    "        \"2020-04-24\",\n",
    "        \"2020-04-25\",\n",
    "        \"2020-04-26\",\n",
    "        \"2020-04-27\",\n",
    "        \"2020-04-28\",\n",
    "        \"2020-04-29\",\n",
    "        \"2020-04-30\",\n",
    "        \"2020-05-01\",\n",
    "        \"2020-05-02\",\n",
    "        \"2020-05-03\",\n",
    "        \"2020-05-04\",\n",
    "        \"2020-05-05\",\n",
    "        \"2020-05-06\",\n",
    "        \"2020-05-07\",\n",
    "        \"2020-05-08\",\n",
    "        \"2020-05-09\",\n",
    "        \"2020-05-10\",\n",
    "        \"2020-05-11\",\n",
    "        \"2020-05-12\",\n",
    "        \"2020-05-13\",\n",
    "        \"2020-05-14\",\n",
    "        \"2020-05-15\",\n",
    "        \"2020-05-16\",\n",
    "        \"2020-05-17\",\n",
    "        \"2020-05-18\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DB...\n",
      "Successfully retrieved DB params.\n",
      "SELECT                to_char(captured_at, 'YYYY-MM-DD') AS date,                estimated_weight_g, estimated_length_mm                FROM prod.biomass_computations                WHERE                to_char(captured_at, 'YYYY-MM-DD') IN ('2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18')                AND date_part('hour', captured_at) BETWEEN 0 AND 24                AND pen_id = 23                AND group_id IN ('23')                AND akpd_score > 0.99                AND estimated_weight_g > 0                AND estimated_weight_g != double precision 'NaN'                ORDER BY date DESC\n",
      "Successfully retrieved from DB: 585 rows\n",
      "['2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-13', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'smart_sample_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8829d61b21e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_smart_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b4e8248c0ad3>\u001b[0m in \u001b[0;36mgenerate_smart_metrics\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# smart_sample_size is np.int64. Quick workaround to make json happy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0msmart_sample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smart_sample_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         resp_for_date = dict(\n\u001b[1;32m    129\u001b[0m             \u001b[0mweightMovingAvg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smart_average_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'smart_sample_size'"
     ]
    }
   ],
   "source": [
    "generate_smart_metrics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
