{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from research.weight_estimation.old.weight_estimator_old import NormalizeCentered2D, NormalizedStabilityTransform, ToTensor, Network\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/alok/biomass_estimation/playground/result_bolaks_pen_id_88_2020-02-10_2020-03-10.csv'\n",
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data transforms so that we can run inference with neural network\n",
    "normalize_centered_2D_transform = NormalizeCentered2D(center=False)\n",
    "normalized_stability_transform = NormalizedStabilityTransform()\n",
    "to_tensor_transform = ToTensor()\n",
    "\n",
    "# Get neural network weights from sample training\n",
    "\n",
    "model_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2019-11-08T00-13-09/nn_epoch_798.pb'\n",
    "model_f, _, _ = s3_access_utils.download_from_url(model_url)\n",
    "torch.load(model_f)\n",
    "\n",
    "weight_predictions = []\n",
    "for idx, row in df.head(1).iterrows():\n",
    "    keypoints = json.loads(row.annotation.replace(\"'\", '\"'))\n",
    "    cm = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "    nomralized_centered_2D_kps = \\\n",
    "        normalize_centered_2D_transform.__call__(input_sample)\n",
    "\n",
    "    normalized_stability_kps = normalized_stability_transform.__call__(nomralized_centered_2D_kps)\n",
    "    tensorized_kps = to_tensor_transform.__call__(normalized_stability_kps)\n",
    "    weight_prediction = network(tensorized_kps['kp_input']).item() * 1e4\n",
    "    weight_predictions.append(weight_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.estimated_weight_g.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorized_kps['kp_input'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomralized_centered_2D_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_stability_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedStabilityTransform(object):\n",
    "    \"\"\"\n",
    "        Transforms world keypoints into a more stable coordinate system - this will lead to better\n",
    "        training / convergence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        modified_kps, label, stereo_pair_id, cm = \\\n",
    "            sample['modified_kps'], sample['label'], sample['stereo_pair_id'], sample['cm']\n",
    "        modified_wkps = pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)\n",
    "        print(modified_wkps)\n",
    "        stabilized_coordinates = {}\n",
    "        for bp in BODY_PARTS:\n",
    "            wkp = modified_wkps[bp]\n",
    "            stabilized_kp_info = [0.5 * wkp[0]/wkp[1], 0.5 * wkp[2]/wkp[1], 0.5 * 0.1/wkp[1]]\n",
    "            stabilized_coordinates[bp] = stabilized_kp_info\n",
    "            \n",
    "        normalized_label = label * 1e-4 if label else None\n",
    "        \n",
    "        transformed_sample = {\n",
    "            'kp_input': stabilized_coordinates,\n",
    "            'label': normalized_label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "\n",
    "def convert_to_world_point(x, y, d, parameters):\n",
    "    \"\"\" from pixel coordinates to world coordinates \"\"\"\n",
    "    # get relevant parameters\n",
    "    pixel_count_width = parameters[\"pixelCountWidth\"]\n",
    "    pixel_count_height = parameters[\"pixelCountHeight\"]\n",
    "    sensor_width = parameters[\"imageSensorWidth\"]\n",
    "    sensor_height = parameters[\"imageSensorHeight\"]\n",
    "    focal_length = parameters[\"focalLength\"]\n",
    "\n",
    "    image_center_x = pixel_count_width / 2.0\n",
    "    image_center_y = pixel_count_height / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "    print(px_x, px_z)\n",
    "\n",
    "    sensor_x = px_x * (sensor_width / pixel_count_width)\n",
    "    sensor_z = px_z * (sensor_height / pixel_count_height)\n",
    "\n",
    "    # now move to world coordinates\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "    return np.array([world_x, world_y, world_z])\n",
    "\n",
    "\n",
    "def depth_from_disp(disp, parameters):\n",
    "    \"\"\" calculate the depth of the point based on the disparity value \"\"\"\n",
    "    focal_length_pixel = parameters[\"focalLengthPixel\"]\n",
    "\n",
    "    baseline = parameters[\"baseline\"]\n",
    "    depth = focal_length_pixel * baseline / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "\n",
    "def pixel2world(left_crop, right_crop, parameters):\n",
    "    \"\"\"2D pixel coordinates to 3D world coordinates\"\"\"\n",
    "\n",
    "    # first create a dic with crop keypoints\n",
    "    image_coordinates = {\"leftCrop\": {},\n",
    "                         \"rightCrop\": {}}\n",
    "    for keypoint in left_crop:\n",
    "        name = keypoint[\"keypointType\"]\n",
    "        image_coordinates[\"leftCrop\"][name] = [keypoint[\"xFrame\"], keypoint[\"yFrame\"]]\n",
    "    for keypoint in right_crop:\n",
    "        name = keypoint[\"keypointType\"]\n",
    "        image_coordinates[\"rightCrop\"][name] = [keypoint[\"xFrame\"], keypoint[\"yFrame\"]]\n",
    "\n",
    "    # then loop through the right crop keypoints and calculate the world coordinates\n",
    "    world_coordinates = {}\n",
    "    for keypoint in left_crop:\n",
    "        name = keypoint[\"keypointType\"]\n",
    "        disparity = image_coordinates[\"leftCrop\"][name][0] - image_coordinates[\"rightCrop\"][name][0]\n",
    "        depth = depth_from_disp(disparity, parameters)\n",
    "        world_point = convert_to_world_point(image_coordinates[\"leftCrop\"][name][0],\n",
    "                                             image_coordinates[\"leftCrop\"][name][1],\n",
    "                                             depth,\n",
    "                                             parameters)\n",
    "        world_coordinates[name] = world_point\n",
    "    return world_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "\n",
    "BODY_PARTS = sorted([\n",
    "    'ADIPOSE_FIN',\n",
    "    'ANAL_FIN',\n",
    "    'DORSAL_FIN',\n",
    "    'EYE',\n",
    "    'PECTORAL_FIN',\n",
    "    'PELVIC_FIN',\n",
    "    'TAIL_NOTCH',\n",
    "    'UPPER_LIP'\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class NormalizeCentered2D(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Transforms the 2D left and right keypoints such that:\n",
    "        (1) The center of the left image 2D keypoints is located at the center of the left image\n",
    "            (i.e. 2D translation)\n",
    "        (2) The left image keypoints are possibly flipped such that the upper-lip x-coordinate \n",
    "            is greater than the tail-notch coordinate. This is done to reduce the total number of \n",
    "            spatial orientations the network must learn from -> reduces the training size\n",
    "        (3) The left image keypoints are then rotated such that upper-lip is located on the x-axis.\n",
    "            As in (2), this is done to reduce the total number of spatial orientations the network \n",
    "            must learn from -> reduces the training size\n",
    "        (4) Rescale all left image keypoints by some random number between 'lo' and 'hi' args\n",
    "        (5) Apply Gaussian random noise \"jitter\" to each keypoint to mimic annotation error\n",
    "        (5) For all transformations above, the right image keypoint coordinates are accordingly\n",
    "            transformed such that the original disparity values are preserved for all keypoints\n",
    "            (or adjusted during rescaling event)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def flip_center_kps(self, left_kps, right_kps):\n",
    "\n",
    "        x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "        x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "        x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "\n",
    "        y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "        y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "        y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "\n",
    "        x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "        x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "        x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "\n",
    "        y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "        y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "        y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "\n",
    "        fc_left_kps, fc_right_kps = {}, {}\n",
    "        flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            if flip_factor > 0:\n",
    "                fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "                fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "            else:\n",
    "                fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "                fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "            fc_left_kps[bp] = fc_left_kp\n",
    "            fc_right_kps[bp] = fc_right_kp\n",
    "\n",
    "        return fc_left_kps, fc_right_kps\n",
    "\n",
    "\n",
    "    def _rotate_cc(self, p, theta):\n",
    "        R = np.array([\n",
    "            [np.cos(theta), -np.sin(theta)],\n",
    "            [np.sin(theta), np.cos(theta)]\n",
    "        ])\n",
    "\n",
    "        rotated_kp = np.dot(R, p)\n",
    "        return rotated_kp\n",
    "\n",
    "\n",
    "    def rotate_kps(self, left_kps, right_kps):\n",
    "        upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "        theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "        r_left_kps, r_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            rotated_kp = self._rotate_cc(left_kps[bp], -theta)\n",
    "            r_left_kps[bp] = rotated_kp\n",
    "            disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "            r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "\n",
    "        return r_left_kps, r_right_kps\n",
    "\n",
    "\n",
    "    def scale_kps(self, left_kps, right_kps, factor):\n",
    "        s_left_kps, s_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "            s_left_kps[bp] = factor * np.array(left_kps[bp])\n",
    "            s_right_kps[bp] = factor * np.array(right_kps[bp])\n",
    "\n",
    "        return s_left_kps, s_right_kps\n",
    "\n",
    "\n",
    "    def jitter_kps(self, left_kps, right_kps, jitter):\n",
    "        j_left_kps, j_right_kps = {}, {}\n",
    "        for bp in BODY_PARTS:\n",
    "            j_left_kps[bp] = np.array([left_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                       left_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "            j_right_kps[bp] = np.array([right_kps[bp][0] + np.random.normal(0, jitter), \n",
    "                                        right_kps[bp][1] + np.random.normal(0, jitter)])\n",
    "\n",
    "        return j_left_kps, j_right_kps\n",
    "\n",
    "\n",
    "\n",
    "    def modify_kps(self, left_kps, right_kps, factor, jitter, cm, rotate=True, center=False):\n",
    "        fc_left_kps, fc_right_kps = self.flip_center_kps(left_kps, right_kps)\n",
    "        if rotate:\n",
    "            r_left_kps, r_right_kps = self.rotate_kps(fc_left_kps, fc_right_kps)\n",
    "            s_left_kps, s_right_kps = self.scale_kps(r_left_kps, r_right_kps, factor)\n",
    "        else:\n",
    "            s_left_kps, s_right_kps = self.scale_kps(fc_left_kps, fc_right_kps, factor)\n",
    "        j_left_kps, j_right_kps  = self.jitter_kps(s_left_kps, s_right_kps, jitter)\n",
    "        j_left_kps_list, j_right_kps_list = [], []\n",
    "        if not center:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "                    'yFrame': j_right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "        else:\n",
    "            for bp in BODY_PARTS:\n",
    "                l_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_left_kps[bp][0],\n",
    "                    'yFrame': j_left_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                r_item = {\n",
    "                    'keypointType': bp,\n",
    "                    'xFrame': j_right_kps[bp][0],\n",
    "                    'yFrame': j_right_kps[bp][1]\n",
    "                }\n",
    "\n",
    "                j_left_kps_list.append(l_item)\n",
    "                j_right_kps_list.append(r_item)\n",
    "\n",
    "\n",
    "        modified_kps = {\n",
    "            'leftCrop': j_left_kps_list,\n",
    "            'rightCrop': j_right_kps_list\n",
    "        }\n",
    "\n",
    "        return modified_kps\n",
    "\n",
    "    \n",
    "    def __init__(self, lo=None, hi=None, jitter=0.0, rotate=True, center=False):\n",
    "        self.lo = lo\n",
    "        self.hi = hi\n",
    "        self.jitter = jitter\n",
    "        self.rotate = rotate\n",
    "        self.center = center\n",
    "    \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        keypoints, cm, stereo_pair_id, label = \\\n",
    "            sample['keypoints'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "        left_keypoints_list = keypoints['leftCrop']\n",
    "        right_keypoints_list = keypoints['rightCrop']\n",
    "        left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "        right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}\n",
    "        \n",
    "        factor = 1.0 \n",
    "        if self.lo and self.hi:\n",
    "            factor = np.random.uniform(low=self.lo, high=self.hi)\n",
    "            \n",
    "        jitter = np.random.uniform(high=self.jitter)\n",
    "        \n",
    "        modified_kps = self.modify_kps(left_kps, right_kps, factor, jitter, cm, \n",
    "            rotate=self.rotate, center=self.center)\n",
    "\n",
    "        kp_input = {}\n",
    "        for idx, _ in enumerate(modified_kps['leftCrop']):\n",
    "            left_item, right_item = modified_kps['leftCrop'][idx], modified_kps['rightCrop'][idx]\n",
    "            bp = left_item['keypointType']\n",
    "            kp_input[bp] = [left_item['xFrame'], left_item['yFrame'], right_item['xFrame'], right_item['yFrame']]\n",
    "\n",
    "\n",
    "        transformed_sample = {\n",
    "            'kp_input': kp_input,\n",
    "            'modified_kps': modified_kps,\n",
    "            'label': label,\n",
    "            'stereo_pair_id': stereo_pair_id,\n",
    "            'cm': cm,\n",
    "            'single_point_inference': sample.get('single_point_inference')\n",
    "        }\n",
    "        \n",
    "        return transformed_sample\n",
    "        \n",
    "\n",
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        kp_input, label, stereo_pair_id = \\\n",
    "            sample['kp_input'], sample.get('label'), sample.get('stereo_pair_id')\n",
    "        \n",
    "        x = []\n",
    "        for bp in BODY_PARTS:\n",
    "            kp_data = kp_input[bp]\n",
    "            x.append(kp_data)\n",
    "        if sample.get('single_point_inference'):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        kp_input_tensor = torch.from_numpy(x).float()\n",
    "        \n",
    "        tensorized_sample = {\n",
    "            'kp_input': kp_input_tensor\n",
    "        }\n",
    "\n",
    "        if label:\n",
    "            label_tensor = torch.from_numpy(np.array([label])).float() if label else None\n",
    "            tensorized_sample['label'] = label_tensor\n",
    "\n",
    "        if stereo_pair_id:\n",
    "            tensorized_sample['stereo_pair_id'] = stereo_pair_id\n",
    "\n",
    "\n",
    "        \n",
    "        return tensorized_sample\n",
    "        \n",
    "\n",
    "class KeypointsDataset(Dataset):\n",
    "    \"\"\"Keypoints dataset\n",
    "\n",
    "    This is the base version of the dataset that is used to map 3D keypoints to a\n",
    "    biomass estimate. The label is the weight, and the input is the 3D workd keypoints\n",
    "    obtained during triangulation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.transform:\n",
    "            input_sample = {\n",
    "                'keypoints': row.keypoints,\n",
    "                'cm': row.camera_metadata,\n",
    "                'stereo_pair_id': row.id,\n",
    "            }\n",
    "            if 'weight' in dict(row).keys():\n",
    "                input_sample['label'] = row.weight\n",
    "            sample = self.transform(input_sample)\n",
    "            return sample\n",
    "\n",
    "        world_keypoints = row.world_keypoints\n",
    "        weight = row.weight\n",
    "\n",
    "        sample = {'kp_input': world_keypoints, 'label': weight, 'stereo_pair_id': row.id}\n",
    "\n",
    "        return sample\n",
    "\n",
    "def main():\n",
    "\n",
    "    # load some data\n",
    "    rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "    query = \"\"\"\n",
    "        select * from keypoint_annotations \n",
    "        where pen_id=61 and captured_at >= '2019-09-13' and captured_at <= '2019-09-20'\n",
    "        and keypoints is not null\n",
    "        order by captured_at\n",
    "        limit 10;\n",
    "    \"\"\"\n",
    "    df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "    # initialize data transforms so that we can run inference with neural network\n",
    "    normalize_centered_2D_transform = NormalizeCentered2D()\n",
    "    to_tensor_transform = ToTensor()\n",
    "\n",
    "\n",
    "    # create dataset and dataloader\n",
    "    dataset = KeypointsDataset(df, transform=transforms.Compose([\n",
    "                                            NormalizeCentered2D(lo=0.3, hi=2.0, jitter=10, center=True),\n",
    "                                            ToTensor()\n",
    "                                         ]))\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=1)\n",
    "    for X_batch in dataloader:\n",
    "        print(X_batch['kp_input'])\n",
    "        print(X_batch['stereo_pair_id'])\n",
    "        break\n",
    "\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': cm,\n",
    "        'stereo_pair_id': row.id,\n",
    "        'single_point_inference': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints, cm, stereo_pair_id, label = \\\n",
    "            sample['keypoints'], sample['cm'], sample.get('stereo_pair_id'), sample.get('label')\n",
    "left_keypoints_list = keypoints['leftCrop']\n",
    "right_keypoints_list = keypoints['rightCrop']\n",
    "left_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in left_keypoints_list}\n",
    "right_kps = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in right_keypoints_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_center_kps(left_kps, right_kps):\n",
    "\n",
    "    x_min_l = min([kp[0] for kp in left_kps.values()])\n",
    "    x_max_l = max([kp[0] for kp in left_kps.values()])\n",
    "    x_mid_l = np.mean([x_min_l, x_max_l])\n",
    "\n",
    "    y_min_l = min([kp[1] for kp in left_kps.values()])\n",
    "    y_max_l = max([kp[1] for kp in left_kps.values()])\n",
    "    y_mid_l = np.mean([y_min_l, y_max_l])\n",
    "\n",
    "    x_min_r = min([kp[0] for kp in right_kps.values()])\n",
    "    x_max_r = max([kp[0] for kp in right_kps.values()])\n",
    "    x_mid_r = np.mean([x_min_r, x_max_r])\n",
    "\n",
    "    y_min_r = min([kp[1] for kp in right_kps.values()])\n",
    "    y_max_r = max([kp[1] for kp in right_kps.values()])\n",
    "    y_mid_r = np.mean([y_min_r, y_max_r])\n",
    "    \n",
    "    print(x_mid_r)\n",
    "    print(y_mid_r)\n",
    "\n",
    "    fc_left_kps, fc_right_kps = {}, {}\n",
    "    flip_factor = 1 if left_kps['UPPER_LIP'][0] > left_kps['TAIL_NOTCH'][0] else -1\n",
    "    for bp in BODY_PARTS:\n",
    "        left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "        if flip_factor > 0:\n",
    "            fc_left_kp = np.array([left_kp[0] - x_mid_l, left_kp[1] - y_mid_l])\n",
    "            fc_right_kp = np.array([right_kp[0] - x_mid_l, right_kp[1] - y_mid_l])\n",
    "        else:\n",
    "            fc_right_kp = np.array([x_mid_r - left_kp[0], left_kp[1] - y_mid_r])\n",
    "            fc_left_kp = np.array([x_mid_r - right_kp[0], right_kp[1] - y_mid_r])\n",
    "        fc_left_kps[bp] = fc_left_kp\n",
    "        fc_right_kps[bp] = fc_right_kp\n",
    "\n",
    "    return fc_left_kps, fc_right_kps\n",
    "\n",
    "def _rotate_cc(p, theta):\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    rotated_kp = np.dot(R, p)\n",
    "    return rotated_kp\n",
    "\n",
    "\n",
    "def rotate_kps(left_kps, right_kps):\n",
    "    upper_lip_x, upper_lip_y = left_kps['UPPER_LIP']\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    print(theta)\n",
    "    r_left_kps, r_right_kps = {}, {}\n",
    "    for bp in BODY_PARTS:\n",
    "        rotated_kp = _rotate_cc(left_kps[bp], -theta)\n",
    "        r_left_kps[bp] = rotated_kp\n",
    "        disp = abs(left_kps[bp][0] - right_kps[bp][0])\n",
    "        r_right_kps[bp] = np.array([rotated_kp[0] - disp, rotated_kp[1]])\n",
    "\n",
    "    return r_left_kps, r_right_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_center_kps(left_kps, right_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = flip_center_kps(left_kps, right_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kps, right_kps = rotate_kps(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kps_list = []\n",
    "right_kps_list = []\n",
    "for bp in BODY_PARTS:\n",
    "    l_item = {\n",
    "        'keypointType': bp,\n",
    "        'xFrame': left_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "        'yFrame': left_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "    }\n",
    "\n",
    "    r_item = {\n",
    "        'keypointType': bp,\n",
    "        'xFrame': right_kps[bp][0] + cm['pixelCountWidth'] / 2.0,\n",
    "        'yFrame': right_kps[bp][1] + cm['pixelCountHeight'] / 2.0\n",
    "    }\n",
    "\n",
    "    left_kps_list.append(l_item)\n",
    "    right_kps_list.append(r_item)\n",
    "\n",
    "modified_kps = {\n",
    "    'leftCrop': left_kps_list,\n",
    "    'rightCrop': right_kps_list\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel2world(modified_kps['leftCrop'], modified_kps['rightCrop'], cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
