{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Template Matching - Normalized Cross Correlation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer\n",
    "from aquabyte.template_matching import enhance\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import defaultdict\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sample dataset\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM keypoint_annotations\n",
    "    WHERE pen_id = 56\n",
    "    AND keypoints -> 'leftCrop' is not null\n",
    "    AND keypoints -> 'rightCrop' is not null\n",
    "    limit 1000;\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize some keypoint annotations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(s3_access_utils, rds_access_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_annotation_id = int(df.id.iloc[0])\n",
    "v.load_data(keypoint_annotation_id)\n",
    "v.display_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Attempt ADIPOSE_FIN correction via normalized cross correlation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part = 'EYE'\n",
    "half_box_size = 25\n",
    "horizontal_search_range = 30\n",
    "vertical_search_range = 5\n",
    "\n",
    "# download left and right crops\n",
    "mask = df.id == keypoint_annotation_id\n",
    "left_crop_url = df[mask].left_image_url.iloc[0]\n",
    "left_crop_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "left_crop_image = Image.open(left_crop_f)\n",
    "left_crop_arr = enhance(np.array(left_crop_image))\n",
    "\n",
    "right_crop_url = df[mask].right_image_url.iloc[0]\n",
    "right_crop_f, _, _ = s3_access_utils.download_from_url(right_crop_url)\n",
    "right_crop_image = Image.open(right_crop_f)\n",
    "right_crop_arr = enhance(np.array(right_crop_image))\n",
    "\n",
    "# get keypoint coordinates\n",
    "keypoints = df[mask].keypoints.iloc[0]\n",
    "left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['leftCrop']}\n",
    "right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['rightCrop']}\n",
    "\n",
    "# jitter keypoints\n",
    "# left_kps = {bp: left_kps[bp] + np.random.normal(0, 10, 2).astype(int) for bp in left_kps.keys()}\n",
    "# right_kps = {bp: right_kps[bp] + np.random.normal(0, 10, 2).astype(int) for bp in right_kps.keys()}\n",
    "\n",
    "# direction 1\n",
    "template = left_crop_arr[left_kps[body_part][1]-half_box_size:left_kps[body_part][1]+half_box_size, \n",
    "                         left_kps[body_part][0]-half_box_size:left_kps[body_part][0]+half_box_size]\n",
    "source = right_crop_arr[right_kps[body_part][1]-half_box_size-vertical_search_range:right_kps[body_part][1]+half_box_size+vertical_search_range, \n",
    "                        right_kps[body_part][0]-half_box_size-horizontal_search_range:right_kps[body_part][0]+half_box_size+horizontal_search_range]\n",
    "print(template.sum(), source.sum())\n",
    "\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "adj_right_keypoint = np.array([right_kps[body_part][0] - horizontal_search_range + b, \n",
    "                      right_kps[body_part][1] - vertical_search_range + a])\n",
    "\n",
    "adj_right = adj_right_keypoint - right_kps[body_part]\n",
    "\n",
    "# direction 2\n",
    "template = right_crop_arr[right_kps[body_part][1]-half_box_size:right_kps[body_part][1]+half_box_size, \n",
    "                          right_kps[body_part][0]-half_box_size:right_kps[body_part][0]+half_box_size]\n",
    "\n",
    "source = left_crop_arr[left_kps[body_part][1]-half_box_size-vertical_search_range:left_kps[body_part][1]+half_box_size+vertical_search_range, \n",
    "                       left_kps[body_part][0]-half_box_size-horizontal_search_range:left_kps[body_part][0]+half_box_size+horizontal_search_range]\n",
    "\n",
    "print(template.sum(), source.sum())\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "adj_left_keypoint = np.array([left_kps[body_part][0] - horizontal_search_range + b, \n",
    "                      left_kps[body_part][1] - vertical_search_range + a])\n",
    "\n",
    "adj_left = adj_left_keypoint - left_kps[body_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(adj_right + adj_left))\n",
    "print(0.5 * (np.linalg.norm(adj_left) + np.linalg.norm(adj_right)))\n",
    "print(np.dot(adj_left, adj_right)/(np.linalg.norm(adj_left) * np.linalg.norm(adj_right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kps[body_part][1]-half_box_size-vertical_search_range,left_kps[body_part][1]+half_box_size+vertical_search_range, left_kps[body_part][0]-half_box_size-horizontal_search_range,left_kps[body_part][0]+half_box_size+horizontal_search_range\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "right_image = plt.imread(right_crop_f)\n",
    "ax.imshow(right_image)\n",
    "ax.scatter([right_kps[body_part][0]], [right_kps[body_part][1]], color='red', s=1)\n",
    "ax.scatter([adj_right_keypoint[0]], [adj_right_keypoint[1]], color='green', s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = ['UPPER_LIP',\n",
    " 'EYE',\n",
    " 'DORSAL_FIN',\n",
    " 'ADIPOSE_FIN',\n",
    " 'UPPER_PRECAUDAL_PIT',\n",
    " 'HYPURAL_PLATE',\n",
    " 'TAIL_NOTCH',\n",
    " 'LOWER_PRECAUDAL_PIT',\n",
    " 'ANAL_FIN',\n",
    " 'PELVIC_FIN',\n",
    " 'PECTORAL_FIN'\n",
    "]\n",
    "\n",
    "\n",
    "# half_box_size = 25\n",
    "half_box_size = 35\n",
    "horizontal_search_range = 50\n",
    "vertical_search_range = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_arr(im_arr, kp, half_box_size, horizontal_search_range=0, vertical_search_range=0):\n",
    "    patch_coord_1_min = kp[1]-half_box_size-vertical_search_range\n",
    "    patch_coord_1_max = kp[1]+half_box_size+vertical_search_range\n",
    "    if patch_coord_1_min < 0:\n",
    "        patch_coord_1_min, patch_coord_1_max = 0, 2*(half_box_size+vertical_search_range)\n",
    "    elif patch_coord_1_max > im_arr.shape[0]-1:\n",
    "        patch_coord_1_min, patch_coord_1_max = im_arr.shape[0]-1-2*(half_box_size+vertical_search_range), \\\n",
    "                                                  im_arr.shape[0]-1\n",
    "\n",
    "    patch_coord_2_min = kp[0]-half_box_size-horizontal_search_range\n",
    "    patch_coord_2_max = kp[0]+half_box_size+horizontal_search_range\n",
    "    if patch_coord_2_min < 0:\n",
    "        patch_coord_2_min, patch_coord_2_max = 0, 2*(half_box_size+horizontal_search_range)\n",
    "    elif patch_coord_2_max > im_arr.shape[1]-1:\n",
    "        patch_coord_2_min, patch_coord_2_max = im_arr.shape[1]-1-2*(half_box_size+horizontal_search_range), \\\n",
    "                                               im_arr.shape[1]-1\n",
    "\n",
    "    patch = im_arr[patch_coord_1_min:patch_coord_1_max, patch_coord_2_min:patch_coord_2_max]\n",
    "    return patch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, keypoint_data = defaultdict(list), defaultdict(list)\n",
    "count = 0\n",
    "for idx, row in df.head(1000).iterrows():\n",
    "    \n",
    "    # download left and right crops\n",
    "    left_crop_url = row.left_image_url\n",
    "    left_crop_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "    left_crop_image = Image.open(left_crop_f)\n",
    "    left_crop_arr = enhance(np.array(left_crop_image))\n",
    "\n",
    "    right_crop_url = row.right_image_url\n",
    "    right_crop_f, _, _ = s3_access_utils.download_from_url(right_crop_url)\n",
    "    right_crop_image = Image.open(right_crop_f)\n",
    "    right_crop_arr = enhance(np.array(right_crop_image))\n",
    "\n",
    "    # get keypoint coordinates\n",
    "    keypoints = row.keypoints\n",
    "    original_left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['leftCrop']}\n",
    "    original_right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['rightCrop']}\n",
    "    \n",
    "    # jitter keypoints\n",
    "    left_kps = {bp: original_left_kps[bp] + np.array([int(np.random.normal(0, 15)), 0]) for bp in original_left_kps.keys()}\n",
    "    right_kps = {bp: original_right_kps[bp] + np.array([int(np.random.normal(0, 15)), 0]) for bp in original_right_kps.keys()}\n",
    "    \n",
    "    left_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in keypoints['leftCrop']}\n",
    "    right_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in keypoints['rightCrop']}\n",
    "    \n",
    "    adj_left_kps, adj_right_kps = {}, {}\n",
    "    for body_part in body_parts:\n",
    "        ###TAKE OUT LATER###\n",
    "#         original_disp = left_kps_frame[body_part][0] - right_kps_frame[body_part][0]\n",
    "#         half_box_size = int(original_disp / 10.5)\n",
    "        ###\n",
    "        \n",
    "        # direction 1\n",
    "        template = get_patch_arr(left_crop_arr, left_kps[body_part], half_box_size)\n",
    "        \n",
    "        source = get_patch_arr(right_crop_arr, right_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "        res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "        adj_right_keypoint = np.array([right_kps[body_part][0] - horizontal_search_range + b, \n",
    "                              right_kps[body_part][1] - vertical_search_range + a])\n",
    "        adj_right_kps[body_part] = adj_right_keypoint\n",
    "\n",
    "        adj_right = adj_right_keypoint - right_kps[body_part]\n",
    "\n",
    "        # direction 2\n",
    "        template = get_patch_arr(right_crop_arr, right_kps[body_part], half_box_size)\n",
    "        source = get_patch_arr(left_crop_arr, left_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "        res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "        adj_left_keypoint = np.array([left_kps[body_part][0] - horizontal_search_range + b, \n",
    "                              left_kps[body_part][1] - vertical_search_range + a])\n",
    "        adj_left_kps[body_part] = adj_left_keypoint\n",
    "\n",
    "        adj_left = adj_left_keypoint - left_kps[body_part]\n",
    "        net_adjustment_magnitude = np.linalg.norm(adj_right + adj_left)\n",
    "        mean_adjustment_magnitude = 0.5 * (np.linalg.norm(adj_left) + np.linalg.norm(adj_right))\n",
    "        cosine_adjustment = np.dot(adj_left, adj_right)/(np.linalg.norm(adj_left) * np.linalg.norm(adj_right))\n",
    "        \n",
    "        disp = abs(left_kps_frame[body_part][0] - right_kps_frame[body_part][0])\n",
    "        depth = depth_from_disp(disp, row.camera_metadata)\n",
    "        \n",
    "        # disparity evolution\n",
    "        old_crop_disp = original_left_kps[body_part][0] - original_right_kps[body_part][0]\n",
    "        new_crop_disp = left_kps[body_part][0] - right_kps[body_part][0]\n",
    "        original_disp = left_kps_frame[body_part][0] - right_kps_frame[body_part][0]\n",
    "        perturbed_disp = left_kps_frame[body_part][0] - right_kps_frame[body_part][0] + new_crop_disp - old_crop_disp\n",
    "        adj_crop_disp = adj_left_keypoint[0] - right_kps[body_part][0]\n",
    "        adj_disp = left_kps_frame[body_part][0] - right_kps_frame[body_part][0] + adj_crop_disp - old_crop_disp\n",
    "        \n",
    "        analysis_data['net_adjustment_magnitude'].append(net_adjustment_magnitude)\n",
    "        analysis_data['mean_adjustment_magnitude'].append(mean_adjustment_magnitude)\n",
    "        analysis_data['cosine_adjustment'].append(cosine_adjustment)\n",
    "        analysis_data['original_disp'].append(original_disp)\n",
    "        analysis_data['perturbed_disp'].append(perturbed_disp)\n",
    "        analysis_data['adj_disp'].append(adj_disp)\n",
    "        analysis_data['body_part'].append(body_part)\n",
    "        analysis_data['depth'].append(depth)\n",
    "        analysis_data['keypoint_annotation_id'].append(row.id)\n",
    "    \n",
    "    keypoint_data['original_left_keypoints'].append(original_left_kps)\n",
    "    keypoint_data['original_right_keypoints'].append(original_right_kps)\n",
    "    keypoint_data['left_keypoints'].append(left_kps)\n",
    "    keypoint_data['right_keypoints'].append(right_kps)\n",
    "    keypoint_data['adj_left_keypoints'].append(adj_left_kps)\n",
    "    keypoint_data['adj_right_keypoints'].append(adj_right_kps)\n",
    "    keypoint_data['left_image_f'].append(left_crop_f)\n",
    "    keypoint_data['right_image_f'].append(right_crop_f)\n",
    "    keypoint_data['keypoint_annotation_id'].append(keypoint_annotation_id)\n",
    "        \n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    \n",
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "keypoint_df = pd.DataFrame(keypoint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_mask = (analysis_df.body_part == 'PECTORAL_FIN')\n",
    "mask = bp_mask & (analysis_df.cosine_adjustment < -0.9) & (analysis_df.net_adjustment_magnitude < 1)\n",
    "plt.hist(analysis_df[mask].perturbed_disp - analysis_df[mask].original_disp, color='blue', alpha=0.6)\n",
    "plt.hist(analysis_df[mask].adj_disp - analysis_df[mask].original_disp, color='red', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print((analysis_df[mask].perturbed_disp - analysis_df[mask].original_disp).std())\n",
    "print((analysis_df[mask].adj_disp - analysis_df[mask].original_disp).std())\n",
    "print(analysis_df[mask].shape[0] / analysis_df[bp_mask].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "good_adjustment_mask = (analysis_df.cosine_adjustment < -0.9) & (analysis_df.net_adjustment_magnitude < 10)\n",
    "minimal_set_present_count = 0\n",
    "for keypoint_annotation_id in analysis_df.keypoint_annotation_id.unique():\n",
    "    id_mask = analysis_df.keypoint_annotation_id == keypoint_annotation_id\n",
    "    body_parts = analysis_df[id_mask & good_adjustment_mask].body_part.tolist()\n",
    "    tail_present = any([bp in body_parts for bp in ['UPPER_PRECAUDAL_PIT', 'LOWER_PRECAUDAL_PIT', 'HYPURAL_PLATE']])\n",
    "    back_present = any([bp in body_parts for bp in ['ADIPOSE_FIN', 'ANAL_FIN']])\n",
    "    middle_present = any([bp in body_parts for bp in ['DORSAL_FIN', 'PELVIC_FIN']])\n",
    "    front_present = all([bp in body_parts for bp in ['PECTORAL_FIN', 'EYE']])\n",
    "    minimal_set_present = tail_present and back_present and middle_present and front_present\n",
    "    if minimal_set_present:\n",
    "        minimal_set_present_count += 1\n",
    "        \n",
    "print(minimal_set_present_count / len(analysis_df.keypoint_annotation_id.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df[analysis_df.body_part == 'UPPER_LIP'].net_adjustment_magnitude, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (analysis_df.body_part == 'UPPER_LIP') & (analysis_df.depth > 1.0) & (analysis_df.depth < 1.5)\n",
    "(analysis_df[mask].cosine_adjustment < -0.).sum() / analysis_df[mask].shape[0]\n",
    "analysis_df[mask].net_adjustment_magnitude.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df.depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_keypoints(row):\n",
    "    if 'leftCrop' in row.keypoints and 'rightCrop' in row.keypoints:\n",
    "        return pixel2world(row.keypoints['leftCrop'], row.keypoints['rightCrop'], row.camera_metadata)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['world_keypoints'] = df.apply(\n",
    "    lambda x: get_world_keypoints(x), axis=1\n",
    ")\n",
    "\n",
    "df['mean_depth'] = df.world_keypoints.apply(lambda x: np.median([y[1] for y in x.values()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(analysis_df.groupby('keypoint_annotation_id')['cosine_adjustment'].median() < -0.9).sum() / len(analysis_df.keypoint_annotation_id.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analysis_df[analysis_df.body_part == 'EYE'].net_adjustment_magnitude, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[(analysis_df.body_part == 'EYE') & (analysis_df.mean_adjustment_magnitude > 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_df = pd.DataFrame(keypoint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_keypoints, right_keypoints, adj_left_keypoints, adj_right_keypoints, left_image_f, right_image_f):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    for bp, kp in left_keypoints.items():\n",
    "        axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "    for bp, kp in right_keypoints.items():\n",
    "        axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "    for bp, kp in adj_left_keypoints.items():\n",
    "        axes[0].scatter([kp[0]], [kp[1]], color='green', s=1)\n",
    "    for bp, kp in adj_right_keypoints.items():\n",
    "        axes[1].scatter([kp[0]], [kp[1]], color='green', s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7\n",
    "left_keypoints = keypoint_df.left_keypoints.iloc[idx]\n",
    "right_keypoints = keypoint_df.right_keypoints.iloc[idx]\n",
    "adj_left_keypoints = keypoint_df.adj_left_keypoints.iloc[idx]\n",
    "adj_right_keypoints = keypoint_df.adj_right_keypoints.iloc[idx]\n",
    "left_image_f = keypoint_df.left_image_f.iloc[idx]\n",
    "right_image_f = keypoint_df.right_image_f.iloc[idx]\n",
    "display_crops(left_keypoints, right_keypoints, adj_left_keypoints, adj_right_keypoints, left_image_f, right_image_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_annotation_id = int(df.id.iloc[4])\n",
    "mask = df.id == keypoint_annotation_id\n",
    "left_crop_url = df[mask].left_image_url.iloc[0]\n",
    "left_crop_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "left_crop_image = Image.open(left_crop_f)\n",
    "left_crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = cv2.ml.EM_create()\n",
    "em.setClustersNumber(2)\n",
    "image = enhance(cv2.imread(left_crop_f))\n",
    "im = cv2.resize(image, (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = em.trainEM(im.reshape(-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = res[2].reshape(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((labels * 255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
