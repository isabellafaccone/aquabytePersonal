{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Template Matching - Normalized Cross Correlation - Dual Check </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import cv2\n",
    "from aquabyte.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from aquabyte.visualize import Visualizer\n",
    "from aquabyte.template_matching import enhance\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import defaultdict\n",
    "from aquabyte.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sample dataset\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM keypoint_annotations\n",
    "    WHERE pen_id = 56\n",
    "    AND keypoints -> 'leftCrop' is not null\n",
    "    AND keypoints -> 'rightCrop' is not null\n",
    "    limit 1000;\n",
    "\"\"\"\n",
    "\n",
    "df = rds_access_utils.extract_from_database(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visualize some keypoint annotations </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(s3_access_utils, rds_access_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_annotation_id = int(df.id.iloc[0])\n",
    "v.load_data(keypoint_annotation_id)\n",
    "v.display_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Attempt ADIPOSE_FIN correction via normalized cross correlation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part = 'EYE'\n",
    "half_box_size = 25\n",
    "horizontal_search_range = 30\n",
    "vertical_search_range = 5\n",
    "\n",
    "# download left and right crops\n",
    "mask = df.id == keypoint_annotation_id\n",
    "left_crop_url = df[mask].left_image_url.iloc[0]\n",
    "left_crop_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "left_crop_image = Image.open(left_crop_f)\n",
    "left_crop_arr = enhance(np.array(left_crop_image))\n",
    "\n",
    "right_crop_url = df[mask].right_image_url.iloc[0]\n",
    "right_crop_f, _, _ = s3_access_utils.download_from_url(right_crop_url)\n",
    "right_crop_image = Image.open(right_crop_f)\n",
    "right_crop_arr = enhance(np.array(right_crop_image))\n",
    "\n",
    "# get keypoint coordinates\n",
    "keypoints = df[mask].keypoints.iloc[0]\n",
    "left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['leftCrop']}\n",
    "right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['rightCrop']}\n",
    "\n",
    "# jitter keypoints\n",
    "# left_kps = {bp: left_kps[bp] + np.random.normal(0, 10, 2).astype(int) for bp in left_kps.keys()}\n",
    "# right_kps = {bp: right_kps[bp] + np.random.normal(0, 10, 2).astype(int) for bp in right_kps.keys()}\n",
    "\n",
    "# direction 1\n",
    "template = left_crop_arr[left_kps[body_part][1]-half_box_size:left_kps[body_part][1]+half_box_size, \n",
    "                         left_kps[body_part][0]-half_box_size:left_kps[body_part][0]+half_box_size]\n",
    "source = right_crop_arr[right_kps[body_part][1]-half_box_size-vertical_search_range:right_kps[body_part][1]+half_box_size+vertical_search_range, \n",
    "                        right_kps[body_part][0]-half_box_size-horizontal_search_range:right_kps[body_part][0]+half_box_size+horizontal_search_range]\n",
    "print(template.sum(), source.sum())\n",
    "\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "adj_right_keypoint = np.array([right_kps[body_part][0] - horizontal_search_range + b, \n",
    "                      right_kps[body_part][1] - vertical_search_range + a])\n",
    "\n",
    "adj_right = adj_right_keypoint - right_kps[body_part]\n",
    "\n",
    "# direction 2\n",
    "template = right_crop_arr[right_kps[body_part][1]-half_box_size:right_kps[body_part][1]+half_box_size, \n",
    "                          right_kps[body_part][0]-half_box_size:right_kps[body_part][0]+half_box_size]\n",
    "\n",
    "source = left_crop_arr[left_kps[body_part][1]-half_box_size-vertical_search_range:left_kps[body_part][1]+half_box_size+vertical_search_range, \n",
    "                       left_kps[body_part][0]-half_box_size-horizontal_search_range:left_kps[body_part][0]+half_box_size+horizontal_search_range]\n",
    "\n",
    "print(template.sum(), source.sum())\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "adj_left_keypoint = np.array([left_kps[body_part][0] - horizontal_search_range + b, \n",
    "                      left_kps[body_part][1] - vertical_search_range + a])\n",
    "\n",
    "adj_left = adj_left_keypoint - left_kps[body_part]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(adj_right + adj_left))\n",
    "print(0.5 * (np.linalg.norm(adj_left) + np.linalg.norm(adj_right)))\n",
    "print(np.dot(adj_left, adj_right)/(np.linalg.norm(adj_left) * np.linalg.norm(adj_right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kps[body_part][1]-half_box_size-vertical_search_range,left_kps[body_part][1]+half_box_size+vertical_search_range, left_kps[body_part][0]-half_box_size-horizontal_search_range,left_kps[body_part][0]+half_box_size+horizontal_search_range\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "right_image = plt.imread(right_crop_f)\n",
    "ax.imshow(right_image)\n",
    "ax.scatter([right_kps[body_part][0]], [right_kps[body_part][1]], color='red', s=1)\n",
    "ax.scatter([adj_right_keypoint[0]], [adj_right_keypoint[1]], color='green', s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = ['UPPER_LIP',\n",
    " 'EYE',\n",
    " 'DORSAL_FIN',\n",
    " 'ADIPOSE_FIN',\n",
    " 'UPPER_PRECAUDAL_PIT',\n",
    " 'HYPURAL_PLATE',\n",
    " 'TAIL_NOTCH',\n",
    " 'LOWER_PRECAUDAL_PIT',\n",
    " 'ANAL_FIN',\n",
    " 'PELVIC_FIN',\n",
    " 'PECTORAL_FIN'\n",
    "]\n",
    "\n",
    "\n",
    "half_box_size = 35\n",
    "horizontal_search_range = 50\n",
    "vertical_search_range = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_arr(im_arr, kp, half_box_size, horizontal_search_range=0, vertical_search_range=0):\n",
    "    patch_coord_1_min = kp[1]-half_box_size-vertical_search_range\n",
    "    patch_coord_1_max = kp[1]+half_box_size+vertical_search_range\n",
    "    if patch_coord_1_min < 0:\n",
    "        patch_coord_1_min, patch_coord_1_max = 0, 2*(half_box_size+vertical_search_range)\n",
    "    elif patch_coord_1_max > im_arr.shape[0]-1:\n",
    "        patch_coord_1_min, patch_coord_1_max = im_arr.shape[0]-1-2*(half_box_size+vertical_search_range), \\\n",
    "                                                  im_arr.shape[0]-1\n",
    "\n",
    "    patch_coord_2_min = kp[0]-half_box_size-horizontal_search_range\n",
    "    patch_coord_2_max = kp[0]+half_box_size+horizontal_search_range\n",
    "    if patch_coord_2_min < 0:\n",
    "        patch_coord_2_min, patch_coord_2_max = 0, 2*(half_box_size+horizontal_search_range)\n",
    "    elif patch_coord_2_max > im_arr.shape[1]-1:\n",
    "        patch_coord_2_min, patch_coord_2_max = im_arr.shape[1]-1-2*(half_box_size+horizontal_search_range), \\\n",
    "                                               im_arr.shape[1]-1\n",
    "\n",
    "    patch = im_arr[patch_coord_1_min:patch_coord_1_max, patch_coord_2_min:patch_coord_2_max]\n",
    "    return patch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, keypoint_data = defaultdict(list), defaultdict(list)\n",
    "count = 0\n",
    "for idx, row in df.head(1000).iterrows():\n",
    "    \n",
    "    # download left and right crops\n",
    "    left_crop_url = row.left_image_url\n",
    "    left_crop_f, _, _ = s3_access_utils.download_from_url(left_crop_url)\n",
    "    left_crop_image = Image.open(left_crop_f)\n",
    "    left_crop_arr = enhance(np.array(left_crop_image))\n",
    "\n",
    "    right_crop_url = row.right_image_url\n",
    "    right_crop_f, _, _ = s3_access_utils.download_from_url(right_crop_url)\n",
    "    right_crop_image = Image.open(right_crop_f)\n",
    "    right_crop_arr = enhance(np.array(right_crop_image))\n",
    "\n",
    "    # get keypoint coordinates\n",
    "    keypoints = row.keypoints\n",
    "    original_left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['leftCrop']}\n",
    "    original_right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in keypoints['rightCrop']}\n",
    "    \n",
    "    # jitter keypoints\n",
    "    left_kps = {bp: original_left_kps[bp] + np.array([int(np.random.normal(0, 15)), 0]) for bp in original_left_kps.keys()}\n",
    "    right_kps = {bp: original_right_kps[bp] + np.array([int(np.random.normal(0, 15)), 0]) for bp in original_right_kps.keys()}\n",
    "    \n",
    "    left_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in keypoints['leftCrop']}\n",
    "    right_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in keypoints['rightCrop']}\n",
    "    \n",
    "    adj_left_kps, adj_right_kps = {}, {}\n",
    "    \n",
    "    for body_part in body_parts:\n",
    "        \n",
    "        # direction 1\n",
    "        template = get_patch_arr(left_crop_arr, left_kps[body_part], half_box_size)\n",
    "        \n",
    "        source = get_patch_arr(right_crop_arr, right_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "        res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "        adj_right_keypoint = np.array([right_kps[body_part][0] - horizontal_search_range + b, \n",
    "                              right_kps[body_part][1] - vertical_search_range + a])\n",
    "        \n",
    "        template_2 = get_patch_arr(right_crop_arr, adj_right_keypoint, half_box_size)\n",
    "        source_2 = get_patch_arr(left_crop_arr, left_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "        \n",
    "        template_2_gray = cv2.cvtColor(template_2, cv2.COLOR_BGR2GRAY)\n",
    "        source_2_gray = cv2.cvtColor(source_2, cv2.COLOR_BGR2GRAY)\n",
    "        res_2 = cv2.matchTemplate(source_2_gray, template_2_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a_2, b_2 = np.unravel_index(np.argmax(res_2, axis=None), res_2.shape)\n",
    "        backproj_left_keypoint = np.array([left_kps[body_part][0] - horizontal_search_range + b_2, \n",
    "                              left_kps[body_part][1] - vertical_search_range + a_2])\n",
    "\n",
    "        net_magnitude_1 = np.linalg.norm(left_kps[body_part] - backproj_left_keypoint)\n",
    "        print(net_magnitude_1, res.max(), res_2.max())\n",
    "\n",
    "        # direction 2\n",
    "        template = get_patch_arr(right_crop_arr, right_kps[body_part], half_box_size)\n",
    "        source = get_patch_arr(left_crop_arr, left_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "        source_gray = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)\n",
    "        res = cv2.matchTemplate(source_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a, b = np.unravel_index(np.argmax(res, axis=None), res.shape)\n",
    "        adj_left_keypoint = np.array([left_kps[body_part][0] - horizontal_search_range + b, \n",
    "                              left_kps[body_part][1] - vertical_search_range + a])\n",
    "        \n",
    "        template_2 = get_patch_arr(left_crop_arr, adj_left_keypoint, half_box_size)\n",
    "        source_2 = get_patch_arr(right_crop_arr, right_kps[body_part], half_box_size, \\\n",
    "                                horizontal_search_range=horizontal_search_range, \\\n",
    "                                vertical_search_range=vertical_search_range)\n",
    "        \n",
    "        template_2_gray = cv2.cvtColor(template_2, cv2.COLOR_BGR2GRAY)\n",
    "        source_2_gray = cv2.cvtColor(source_2, cv2.COLOR_BGR2GRAY)\n",
    "        res_2 = cv2.matchTemplate(source_2_gray, template_2_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        a_2, b_2 = np.unravel_index(np.argmax(res_2, axis=None), res_2.shape)\n",
    "        backproj_right_keypoint = np.array([right_kps[body_part][0] - horizontal_search_range + b_2, \n",
    "                                            right_kps[body_part][1] - vertical_search_range + a_2])\n",
    "        \n",
    "        net_magnitude_2 = np.linalg.norm(right_kps[body_part] - backproj_right_keypoint)\n",
    "        \n",
    "        if (net_magnitude_1 <= net_magnitude_2) and (net_magnitude_1 < 3):\n",
    "            adj_left_kps[body_part] = backproj_left_keypoint\n",
    "            adj_right_kps[body_part] = adj_right_keypoint\n",
    "        elif (net_magnitude_2 <= net_magnitude_1) and (net_magnitude_2 < 3):\n",
    "            adj_left_kps[body_part] = adj_left_keypoint\n",
    "            adj_right_kps[body_part] = backproj_right_keypoint\n",
    "\n",
    "        analysis_data['net_magnitude_1'].append(net_magnitude_1)\n",
    "        analysis_data['net_magnitude_2'].append(net_magnitude_2)\n",
    "        analysis_data['body_part'].append(body_part)\n",
    "        analysis_data['keypoint_annotation_id'].append(row.id)\n",
    "        \n",
    "    keypoint_data['original_left_keypoints'].append(original_left_kps)\n",
    "    keypoint_data['original_right_keypoints'].append(original_right_kps)\n",
    "    keypoint_data['left_keypoints'].append(left_kps)\n",
    "    keypoint_data['right_keypoints'].append(right_kps)\n",
    "#     keypoint_data['backproj_left_keypoints'].append(backproj_left_kps)\n",
    "#     keypoint_data['backproj_right_keypoints'].append(backproj_right_kps)\n",
    "    keypoint_data['adj_left_keypoints'].append(adj_left_kps)\n",
    "    keypoint_data['adj_right_keypoints'].append(adj_right_kps)\n",
    "    keypoint_data['left_image_f'].append(left_crop_f)\n",
    "    keypoint_data['right_image_f'].append(right_crop_f)\n",
    "    keypoint_data['keypoint_annotation_id'].append(keypoint_annotation_id)\n",
    "\n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    \n",
    "analysis_df = pd.DataFrame(analysis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "keypoint_df = pd.DataFrame(keypoint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = analysis_df.body_part == 'PECTORAL_FIN'\n",
    "well_behaved_mask = mask & ((analysis_df.net_magnitude_1 < 8) | (analysis_df.net_magnitude_2 < 8))\n",
    "analysis_df[well_behaved_mask].shape[0] / analysis_df[mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_adjustment_mask = (analysis_df.net_magnitude_1 < 8) | (analysis_df.net_magnitude_2 < 8)\n",
    "minimal_set_present_count = 0\n",
    "for keypoint_annotation_id in analysis_df.keypoint_annotation_id.unique():\n",
    "    id_mask = analysis_df.keypoint_annotation_id == keypoint_annotation_id\n",
    "    body_parts = analysis_df[id_mask & good_adjustment_mask].body_part.tolist()\n",
    "    tail_present = any([bp in body_parts for bp in ['UPPER_PRECAUDAL_PIT', 'LOWER_PRECAUDAL_PIT', 'HYPURAL_PLATE']])\n",
    "    back_present = any([bp in body_parts for bp in ['ADIPOSE_FIN', 'ANAL_FIN']])\n",
    "    middle_present = all([bp in body_parts for bp in ['DORSAL_FIN', 'PELVIC_FIN']])\n",
    "    front_present = all([bp in body_parts for bp in ['PECTORAL_FIN', 'EYE']])\n",
    "    minimal_set_present = tail_present and back_present and middle_present and front_present\n",
    "    if minimal_set_present:\n",
    "        minimal_set_present_count += 1\n",
    "        \n",
    "print(minimal_set_present_count / len(analysis_df.keypoint_annotation_id.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_df = pd.DataFrame(keypoint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_crops(left_keypoints, right_keypoints, adj_left_keypoints, adj_right_keypoints, left_image_f, right_image_f):\n",
    "def display_crops(adj_left_keypoints, adj_right_keypoints, left_image_f, right_image_f):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "#     for bp, kp in left_keypoints.items():\n",
    "#         axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "#     for bp, kp in right_keypoints.items():\n",
    "#         axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "    for bp, kp in adj_left_keypoints.items():\n",
    "        axes[0].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "    for bp, kp in adj_right_keypoints.items():\n",
    "        axes[1].scatter([kp[0]], [kp[1]], color='red', s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 109\n",
    "left_keypoints = keypoint_df.left_keypoints.iloc[idx]\n",
    "right_keypoints = keypoint_df.right_keypoints.iloc[idx]\n",
    "adj_left_keypoints = keypoint_df.adj_left_keypoints.iloc[idx]\n",
    "adj_right_keypoints = keypoint_df.adj_right_keypoints.iloc[idx]\n",
    "left_image_f = keypoint_df.left_image_f.iloc[idx]\n",
    "right_image_f = keypoint_df.right_image_f.iloc[idx]\n",
    "display_crops(adj_left_keypoints, adj_right_keypoints, left_image_f, right_image_f)\n",
    "display_crops(left_keypoints, right_keypoints, left_image_f, right_image_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
