{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from research.weight_estimation.keypoint_utils.body_parts import BodyParts\n",
    "from research.utils.image_utils import Picture\n",
    "from research.weight_estimation.keypoint_utils.akpr import get_homography_and_matches, generate_sift_adjustment\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = BodyParts().get_core_body_parts()\n",
    "s3_access_utils = S3AccessUtils('/root/data')\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM keypoint_annotations\n",
    "    WHERE pen_id=5\n",
    "    AND captured_at BETWEEN '2019-06-05' AND '2019-07-02'\n",
    "    AND keypoints is not null\n",
    "    AND keypoints -> 'leftCrop' is not null\n",
    "    AND keypoints -> 'rightCrop' is not null\n",
    "    AND is_qa = TRUE;\n",
    "\"\"\"\n",
    "\n",
    "mdf = rds_access_utils.extract_from_database(query)\n",
    "print('Manual dataframe loaded!')\n",
    "\n",
    "adf = pd.concat([\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/output-pen=5/biomass_output,pen=5,range=(2019-06-05,2019-06-12).csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/output-pen=5/biomass_output,pen=5,range=(2019-06-12,2019-06-19).csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/output-pen=5/biomass_output,pen=5,range=(2019-06-19,2019-06-26).csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/output-pen=5/biomass_output,pen=5,range=(2019-06-26,2019-07-03).csv'),\n",
    "    pd.read_csv('/root/data/alok/biomass_estimation/playground/output-pen=5/biomass_output,pen=5,range=(2019-07-03,2019-07-04).csv')\n",
    "])\n",
    "\n",
    "adf = adf[adf.akpd_score > 0.9].copy(deep=True)\n",
    "print('AKPD dataframe loaded!')\n",
    "\n",
    "url_intersection = sorted(list(set(mdf.left_image_url).intersection(adf.left_crop_url)))\n",
    "df = adf[adf.left_crop_url.isin(url_intersection)].sort_values('left_crop_url')\n",
    "df['manual_keypoints'] = mdf[mdf.left_image_url.isin(url_intersection)].sort_values('left_image_url').keypoints.values\n",
    "df['camera_metadata'] = mdf[mdf.left_image_url.isin(url_intersection)].sort_values('left_image_url').camera_metadata.values\n",
    "df['left_crop_metadata'] = mdf[mdf.left_image_url.isin(url_intersection)].sort_values('left_image_url').left_crop_metadata.values\n",
    "df['right_crop_metadata'] = mdf[mdf.left_image_url.isin(url_intersection)].sort_values('left_image_url').right_crop_metadata.values\n",
    "\n",
    "\n",
    "\n",
    "df = df.sort_values('captured_at')\n",
    "df['estimated_weight_g'] = df.weight\n",
    "df.index = pd.to_datetime(df.captured_at)\n",
    "print('Manual and AKPD Dataframes Joined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "keypoint_data, analysis_data = defaultdict(list), defaultdict(list)\n",
    "adj_anns = []\n",
    "for idx, row in df.head(1000).iterrows():\n",
    "    print(count)\n",
    "    count += 1\n",
    "    \n",
    "    # get image information and metadata\n",
    "    left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "    left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "    \n",
    "    # get keypoint coordinates\n",
    "    ann = row.manual_keypoints\n",
    "    left_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in ann['leftCrop']}\n",
    "    right_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in ann['rightCrop']}\n",
    "    left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in ann['leftCrop']}\n",
    "    right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in ann['rightCrop']}\n",
    "    \n",
    "    # jitter keypoints\n",
    "    akpd_ann = json.loads(row.annotation)\n",
    "    jittered_left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in akpd_ann['leftCrop']}\n",
    "    jittered_right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in akpd_ann['rightCrop']}\n",
    "    jittered_left_kps_frame = {bp: jittered_left_kps[bp] + np.array([left_crop_metadata['x_coord'], left_crop_metadata['y_coord']]) \n",
    "                               for bp in body_parts}\n",
    "    jittered_right_kps_frame = {bp: jittered_right_kps[bp] + np.array([right_crop_metadata['x_coord'], right_crop_metadata['y_coord']]) \n",
    "                               for bp in body_parts}\n",
    "    \n",
    "\n",
    "    left_fish_picture = Picture(s3_access_utils=s3_access_utils, image_url=left_crop_url)\n",
    "    right_fish_picture = Picture(s3_access_utils=s3_access_utils, image_url=right_crop_url)\n",
    "    left_fish_picture.enhance(in_place=True, sharpen=True)\n",
    "    right_fish_picture.enhance(in_place=True, sharpen=True)\n",
    "    sift = cv2.KAZE_create()\n",
    "    left_items, right_items = [], []\n",
    "    for bp in body_parts:\n",
    "        \n",
    "        try:\n",
    "            left_item, right_item, num_matches = generate_sift_adjustment(bp, left_crop_metadata, left_fish_picture,\n",
    "                                                                          jittered_left_kps, right_crop_metadata,\n",
    "                                                                          right_fish_picture, jittered_right_kps, sift)\n",
    "        except:\n",
    "            continue\n",
    "        left_items.append(left_item)\n",
    "        right_items.append(right_item)\n",
    "        \n",
    "        original_disp = abs(left_kps_frame[bp][0] - right_kps_frame[bp][0])\n",
    "        jittered_disp = abs(jittered_left_kps_frame[bp][0] - jittered_right_kps_frame[bp][0])\n",
    "        adj_disp = abs(left_item['xFrame'] - right_item['xFrame'])\n",
    "        \n",
    "        analysis_data['left_crop_url'].append(left_crop_url)\n",
    "        analysis_data['body_part'].append(bp)\n",
    "        analysis_data['original_disp'].append(original_disp)\n",
    "        analysis_data['jittered_disp'].append(jittered_disp)\n",
    "        analysis_data['adj_disp'].append(adj_disp)\n",
    "        analysis_data['num_matches'].append(num_matches)\n",
    "    \n",
    "    adj_ann = {\n",
    "        'leftCrop': left_items,\n",
    "        'rightCrop': right_items\n",
    "    }\n",
    "    keypoint_data['left_crop_url'].append(left_crop_url)\n",
    "    keypoint_data['right_crop_url'].append(right_crop_url)\n",
    "    keypoint_data['ann'].append(ann)\n",
    "    keypoint_data['akpd_ann'].append(akpd_ann)\n",
    "    keypoint_data['adj_ann'].append(adj_ann)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "keypoint_df = pd.DataFrame(keypoint_data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fish_picture.get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['abs_error'] = (analysis_df.adj_disp - analysis_df.original_disp).abs()\n",
    "analysis_df[(analysis_df.num_matches > 30) & (analysis_df.abs_error > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url = 'https://s3-eu-west-1.amazonaws.com/aquabyte-crops/environment=production/site-id=23/pen-id=5/date=2019-06-06/hour=06/at=2019-06-06T06:13:57.247786000Z/left_frame_crop_1430_366_3322_1227.jpg'\n",
    "row = keypoint_df[keypoint_df.left_crop_url == left_crop_url].iloc[0]\n",
    "left_crop_url, right_crop_url, ann, adj_ann = row.left_crop_url, row.right_crop_url, row.ann, row.adj_ann\n",
    "akpd_ann = json.loads(df[df.left_crop_url == left_crop_url].annotation.iloc[0])\n",
    "left_crop_metadata = df[df.left_crop_url == left_crop_url].left_crop_metadata.iloc[0]\n",
    "right_crop_metadata = df[df.left_crop_url == left_crop_url].right_crop_metadata.iloc[0]\n",
    "left_picture, right_picture = Picture(s3_access_utils=s3_access_utils, image_url=left_crop_url), \\\n",
    "                              Picture(s3_access_utils=s3_access_utils, image_url=right_crop_url)\n",
    "left_picture.enhance(sharpen=False)\n",
    "right_picture.enhance(sharpen=False)\n",
    "###\n",
    "\n",
    "left_image_arr = left_picture.get_image_arr()\n",
    "blurred = cv2.GaussianBlur(left_image_arr, (21, 21), 0)\n",
    "sharpened = cv2.addWeighted(left_image_arr, 2.0, blurred, -1.0, 0)\n",
    "left_picture.image_arr = sharpened\n",
    "left_picture.image = Image.fromarray(sharpened)\n",
    "\n",
    "right_image_arr = right_picture.get_image_arr()\n",
    "blurred = cv2.GaussianBlur(right_image_arr, (21, 21), 0)\n",
    "sharpened = cv2.addWeighted(right_image_arr, 2.0, blurred, -1.0, 0)\n",
    "right_picture.image_arr = sharpened\n",
    "right_picture.image = Image.fromarray(sharpened)\n",
    "\n",
    "###\n",
    "\n",
    "left_crop_image, right_crop_image = left_picture.get_image(), right_picture.get_image()\n",
    "left_draw, right_draw = ImageDraw.Draw(left_crop_image), ImageDraw.Draw(right_crop_image)\n",
    "\n",
    "r = 3\n",
    "for item in akpd_ann['leftCrop']:\n",
    "    x, y = item['xCrop'], item['yCrop']\n",
    "    left_draw.ellipse((x - r, y - r, x + r, y + r), fill='red', outline='red')\n",
    "for item in akpd_ann['rightCrop']:\n",
    "    x, y = item['xCrop'], item['yCrop']\n",
    "    right_draw.ellipse((x - r, y - r, x + r, y + r), fill='red', outline='red')\n",
    "\n",
    "for item in adj_ann['leftCrop']:\n",
    "    x, y = item['xCrop'], item['yCrop']\n",
    "    left_draw.ellipse((x - r, y - r, x + r, y + r), fill='green', outline='green')\n",
    "for item in adj_ann['rightCrop']:\n",
    "    x, y = item['xCrop'], item['yCrop']\n",
    "    right_draw.ellipse((x - r, y - r, x + r, y + r), fill='green', outline='green')\n",
    "\n",
    "    \n",
    "left_crop_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Delaunay\n",
    "from itertools import compress\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p)>=0\n",
    "\n",
    "\n",
    "def apply_convex_hull_filter(kp, des, canonical_kps, bbox):\n",
    "    X_canon_kps = np.array(list(canonical_kps.values()))\n",
    "    X_kp = np.array([x.pt for x in kp]).reshape(-1, 2) + np.array([bbox['x_min'], bbox['y_min']])\n",
    "    is_valid = in_hull(X_kp, X_canon_kps)\n",
    "    kp = list(compress(kp, is_valid))\n",
    "    des = des[is_valid]\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def get_homography_and_matches(sift, left_patch, right_patch,\n",
    "                               left_kps, right_kps,\n",
    "                               left_bbox, right_bbox,\n",
    "                               good_perc=0.7, min_match_count=3):\n",
    "\n",
    "    kp1, des1 = sift.detectAndCompute(left_patch, None)\n",
    "    kp2, des2 = sift.detectAndCompute(right_patch, None)\n",
    "\n",
    "#     apply convex hull filter\n",
    "    kp1, des1 = apply_convex_hull_filter(kp1, des1, left_kps, left_bbox)\n",
    "    kp2, des2 = apply_convex_hull_filter(kp2, des2, right_kps, right_bbox)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < good_perc * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    H, matches_mask = np.eye(3), None\n",
    "    if len(good) >= min_match_count:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "    return H, kp1, kp2, good, matches_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.KAZE_create()\n",
    "left_items, right_items = [], []\n",
    "bp = 'UPPER_LIP'\n",
    "\n",
    "left_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in akpd_ann['leftCrop']}\n",
    "right_kps_frame = {item['keypointType']: np.array([item['xFrame'], item['yFrame']]) for item in akpd_ann['rightCrop']}\n",
    "left_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in akpd_ann['leftCrop']}\n",
    "right_kps = {item['keypointType']: np.array([item['xCrop'], item['yCrop']]) for item in akpd_ann['rightCrop']}\n",
    "\n",
    "left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "left_crop, left_bbox = left_picture.generate_crop_given_center(left_kp[0], left_kp[1], 600, 200)\n",
    "right_crop, right_bbox = right_picture.generate_crop_given_center(right_kp[0], right_kp[1], 600, 200)\n",
    "H, kp1, kp2, good, matches_mask = get_homography_and_matches(sift, left_crop, right_crop, \n",
    "                                                            left_kps, right_kps,\n",
    "                                                            left_bbox, right_bbox)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "img1 = np.array(left_crop)\n",
    "img2 = np.array(right_crop)\n",
    "\n",
    "h,w,d = img1.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts, H)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "img = cv2.drawMatches(img1,kp1,img2,kp2,good,None,\n",
    "                      matchesMask=matches_mask, singlePointColor=None)\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_left_kp = [left_kp[0] - left_bbox['x_min'], left_kp[1] - left_bbox['y_min']]\n",
    "local_right_kp = cv2.perspectiveTransform(np.array([local_left_kp[0], local_left_kp[1]]).reshape(-1, 1, 2).astype(float), H).squeeze()\n",
    "right_kp = [local_right_kp[0] + right_bbox['x_min'], local_right_kp[1] + right_bbox['y_min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_kp_frame = left_kp + np.array([left_crop_metadata['x_coord'], left_crop_metadata['y_coord']])  \n",
    "right_kp_frame = right_kp + np.array([right_crop_metadata['x_coord'], right_crop_metadata['y_coord']])\n",
    "print(left_kp_frame - right_kp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(matches_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(matches_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts.reshape(-1, 2)[np.array(matches_mask).astype(bool)] - \\\n",
    "dst_pts.reshape(-1, 2)[np.array(matches_mask).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = src_pts.reshape(-1, 2)[np.array(matches_mask).astype(bool)]\n",
    "X = np.hstack([X, np.ones(X.shape[0]).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prime = np.dot(H, X.T).T\n",
    "X_prime[:, 0] = X_prime[:, 0] / X_prime[:, 2]\n",
    "X_prime[:, 1] = X_prime[:, 1] / X_prime[:, 2]\n",
    "X_prime[:, 2] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, :-1] - X_prime[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "for idx, bp in enumerate(body_parts):\n",
    "    \n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    \n",
    "    bp_mask = analysis_df.body_part == bp\n",
    "    behavior_mask = (analysis_df.num_matches > 20) & (abs(analysis_df.original_disp - analysis_df.adj_disp) < 100)\n",
    "    pre_adj_err = (analysis_df[bp_mask].jittered_disp - analysis_df[bp_mask].original_disp).values\n",
    "    post_adj_err = (analysis_df[bp_mask & behavior_mask].adj_disp - analysis_df[bp_mask & behavior_mask].original_disp).values\n",
    "    \n",
    "    print(analysis_df[bp_mask & behavior_mask].shape[0] / analysis_df[bp_mask].shape[0])\n",
    "    \n",
    "    pre_adj_rms = np.mean(pre_adj_err**2)**0.5\n",
    "    post_adj_rms = np.mean(post_adj_err**2)**0.5\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    ax.hist(pre_adj_err, bins=50, color='blue', alpha=0.7)\n",
    "    ax.hist(post_adj_err, bins=50, color='red', alpha=0.7)\n",
    "    ax.grid()\n",
    "    ax.set_title('Body part: {}, Pre RMS: {}, Post RMS: {}'.format(bp, round(pre_adj_rms, 2), \n",
    "                                                               round(post_adj_rms, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disparity_and_depth(manual_ann, akpd_ann, camera_metadata):\n",
    "    if 'leftCrop' in manual_ann and 'rightCrop' in manual_ann:\n",
    "        world_keypoints = pixel2world(manual_ann['leftCrop'], manual_ann['rightCrop'], camera_metadata)\n",
    "        depth = np.mean([x[1] for x in world_keypoints.values()])\n",
    "        \n",
    "        manual_left_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in manual_ann['leftCrop']}\n",
    "        manual_right_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in manual_ann['rightCrop']}\n",
    "        akpd_left_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in akpd_ann['leftCrop']}\n",
    "        akpd_right_keypoints = {item['keypointType']: [item['xFrame'], item['yFrame']] for item in akpd_ann['rightCrop']}\n",
    "        \n",
    "        manual_disps = []\n",
    "        akpd_disps = []\n",
    "        for bp in body_parts:\n",
    "            manual_disp = abs(manual_left_keypoints[bp][0] - manual_right_keypoints[bp][0])\n",
    "            akpd_disp = abs(akpd_left_keypoints[bp][0] - akpd_right_keypoints[bp][0])\n",
    "            manual_disps.append(manual_disp)\n",
    "            akpd_disps.append(akpd_disp)\n",
    "            \n",
    "        return manual_disps, akpd_disps, [depth] * len(manual_disps)\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_manual_disps, all_akpd_disps, all_depths = [], [], []\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    manual_ann = row.manual_keypoints\n",
    "    akpd_ann = json.loads(row.annotation)\n",
    "    camera_metadata = row.camera_metadata\n",
    "    manual_disps, akpd_disps, depths = get_disparity_and_depth(manual_ann, akpd_ann, camera_metadata)\n",
    "    all_manual_disps.extend(manual_disps)\n",
    "    all_akpd_disps.extend(akpd_disps)\n",
    "    all_depths.extend(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame({'manual_disp': all_manual_disps, 'akpd_disp': all_akpd_disps, 'depth': all_depths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['error'] = tdf.akpd_disp - tdf.manual_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(tdf.depth, tdf.error)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 2.2\n",
    "tdf[(tdf.depth > low) & (tdf.depth < low + 0.1)].error.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
