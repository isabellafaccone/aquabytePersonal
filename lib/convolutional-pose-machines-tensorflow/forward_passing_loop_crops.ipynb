{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/root/data/models/keypoints_detection/2019_05_03_16_59_35/config.json' \n",
    "checkpoint_path = '/root/data/models/keypoints_detection/2019_05_03_16_59_35/weights/fish_test-136'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(config_path))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = 3\n",
    "    joints = 8\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = 21\n",
    "    batch_size = 1\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                    \"ADIPOSE_FIN\",\n",
    "                    \"UPPER_LIP\",\n",
    "                    \"ANAL_FIN\",\n",
    "                    \"PELVIC_FIN\",\n",
    "                    \"EYE\",\n",
    "                    \"PECTORAL_FIN\",\n",
    "                    \"DORSAL_FIN\"]\n",
    "    normalize = True\n",
    "    heatmap_size = 64\n",
    "    joint_gaussian_variance = 1.0\n",
    "    augmentation = None\n",
    "    crop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import importlib\n",
    "from models.nets import fish_test\n",
    "from utils import cpm_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import pywrap_tensorflow\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_tensors_in_checkpoint_file(checkpoint_path, \"\", False,\n",
    "#                                      all_tensor_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "# var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "# for key in sorted(var_to_shape_map):\n",
    "#     print(\"tensor_name: \", key, reader.get_tensor(key).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "tf_device = '/gpu:0'\n",
    "with tf.device(tf_device):\n",
    "    model = fish_test.CPM_Model(FLAGS.input_size, 2, FLAGS.stages, FLAGS.joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cmap_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stage_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, FLAGS.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_center_map = cpm_utils.gaussian_img(FLAGS.input_size[0],\n",
    "                                         FLAGS.input_size[0], \n",
    "                                         FLAGS.input_size[0] / 2,\n",
    "                                         FLAGS.input_size[0] / 2,\n",
    "                                         FLAGS.cmap_radius)\n",
    "test_center_map = np.reshape(test_center_map, [1, FLAGS.input_size[0], FLAGS.input_size[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from utils.utils import DataGenerator, load_image_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"/root/data/fish_detections/aquabyte-crops/environment=production/site-id=23/pen-id=4/*/*/*/*\")\n",
    "# annotations = ['/root/data/gtsf_phase_I/2019-05-02/2019-05-02_cogito_annotations.json']\n",
    "print(\"Total number of images: {}\".format(len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Froward pass loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in tqdm(images):\n",
    "    try:\n",
    "        original = cv2.imread(image)\n",
    "\n",
    "        height, width, _ = original.shape\n",
    "        img_input = cv2.resize(original, tuple(config['input_size']))\n",
    "        img_input  = img_input / 255.0 - 0.5\n",
    "        img_input = img_input[np.newaxis, ...]\n",
    "\n",
    "        with tf.device(tf_device):   \n",
    "            predict_heatmap, stage_heatmap_np = sess.run([model.current_heatmap,\n",
    "                                                      model.stage_heatmap,\n",
    "                                                      ],\n",
    "                                                     feed_dict={'input_placeholder:0': img_input,\n",
    "                                                                'cmap_placeholder:0': test_center_map})\n",
    "        final_stage_heatmap = predict_heatmap.squeeze()  \n",
    "\n",
    "        keypoints = {}\n",
    "        for c in range(config['num_of_joints']):\n",
    "            hm = cv2.resize(final_stage_heatmap[..., c], (width, height))\n",
    "            hm_max = np.where(hm == hm.max())\n",
    "            coordinates = [int(np.mean(hm_max[0])), int(np.mean(hm_max[1]))]\n",
    "            coordinates[0] = int(coordinates[0])\n",
    "            coordinates[1] = int(coordinates[1])\n",
    "            keypoints[config['keypoints_order'][c]] = coordinates\n",
    "\n",
    "        results = {}\n",
    "        results['keypoints'] = keypoints\n",
    "        results['image_path'] = image\n",
    "        results['height'] = height\n",
    "        results['width'] = width\n",
    "        with open(image.replace('jpg', 'json'), 'w') as f:\n",
    "            json.dump(results, f)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(original)\n",
    "for (k,v) in keypoints.items():\n",
    "    plt.scatter(v[1], v[0], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = np.random.choice(val_annotations)\n",
    "full = cv2.imread(ann['local_path'])\n",
    "img_input, kp_resized = load_image_keypoints(ann, FLAGS)\n",
    "predictions = np.array(ann[\"predictions\"])\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img_input)\n",
    "plt.scatter(predictions[:, 0], predictions[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/thomas/biomass_kp_predictions_val.json', 'w') as f:\n",
    "    json.dump(val_annotations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,v) in low_rez.items():\n",
    "    print(\"Average error on {}x{} images for keypoint {} is {}\".format(FLAGS.input_size[0],\n",
    "                                                                    FLAGS.input_size[0],k, np.median(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k,v) in high_rez.items():\n",
    "    print(\"Average error on full rez images for keypoint {} is {}\".format( k, np.median(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = '190313010007'\n",
    "debug = '190301010006'\n",
    "debug = '190313010009'\n",
    "debug = '190301010014'\n",
    "debug = '190313010011'\n",
    "debug = '190313010009'\n",
    "# bug = '190313010008'\n",
    "\n",
    "debug_ann = [ann for ann in val_annotations if ann[\"timestamp\"] == debug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, keypoints = load_image_keypoints(debug_ann[0], FLAGS, reshape=False)\n",
    "preds = np.array(debug_ann[0][\"predictions\"])\n",
    "f, ax = plt.subplots(1, figsize=(20,10))\n",
    "ax.imshow(image)\n",
    "ax.scatter(keypoints[:, 0], keypoints[:, 1], c=\"r\")\n",
    "ax.scatter(preds[:, 0], preds[:, 1], c=\"y\")\n",
    "for (i, t) in enumerate(FLAGS.keypoints_order):\n",
    "    ax.text(preds[i, 0], preds[i, 1], t, {\"color\": \"w\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, keypoints = load_image_keypoints(debug_ann[1], FLAGS, reshape=False)\n",
    "preds = np.array(debug_ann[1][\"predictions\"])\n",
    "f, ax = plt.subplots(1, figsize=(20,10))\n",
    "ax.imshow(image)\n",
    "ax.scatter(keypoints[:, 0], keypoints[:, 1], c=\"r\")\n",
    "ax.scatter(preds[:, 0], preds[:, 1], c=\"y\")\n",
    "for (i, t) in enumerate(FLAGS.keypoints_order):\n",
    "    ax.text(preds[i, 0], preds[i, 1], t, {\"color\": \"w\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disparity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_ann_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs per timestamp\n",
    "pairs = {}\n",
    "for ann in val_annotations:\n",
    "    if ann[\"species\"] != \"salmon\":\n",
    "        continue\n",
    "    if ann[\"kfactor\"] < 0.3:\n",
    "        continue\n",
    "    timestamp = ann[\"timestamp\"]\n",
    "    side = os.path.basename(ann[\"local_path\"]).split(\"_\")[0]\n",
    "    ann[\"side\"] = side\n",
    "    if timestamp not in pairs:\n",
    "        pairs[timestamp] = {}\n",
    "    pairs[timestamp][side] = ann\n",
    "\n",
    "full_pairs = [k for (k, v)in pairs.items() if \"left\" in v and \"right\" in v]\n",
    "print(\"Number of full pairs: {}\".format(len(full_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_disparities = []\n",
    "pred_disparities= []\n",
    "\n",
    "for ts in full_pairs:\n",
    "    left_ann = pairs[ts][\"left\"]\n",
    "    right_ann = pairs[ts][\"right\"]\n",
    "    \n",
    "    left_keypoints = load_ann_keypoints(left_ann, FLAGS.keypoints_order)\n",
    "    xmin = left_keypoints[:, 1].min()\n",
    "    ymin = left_keypoints[:, 0].min()\n",
    "    left_predictions = np.array(left_ann[\"predictions\"])\n",
    "    left_predictions[:, 0] += ymin-buffer\n",
    "    left_predictions[:, 1] += xmin-buffer\n",
    "    \n",
    "    right_keypoints = load_ann_keypoints(right_ann, FLAGS.keypoints_order)\n",
    "    xmin = right_keypoints[:, 1].min()\n",
    "    ymin = right_keypoints[:, 0].min()\n",
    "    right_predictions = np.array(right_ann[\"predictions\"])\n",
    "    right_predictions[:, 0] += ymin-buffer\n",
    "    right_predictions[:, 1] += xmin-buffer\n",
    "    \n",
    "    ground_truth_disparities.append(left_keypoints[:, 0] - right_keypoints[:, 0])\n",
    "    pred_disparities.append(left_predictions[:, 0] - right_predictions[:, 0])\n",
    "    \n",
    "ground_truth_disparities = np.array(ground_truth_disparities)\n",
    "pred_disparities = np.array(pred_disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pairs[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = np.mean(ground_truth_disparities - pred_disparities)\n",
    "print(\"Mean disparity error: {}\".format(mean_error))\n",
    "relative_error = np.mean((ground_truth_disparities - pred_disparities)*100 / ground_truth_disparities)\n",
    "print(\"Mean relative disparity error: {}\".format(relative_error))\n",
    "abs_relative_error = np.mean(np.abs((ground_truth_disparities - pred_disparities)*100 / ground_truth_disparities))\n",
    "print(\"Mean absolute relative disparity error: {}\".format(abs_relative_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = ground_truth_disparities - pred_disparities\n",
    "np.where(error > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pairs[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
