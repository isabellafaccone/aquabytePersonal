{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf records files for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import cpm_utils\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import load_image_keypoints\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = (1024, 1024)\n",
    "    heatmap_size = 128\n",
    "    cpm_stages = 4\n",
    "    joint_gaussian_variance = 1.0\n",
    "    center_radius = 21\n",
    "    num_of_joints = 8\n",
    "    color_channel = 'RGB'\n",
    "    normalize = True\n",
    "    use_gpu = True\n",
    "    gpu_id = 0\n",
    "    \n",
    "    gradient_clipping = True # gradient clipping\n",
    "\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                        \"ADIPOSE_FIN\",\n",
    "                        \"UPPER_LIP\",\n",
    "                        \"ANAL_FIN\",\n",
    "                        \"PELVIC_FIN\",\n",
    "                        \"EYE\",\n",
    "                        \"PECTORAL_FIN\",\n",
    "                        \"DORSAL_FIN\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Training settings\n",
    "    \"\"\"\n",
    "    network_def = 'fish_test'\n",
    "    train_img_dir = ''\n",
    "    val_img_dir = ''\n",
    "    bg_img_dir = ''\n",
    "    pretrained_model = 'fish_test'\n",
    "    batch_size = 4\n",
    "    init_lr = 0.001\n",
    "    lr_decay_rate = 0.45\n",
    "    lr_decay_step = 8000\n",
    "    augmentation = None\n",
    "    buffer_range = [int(n) for n in np.arange(100, 600, 100)] # useless if crop = False\n",
    "    crop = False # crop input image based on keypoints - for GTSF only\n",
    "    \n",
    "    epochs=200\n",
    "\n",
    "    hnm = True  # Make sure generate hnm files first\n",
    "    do_cropping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_file = 'cpm_sample_dataset_512x512.tfrecords'\n",
    "dataset_dir = 'utils/dataset/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _float64_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['/root/data/bati/labels/labels_2019-04-16.json']\n",
    "labels = glob.glob('/root/data/bati/labels/labels_2019-0*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf records here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cpm_utils import make_heatmap_single\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jsonfile in tqdm(labels):\n",
    "    date = os.path.basename(jsonfile).split('.')[0]\n",
    "    annotations = json.load(open(jsonfile))\n",
    "    print('{}. Total number of annotations: {}'.format(date, len(annotations)))\n",
    "    record_path = '/root/data/bati/tfrecords/{}.records'.format(date)\n",
    "    if os.path.isfile(record_path):\n",
    "        continue\n",
    "    with tf.python_io.TFRecordWriter(record_path) as writer:\n",
    "        for ann in tqdm(annotations):\n",
    "            try:\n",
    "                image, keypoints = load_image_keypoints(ann, FLAGS)\n",
    "                heatmap = make_heatmap_single(FLAGS.input_size[0], \n",
    "                                              FLAGS.heatmap_size, \n",
    "                                              FLAGS.joint_gaussian_variance,\n",
    "                                              keypoints)\n",
    "                image = image.flatten()\n",
    "                heatmap = heatmap.flatten()\n",
    "                keypoints = keypoints.flatten()\n",
    "\n",
    "                # print(image.shape)\n",
    "                img_bytes = image.tostring()\n",
    "                heatmap_bytes = heatmap.tostring()\n",
    "                kps_bytes = keypoints.tostring()\n",
    "\n",
    "                data = {'image': _bytes_feature(img_bytes),\n",
    "                        'heatmaps':  _bytes_feature(heatmap_bytes),\n",
    "                        'keypoints': _bytes_feature(kps_bytes)}\n",
    "    #             data = {'keypoints': _bytes_feature(kps_bytes)}\n",
    "                feature = tf.train.Features(feature=data)\n",
    "                example = tf.train.Example(features=feature)\n",
    "                serialized = example.SerializeToString()\n",
    "                writer.write(serialized)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH = 3\n",
    "HEIGHT = 1024\n",
    "WIDTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fn(data_record):\n",
    "    features = {'image': tf.FixedLenFeature([], tf.string),\n",
    "                'heatmaps': tf.FixedLenFeature([], tf.string),\n",
    "                'keypoints': tf.FixedLenFeature([], tf.string)}\n",
    "    sample = tf.parse_single_example(data_record, features)\n",
    "    \n",
    "    image = tf.decode_raw(sample['image'], tf.uint8)      \n",
    "    image.set_shape([HEIGHT * WIDTH * DEPTH])\n",
    "    image = tf.reshape(image, [HEIGHT, WIDTH, DEPTH])\n",
    "    \n",
    "    heatmaps = tf.decode_raw(sample['heatmaps'], tf.float64)\n",
    "    heatmaps.set_shape([FLAGS.heatmap_size * FLAGS.heatmap_size * (FLAGS.num_of_joints + 1)])\n",
    "    heatmaps = tf.reshape(heatmaps, [FLAGS.heatmap_size, FLAGS.heatmap_size, (FLAGS.num_of_joints + 1)])\n",
    "    \n",
    "    keypoints = tf.decode_raw(sample['keypoints'], tf.int64)\n",
    "    keypoints.set_shape([FLAGS.num_of_joints*2])\n",
    "    keypoints = tf.reshape(keypoints, [FLAGS.num_of_joints, 2])\n",
    "    \n",
    "    return image, keypoints, heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/root/data/bati/tfrecords/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all tfrecord paths\n",
    "dataset = tf.data.TFRecordDataset(files).repeat()\n",
    "dataset = dataset.map(extract_fn, num_parallel_calls=4)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(FLAGS.batch_size)\n",
    "dataset = dataset.prefetch(4)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "image, keypoints, heatmaps = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        print(count)\n",
    "        count += 1\n",
    "        start = time()\n",
    "        out = sess.run(image)\n",
    "        kps = sess.run(keypoints)\n",
    "        hms = sess.run(heatmaps)\n",
    "        end = time()\n",
    "        print(end - start)\n",
    "#         plt.imshow(image)\n",
    "#         plt.scatter(keypoints[:, 0], keypoints[:, 1])\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
