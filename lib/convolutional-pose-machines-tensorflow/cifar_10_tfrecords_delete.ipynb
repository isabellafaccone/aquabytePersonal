{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tarfile\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_FILENAME = 'cifar-10-python.tar.gz'\n",
    "CIFAR_DOWNLOAD_URL = 'https://www.cs.toronto.edu/~kriz/' + CIFAR_FILENAME\n",
    "CIFAR_LOCAL_FOLDER = 'cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _get_file_names():\n",
    "  \"\"\"Returns the file names expected to exist in the input_dir.\"\"\"\n",
    "  file_names = {}\n",
    "  file_names['train'] = ['data_batch_%d' % i for i in xrange(1, 5)]\n",
    "  file_names['validation'] = ['data_batch_5']\n",
    "  file_names['eval'] = ['test_batch']\n",
    "  return file_names\n",
    "\n",
    "\n",
    "def read_pickle_from_file(filename):\n",
    "  with tf.gfile.Open(filename, 'rb') as f:\n",
    "    if sys.version_info >= (3, 0):\n",
    "      data_dict = pickle.load(f, encoding='bytes')\n",
    "    else:\n",
    "      data_dict = pickle.load(f)\n",
    "  return data_dict\n",
    "\n",
    "\n",
    "def convert_to_tfrecord(input_files, output_file):\n",
    "  \"\"\"Converts a file to TFRecords.\"\"\"\n",
    "  print('Generating %s' % output_file)\n",
    "  with tf.python_io.TFRecordWriter(output_file) as record_writer:\n",
    "    for input_file in input_files:\n",
    "      data_dict = read_pickle_from_file(input_file)\n",
    "      data = data_dict[b'data']\n",
    "      labels = data_dict[b'labels']\n",
    "      num_entries_in_batch = len(labels)\n",
    "      for i in range(num_entries_in_batch):\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'image': _bytes_feature(data[i].tobytes()),\n",
    "                'label': _int64_feature(labels[i])\n",
    "            }))\n",
    "        record_writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def main(data_dir):\n",
    "  print('Download from {} and extract.'.format(CIFAR_DOWNLOAD_URL))\n",
    "  # download_and_extract(data_dir)\n",
    "  file_names = _get_file_names()\n",
    "  input_dir = os.path.join(data_dir, CIFAR_LOCAL_FOLDER)\n",
    "  for mode, files in file_names.items():\n",
    "    input_files = [os.path.join(input_dir, f) for f in files]\n",
    "    output_file = os.path.join(data_dir, mode + '.tfrecords')\n",
    "    try:\n",
    "      os.remove(output_file)\n",
    "    except OSError:\n",
    "      pass\n",
    "    # Convert to tf.train.Example and write the to TFRecords.\n",
    "    convert_to_tfrecord(input_files, output_file)\n",
    "  print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = read_pickle_from_file('/root/data/cifar10/cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main('/root/data/cifar10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = read_pickle_from_file('/root/data/cifar10/cifar-10-batches-py/data_batch_1')\n",
    "data = data_dict[b'data']\n",
    "labels = data_dict[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[b'data'][0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_dict[b'data'][0, ...].reshape(3, 32, 32).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(self, image):\n",
    "# \"\"\"Preprocess a single image in [height, width, depth] layout.\"\"\"\n",
    "# if self.subset == 'train' and self.use_distortion:\n",
    "#   # Pad 4 pixels on each dimension of feature map, done in mini-batch\n",
    "#   image = tf.image.resize_image_with_crop_or_pad(image, 40, 40)\n",
    "#   image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "#   image = tf.image.random_flip_left_right(image)\n",
    "# return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    # Custom preprocessing.\n",
    "#     image = self.preprocess(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(['/root/data/cifar10/train.tfrecords']).repeat()\n",
    "\n",
    "# Parse records.\n",
    "dataset = dataset.map(parser, num_parallel_calls=4)\n",
    "# Batch it up.\n",
    "dataset = dataset.batch(4)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "image_batch, label_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        image = sess.run(image_batch)\n",
    "        print(image.shape)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image[0, ...].squeeze().astype(np.uint64))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
