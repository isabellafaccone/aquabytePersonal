{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # Default graph is initialized when the library is imported\n",
    "import os\n",
    "from tensorflow.python.platform import gfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from time import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_path = '/root/data/models/keypoints_detection/2019_05_10_00_36_40/weights/model_76.pb'\n",
    "config_path = '/root/data/models/keypoints_detection/2019_05_10_00_36_40/config.json'\n",
    "config = json.load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks at this too \n",
    "* https://github.com/MarvinTeichmann/KittiSeg/blob/master/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Graph().as_default() as graph: # Set default graph as graph\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         # Load the graph in graph_def\n",
    "#         print(\"load graph\")\n",
    "\n",
    "#         # We load the protobuf file from the disk and parse it to retrive the unserialized graph_drf\n",
    "#         with gfile.FastGFile(proto_path,'rb') as f:\n",
    "\n",
    "#             print(\"Load Image...\")\n",
    "#             # Read the image & get statstics\n",
    "#             image = cv2.imread('/root/data/bati/images/23/4/2019-04-16/left_frame_crop_1006_793_2674_13851555410095.jpg')\n",
    "#             image = cv2.resize(image, (512, 512))\n",
    "#             image = np.expand_dims(image, axis=0)\n",
    "#             # image = image.astype(float)\n",
    "#             Input_image_shape=image.shape\n",
    "#             # height,width,channels = Input_image_shape\n",
    "\n",
    "#             print(\"Plot image...\")\n",
    "#             #scipy.misc.imshow(image)\n",
    "\n",
    "#             # Set FCN graph to the default graph\n",
    "#             graph_def = tf.GraphDef()\n",
    "#             graph_def.ParseFromString(f.read())\n",
    "#             sess.graph.as_default()\n",
    "\n",
    "#             # Import a graph_def into the current default Graph (In this case, the weights are (typically) embedded in the graph)\n",
    "\n",
    "#             tf.import_graph_def(\n",
    "#             graph_def,\n",
    "#             input_map=None,\n",
    "#             return_elements=None,\n",
    "#             name=\"\",\n",
    "#             op_dict=None,\n",
    "#             producer_op_list=None\n",
    "#             )\n",
    "\n",
    "#             # Print the name of operations in the session\n",
    "# #             for op in graph.get_operations():\n",
    "# #                     print(\"Operation Name :\",op.name)         # Operation name\n",
    "# #                     print(\"Tensor Stats :\",str(op.values()))     # Tensor name\n",
    "\n",
    "#             # INFERENCE Here\n",
    "#             l_input = graph.get_tensor_by_name('input_placeholder:0') # Input Tensor\n",
    "#             l_output = graph.get_tensor_by_name('stage_3/mid_conv7/BiasAdd:0') # Output Tensor\n",
    "\n",
    "#             print(\"Shape of input : \", tf.shape(l_input))\n",
    "#             #initialize_all_variables\n",
    "#             tf.global_variables_initializer()\n",
    "\n",
    "#             # Run Kitty model on single image\n",
    "#             start = time()\n",
    "#             Session_out = sess.run( l_output, feed_dict = {l_input : image} )\n",
    "#             end = time()\n",
    "#             print('Inference speed: {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import DataGenerator, load_image_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ann = {'Agreement': None,\n",
    " 'Created At': '2019-03-22T11:20:11.000Z',\n",
    " 'Created By': 'labeler309@cogitotech.com',\n",
    " 'DataRow ID': 'cjtig6gc0ykp30bj46fvyl4lk',\n",
    " 'Dataset Name': 'urls_2019-03-06.csv',\n",
    " 'External ID': None,\n",
    " 'ID': 'cjtjz3gxr5x9d08558tutdzc0',\n",
    " 'Label': {'ADIPOSE_FIN': [{'geometry': {'x': 1832, 'y': 1426}}],\n",
    "  'ANAL_FIN': [{'geometry': {'x': 1710, 'y': 1756}}],\n",
    "  'DORSAL_FIN': [{'geometry': {'x': 1062, 'y': 1307}}],\n",
    "  'EYE': [{'geometry': {'x': 279, 'y': 1496}}],\n",
    "  'PECTORAL_FIN': [{'geometry': {'x': 476, 'y': 1669}}],\n",
    "  'PELVIC_FIN': [{'geometry': {'x': 1206, 'y': 1806}}],\n",
    "  'TAIL_NOTCH': [{'geometry': {'x': 2391, 'y': 1508}}],\n",
    "  'UPPER_LIP': [{'geometry': {'x': 214, 'y': 1494}}]},\n",
    " 'Labeled Data': 'https://s3-eu-west-1.amazonaws.com/aquabyte-groundtruths/phase_I/small-pen-test-site/1/2019-03-06/190306010020/rectified/right_small-pen-test-site_1_1551866655849.jpg',\n",
    " 'Project Name': '2019-03-06: GTSF Phase I Keypoint Annotations',\n",
    " 'Reviews': [],\n",
    " 'Seconds to Label': 109.074,\n",
    " 'View Label': 'https://image-segmentation-v4.labelbox.com?project=cjtig6842jqtp0988oocp4kxb&label=cjtjz3gxr5x9d08558tutdzc0',\n",
    " 'breath': 73,\n",
    " 'kfactor': 1.2123891722600588,\n",
    " 'length': 577,\n",
    " 'local_path': '/root/data/gtsf_phase_I/2019-03-06/190306010020/rectified/right_small-pen-test-site_1_1551866655849.jpg',\n",
    " 'species': 'salmon',\n",
    " 'timestamp': '190306010020',\n",
    " 'weight': 2329,\n",
    " 'width': 125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = 3\n",
    "    joints = 8\n",
    "    cmap_radius = 21\n",
    "    batch_size = 1\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                    \"ADIPOSE_FIN\",\n",
    "                    \"UPPER_LIP\",\n",
    "                    \"ANAL_FIN\",\n",
    "                    \"PELVIC_FIN\",\n",
    "                    \"EYE\",\n",
    "                    \"PECTORAL_FIN\",\n",
    "                    \"DORSAL_FIN\"]\n",
    "    normalize = True\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = 1.0\n",
    "    augmentation = None\n",
    "    crop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1207 114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (699, 2377, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_input, kp_resized = load_image_keypoints(random_ann, FLAGS)\n",
    "# plt.imshow(img_input)\n",
    "# plt.show()\n",
    "img_input = cv2.imread(random_ann['local_path'])\n",
    "plt.imshow(img_input)\n",
    "plt.show()\n",
    "\n",
    "img_input = img_input[1207-buffer:1207+699+buffer, np.max([114-buffer, 0]):114+2377+buffer, :]\n",
    "image = copy.copy(img_input)\n",
    "height, width, _ = image.shape\n",
    "plt.imshow(img_input)\n",
    "plt.show()\n",
    "img_input = cv2.resize(img_input, (512, 512))\n",
    "plt.imshow(img_input)\n",
    "plt.show()\n",
    "img_input  = img_input / 255.0 - 0.5\n",
    "img_input = img_input[np.newaxis, ...]\n",
    "# image, keypoints = load_image_keypoints(random_ann, FLAGS, reshape=False)\n",
    "# height, width, _ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(\n",
    "            graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            name=\"\",\n",
    "            op_dict=None,\n",
    "            producer_op_list=None\n",
    "            )\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(proto_path)\n",
    "l_input = graph.get_tensor_by_name('input_placeholder:0') # Input Tensor\n",
    "l_output = graph.get_tensor_by_name('stage_3/mid_conv7/BiasAdd:0') # Output Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in graph.get_operations():\n",
    "    print(\"Tensor Stats :\",str(op.values()))\n",
    "    break# Tensor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    predict_heatmap = sess.run( l_output, feed_dict = {l_input : img_input} )\n",
    "    print(predict_heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stage_heatmap = predict_heatmap.squeeze()\n",
    "print(final_stage_heatmap.shape)\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(image)\n",
    "for c in range(8):\n",
    "    hm = cv2.resize(final_stage_heatmap[..., c], (width, height))\n",
    "    hm_max = np.where(hm == hm.max())\n",
    "    ax.scatter(hm_max[1], hm_max[0], c=\"r\")\n",
    "# plt.scatter(keypoints[:, 0], keypoints[:, 1], c=\"b\")\n",
    "# ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
