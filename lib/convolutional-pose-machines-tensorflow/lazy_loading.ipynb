{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = (1024, 1024)\n",
    "    heatmap_size = 128\n",
    "    cpm_stages = 3\n",
    "    joint_gaussian_variance = 1.0\n",
    "    center_radius = 21\n",
    "    num_of_joints = 8\n",
    "    color_channel = 'RGB'\n",
    "    normalize = True\n",
    "    use_gpu = True\n",
    "    gpu_id = 0\n",
    "    \n",
    "    gradient_clipping = True # gradient clipping\n",
    "\n",
    "    \"\"\"\n",
    "    Demo settings\n",
    "    \"\"\"\n",
    "    # 'MULTI': show multiple stage heatmaps\n",
    "    # 'SINGLE': show last stage heatmap\n",
    "    # 'Joint_HM': show last stage heatmap for each joint\n",
    "    # 'image or video path': show detection on single image or video\n",
    "    DEMO_TYPE = 'SINGLE'\n",
    "\n",
    "    model_path = 'cpm_hand'\n",
    "    cam_id = 0\n",
    "\n",
    "    use_kalman = True\n",
    "    kalman_noise = 0.03\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                        \"ADIPOSE_FIN\",\n",
    "                        \"UPPER_LIP\",\n",
    "                        \"ANAL_FIN\",\n",
    "                        \"PELVIC_FIN\",\n",
    "                        \"EYE\",\n",
    "                        \"PECTORAL_FIN\",\n",
    "                        \"DORSAL_FIN\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Training settings\n",
    "    \"\"\"\n",
    "    network_def = 'fish_test'\n",
    "    train_img_dir = ''\n",
    "    val_img_dir = ''\n",
    "    bg_img_dir = ''\n",
    "    pretrained_model = 'fish_test'\n",
    "    batch_size = 4\n",
    "    init_lr = 0.001\n",
    "    lr_decay_rate = 0.5\n",
    "    lr_decay_step = 10000\n",
    "    steps_per_epoch = 1000\n",
    "    val_steps_per_epochs = 250\n",
    "    \n",
    "    augmentation = None\n",
    "    buffer_range = [int(n) for n in np.arange(100, 600, 100)] # useless if crop = False\n",
    "    crop = False # crop input image based on keypoints - for GTSF only\n",
    "#     augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "# #                                  albu.Rotate(limit=10, p=1.0)\n",
    "#                                 ], \n",
    "#                                  p=1.0,\n",
    "#                                  keypoint_params={'format': 'xy'})\n",
    "    \n",
    "    epochs=200\n",
    "\n",
    "    hnm = True  # Make sure generate hnm files first\n",
    "    do_cropping = True\n",
    "\n",
    "    \"\"\"\n",
    "    For Freeze graphs\n",
    "    \"\"\"\n",
    "    output_node_names = 'stage_3/mid_conv7/BiasAdd:0'\n",
    "    validation_files = None\n",
    "    training_files = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from utils.utils import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = glob.glob('/root/data/bati/labels/labels_*')\n",
    "print(\"Total number of days: {}\".format(len(annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = []\n",
    "for jpath in annotations:\n",
    "    train_annotations += json.load(open(jpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training data: {}\".format(len(train_annotations)))\n",
    "# train_annotations= [ann for ann in train_annotations if ann[\"species\"] == \"salmon\"]\n",
    "print(\"Number of training data: {}\".format(len(train_annotations)))\n",
    "\n",
    "for ann in train_annotations:\n",
    "    ann['local_path'] = ann['local_path'].replace('/app', '/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(train_annotations, FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(train_generator.__len__())):\n",
    "    x,y, hm = train_generator[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
