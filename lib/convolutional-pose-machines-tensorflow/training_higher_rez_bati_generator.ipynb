{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import albumentations as albu\n",
    "\n",
    "from utils import cpm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = (1024, 1024)\n",
    "    heatmap_size = 128\n",
    "    cpm_stages = 3\n",
    "    joint_gaussian_variance = 1.0\n",
    "    center_radius = 21\n",
    "    num_of_joints = 8\n",
    "    color_channel = 'RGB'\n",
    "    normalize = True\n",
    "    use_gpu = True\n",
    "    gpu_id = 0\n",
    "    \n",
    "    gradient_clipping = True # gradient clipping\n",
    "\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                        \"ADIPOSE_FIN\",\n",
    "                        \"UPPER_LIP\",\n",
    "                        \"ANAL_FIN\",\n",
    "                        \"PELVIC_FIN\",\n",
    "                        \"EYE\",\n",
    "                        \"PECTORAL_FIN\",\n",
    "                        \"DORSAL_FIN\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Training settings\n",
    "    \"\"\"\n",
    "    network_def = 'fish_test'\n",
    "    train_img_dir = ''\n",
    "    val_img_dir = ''\n",
    "    bg_img_dir = ''\n",
    "    pretrained_model = 'fish_test'\n",
    "    batch_size = 4\n",
    "    init_lr = 0.001\n",
    "    lr_decay_rate = 0.5\n",
    "    lr_decay_step = 10000\n",
    "    steps_per_epoch = 1000\n",
    "    val_steps_per_epochs = 250\n",
    "    \n",
    "    augmentation = None\n",
    "    buffer_range = [int(n) for n in np.arange(100, 600, 100)] # useless if crop = False\n",
    "    crop = False # crop input image based on keypoints - for GTSF only\n",
    "#     augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "# #                                  albu.Rotate(limit=10, p=1.0)\n",
    "#                                 ], \n",
    "#                                  p=1.0,\n",
    "#                                  keypoint_params={'format': 'xy'})\n",
    "    \n",
    "    epochs=200\n",
    "\n",
    "    hnm = True  # Make sure generate hnm files first\n",
    "    do_cropping = True\n",
    "\n",
    "    \"\"\"\n",
    "    For Freeze graphs\n",
    "    \"\"\"\n",
    "    output_node_names = 'stage_3/mid_conv7/BiasAdd:0'\n",
    "    validation_files = None\n",
    "    training_files = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpm_model = importlib.import_module('models.nets.' + FLAGS.network_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a bunch of folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datenow = str(datetime.now()).split(\".\")[0].replace(\" \",\"_\").replace(\"-\",\"_\").replace(\":\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/root/data/models/keypoints_detection/{}\".format(datenow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "model_path_suffix = os.path.join(FLAGS.network_def,\n",
    "                                 'input_{}_output_{}'.format(FLAGS.input_size, FLAGS.heatmap_size),\n",
    "                                 'joints_{}'.format(FLAGS.num_of_joints),\n",
    "                                 'stages_{}'.format(FLAGS.cpm_stages),\n",
    "                                 'init_{}_rate_{}_step_{}'.format(FLAGS.init_lr, FLAGS.lr_decay_rate,\n",
    "                                                                  FLAGS.lr_decay_step)\n",
    "                                 )\n",
    "model_save_dir = os.path.join(base_dir,\n",
    "                              'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cpm_model.CPM_Model(input_size=FLAGS.input_size,\n",
    "                            heatmap_size=FLAGS.heatmap_size,\n",
    "                            stages=FLAGS.cpm_stages,\n",
    "                            joints=FLAGS.num_of_joints,\n",
    "                            img_type=FLAGS.color_channel,\n",
    "                            is_training=True)\n",
    "model.build_loss(FLAGS.init_lr, \n",
    "                 FLAGS.lr_decay_rate, \n",
    "                 FLAGS.lr_decay_step, \n",
    "                 optimizer='RMSProp', \n",
    "                 clipping=FLAGS.gradient_clipping)\n",
    "print('=====Model Build=====\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from utils.utils import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(193)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the gtsf session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = glob.glob('/root/data/bati/tfrecords/*')\n",
    "print(\"Total number of days: {}\".format(len(annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Val split. Let's split by experiment. Better practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(len(annotations)*0.8)\n",
    "random.shuffle(annotations)\n",
    "train_files = annotations[:cutoff]\n",
    "val_files = annotations[cutoff:]\n",
    "print(\"Number of training files: {}\".format(len(train_files)))\n",
    "print(\"Number of validation files: {}\".format(len(val_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.validation_files = val_files\n",
    "FLAGS.training_files = train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fn(data_record):\n",
    "    features = {'image': tf.FixedLenFeature([], tf.string),\n",
    "                'heatmaps': tf.FixedLenFeature([], tf.string),\n",
    "                'keypoints': tf.FixedLenFeature([], tf.string)}\n",
    "    sample = tf.parse_single_example(data_record, features)\n",
    "    \n",
    "    image = tf.decode_raw(sample['image'], tf.uint8)      \n",
    "    image.set_shape([FLAGS.input_size[0] * FLAGS.input_size[1] * 3])\n",
    "    image = tf.reshape(image, [FLAGS.input_size[0], FLAGS.input_size[1], 3])\n",
    "    \n",
    "    heatmaps = tf.decode_raw(sample['heatmaps'], tf.float64)\n",
    "    heatmaps.set_shape([FLAGS.heatmap_size * FLAGS.heatmap_size * (FLAGS.num_of_joints + 1)])\n",
    "    heatmaps = tf.reshape(heatmaps, [FLAGS.heatmap_size, FLAGS.heatmap_size, (FLAGS.num_of_joints + 1)])\n",
    "    \n",
    "    keypoints = tf.decode_raw(sample['keypoints'], tf.int64)\n",
    "    keypoints.set_shape([FLAGS.num_of_joints*2])\n",
    "    keypoints = tf.reshape(keypoints, [FLAGS.num_of_joints, 2])\n",
    "    \n",
    "    return image, keypoints, heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(files):\n",
    "    # Initialize all tfrecord paths\n",
    "    dataset = tf.data.TFRecordDataset(files).apply(tf.contrib.data.shuffle_and_repeat(100))\n",
    "    dataset = dataset.map(extract_fn, num_parallel_calls=12)\n",
    "#     dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(FLAGS.batch_size)\n",
    "    dataset = dataset.prefetch(4)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    out = iterator.get_next()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = create_generator(train_files)\n",
    "val_iterator = create_generator(val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "print(model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config\n",
    "with open(os.path.join(base_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump({k:v for (k,v) in FLAGS.__dict__.items() if k not in  [\"__dict__\", '__weakref__', 'augmentation']}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_current_training_stats(global_step, cur_lr, stage_losses, total_loss, time_elapsed):\n",
    "    stats = 'Step: {}/{} ----- Cur_lr: {:1.7f} ----- Time: {:>2.2f} sec.'.format(global_step, FLAGS.steps_per_epoch * FLAGS.epochs,\n",
    "                                                                                 cur_lr, time_elapsed)\n",
    "    losses = ' | '.join(\n",
    "        ['S{} loss: {:>7.2f}'.format(stage_num + 1, stage_losses[stage_num]) for stage_num in range(FLAGS.cpm_stages)])\n",
    "    losses += ' | Total loss: {}'.format(total_loss)\n",
    "    print(stats)\n",
    "    print(losses + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "device_count = {'GPU': 1} if FLAGS.use_gpu else {'GPU': 0}\n",
    "\n",
    "# cause fuck tensorboard\n",
    "history = {\"train_stages_loss\":[],\n",
    "           \"train_total_loss\": [],\n",
    "           \"val_total_loss\": [],\n",
    "           \"learning_rate\": []}\n",
    "\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(device_count=device_count,\n",
    "                                      allow_soft_placement=True)) as sess:\n",
    "    # Create model saver\n",
    "    saver = tf.train.Saver(max_to_keep=None) #max_to_keep=None)\n",
    "\n",
    "    # Init all vars\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        print(\"Epoch {} starts. Number of training steps {}\".format(epoch, FLAGS.steps_per_epoch))\n",
    "        \n",
    "        training_itr = 0\n",
    "        \n",
    "        while training_itr < FLAGS.steps_per_epoch:\n",
    "            t1 = time.time()\n",
    "            # load input + labels\n",
    "            batch_x_np, _, batch_gt_heatmap_np = sess.run(train_iterator)\n",
    "            # print(time.time() - t1)\n",
    "            training_itr += 1\n",
    "            \n",
    "            # Forward and update weights\n",
    "            stage_losses_np, total_loss_np, _, summaries, current_lr, \\\n",
    "            stage_heatmap_np, global_step = sess.run([model.stage_loss,\n",
    "                                                  model.total_loss,\n",
    "                                                  model.train_op,\n",
    "                                                  merged_summary,\n",
    "                                                  model.cur_lr,\n",
    "                                                  model.stage_heatmap,\n",
    "                                                  model.global_step\n",
    "                                                  ],\n",
    "                                                 feed_dict={model.input_images: batch_x_np,\n",
    "                                                            model.gt_hmap_placeholder: batch_gt_heatmap_np})\n",
    "            # print(time.time() - t1)\n",
    "            history[\"train_stages_loss\"].append([float(s) for s in stage_losses_np])\n",
    "            history[\"train_total_loss\"].append(float(total_loss_np))\n",
    "            history['learning_rate'].append(float(current_lr))\n",
    "            # Show training info\n",
    "            if global_step % 10 == 0:\n",
    "                print_current_training_stats(global_step, current_lr, stage_losses_np, total_loss_np, time.time() - t1)\n",
    "\n",
    "        saver.save(sess=sess, save_path=model_save_dir + '/' + FLAGS.network_def.split('.py')[0], \n",
    "                   global_step=epoch)\n",
    "        print('\\nModel checkpoint saved...\\n')\n",
    "        \n",
    "        # now validation stuff\n",
    "        mean_val_loss = 0\n",
    "        val_itr = 0\n",
    "        while val_itr < FLAGS.val_steps_per_epochs:\n",
    "            # load input + labels\n",
    "            batch_x_np, _, batch_gt_heatmap_np = val_iterator\n",
    "            val_itr += 1\n",
    "\n",
    "            val_total_loss, summaries = sess.run([model.total_loss, merged_summary],\n",
    "                                                 feed_dict={model.input_images: batch_x_np,\n",
    "                                                               model.gt_hmap_placeholder: batch_gt_heatmap_np})\n",
    "            mean_val_loss += val_total_loss\n",
    "        \n",
    "        val_mean_loss = mean_val_loss / FLAGS.val_steps_per_epochs\n",
    "        history[\"val_total_loss\"].append(float(val_mean_loss))\n",
    "        print('\\nValidation loss: {:>7.2f}\\n'.format(val_mean_loss))\n",
    "        # save history\n",
    "        with open(os.path.join(base_dir, \"history.json\"), \"w\") as f:\n",
    "            json.dump(history, f)\n",
    "        \n",
    "        print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
