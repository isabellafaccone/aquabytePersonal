{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    \"\"\" \"\"\"\n",
    "    \"\"\"\n",
    "    General settings\n",
    "    \"\"\"\n",
    "    input_size = (1024, 1024)\n",
    "    heatmap_size = 128\n",
    "    cpm_stages = 4\n",
    "    joint_gaussian_variance = 1.0\n",
    "    center_radius = 21\n",
    "    num_of_joints = 8\n",
    "    color_channel = 'RGB'\n",
    "    normalize = True\n",
    "    use_gpu = True\n",
    "    gpu_id = 0\n",
    "    \n",
    "    gradient_clipping = True # gradient clipping\n",
    "\n",
    "    \"\"\"\n",
    "    Demo settings\n",
    "    \"\"\"\n",
    "    # 'MULTI': show multiple stage heatmaps\n",
    "    # 'SINGLE': show last stage heatmap\n",
    "    # 'Joint_HM': show last stage heatmap for each joint\n",
    "    # 'image or video path': show detection on single image or video\n",
    "    DEMO_TYPE = 'SINGLE'\n",
    "\n",
    "    model_path = 'cpm_hand'\n",
    "    cam_id = 0\n",
    "\n",
    "    use_kalman = True\n",
    "    kalman_noise = 0.03\n",
    "    keypoints_order = [\"TAIL_NOTCH\",\n",
    "                        \"ADIPOSE_FIN\",\n",
    "                        \"UPPER_LIP\",\n",
    "                        \"ANAL_FIN\",\n",
    "                        \"PELVIC_FIN\",\n",
    "                        \"EYE\",\n",
    "                        \"PECTORAL_FIN\",\n",
    "                        \"DORSAL_FIN\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Training settings\n",
    "    \"\"\"\n",
    "    network_def = 'fish_test'\n",
    "    train_img_dir = ''\n",
    "    val_img_dir = ''\n",
    "    bg_img_dir = ''\n",
    "    pretrained_model = 'fish_test'\n",
    "    batch_size = 4\n",
    "    init_lr = 0.001\n",
    "    lr_decay_rate = 0.45\n",
    "    lr_decay_step = 8000\n",
    "    augmentation = None\n",
    "    buffer_range = [int(n) for n in np.arange(100, 600, 100)] # useless if crop = False\n",
    "    crop = False # crop input image based on keypoints - for GTSF only\n",
    "#     augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "# #                                  albu.Rotate(limit=10, p=1.0)\n",
    "#                                 ], \n",
    "#                                  p=1.0,\n",
    "#                                  keypoint_params={'format': 'xy'})\n",
    "    \n",
    "    epochs=200\n",
    "\n",
    "    hnm = True  # Make sure generate hnm files first\n",
    "    do_cropping = True\n",
    "\n",
    "    \"\"\"\n",
    "    For Freeze graphs\n",
    "    \"\"\"\n",
    "    output_node_names = 'stage_3/mid_conv7/BiasAdd:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import DataGenerator, data_generator\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open('/root/data/bati/labels/labels_2019-05-10.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotations:\n",
    "    ann['local_path'] = ann['local_path'].replace('/app', '/root')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cpm_utils import make_gaussian\n",
    "from utils.utils import load_image_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap_single(input_size, heatmap_size, gaussian_variance, batch_joints):\n",
    "    scale_factor = input_size // heatmap_size\n",
    "    gt_heatmap_np = []\n",
    "    invert_heatmap_np = np.ones(shape=(heatmap_size, heatmap_size))\n",
    "    for j in range(batch_joints.shape[0]):\n",
    "        cur_joint_heatmap = make_gaussian(heatmap_size,\n",
    "                                          gaussian_variance,\n",
    "                                          center=(batch_joints[j] // scale_factor))\n",
    "        gt_heatmap_np.append(cur_joint_heatmap)\n",
    "        invert_heatmap_np -= cur_joint_heatmap\n",
    "    gt_heatmap_np.append(invert_heatmap_np)\n",
    "    gt_heatmap_np = np.array(gt_heatmap_np)\n",
    "    gt_heatmap_np = np.transpose(gt_heatmap_np, (1, 2, 0))\n",
    "    return gt_heatmap_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_keypoints_gaussian(annotation):\n",
    "#     print('test')\n",
    "    image, keypoints = load_image_keypoints(annotation, FLAGS)\n",
    "    heatmap = make_heatmap_single(FLAGS.input_size[0], \n",
    "                                FLAGS.heatmap_size, \n",
    "                                FLAGS.joint_gaussian_variance,\n",
    "                                keypoints)\n",
    "    return image, keypoints, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# end = time.time()\n",
    "# print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from utils.utils import DataGeneratorAsync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator(keras.utils.Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, annotations_set, FLAGS):\n",
    "#         'Initialization'\n",
    "#         start = time.time()\n",
    "#         self.annotations = annotations_set\n",
    "#         self.on_epoch_end()\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return len(self.annotations) // self.FLAGS.batch_size\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         pool = Pool(4)\n",
    "#         data = pool.map(load_image_keypoints_gaussian, \n",
    "#                         self.annotations[index*FLAGS.batch_size: (index+1)*FLAGS.batch_size]\n",
    "#                        )\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "#         images = np.array([d[0] for d in data])\n",
    "#         keypoints = np.array([d[1] for d in data])\n",
    "#         heatmaps = np.array([d[2] for d in data])\n",
    "#         return images, keypoints, heatmaps\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         np.random.shuffle(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, annotations_set, FLAGS):\n",
    "        'Initialization'\n",
    "        start = time.time()\n",
    "        self.annotations = annotations_set\n",
    "        self.on_epoch_end()\n",
    "        self.FLAGS = FLAGS\n",
    "        pool = Pool(8)\n",
    "        self.data = pool.map_async(load_image_keypoints_gaussian, self.annotations[:100])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        self.batches = []\n",
    "        self._create_batches()\n",
    "        end = time.time()\n",
    "        print('Data is ready for training {}'.format(end-start))\n",
    "        \n",
    "    def _create_batches(self):\n",
    "        data = self.data.get()\n",
    "        images = [t[0] for t in data]\n",
    "        keypoints = [t[1] for t in data]\n",
    "        heatmaps = [t[2] for t in data]\n",
    "        \n",
    "        batch_images = [images[k:k+self.FLAGS.batch_size] for k in range(0, len(images), self.FLAGS.batch_size)]\n",
    "        batch_keypoints = [keypoints[k:k+self.FLAGS.batch_size] for k in range(0, len(keypoints), self.FLAGS.batch_size)]\n",
    "        batch_heatmaps = [heatmaps[k:k+self.FLAGS.batch_size] for k in range(0, len(heatmaps), self.FLAGS.batch_size)]\n",
    "        \n",
    "        for (img, kp, hm) in zip(batch_images, batch_keypoints, batch_heatmaps):\n",
    "            self.batches.append([np.array(img), \n",
    "                                 np.array(batch_keypoints), \n",
    "                                 np.array(batch_heatmaps)])\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.annotations) // self.FLAGS.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        return self.batches[index]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        np.random.shuffle(self.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(annotations)\n",
    "gen = DataGenerator(annotations, FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(25):\n",
    "    print(i)\n",
    "    start = time.time()\n",
    "    output = gen[i]\n",
    "    \n",
    "    print(output[0].shape)\n",
    "    end = time.time()\n",
    "    # time.sleep(0.1)\n",
    "#     print(\"Loading time: {}\".format((end - start)))\n",
    "end = time.time()\n",
    "print(\"Loading time: {}\".format((end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
