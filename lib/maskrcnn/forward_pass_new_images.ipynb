{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[l[i:i + n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/'\n",
    "# experiences = os.listdir(base_dir)\n",
    "# all_image_path = []\n",
    "# for experience in experiences:\n",
    "#     folder_path = os.path.join(base_dir, experience)\n",
    "#     if not os.path.isdir(folder_path):\n",
    "#         continue\n",
    "#     if \"rectified\" not in folder_path:\n",
    "#         continue\n",
    "#     if \"reference\" in folder_path:\n",
    "#         continue\n",
    "#     print(folder_path)\n",
    "#     all_image_path += glob.glob(folder_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_image_path = glob.glob('/root/data/depthmap/*.jpg')\n",
    "# all_image_path = sorted(all_image_path, key = lambda k:int(os.path.basename(k).split('.')[0].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path = []\n",
    "with open('/root/thomas/github/cv_research/thomas/full_pipeline/small_pen/to_forwardpass.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        all_image_path.append(line[:-1])\n",
    "all_image_path = sorted(all_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(all_image_path[:], columns=['image path'])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    Load a dataset for target estimation\n",
    "    \n",
    "    Args:\n",
    "       - dataframe: DataFrame of image path\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.dataframe.iloc[:, 0][index]\n",
    "        img = skimage.io.imread(img_path)\n",
    "        \n",
    "        return img, img_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - MaskRCNN forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mcoco.coco as coco\n",
    "# import mextra.utils as extra_utils\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "BASE_DIR = '/root/data/models/erko/mask_rcnn_instance_segmentation'\n",
    "DATA_DIR = '/root/data/erko/'\n",
    "WEIGHTS_DIR = os.path.join(BASE_DIR, \"weights\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(WEIGHTS_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "rpn_anchor_template = (1, 2, 4, 8, 16) # anchor sizes in pixels\n",
    "rpn_anchor_scales = tuple(i * (image_size // 16) for i in rpn_anchor_template)\n",
    "\n",
    "class FishConfig(Config):\n",
    "    \"\"\"Configuration for training on the shapes dataset.\n",
    "    \"\"\"\n",
    "    # name your experiments here\n",
    "    NAME = \"full\"\n",
    "\n",
    "    # Train on 1 GPU and 2 images per GPU. Put multiple images on each\n",
    "    # GPU if the images are small. Batch size is 2 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 7 + 1  # background + 3 shapes (triangles, circles, and squares)\n",
    "\n",
    "    # Use smaller images for faster training. \n",
    "    IMAGE_MAX_DIM = image_size\n",
    "    IMAGE_MIN_DIM = image_size\n",
    "    \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = rpn_anchor_scales\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "\n",
    "    VALIDATION_STEPS = 300\n",
    "    \n",
    "config = FishConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/root/data/models/small_pen/body_parts/logs/body_parts_uncomlpete_1024_20181010_21H08/mask_rcnn_body_parts_uncomlpete_1024_0100.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(FishConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "\n",
    "# model_path = '/root/data/models/erko/mask_rcnn_instance_segmentation/logs/full_20181002_19H09/mask_rcnn_full_0097.h5'\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image, img_path = data_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed = []\n",
    "# for i in range(1, 10):\n",
    "#     class InferenceConfig(FishConfig):\n",
    "#         GPU_COUNT = 1\n",
    "#         print(i)\n",
    "#         IMAGES_PER_GPU = i\n",
    "\n",
    "#     inference_config = InferenceConfig()\n",
    "\n",
    "#     # Recreate the model in inference mode\n",
    "#     model = modellib.MaskRCNN(mode=\"inference\", \n",
    "#                               config=inference_config,\n",
    "#                               model_dir=MODEL_DIR)\n",
    "\n",
    "#     # Get path to saved weights\n",
    "#     # Either set a specific path or find last trained weights\n",
    "#     # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "#     model.find_last()[1]\n",
    "\n",
    "#     # Load trained weights (fill in path to trained weights here)\n",
    "#     assert model_path != \"\", \"Provide path to trained weights\"\n",
    "\n",
    "#     # model_path = '/root/data/models/erko/mask_rcnn_instance_segmentation/logs/full_20181002_19H09/mask_rcnn_full_0097.h5'\n",
    "#     print(\"Loading weights from \", model_path)\n",
    "#     model.load_weights(model_path, by_name=True)\n",
    "\n",
    "#     start = time.time()\n",
    "#     results = model.detect([original_image]*i, verbose=1)\n",
    "#     end = time.time()\n",
    "#     speed.append(end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear = [k*speed[0] for k in range(1, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, 10), linear)\n",
    "# plt.plot(range(1, 10), speed)\n",
    "# plt.legend(['ohne batch', 'mit batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     while True:\n",
    "#         for image_id in range(len(data_generator)):\n",
    "#             original_image, _ = data_generator[image_id]\n",
    "#             results = model.detect([original_image], verbose=1)\n",
    "#             r = results[0]\n",
    "#             visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             ['BG', 'salmon'], r['scores'], ax=get_ax())\n",
    "\n",
    "#             input('Press enter to continue: ')\n",
    "# except KeyboardInterrupt:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Save coco file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import NamedTemporaryFile\n",
    "from pycocotools.coco import COCO\n",
    "from mextra.utils import result_to_coco\n",
    "from cococreatortools import * \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO = {\n",
    "    \"description\": \"Fish data\",\n",
    "    \"url\": \"https://github.com/waspinator/pycococreator\",\n",
    "    \"version\": \"0.1.0\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"thossler\",\n",
    "    \"date_created\": datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "        \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'name': 'salmon',\n",
    "        'supercategory': 'fish',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = {\"info\": INFO, \"licenses\": LICENSES, \"categories\": CATEGORIES, \"images\": [], \"annotations\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_generator)\n",
    "segmentation_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in tqdm(range(len(data_generator))):\n",
    "    original_image, img_path = data_generator[image_id]\n",
    "    height,width,_ = original_image.shape\n",
    "    print(img_path)\n",
    "    if original_image is not None:\n",
    "        print(image_id)\n",
    "        \n",
    "        results = model.detect([original_image], verbose=1)[0]\n",
    "\n",
    "        # create the coco stuff\n",
    "        image_info = create_image_info(image_id, img_path, [width, height])\n",
    "        coco_output['images'].append(image_info)\n",
    "\n",
    "        # loop through all the fish detected\n",
    "        detections_number = len(results['class_ids'])\n",
    "        for k in range(detections_number):\n",
    "            # print(segmentation_id)\n",
    "            category_info = {'id': int(results['class_ids'][k])}\n",
    "            binary_mask = results['masks'][..., k]\n",
    "            annotation_info = create_annotation_info(segmentation_id, image_id, category_info, binary_mask,\n",
    "                                                     [width, height], bounding_box=results['rois'][k, ...], tolerance=2)\n",
    "            if annotation_info is not None:\n",
    "                coco_output[\"annotations\"].append(annotation_info)\n",
    "            segmentation_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['class_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/small_pen_data_collection/body_parts_detection_20181017.json', 'w') as f:\n",
    "    json.dump(coco_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
