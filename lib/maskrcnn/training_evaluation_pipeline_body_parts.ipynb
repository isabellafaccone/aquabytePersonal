{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "import numpy as np\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open('/root/data/aquabyte-images-resized/segmentation-trainer/Train/body_parts_annotations_20181031.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in annotations['images']:\n",
    "    img[\"local_path\"] = img[\"local-path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/aquabyte-images/cocofiles/coco_body_parts_2018-10-10.json', 'w') as f:\n",
    "    json.dump(annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for an in annotations['images']:\n",
    "    if 'local_path' in an:\n",
    "        an['local_path'] = an['local_path'].replace('sotra-small-pen/pen-1', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/small_pen_data_collection/body_parts_annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/root/data/aquabyte-images/'\n",
    "# coco_file_dir = 'cocofiles'\n",
    "# targets = ['full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_coco_files = []\n",
    "# for file in os.listdir(data_path + coco_file_dir):\n",
    "#     count = 0\n",
    "#     for target in targets:\n",
    "#         if target in file:\n",
    "#             count += 1\n",
    "#     if count == len(targets):\n",
    "#         target_coco_files.append(file)  \n",
    "# size_dict = {}\n",
    "# datas = []\n",
    "# for coco_file in target_coco_files:\n",
    "#     with open(data_path + coco_file_dir + '/' + coco_file) as f:\n",
    "#         coco_dict = json.load(f)\n",
    "#         datas.append(coco_dict)\n",
    "#         size = len(coco_dict['annotations'])\n",
    "#         size_dict[size] = data_path + coco_file_dir + '/' + coco_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_dict = datas[0]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_coco_sizes = [x for x in size_dict.keys() if x < 1000]\n",
    "# print('Split is {}'.format(float(sum(test_coco_sizes)) / sum(size_dict.keys())))\n",
    "# test_coco_files = [size_dict[x] for x in test_coco_sizes]\n",
    "# train_coco_files = [size_dict[x] for x in list(set(size_dict.keys()) - set(test_coco_sizes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /root/data/small_pen_data_collection/body_parts_annotations_misrectified.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coco_files = ['/root/data/aquabyte-images-resized/cocofiles/coco_body_parts_2018-10-10.json']\n",
    "test_coco_files = train_coco_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import keras\n",
    "\n",
    "sys.path.insert(0, '../libraries')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize as visualize\n",
    "from mrcnn.model import log\n",
    "import mcoco.coco as coco\n",
    "from keras.callbacks import Callback\n",
    "# import mextra.utils as extra_utils\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from slack import SlackCallback\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "BASE_DIR = '/root/data/models/small_pen/body_parts/'\n",
    "DATA_DIR = '/root/data/erko/'\n",
    "WEIGHTS_DIR = os.path.join(BASE_DIR, \"weights\")\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(WEIGHTS_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    if not os.path.isdir(os.path.dirname(COCO_MODEL_PATH)):\n",
    "        os.makedirs(os.path.dirname(COCO_MODEL_PATH))\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove eye and body\n",
    "# [1, 3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = coco.CocoDataset()\n",
    "for coco_file in train_coco_files:\n",
    "    dataset_train.load_coco(coco_file, class_ids=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "dataset_train.prepare()\n",
    "print(\"Number of train images: {}\".format(dataset_train.num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validate = coco.CocoDataset()\n",
    "for coco_file in test_coco_files:\n",
    "    dataset_validate.load_coco(coco_file, class_ids=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "dataset_validate.prepare()\n",
    "print(\"Number of train images: {}\".format(dataset_validate.num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_id = np.random.choice(dataset_train.image_ids)\n",
    "image = dataset_train.load_image(random_image_id)\n",
    "mask = dataset_train.load_mask(random_image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f ,ax = plt.subplots(1, figsize=(20, 20))\n",
    "ax.imshow(image); \n",
    "for k in range(mask[0].shape[-1]):\n",
    "    # draw mask\n",
    "    m = mask[0][...,k]\n",
    "    x, y = np.nonzero(m)\n",
    "    img = np.ones( (m.shape[0], m.shape[1], 3) )\n",
    "    color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "    for i in range(3):\n",
    "        img[:,:,i] = color_mask[i]\n",
    "    ax.imshow(np.dstack( (img, m*0.3) ))\n",
    "    \n",
    "    # draw bbox\n",
    "    bbox = [min(y), min(x), max(y)-min(y), max(x)-min(x)]\n",
    "    rec = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax.add_patch(rec)\n",
    "    \n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1024\n",
    "rpn_anchor_template = (1, 2, 4, 8, 16) # anchor sizes in pixels\n",
    "rpn_anchor_scales = tuple(i * (image_size // 16) for i in rpn_anchor_template)\n",
    "\n",
    "class FishConfig(Config):\n",
    "    \"\"\"Configuration for training on the shapes dataset.\n",
    "    \"\"\"\n",
    "    # name your experiments here\n",
    "    NAME = \"todelete\"\n",
    "\n",
    "    # Train on 1 GPU and 2 images per GPU. Put multiple images on each\n",
    "    # GPU if the images are small. Batch size is 2 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = dataset_train.num_classes-1  # background + 3 shapes (triangles, circles, and squares)\n",
    "\n",
    "    # Use smaller images for faster training. \n",
    "    IMAGE_MAX_DIM = image_size\n",
    "    IMAGE_MIN_DIM = image_size\n",
    "    \n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = rpn_anchor_scales\n",
    "\n",
    "    # Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    VALIDATION_STEPS = 10\n",
    "    \n",
    "config = FishConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inititalize_weights_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if inititalize_weights_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "    \n",
    "elif inititalize_weights_with == \"coco\":\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    \n",
    "elif inititalize_weights_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save config\n",
    "c = config.to_json(model.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness,\n",
    "    MotionBlur,\n",
    "    MedianBlur,\n",
    "    Blur\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation = {'albumentations': [\n",
    "#     OneOf([RandomSizedCrop(min_max_height=(300, 300), height=1024, width=1024, p=0.5),\n",
    "#           PadIfNeeded(min_height=1024, min_width=1024, p=0.5)], p=1),\n",
    "#     CLAHE(p=0.6),\n",
    "#     RandomContrast(p=0.6),\n",
    "#     RandomBrightness(p=0.8),\n",
    "#     RandomGamma(p=0.8)], 'imgaug': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = {'albumentations': [OneOf([CLAHE(p=0.2),\n",
    "                                          RandomContrast(p=0.3),\n",
    "                                          RandomBrightness(p=0.4),\n",
    "                                          RandomGamma(p=0.1)], p=0.5),\n",
    "                                   HorizontalFlip(p=0.5),\n",
    "                                   OneOf([MotionBlur(p=.5),\n",
    "                                          MedianBlur(blur_limit=3, p=.2),\n",
    "                                          Blur(blur_limit=3, p=.3)], p=0.1)\n",
    "                                  ], \n",
    "                'imgaug': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "saveh = SaveHistory(os.path.join(model.log_dir, 'history_{}.json'.format(config.NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"xoxp-217481132931-327085549508-466279718992-800b8e847421c61bf073fbbd61d4aa3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more callbacks here if necessary\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=model.log_dir,\n",
    "                                histogram_freq=0, write_graph=True, write_images=False),\n",
    "    keras.callbacks.ModelCheckpoint(model.checkpoint_path,\n",
    "                                    verbose=0, save_weights_only=True),\n",
    "    saveh,\n",
    "    # SlackCallback(token)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_validate, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=100, # starts from the previous epoch, so only 1 additional is trained \n",
    "            layers=\"all\",\n",
    "            callback_list=callbacks,\n",
    "            augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'_'.join('test test test'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/root/data/models/erko/mask_rcnn_instance_segmentation/logs/body_part_segmentation_20181031_21H02/mask_rcnn_body_part_segmentation_0100.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = json.load(open('/root/data/models/erko/mask_rcnn_instance_segmentation/logs/body_part_segmentation_20181031_21H02/config_Body_part_segmentation.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(FishConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Visualisation of prediction on every image of test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions** : Press enter to continue to next image, and ctrl + c or pause the kernel to stop (then enter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        for image_id in dataset_validate.image_ids:\n",
    "            print(image_id)\n",
    "            original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_validate, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "            log(\"original_image\", original_image)\n",
    "            log(\"image_meta\", image_meta)\n",
    "            log(\"gt_class_id\", gt_class_id)\n",
    "            log(\"gt_bbox\", gt_bbox)\n",
    "            log(\"gt_mask\", gt_mask)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(original_image)\n",
    "            plt.show()\n",
    "\n",
    "            visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_validate.class_names, figsize=(8, 8))\n",
    "\n",
    "            results = model.detect([original_image], verbose=1)\n",
    "            r = results[0]\n",
    "            visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_validate.class_names, r['scores'], ax=get_ax())\n",
    "\n",
    "            visualize.display_differences(original_image, gt_bbox, gt_class_id, gt_mask,\n",
    "                        r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "                        dataset_validate.class_names)\n",
    "\n",
    "            input('Press enter to continue: ')\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Evaluation of prediction on every image of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_validate.class_info = [{'id': 0, 'name': 'BG', 'source': ''},\n",
    "#  {'id': 1, 'name': 'salmon', 'source': 'coco'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mextra.utils import compute_per_class_precision, compute_multiple_per_class_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =\\\n",
    "compute_multiple_per_class_precision(model, inference_config, dataset_validate, iou_threshold=0.5)\n",
    "complete_predictions = []\n",
    "\n",
    "for shape in predictions:\n",
    "    complete_predictions += predictions[shape]\n",
    "    print(\"{} ({}): {}\".format(shape, len(predictions[shape]), np.mean(predictions[shape])))\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"average: {}\".format(np.mean(complete_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average: {}\".format(np.mean(complete_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Complementary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mextra.utils import compute_per_class_precision\n",
    "from mrcnn.utils import compute_recall, compute_precision, compute_overlaps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'nb_gt_fish':[], 'nb_pred_fish':[]}\n",
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mask_iou = []\n",
    "mean_precision = []\n",
    "mean_recall = []\n",
    "for i in tqdm(range(len(dataset_validate.image_ids))):\n",
    "    image_id = dataset_validate.image_ids[i]\n",
    "    image, _, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_validate, inference_config,\n",
    "                                image_id, use_mini_mask=False)\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Fill histogram dict\n",
    "    d['nb_gt_fish'].append(float(gt_mask.shape[-1]))\n",
    "    d['nb_pred_fish'].append(float(r['masks'].shape[-1]))\n",
    "    # Recall\n",
    "    mean_recall.append(compute_recall(pred_boxes=r['rois'], gt_boxes=gt_bbox, iou=iou_threshold)[0])\n",
    "    # Precision\n",
    "    mean_precision.append(compute_precision(pred_boxes=r['rois'], gt_boxes=gt_bbox, iou=iou_threshold))\n",
    "    class_precision_info =\\\n",
    "    compute_per_class_precision(gt_bbox, gt_class_id, gt_mask,\n",
    "                r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r[\"masks\"],\n",
    "                dataset_validate.class_info, 0.5)\n",
    "#     # Compute mask overlap\n",
    "#     for overlap in list(class_precision_info['salmon']['overlaps']):\n",
    "#         temp = overlap[overlap!=0]\n",
    "#         if len(temp) > 0:\n",
    "#             mean_mask_iou.append(float(temp.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Mask overlap: {}'.format(sum(mean_mask_iou) / len(mean_mask_iou)))\n",
    "print('Mean precision: {}'.format(sum(mean_precision) / len(mean_precision)))\n",
    "print('Mean recall: {}'.format(sum(mean_recall) / len(mean_recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
