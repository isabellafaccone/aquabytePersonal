{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from research.utils.datetime_utils import day_difference, add_days\n",
    "from research.utils.datetime_utils import get_dates_in_range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    ['2020-02-01', '2020-02-28', 'Feb'],\n",
    "    ['2020-03-01', '2020-03-31', 'Mar'],\n",
    "    ['2020-04-01', '2020-04-30', 'Apr'],\n",
    "    ['2020-05-01', '2020-05-31', 'May'],\n",
    "    ['2020-06-01', '2020-06-30', 'Jun'],\n",
    "    ['2020-07-01', '2020-07-31', 'Jul'],\n",
    "    ['2020-08-01', '2020-08-31', 'Aug'],\n",
    "    ['2020-09-01', '2020-09-30', 'Sep'],\n",
    "    ['2020-10-01', '2020-10-28', 'Oct'],\n",
    "    ['2020-11-01', '2020-11-30', 'Nov'],\n",
    "    ['2020-12-01', '2020-12-31', 'Dec']\n",
    "#     ['2021-01-01', '2020-01-31', 'Jan'],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akpd_filter = 0.99\n",
    "    \n",
    "for date in dates:\n",
    "    start_date = date[0]\n",
    "    end_date = date[1]\n",
    "\n",
    "    if True:\n",
    "        query = '''\n",
    "            SELECT pen_id, captured_at, annotation, camera_metadata, estimated_weight_g, akpd_score FROM prod.biomass_computations\n",
    "              WHERE captured_at >= '%s'\n",
    "              AND captured_at <= '%s'\n",
    "              AND akpd_score > %0.4f;\n",
    "        ''' % (start_date, end_date, akpd_filter)\n",
    "    else:\n",
    "        query = \"\"\"\n",
    "            SELECT pen_id, captured_at, annotation, camera_metadata, estimated_weight_g, akpd_score FROM (\n",
    "              (SELECT pen_id, captured_at, left_crop_url, annotation, camera_metadata FROM prod.crop_annotation cas\n",
    "              INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "              WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "              AND cas.annotation_state_id = 3) a\n",
    "            RIGHT JOIN \n",
    "              (SELECT left_crop_url, estimated_weight_g, akpd_score FROM prod.biomass_computations\n",
    "              WHERE prod.biomass_computations.captured_at >= '%s'\n",
    "              AND prod.biomass_computations.captured_at <= '%s'\n",
    "              AND prod.biomass_computations.akpd_score > %0.4f) bc \n",
    "            ON \n",
    "              (a.left_crop_url=bc.left_crop_url)\n",
    "            ) x\n",
    "            WHERE x.captured_at >= '%s'\n",
    "            AND x.captured_at <= '%s';\n",
    "        \"\"\" % (start_date, end_date, akpd_filter, start_date, end_date)\n",
    "\n",
    "    df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "    depths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        depths.append(depth)\n",
    "    df['depth'] = depths\n",
    "\n",
    "    df = df.sort_values('captured_at').copy(deep=True)\n",
    "    df.index = pd.to_datetime(df.captured_at)\n",
    "    df['date'] = df.index.date\n",
    "    \n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('captured_at').copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "avg_depth = []\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    date = dates[index]\n",
    "    avg_depth.append(np.percentile(df.depth, 99))\n",
    "    \n",
    "plt.plot(avg_depth)\n",
    "    \n",
    "plt.title('Avg depth from camera over 2020')\n",
    "plt.xlabel('Avg weight')\n",
    "plt.ylabel('Depth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "avg_depth = []\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    df2 = df[(df.estimated_weight_g > 4000) & (df.estimated_weight_g < 5000)]\n",
    "    avg_depth.append(np.percentile(df2.depth, 99))\n",
    "    \n",
    "plt.plot(avg_depth)\n",
    "    \n",
    "plt.title('Avg depth from camera over 2020')\n",
    "plt.xlabel('Avg weight')\n",
    "plt.ylabel('Depth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for pen_id in list(set(dfs[4].pen_id)):\n",
    "    pen_plots = []\n",
    "    for index, df in enumerate(dfs):\n",
    "        df2 = df[(df.pen_id == pen_id) & (df.estimated_weight_g > 4000) & (df.estimated_weight_g < 5000)]\n",
    "        if len(df2) == 0:\n",
    "            pen_plots.append(None)\n",
    "        else:\n",
    "            pen_plots.append(np.percentile(df2.depth, 99))\n",
    "    plt.plot(pen_plots)\n",
    "    \n",
    "avg_depth = []\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    date = dates[index]\n",
    "    avg_depth.append(np.percentile(df.depth, 99))\n",
    "    \n",
    "plt.plot(avg_depth, 'o')\n",
    "    \n",
    "plt.title('Avg depth from camera over 2020')\n",
    "plt.xlabel('Avg weight')\n",
    "plt.ylabel('Depth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pen_ids = list(set(dfs[-1].pen_id))\n",
    "\n",
    "for df in dfs[-4:-1]:\n",
    "    all_pen_ids = [p for p in list(set(df.pen_id)) if p in all_pen_ids]\n",
    "    \n",
    "    \n",
    "all_pen_ids\n",
    "\n",
    "# len(dfs[-4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_pens = all_pen_ids\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(all_pens), ncols=3, figsize=(30, 5*len(all_pens)))\n",
    "\n",
    "for pen, ax in zip(all_pens, axes):\n",
    "    depth1 = dfs[-4][dfs[-4].pen_id == pen].depth\n",
    "    depth2 = dfs[-3][dfs[-3].pen_id == pen].depth\n",
    "    depth3 = dfs[-2][dfs[-2].pen_id == pen].depth\n",
    "    \n",
    "    x = np.linspace(0.5, 2, 100)\n",
    "    \n",
    "#     ax[0].plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(depth1)))\n",
    "#     ax[1].plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(depth2)))\n",
    "#     ax[2].plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(depth3)))\n",
    "    ax[0].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth1)))\n",
    "    ax[1].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth2)))\n",
    "    ax[2].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth3)))\n",
    "    \n",
    "    ax[0].hist(depth1, range=(0.5, 2), bins = 20, density = True)\n",
    "    ax[1].hist(depth2, range=(0.5, 2), bins = 20, density = True)\n",
    "    ax[2].hist(depth3, range=(0.5, 2), bins = 20, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_pens = all_pen_ids\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(all_pens), ncols=3, figsize=(30, 5*len(all_pens)))\n",
    "\n",
    "for pen, ax in zip(all_pens, axes):\n",
    "    depth1 = dfs[-4][dfs[-4].pen_id == pen].estimated_weight_g\n",
    "    depth2 = dfs[-3][dfs[-3].pen_id == pen].estimated_weight_g\n",
    "    depth3 = dfs[-2][dfs[-2].pen_id == pen].estimated_weight_g\n",
    "    \n",
    "    x = np.linspace(0, 10000, 100)\n",
    "    ax[0].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth1)))\n",
    "    ax[1].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth2)))\n",
    "    ax[2].plot(x, stats.norm.pdf(x, *stats.norm.fit(depth3)))\n",
    "    \n",
    "    ax[0].hist(depth1, range=(0, 10000), bins = 30, density = True)\n",
    "    ax[1].hist(depth2, range=(0, 10000), bins = 30, density = True)\n",
    "    ax[2].hist(depth3, range=(0, 10000), bins = 30, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "depth_weights = []\n",
    "\n",
    "for index, weight in enumerate(weights):\n",
    "    depth_weights.append([])\n",
    "\n",
    "for index, df in enumerate(dfs):\n",
    "    date = dates[index]\n",
    "    \n",
    "#     depths = np.arange(0, 2.5, 0.1)\n",
    "#     weights = []\n",
    "\n",
    "#     for depth in depths:\n",
    "#         mask = (df['depth'] > depth) & (df['depth'] < depth + 0.1)\n",
    "#         weights.append(np.mean(df[mask]['estimated_weight_g']))\n",
    "\n",
    "    weights = np.arange(0, 8000, 500)\n",
    "    depths = []\n",
    "    \n",
    "    for index, weight in enumerate(weights):\n",
    "        mask = (df['estimated_weight_g'] > weight) & (df['estimated_weight_g'] < weight + 500)\n",
    "        depths.append(np.mean(df[mask]['depth']))\n",
    "        \n",
    "        depth_weights[index].append(np.mean(df[mask]['depth']))\n",
    "        \n",
    "    plt.plot(weights, depths, label = date[2])\n",
    "    \n",
    "plt.title('Avg depth from camera over 2020')\n",
    "plt.xlabel('Avg weight')\n",
    "plt.ylabel('Depth')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, depth_weight in enumerate(depth_weights):\n",
    "    plt.plot(depth_weight, label = weights[index])\n",
    "    \n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1.depth.resample('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_by_day = df_pt1.depth.resample('D').agg(lambda x: x.mean()).fillna(method='ffill')\n",
    "depth_by_day_95 = df_pt1.depth.resample('D').agg(lambda x: np.percentile(x or [1], 95)).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot(depth_by_day)\n",
    "plt.plot(depth_by_day)\n",
    "plt.title('Avg depth from camera over 2020')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Depth from camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
