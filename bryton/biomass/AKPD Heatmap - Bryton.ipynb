{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "# from weight_estimation.dataset import prepare_gtsf_data, compute_akpd_score\n",
    "# from weight_estimation.train import train, augment, normalize, get_data_split, train_model\n",
    "from typing import Dict, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPPER_LIP = 'UPPER_LIP'\n",
    "EYE = 'EYE'\n",
    "PECTORAL_FIN = 'PECTORAL_FIN'\n",
    "DORSAL_FIN = 'DORSAL_FIN'\n",
    "PELVIC_FIN = 'PELVIC_FIN'\n",
    "ADIPOSE_FIN = 'ADIPOSE_FIN'\n",
    "ANAL_FIN = 'ANAL_FIN'\n",
    "TAIL_NOTCH = 'TAIL_NOTCH'\n",
    "UPPER_PRECAUDAL_PIT = 'UPPER_PRECAUDAL_PIT'\n",
    "LOWER_PRECAUDAL_PIT = 'LOWER_PRECAUDAL_PIT'\n",
    "HYPURAL_PLATE = 'HYPURAL_PLATE'\n",
    "\n",
    "core_body_parts = sorted([UPPER_LIP,\n",
    "                          EYE,\n",
    "                          PECTORAL_FIN,\n",
    "                          DORSAL_FIN,\n",
    "                          PELVIC_FIN,\n",
    "                          ADIPOSE_FIN,\n",
    "                          ANAL_FIN,\n",
    "                          TAIL_NOTCH])\n",
    "\n",
    "auxiliary_body_parts = sorted([UPPER_PRECAUDAL_PIT,\n",
    "                               LOWER_PRECAUDAL_PIT,\n",
    "                               HYPURAL_PLATE])\n",
    "\n",
    "all_body_parts = sorted(core_body_parts + auxiliary_body_parts)\n",
    "\n",
    "body_parts = {\n",
    "    'core_body_parts': core_body_parts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m', 'pixel_count_width',\n",
    "                             'pixel_count_height', 'image_sensor_width', 'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in body_parts['core_body_parts']:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "def get_ann_from_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Dict:\n",
    "    \"\"\"Constructs annotation from left and right key-point arrays (i.e. inverse of\n",
    "    get_left_right_keypoint_arrs method.\"\"\"\n",
    "\n",
    "    ann = {'leftCrop': [], 'rightCrop': []}\n",
    "    for idx in range(X_left.shape[0]):\n",
    "        x_left, y_left = tuple(X_left[idx, :])\n",
    "        x_right, y_right = tuple(X_right[idx, :])\n",
    "        body_part = body_parts['core_body_parts'][idx]\n",
    "        left_item = dict(keypointType=body_part, xFrame=x_left, yFrame=y_left)\n",
    "        right_item = dict(keypointType=body_part, xFrame=x_right, yFrame=y_right)\n",
    "        ann['leftCrop'].append(left_item)\n",
    "        ann['rightCrop'].append(right_item)\n",
    "\n",
    "    return ann\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> np.ndarray:\n",
    "    \"\"\"Converts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world).reshape(1, -1)\n",
    "    return X\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import json, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from research.weight_estimation.akpd_utils.akpd_scorer import generate_confidence_score\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "# generate raw GTSF dataframe from database\n",
    "def generate_raw_df(start_date, end_date):\n",
    "    rds = RDSAccessUtils(json.load(open(os.environ['PROD_RESEARCH_SQL_CREDENTIALS'])))\n",
    "    query = \"\"\"\n",
    "        select * from research.fish_metadata a left join keypoint_annotations b\n",
    "        on a.left_url = b.left_image_url \n",
    "        where b.keypoints -> 'leftCrop' is not null\n",
    "        and b.keypoints -> 'rightCrop' is not null\n",
    "        and b.captured_at between '{0}' and '{1}';\n",
    "    \"\"\".format(start_date, end_date)\n",
    "    df = rds.extract_from_database(query)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df.data.apply(lambda x: x['species'].lower()) == 'salmon'].copy(deep=True)\n",
    "    qa_df = df[df.is_qa == True]\n",
    "    cogito_df = df[(df.is_qa != True) & ~(df.left_image_url.isin(qa_df.left_image_url))]\n",
    "    df = pd.concat([qa_df, cogito_df], axis=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_akpd_score(akpd_scorer_network, keypoints: Dict, camera_metadata: Dict) -> float:\n",
    "    input_sample = {\n",
    "        'keypoints': keypoints,\n",
    "        'cm': camera_metadata,\n",
    "        'stereo_pair_id': 0,\n",
    "        'single_point_inference': True\n",
    "    }\n",
    "\n",
    "    akpd_score = generate_confidence_score(input_sample, akpd_scorer_network)\n",
    "    return akpd_score\n",
    "\n",
    "\n",
    "def generate_akpd_scores(df: pd.DataFrame, akpd_scorer_f: str) -> List[float]:\n",
    "    akpd_scorer_network = load_model(akpd_scorer_f)\n",
    "    akpd_scores = []\n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if count % 1000 == 0:\n",
    "            print('Percentage complete: {}%'.format(round(100 * count / df.shape[0], 2)))\n",
    "        count += 1\n",
    "        akpd_score = compute_akpd_score(akpd_scorer_network, row.keypoints, row.camera_metadata)\n",
    "        akpd_scores.append(akpd_score)\n",
    "    return akpd_scores\n",
    "\n",
    "\n",
    "def generate_depths(df: pd.DataFrame):\n",
    "    depths = []\n",
    "    for _, row in df.iterrows():\n",
    "        annotation = row.keypoints\n",
    "        camera_metadata = row.camera_metadata\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "        X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "        X_world = convert_to_world_point_arr(X_left, X_right, cm)\n",
    "        depths.append(np.mean(X_world[:, ]))\n",
    "    return depths\n",
    "\n",
    "\n",
    "def prepare_gtsf_data(start_date: str, end_date: str, akpd_scorer_f: str,\n",
    "                      akpd_score_cutoff: float, depth_cutoff: float) -> pd.DataFrame:\n",
    "    df = generate_raw_df(start_date, end_date)\n",
    "    print('Raw data loaded!')\n",
    "    df = process(df)\n",
    "    print('Data preprocessed!')\n",
    "    df['k_factor'] = 1e5 * df.weight / df.data.apply(lambda x: x['lengthMms']**3).astype(float)\n",
    "    df['akpd_score'] = generate_akpd_scores(df, akpd_scorer_f)\n",
    "    df['depth'] = generate_depths(df)\n",
    "    mask = (df.akpd_score > akpd_score_cutoff) & (df.depth < depth_cutoff)\n",
    "    df = df[mask].copy(deep=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm as colormap\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.interpolate import interpn\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "\n",
    "\n",
    "def augment(df: pd.DataFrame, augmentation_config: Dict) -> pd.DataFrame:\n",
    "    print('hello')\n",
    "    # trials = augmentation_config['trials']\n",
    "    counts, _ = np.histogram(df.weight, bins=np.arange(0, 10000, 1000))\n",
    "    trial_values = (5.0 / (counts / np.max(counts))).astype(int)\n",
    "    max_jitter_std = augmentation_config['max_jitter_std']\n",
    "    min_scaling_factor = augmentation_config['min_scaling_factor']\n",
    "    max_scaling_factor = augmentation_config['max_scaling_factor']\n",
    "\n",
    "    augmented_data = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        weight = row.weight\n",
    "        trials = trial_values[min(int(weight / 1000), len(trial_values) - 1)]\n",
    "        for _ in range(trials):\n",
    "            scaling_factor = np.random.uniform(min_scaling_factor, max_scaling_factor)\n",
    "            jitter_std = np.random.uniform(0, max_jitter_std)\n",
    "            ann = row.keypoints\n",
    "            X_left, X_right = get_left_right_keypoint_arrs(ann)\n",
    "\n",
    "            # rescale\n",
    "            X_left = X_left * scaling_factor\n",
    "            X_right = X_right * scaling_factor\n",
    "\n",
    "            # add jitter\n",
    "            X_left[:, 0] += np.random.normal(0, jitter_std, X_left.shape[0])\n",
    "            X_right[:, 0] += np.random.normal(0, jitter_std, X_right.shape[0])\n",
    "\n",
    "            # reconstruct annotation\n",
    "            ann = get_ann_from_keypoint_arrs(X_left, X_right)\n",
    "            augmented_data['annotation'].append(ann)\n",
    "            augmented_data['fish_id'].append(row.fish_id)\n",
    "            augmented_data['weight'].append(row.weight)\n",
    "            augmented_data['kf'].append(row.k_factor)\n",
    "            augmented_data['camera_metadata'].append(row.camera_metadata)\n",
    "\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "    return augmented_df\n",
    "\n",
    "\n",
    "def normalize(anns: List, camera_metadatas: List) -> np.ndarray:\n",
    "    norm_anns = []\n",
    "    for ann, camera_metadata in zip(anns, camera_metadatas):\n",
    "\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        norm_ann = convert_to_nn_input(ann, cm)\n",
    "        norm_anns.append(norm_ann)\n",
    "    return np.array(norm_anns)\n",
    "\n",
    "\n",
    "def get_data_split(X: np.ndarray, y: np.ndarray, fish_ids: np.ndarray, train_pct: float,\n",
    "                   val_pct: float) -> Tuple:\n",
    "    # select train / test sets such that there are no overlapping fish IDs\n",
    "\n",
    "    test_pct = 1.0 - train_pct - val_pct\n",
    "    unique_fish_ids = np.array(list(set(fish_ids)))\n",
    "    train_cnt, val_cnt, test_cnt = np.random.multinomial(len(unique_fish_ids),\n",
    "                                                         [train_pct, val_pct, test_pct])\n",
    "\n",
    "    assignments = np.array([0] * train_cnt + [1] * val_cnt + [2] * test_cnt)\n",
    "    np.random.shuffle(assignments)\n",
    "    train_fish_ids = unique_fish_ids[np.where(assignments == 0)]\n",
    "    val_fish_ids = unique_fish_ids[np.where(assignments == 1)]\n",
    "    test_fish_ids = unique_fish_ids[np.where(assignments == 2)]\n",
    "\n",
    "    train_mask = np.isin(fish_ids, train_fish_ids)\n",
    "    val_mask = np.isin(fish_ids, val_fish_ids)\n",
    "    test_mask = np.isin(fish_ids, test_fish_ids)\n",
    "\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, train_config):\n",
    "    inputs = Input(shape=(24,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def density_scatter(x, y, bins=20, **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    data, x_e, y_e = np.histogram2d(x, y, bins=bins, density=True)\n",
    "    z = interpn((0.5*(x_e[1:] + x_e[:-1]), 0.5*(y_e[1:]+y_e[:-1])), data, np.vstack([x, y]).T,\n",
    "                method=\"splinef2d\", bounds_error=False)\n",
    "\n",
    "    z[np.where(np.isnan(z))] = 0.0\n",
    "\n",
    "    # Sort the points by density, so that the densest points are plotted last\n",
    "    idx = z.argsort()\n",
    "    x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "    ax.scatter(x, y, c=z, **kwargs)\n",
    "\n",
    "    norm = Normalize(vmin=np.min(z), vmax=np.max(z))\n",
    "    cbar = fig.colorbar(colormap.ScalarMappable(norm=norm), ax=ax)\n",
    "    cbar.ax.set_ylabel('Density')\n",
    "\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_ylabel('Ground Truth')\n",
    "    ax.grid()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_accuracy_details(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train).squeeze().astype(float)\n",
    "    y_test_pred = model.predict(X_test).squeeze().astype(float)\n",
    "    ax_train = density_scatter(1e4 * y_train, 1e4 * y_train_pred)\n",
    "    ax_test = density_scatter(1e4 * y_test, 1e4 * y_test_pred)\n",
    "    train_stats = {\n",
    "        'mean_absolute_error_pct': 100 * np.mean(np.abs((y_train_pred - y_train) / y_train)),\n",
    "        'mean_error_pct': 100 * np.mean(y_train_pred - y_train) / np.mean(y_train)\n",
    "    }\n",
    "    test_stats = {\n",
    "        'mean_absolute_error_pct': 100 * np.mean(np.abs((y_test_pred - y_test) / y_test)),\n",
    "        'mean_error_pct': 100 * np.mean(y_test_pred - y_test) / np.mean(y_test)\n",
    "    }\n",
    "\n",
    "    return ax_train, ax_test, train_stats, test_stats\n",
    "\n",
    "\n",
    "def train(df, augmentation_config, train_config, weight):\n",
    "    print('here')\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    augmented_df = augment(df, augmentation_config)\n",
    "    anns = augmented_df.annotation.values.tolist()\n",
    "    cms = augmented_df.camera_metadata.values.tolist()\n",
    "    X = normalize(anns, cms)\n",
    "\n",
    "    if weight:\n",
    "        y = 1e-4 * augmented_df.weight.values\n",
    "    else:\n",
    "        y = (augmented_df.kf.values - 1.2) / 0.3\n",
    "    print(y)\n",
    "    fish_ids = augmented_df.fish_id.values\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = get_data_split(X, y, fish_ids,\n",
    "                                                                    train_config['train_pct'],\n",
    "                                                                    train_config['val_pct'])\n",
    "    model = train_model(X_train, y_train, X_val, y_val, train_config)\n",
    "    ax_train, ax_test, train_stats, test_stats = \\\n",
    "        generate_accuracy_details(model, X_train, y_train, X_test, y_test)\n",
    "    return model, ax_train, ax_test, train_stats, test_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KP = [\"TAIL_NOTCH\", \"ADIPOSE_FIN\", \"UPPER_LIP\", \"ANAL_FIN\", \"PELVIC_FIN\", \"EYE\", \"PECTORAL_FIN\", \"DORSAL_FIN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/root/data/alok/biomass_estimation/playground/gtsf_keypoints_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded!\n",
      "Data preprocessed!\n",
      "Percentage complete: 0.0%\n",
      "Percentage complete: 6.39%\n",
      "Percentage complete: 12.78%\n",
      "Percentage complete: 19.17%\n",
      "Percentage complete: 25.56%\n",
      "Percentage complete: 31.94%\n",
      "Percentage complete: 38.33%\n",
      "Percentage complete: 44.72%\n",
      "Percentage complete: 51.11%\n",
      "Percentage complete: 57.5%\n",
      "Percentage complete: 63.89%\n",
      "Percentage complete: 70.28%\n",
      "Percentage complete: 76.67%\n",
      "Percentage complete: 83.06%\n",
      "Percentage complete: 89.45%\n",
      "Percentage complete: 95.83%\n",
      "Raw data loaded!\n",
      "Data preprocessed!\n",
      "Percentage complete: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/numpy/core/_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "akpd_scorer_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/keypoint-detection-scorer/akpd_scorer_model_TF.h5'\n",
    "akpd_scorer_f, _, _ = s3.download_from_url(akpd_scorer_url)\n",
    "df1 = prepare_gtsf_data('2019-03-01', '2019-09-20', akpd_scorer_f, 0.5, 1.0)\n",
    "\n",
    "df2 = prepare_gtsf_data('2020-06-01', '2020-08-20', akpd_scorer_f, 0.5, 1.0)\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/bryton/gtsf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "\n",
    "gt_metadata = {'pen_id': 144,\n",
    " 'gutted_average_weight': 8000,\n",
    " 'gutted_weight_distribution': None,\n",
    " 'expected_loss_factor': 0.16,\n",
    " 'last_feeding_date': '2021-01-11',\n",
    " 'harvest_date': '2021-01-15',\n",
    " 'slaughter_date': '2021-01-15'}\n",
    "\n",
    "df2 = extract_biomass_data(gt_metadata['pen_id'], '2021-01-01', '2021-01-12', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from functools import singledispatch\n",
    "\n",
    "\n",
    "@singledispatch\n",
    "def to_serializable(val):\n",
    "    \"\"\"Used by default.\"\"\"\n",
    "    return str(val)\n",
    "\n",
    "\n",
    "@to_serializable.register(np.float32)\n",
    "def ts_float32(val):\n",
    "    \"\"\"Used if *val* is an instance of numpy.float32.\"\"\"\n",
    "    return np.float64(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(keypoints_new, open('/root/data/alok/biomass_estimation/playground/keypoints_new.json', 'w'), default=to_serializable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_url</th>\n",
       "      <th>fish_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>data</th>\n",
       "      <th>stereo_parameters_url</th>\n",
       "      <th>ts_created</th>\n",
       "      <th>ts_updated</th>\n",
       "      <th>data_collection_type_id</th>\n",
       "      <th>id</th>\n",
       "      <th>fish_detection_id</th>\n",
       "      <th>...</th>\n",
       "      <th>left_crop_metadata</th>\n",
       "      <th>right_crop_metadata</th>\n",
       "      <th>camera_metadata</th>\n",
       "      <th>captured_at</th>\n",
       "      <th>is_obscured_floy_tag</th>\n",
       "      <th>is_floy_tag_not_present</th>\n",
       "      <th>k_factor</th>\n",
       "      <th>akpd_score</th>\n",
       "      <th>depth</th>\n",
       "      <th>keypoints_new_crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010048_bolaks-mjanes</td>\n",
       "      <td>4976</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:53.137423+00:00</td>\n",
       "      <td>2019-08-09 04:51:53.137423+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>513838</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'width': 2958, 'height': 887, 'x_coord': 925,...</td>\n",
       "      <td>{'width': 2972, 'height': 896, 'x_coord': 531,...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:17:33.444000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.327622</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>0.280849</td>\n",
       "      <td>{'leftCrop': [{'xCrop': 2845, 'yCrop': 525, 'x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010041_bolaks-mjanes</td>\n",
       "      <td>5571</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:53.761697+00:00</td>\n",
       "      <td>2019-08-09 04:51:53.761697+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>513974</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'width': 2656, 'height': 1660, 'x_coord': 104...</td>\n",
       "      <td>{'width': 2659, 'height': 1720, 'x_coord': 594...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 10:51:19.235000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.524106</td>\n",
       "      <td>0.991292</td>\n",
       "      <td>0.267675</td>\n",
       "      <td>{'leftCrop': [{'xCrop': 2464, 'yCrop': 312, 'x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010041_bolaks-mjanes</td>\n",
       "      <td>5571</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:58.764858+00:00</td>\n",
       "      <td>2019-08-09 04:51:58.764858+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>513938</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'width': 2566, 'height': 2122, 'x_coord': 101...</td>\n",
       "      <td>{'width': 2662, 'height': 2095, 'x_coord': 449...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:00:31.233000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.524106</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.257723</td>\n",
       "      <td>{'leftCrop': [{'xCrop': 2295, 'yCrop': 1763, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010004_bolaks-mjanes</td>\n",
       "      <td>4963</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:52:00.015111+00:00</td>\n",
       "      <td>2019-08-09 04:52:00.015111+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>513945</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'width': 2762, 'height': 813, 'x_coord': 983,...</td>\n",
       "      <td>{'width': 2737, 'height': 827, 'x_coord': 575,...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 08:07:37.747000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.628168</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.278704</td>\n",
       "      <td>{'leftCrop': [{'xCrop': 2615, 'yCrop': 412, 'x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010045_bolaks-mjanes</td>\n",
       "      <td>4760</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:52:01.264800+00:00</td>\n",
       "      <td>2019-08-09 04:52:01.264800+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>514005</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>{'width': 2763, 'height': 862, 'x_coord': 875,...</td>\n",
       "      <td>{'width': 2714, 'height': 885, 'x_coord': 422,...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:12:22.538000+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.575576</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.259930</td>\n",
       "      <td>{'leftCrop': [{'xCrop': 2655, 'yCrop': 545, 'x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            left_url  \\\n",
       "0  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "1  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "2  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "3  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "4  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "\n",
       "                      fish_id  weight  \\\n",
       "0  190607010048_bolaks-mjanes    4976   \n",
       "1  190607010041_bolaks-mjanes    5571   \n",
       "2  190607010041_bolaks-mjanes    5571   \n",
       "3  190607010004_bolaks-mjanes    4963   \n",
       "4  190607010045_bolaks-mjanes    4760   \n",
       "\n",
       "                                                data  \\\n",
       "0  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "1  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "2  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "3  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "4  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "\n",
       "                               stereo_parameters_url  \\\n",
       "0  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "1  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "2  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "3  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "4  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "\n",
       "                        ts_created                       ts_updated  \\\n",
       "0 2019-08-09 04:51:53.137423+00:00 2019-08-09 04:51:53.137423+00:00   \n",
       "1 2019-08-09 04:51:53.761697+00:00 2019-08-09 04:51:53.761697+00:00   \n",
       "2 2019-08-09 04:51:58.764858+00:00 2019-08-09 04:51:58.764858+00:00   \n",
       "3 2019-08-09 04:52:00.015111+00:00 2019-08-09 04:52:00.015111+00:00   \n",
       "4 2019-08-09 04:52:01.264800+00:00 2019-08-09 04:52:01.264800+00:00   \n",
       "\n",
       "  data_collection_type_id      id fish_detection_id  ...  \\\n",
       "0                    None  513838              None  ...   \n",
       "1                    None  513974              None  ...   \n",
       "2                    None  513938              None  ...   \n",
       "3                    None  513945              None  ...   \n",
       "4                    None  514005              None  ...   \n",
       "\n",
       "                                  left_crop_metadata  \\\n",
       "0  {'width': 2958, 'height': 887, 'x_coord': 925,...   \n",
       "1  {'width': 2656, 'height': 1660, 'x_coord': 104...   \n",
       "2  {'width': 2566, 'height': 2122, 'x_coord': 101...   \n",
       "3  {'width': 2762, 'height': 813, 'x_coord': 983,...   \n",
       "4  {'width': 2763, 'height': 862, 'x_coord': 875,...   \n",
       "\n",
       "                                 right_crop_metadata  \\\n",
       "0  {'width': 2972, 'height': 896, 'x_coord': 531,...   \n",
       "1  {'width': 2659, 'height': 1720, 'x_coord': 594...   \n",
       "2  {'width': 2662, 'height': 2095, 'x_coord': 449...   \n",
       "3  {'width': 2737, 'height': 827, 'x_coord': 575,...   \n",
       "4  {'width': 2714, 'height': 885, 'x_coord': 422,...   \n",
       "\n",
       "                                     camera_metadata  \\\n",
       "0  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "1  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "2  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "3  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "4  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "\n",
       "                       captured_at is_obscured_floy_tag  \\\n",
       "0 2019-06-07 11:17:33.444000+00:00                 None   \n",
       "1 2019-06-07 10:51:19.235000+00:00                 None   \n",
       "2 2019-06-07 11:00:31.233000+00:00                 None   \n",
       "3 2019-06-07 08:07:37.747000+00:00                 None   \n",
       "4 2019-06-07 11:12:22.538000+00:00                 None   \n",
       "\n",
       "  is_floy_tag_not_present  k_factor akpd_score     depth  \\\n",
       "0                    None  1.327622   0.983300  0.280849   \n",
       "1                    None  1.524106   0.991292  0.267675   \n",
       "2                    None  1.524106   0.998707  0.257723   \n",
       "3                    None  1.628168   0.996094  0.278704   \n",
       "4                    None  1.575576   0.994926  0.259930   \n",
       "\n",
       "                                  keypoints_new_crop  \n",
       "0  {'leftCrop': [{'xCrop': 2845, 'yCrop': 525, 'x...  \n",
       "1  {'leftCrop': [{'xCrop': 2464, 'yCrop': 312, 'x...  \n",
       "2  {'leftCrop': [{'xCrop': 2295, 'yCrop': 1763, '...  \n",
       "3  {'leftCrop': [{'xCrop': 2615, 'yCrop': 412, 'x...  \n",
       "4  {'leftCrop': [{'xCrop': 2655, 'yCrop': 545, 'x...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keypoints_new_crop'] = keypoints_new_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/root/data/bryton/gtsf_heatmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keypoints_new_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xCrop': 2845,\n",
       " 'yCrop': 525,\n",
       " 'xCropNew': 2848,\n",
       " 'yCropNew': 528,\n",
       " 'xFrame': 3770,\n",
       " 'yFrame': 1556,\n",
       " 'xFrameNew': 3773,\n",
       " 'yFrameNew': 1559,\n",
       " 'score': 0.7335928,\n",
       " 'scoreAvg': 0.32478037,\n",
       " 'scoreMax': 0.7727444,\n",
       " 'keypointType': 'TAIL_NOTCH'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_new_crop[0]['leftCrop'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "depths = []\n",
    "scores = []\n",
    "akpd_scores = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    weights.append(row['data']['weightKgs'])\n",
    "    depths.append(row['depth'])\n",
    "    akpd_scores.append(row['akpd_score'])\n",
    "    \n",
    "for row in keypoints_new_crop:\n",
    "    all_scores = []\n",
    "    \n",
    "    for kp in row['leftCrop']:\n",
    "        all_scores.append(kp['scoreMax'])\n",
    "    \n",
    "    scores.append(np.mean(all_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.33220886,  0.2405703 , -0.06520308],\n",
       "       [-0.33220886,  1.        , -0.16190257,  0.02991022],\n",
       "       [ 0.2405703 , -0.16190257,  1.        ,  0.10005352],\n",
       "       [-0.06520308,  0.02991022,  0.10005352,  1.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.array([weights, depths, scores, akpd_scores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.35260249],\n",
       "       [-0.35260249,  1.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.corrcoef(weights, akpd_scores)\n",
    "np.corrcoef(akpd_scores[0:len(scores)], scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f84192b9c18>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.array(depths)\n",
    "scores = np.array(scores)\n",
    "akpd_scores = np.array(akpd_scores)\n",
    "\n",
    "depth_ranges = np.arange(0, 1, 0.05)\n",
    "\n",
    "depth_score = []\n",
    "depth_akpd_score = []\n",
    "\n",
    "for depth_range in depth_ranges:\n",
    "    mask = (depths > depth_range) & (depths < depth_range + .05)\n",
    "#     print(depth_range, sum(mask))\n",
    "    depth_score.append(np.mean(scores[mask]))\n",
    "    depth_akpd_score.append(np.mean(akpd_scores[mask]))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "    \n",
    "ax.plot(depth_ranges, depth_score, color = 'blue', label = 'Heatmap AKPD score')\n",
    "ax1.plot(depth_ranges, depth_akpd_score, color = 'red', label = 'AKPD score')\n",
    "ax.set_xlabel('Depth')\n",
    "ax.set_ylabel('Max heatmap score')\n",
    "ax1.set_ylabel('AKPD score')\n",
    "ax.set_title('AKPD and Max heatmap score vs Depth')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15367"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 15367\n",
      "100 out of 15367\n",
      "200 out of 15367\n",
      "300 out of 15367\n",
      "400 out of 15367\n",
      "500 out of 15367\n",
      "600 out of 15367\n",
      "700 out of 15367\n",
      "800 out of 15367\n",
      "900 out of 15367\n",
      "1000 out of 15367\n",
      "1100 out of 15367\n",
      "1200 out of 15367\n",
      "1300 out of 15367\n",
      "1400 out of 15367\n",
      "1500 out of 15367\n",
      "1600 out of 15367\n",
      "1700 out of 15367\n",
      "1800 out of 15367\n",
      "1900 out of 15367\n",
      "2000 out of 15367\n",
      "2100 out of 15367\n",
      "2200 out of 15367\n",
      "2300 out of 15367\n",
      "2400 out of 15367\n",
      "2500 out of 15367\n",
      "2600 out of 15367\n",
      "2700 out of 15367\n",
      "2800 out of 15367\n",
      "2900 out of 15367\n",
      "3000 out of 15367\n",
      "3100 out of 15367\n",
      "3200 out of 15367\n",
      "3300 out of 15367\n",
      "3400 out of 15367\n",
      "3500 out of 15367\n",
      "3600 out of 15367\n",
      "3700 out of 15367\n",
      "3800 out of 15367\n",
      "3900 out of 15367\n",
      "4000 out of 15367\n",
      "4100 out of 15367\n",
      "4200 out of 15367\n",
      "4300 out of 15367\n",
      "4400 out of 15367\n",
      "4500 out of 15367\n",
      "4600 out of 15367\n",
      "4700 out of 15367\n",
      "4800 out of 15367\n",
      "4900 out of 15367\n",
      "5000 out of 15367\n",
      "5100 out of 15367\n",
      "5200 out of 15367\n",
      "5300 out of 15367\n",
      "5400 out of 15367\n",
      "5500 out of 15367\n",
      "5600 out of 15367\n",
      "5700 out of 15367\n",
      "5800 out of 15367\n",
      "5900 out of 15367\n",
      "6000 out of 15367\n",
      "6100 out of 15367\n",
      "6200 out of 15367\n",
      "6300 out of 15367\n",
      "6400 out of 15367\n",
      "6500 out of 15367\n",
      "6600 out of 15367\n",
      "6700 out of 15367\n",
      "6800 out of 15367\n",
      "6900 out of 15367\n",
      "7000 out of 15367\n",
      "7100 out of 15367\n",
      "7200 out of 15367\n",
      "7300 out of 15367\n",
      "7400 out of 15367\n",
      "7500 out of 15367\n",
      "7600 out of 15367\n",
      "7700 out of 15367\n",
      "7800 out of 15367\n",
      "7900 out of 15367\n",
      "8000 out of 15367\n",
      "8100 out of 15367\n",
      "8200 out of 15367\n",
      "8300 out of 15367\n",
      "8400 out of 15367\n",
      "8500 out of 15367\n",
      "8600 out of 15367\n",
      "8700 out of 15367\n",
      "8800 out of 15367\n",
      "8900 out of 15367\n",
      "9000 out of 15367\n",
      "9100 out of 15367\n",
      "9200 out of 15367\n",
      "9300 out of 15367\n",
      "9400 out of 15367\n",
      "9500 out of 15367\n",
      "9600 out of 15367\n",
      "9700 out of 15367\n",
      "9800 out of 15367\n",
      "9900 out of 15367\n",
      "10000 out of 15367\n",
      "10100 out of 15367\n",
      "10200 out of 15367\n",
      "10300 out of 15367\n",
      "10400 out of 15367\n",
      "10500 out of 15367\n",
      "10600 out of 15367\n",
      "10700 out of 15367\n",
      "10800 out of 15367\n",
      "10900 out of 15367\n",
      "11000 out of 15367\n",
      "11100 out of 15367\n",
      "11200 out of 15367\n",
      "11300 out of 15367\n",
      "11400 out of 15367\n",
      "11500 out of 15367\n",
      "11600 out of 15367\n",
      "11700 out of 15367\n",
      "11800 out of 15367\n",
      "11900 out of 15367\n",
      "12000 out of 15367\n",
      "12100 out of 15367\n",
      "12200 out of 15367\n",
      "12300 out of 15367\n",
      "12400 out of 15367\n",
      "12500 out of 15367\n",
      "12600 out of 15367\n",
      "12700 out of 15367\n",
      "12800 out of 15367\n",
      "12900 out of 15367\n",
      "13000 out of 15367\n",
      "13100 out of 15367\n",
      "13200 out of 15367\n",
      "13300 out of 15367\n",
      "13400 out of 15367\n",
      "13500 out of 15367\n",
      "13600 out of 15367\n",
      "13700 out of 15367\n",
      "13800 out of 15367\n",
      "13900 out of 15367\n",
      "14000 out of 15367\n",
      "14100 out of 15367\n",
      "14200 out of 15367\n",
      "14300 out of 15367\n",
      "14400 out of 15367\n",
      "14500 out of 15367\n",
      "14600 out of 15367\n",
      "14700 out of 15367\n",
      "14800 out of 15367\n",
      "14900 out of 15367\n",
      "15000 out of 15367\n",
      "15100 out of 15367\n",
      "15200 out of 15367\n",
      "15300 out of 15367\n"
     ]
    }
   ],
   "source": [
    "# keypoints_new_crop = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if count % 100 == 0:\n",
    "        print(count, 'out of', len(df))\n",
    "\n",
    "    count = count + 1\n",
    "    \n",
    "    if count < 13101:\n",
    "        continue\n",
    "        \n",
    "    oL, oR, kpL, kpR, kpLScore, kpRScore, kpLScoreAvg, kpRScoreAvg, kpLScoreMax, kpRScoreMax = get_keypoints_with_crop(row)\n",
    "    \n",
    "    newKeypoints = {\n",
    "        'leftCrop': [],\n",
    "        'rightCrop': []\n",
    "    }\n",
    "    \n",
    "    left_crop_metadata = row.left_crop_metadata\n",
    "    right_crop_metadata = row.right_crop_metadata\n",
    "    \n",
    "    for i in np.arange(0, len(KP), 1):\n",
    "        newKeypoints['leftCrop'].append({\n",
    "            'xCrop': oL[i][0],\n",
    "            'yCrop': oL[i][1],\n",
    "            'xCropNew': kpL[i][0],\n",
    "            'yCropNew': kpL[i][1],\n",
    "            'xFrame': oL[i][0] + left_crop_metadata['x_coord'],\n",
    "            'yFrame': oL[i][1] + left_crop_metadata['y_coord'],\n",
    "            'xFrameNew': kpL[i][0] + left_crop_metadata['x_coord'],\n",
    "            'yFrameNew': kpL[i][1] + left_crop_metadata['y_coord'],\n",
    "            'score': kpLScore[i],\n",
    "            'scoreAvg': kpLScoreAvg[i],\n",
    "            'scoreMax': kpLScoreMax[i],\n",
    "            'keypointType': KP[i]\n",
    "        })\n",
    "        \n",
    "        newKeypoints['rightCrop'].append({\n",
    "            'xCrop': oR[i][0],\n",
    "            'yCrop': oR[i][1],\n",
    "            'xCropNew': kpR[i][0],\n",
    "            'yCropNew': kpR[i][1],\n",
    "            'xFrame': oR[i][0] + right_crop_metadata['x_coord'],\n",
    "            'yFrame': oR[i][1] + right_crop_metadata['y_coord'],\n",
    "            'xFrameNew': kpR[i][0] + right_crop_metadata['x_coord'],\n",
    "            'yFrameNew': kpR[i][1] + right_crop_metadata['y_coord'],\n",
    "            'score': kpRScore[i],\n",
    "            'scoreAvg': kpRScoreAvg[i],\n",
    "            'scoreMax': kpRScoreMax[i],\n",
    "            'keypointType': KP[i]\n",
    "        })\n",
    "        \n",
    "    keypoints_new_crop.append(newKeypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_bak_path = '/root/data/bati/model/config.json'\n",
    "# config_bak = json.load(open(config_bak_path))\n",
    "# config_bak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-296fb27fd244>:34: calling import_graph_def (from tensorflow.python.framework.importer) with op_dict is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "config_path = '/root/data/bryton/akpd_production_config.json'\n",
    "# config_path = '/root/data/bati/model/config_4_stage.json'\n",
    "\n",
    "checkpoint_path = '/root/data/bryton/model_499.pb'\n",
    "config = json.load(open(config_path))\n",
    "\n",
    "class FLAGS(object):\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = config[\"cpm_stages\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = 512#config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    crop = config[\"crop\"]\n",
    "    augmentation = None\n",
    "    \n",
    "def load_pb(path_to_pb):\n",
    "    with tf.io.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, input_map=None,\n",
    "                                return_elements=None,\n",
    "                                name=\"\",\n",
    "                                op_dict=None,\n",
    "                                producer_op_list=None)\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "#         for t in graph_nodes:\n",
    "#             print(t.name)\n",
    "        return graph\n",
    "\n",
    "mod = load_pb(checkpoint_path)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "sess.graph.as_default()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "tf_device = '/gpu:0'\n",
    "with tf.device(tf_device):\n",
    "    model = mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def image_resize(image, FLAGS):\n",
    "    height, width, _ = image.shape\n",
    "    ratio_width = width / FLAGS.input_size[0]\n",
    "    ratio_height = height / FLAGS.input_size[1]\n",
    "    image = cv2.resize(image, FLAGS.input_size)\n",
    "    image  = image / 255.0 - 0.5\n",
    "    image = image[np.newaxis, ...]\n",
    "    return image\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(row):\n",
    "    imL = row['left_image_url']\n",
    "    imR = row['right_image_url']\n",
    "    lco = row['left_crop_metadata']\n",
    "    rco = row['right_crop_metadata']\n",
    "    meta = row['camera_metadata']\n",
    "\n",
    "    imageL = url_to_image(imL)\n",
    "    imageR = url_to_image(imR)\n",
    "    \n",
    "    \n",
    "\n",
    "    img1 = enhance(imageL)\n",
    "    img2 = enhance(imageR)\n",
    "\n",
    "    heightL, widthL, _ = img1.shape\n",
    "    img_input = image_resize(img1, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "\n",
    "    heightR, widthR, _ = img2.shape\n",
    "    img_input = image_resize(img2, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "\n",
    "    oL = [] # original left key-points using max method\n",
    "    oR = [] # original right key-points using max method\n",
    "    kpL = [] # new left key-points using avg method\n",
    "    kpR = [] # new right key-points using avg method\n",
    "    kpLScore = []\n",
    "    kpRScore = []\n",
    "    kpLScoreAvg = []\n",
    "    kpRScoreAvg = []\n",
    "    kpLScoreMax = []\n",
    "    kpRScoreMax = []\n",
    "\n",
    "    for c in np.arange(0, len(KP), 1):\n",
    "        hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "        hm_maxL = list(np.where(hm == hm.max()))   \n",
    "        \n",
    "        ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape) # 2D locations corresponding to highest 10000 heatmap values\n",
    "        x = np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "        y = np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "\n",
    "        oL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "        kpL.append([int(np.rint(x)), int(np.rint(y))])\n",
    "        kpLScore.append(hm[int(np.rint(y)), int(np.rint(x))])\n",
    "        kpLScoreAvg.append(np.mean(hm[ii]))\n",
    "        kpLScoreMax.append(hm.max())\n",
    "\n",
    "        hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "        hm_maxR = np.where(hm == hm.max())\n",
    "    \n",
    "        ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape)\n",
    "        x = np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "        y = np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "\n",
    "        oR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "        kpR.append([int(np.rint(x)), int(np.rint(y))])\n",
    "        kpRScore.append(hm[int(np.rint(y)), int(np.rint(x))])\n",
    "        kpRScoreAvg.append(np.mean(hm[ii]))\n",
    "        kpRScoreMax.append(hm.max())\n",
    "\n",
    "    return oL, oR, kpL, kpR, kpLScore, kpRScore, kpLScoreAvg, kpRScoreAvg, kpLScoreMax, kpRScoreMax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_with_crop(row):\n",
    "    imL = row['left_image_url']\n",
    "    imR = row['right_image_url']\n",
    "    lco = row['left_crop_metadata']\n",
    "    rco = row['right_crop_metadata']\n",
    "    meta = row['camera_metadata']\n",
    "    gt_keypoints = row['keypoints']\n",
    "\n",
    "    # imL = row['left_crop_url']\n",
    "    # imR = row['right_crop_url']\n",
    "    # lco = row['left_crop_metadata']\n",
    "    # rco = row['right_crop_metadata']\n",
    "    # meta = row['camera_metadata']\n",
    "\n",
    "    imageL = url_to_image(imL)\n",
    "    imageR = url_to_image(imR)\n",
    "\n",
    "    leftCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "    rightCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "\n",
    "    for keypoint in gt_keypoints['leftCrop']:\n",
    "        leftCrop[0] = min(leftCrop[0], keypoint['xCrop'])\n",
    "        leftCrop[1] = max(leftCrop[1], keypoint['xCrop'])\n",
    "        leftCrop[2] = min(leftCrop[2], keypoint['yCrop'])\n",
    "        leftCrop[3] = max(leftCrop[3], keypoint['yCrop'])\n",
    "\n",
    "    for keypoint in gt_keypoints['rightCrop']:\n",
    "        rightCrop[0] = min(rightCrop[0], keypoint['xCrop'])\n",
    "        rightCrop[1] = max(rightCrop[1], keypoint['xCrop'])\n",
    "        rightCrop[2] = min(rightCrop[2], keypoint['yCrop'])\n",
    "        rightCrop[3] = max(rightCrop[3], keypoint['yCrop'])\n",
    "\n",
    "    buffer = 100\n",
    "\n",
    "    cropL = [max(leftCrop[0] - buffer, 0), min(leftCrop[1] + buffer, meta['pixelCountWidth']), max(leftCrop[2] - buffer, 0), min(leftCrop[3] + buffer, meta['pixelCountHeight'])]\n",
    "    min_x, max_x, min_y, max_y = cropL\n",
    "\n",
    "    newImageL = imageL[min_y:(max_y + 1), min_x:(max_x+1),:]\n",
    "\n",
    "    cropR = [max(rightCrop[0] - buffer, 0), min(rightCrop[1] + buffer, meta['pixelCountWidth']), max(rightCrop[2] - buffer, 0), min(rightCrop[3] + buffer, meta['pixelCountHeight'])]\n",
    "    min_x, max_x, min_y, max_y = cropR\n",
    "\n",
    "    newImageR = imageR[min_y:(max_y + 1), min_x:(max_x+1),:]\n",
    "\n",
    "    img1 = enhance(newImageL)\n",
    "    img2 = enhance(newImageR)\n",
    "\n",
    "    heightL, widthL, _ = img1.shape\n",
    "    img_input = image_resize(img1, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "\n",
    "    heightR, widthR, _ = img2.shape\n",
    "    img_input = image_resize(img2, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "\n",
    "    oL = [] # original left key-points using max method\n",
    "    oR = [] # original right key-points using max method\n",
    "    kpL = [] # new left key-points using avg method\n",
    "    kpR = [] # new right key-points using avg method\n",
    "    kpLScore = []\n",
    "    kpRScore = []\n",
    "    kpLScoreAvg = []\n",
    "    kpRScoreAvg = []\n",
    "    kpLScoreMax = []\n",
    "    kpRScoreMax = []\n",
    "\n",
    "    for c in np.arange(0, len(KP), 1):\n",
    "        hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "        hm_maxL = list(np.where(hm == hm.max()))   \n",
    "        \n",
    "        ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape) # 2D locations corresponding to highest 10000 heatmap values\n",
    "        x = np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "        y = np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "\n",
    "        oL.append([cropL[0] + int(hm_maxL[1][0]), cropL[2] + int(hm_maxL[0][0])]) \n",
    "        kpL.append([cropL[0] + int(np.rint(x)), cropL[2] + int(np.rint(y))])\n",
    "        kpLScore.append(hm[int(np.rint(y)), int(np.rint(x))])\n",
    "        kpLScoreAvg.append(np.mean(hm[ii]))\n",
    "        kpLScoreMax.append(hm.max())\n",
    "\n",
    "        hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "        hm_maxR = np.where(hm == hm.max())\n",
    "    \n",
    "        ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape)\n",
    "        x = np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "        y = np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "\n",
    "        oR.append([cropR[0] + int(hm_maxR[1][0]), cropR[2] + int(hm_maxR[0][0])])\n",
    "        kpR.append([cropR[0] + int(np.rint(x)), cropR[2] + int(np.rint(y))])\n",
    "        kpRScore.append(hm[int(np.rint(y)), int(np.rint(x))])\n",
    "        kpRScoreAvg.append(np.mean(hm[ii]))\n",
    "        kpRScoreMax.append(hm.max())\n",
    "\n",
    "    return oL, oR, kpL, kpR, kpLScore, kpRScore, kpLScoreAvg, kpRScoreAvg, kpLScoreMax, kpRScoreMax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[24]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[24]\n",
    "    \n",
    "imL = row['left_image_url']\n",
    "imR = row['right_image_url']\n",
    "lco = row['left_crop_metadata']\n",
    "rco = row['right_crop_metadata']\n",
    "meta = ast.literal_eval(row['camera_metadata'])\n",
    "\n",
    "gt_keypoints = ast.literal_eval(row['keypoints'])\n",
    "\n",
    "# imL = row['left_crop_url']\n",
    "# imR = row['right_crop_url']\n",
    "# lco = row['left_crop_metadata']\n",
    "# rco = row['right_crop_metadata']\n",
    "# meta = row['camera_metadata']\n",
    "\n",
    "imageL = url_to_image(imL)\n",
    "imageR = url_to_image(imR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "rightCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "\n",
    "for keypoint in gt_keypoints['leftCrop']:\n",
    "    leftCrop[0] = min(leftCrop[0], keypoint['xCrop'])\n",
    "    leftCrop[1] = max(leftCrop[1], keypoint['xCrop'])\n",
    "    leftCrop[2] = min(leftCrop[2], keypoint['yCrop'])\n",
    "    leftCrop[3] = max(leftCrop[3], keypoint['yCrop'])\n",
    "    \n",
    "buffer = 100\n",
    "\n",
    "min_x, max_x, min_y, max_y = [max(leftCrop[0] - buffer, 0), min(leftCrop[1] + buffer, meta['pixelCountWidth']), max(leftCrop[2] - buffer, 0), min(leftCrop[3] + buffer, meta['pixelCountHeight'])]\n",
    "print(max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.imshow(imageL[min_y:(max_y + 1), min_x:(max_x+1),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['input_name']='input_placeholder:0'\n",
    "config['output_name']='stage_3/mid_conv7/BiasAdd:0'\n",
    "\n",
    "# for row in df.iterrows():\n",
    "\n",
    "\n",
    "# def get_keypoints(row):\n",
    "    # row = df.iloc[0]\n",
    "row = df.iloc[24]\n",
    "    \n",
    "imL = row['left_image_url']\n",
    "imR = row['right_image_url']\n",
    "lco = row['left_crop_metadata']\n",
    "rco = row['right_crop_metadata']\n",
    "meta = ast.literal_eval(row['camera_metadata'])\n",
    "gt_keypoints = ast.literal_eval(row['keypoints'])\n",
    "\n",
    "# imL = row['left_crop_url']\n",
    "# imR = row['right_crop_url']\n",
    "# lco = row['left_crop_metadata']\n",
    "# rco = row['right_crop_metadata']\n",
    "# meta = row['camera_metadata']\n",
    "\n",
    "imageL = url_to_image(imL)\n",
    "imageR = url_to_image(imR)\n",
    "\n",
    "leftCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "rightCrop = [meta['pixelCountWidth'], 0, meta['pixelCountHeight'], 0]\n",
    "\n",
    "for keypoint in gt_keypoints['leftCrop']:\n",
    "    leftCrop[0] = min(leftCrop[0], keypoint['xCrop'])\n",
    "    leftCrop[1] = max(leftCrop[1], keypoint['xCrop'])\n",
    "    leftCrop[2] = min(leftCrop[2], keypoint['yCrop'])\n",
    "    leftCrop[3] = max(leftCrop[3], keypoint['yCrop'])\n",
    "\n",
    "for keypoint in gt_keypoints['rightCrop']:\n",
    "    rightCrop[0] = min(rightCrop[0], keypoint['xCrop'])\n",
    "    rightCrop[1] = max(rightCrop[1], keypoint['xCrop'])\n",
    "    rightCrop[2] = min(rightCrop[2], keypoint['yCrop'])\n",
    "    rightCrop[3] = max(rightCrop[3], keypoint['yCrop'])\n",
    "    \n",
    "buffer = 100\n",
    "\n",
    "cropL = [max(leftCrop[0] - buffer, 0), min(leftCrop[1] + buffer, meta['pixelCountWidth']), max(leftCrop[2] - buffer, 0), min(leftCrop[3] + buffer, meta['pixelCountHeight'])]\n",
    "min_x, max_x, min_y, max_y = cropL\n",
    "\n",
    "newImageL = imageL[min_y:(max_y + 1), min_x:(max_x+1),:]\n",
    "\n",
    "cropR = [max(rightCrop[0] - buffer, 0), min(rightCrop[1] + buffer, meta['pixelCountWidth']), max(rightCrop[2] - buffer, 0), min(rightCrop[3] + buffer, meta['pixelCountHeight'])]\n",
    "min_x, max_x, min_y, max_y = cropR\n",
    "\n",
    "newImageR = imageR[min_y:(max_y + 1), min_x:(max_x+1),:]\n",
    "\n",
    "img1 = enhance(newImageL)\n",
    "img2 = enhance(newImageR)\n",
    "\n",
    "heightL, widthL, _ = img1.shape\n",
    "img_input = image_resize(img1, FLAGS)\n",
    "with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "    predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "\n",
    "heightR, widthR, _ = img2.shape\n",
    "img_input = image_resize(img2, FLAGS)\n",
    "with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "    predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "\n",
    "# SIFT matching\n",
    "# MIN_MATCH_COUNT = 10\n",
    "# GOOD_PERC = 0.7\n",
    "# sift = cv2.KAZE_create()\n",
    "# FLANN_INDEX_KDTREE = 0\n",
    "# index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "# search_params = dict(checks = 50)\n",
    "\n",
    "# kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "# kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "# flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "# matches = flann.knnMatch(des1,des2,k=2)\n",
    "# good = []\n",
    "# for m,n in matches:\n",
    "#     if m.distance < GOOD_PERC*n.distance:\n",
    "#         good.append(m)\n",
    "# if len(good)>=MIN_MATCH_COUNT:\n",
    "#     src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "#     dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "#     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "#     matchesMask = mask.ravel().tolist()\n",
    "# else:\n",
    "#     print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "#     matchesMask = None\n",
    "\n",
    "# Hx=M\n",
    "# Hy=np.linalg.inv(M)\n",
    "\n",
    "# kpL = []\n",
    "# kpR = []    \n",
    "# kpL2R = []\n",
    "# kpR2L = [] \n",
    "# im1ps = []\n",
    "# im2ps = []\n",
    "# gtL2R = []\n",
    "# gtR2L = [] \n",
    "# gt1ps = []\n",
    "# gt2ps = []\n",
    "\n",
    "# for c in np.arange(0, len(KP), 1):\n",
    "#     hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "\n",
    "#     hm_maxL = list(np.where(hm == hm.max()))   \n",
    "#     kpL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "#     ptx=np.array([kpL[c][0],kpL[c][1],1])\n",
    "#     zx=np.dot(Hx,ptx)\n",
    "#     kpL2R.append([int(zx[0]/zx[2]), int(zx[1]/zx[2])]) \n",
    "\n",
    "#     hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "#     hm_maxR = np.where(hm == hm.max())\n",
    "#     kpR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "#     pty=np.array([kpR[c][0],kpR[c][1],1])\n",
    "#     zy=np.dot(Hy,pty)\n",
    "#     kpR2L.append([int(zy[0]/zy[2]), int(zy[1]/zy[2])]) \n",
    "\n",
    "#     im1ps.append([int((kpL[c][0]+kpR2L[c][0])/2), int((kpL[c][1]+kpR2L[c][1])/2)]) \n",
    "#     im2ps.append([int((kpR[c][0]+kpL2R[c][0])/2), int((kpR[c][1]+kpL2R[c][1])/2)]) \n",
    "        \n",
    "#     return kpL, kpR, im1ps, im2ps, final_stage_heatmapL, final_stage_heatmapR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_keypoints_left = []\n",
    "refined_keypoints_right = []\n",
    "\n",
    "for c in np.arange(0, len(KP), 1):\n",
    "    hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "    ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape)\n",
    "    # list(np.where(hm == hm.max()))\n",
    "    x = cropL[0] + np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "    y = cropL[2] + np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "    \n",
    "    refined_keypoints_left.append([np.rint(x), np.rint(y)])\n",
    "\n",
    "    hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "    ii = np.unravel_index(np.argsort(hm.ravel())[-10000:], hm.shape)\n",
    "    # list(np.where(hm == hm.max()))\n",
    "    x = cropR[0] + np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "    y = cropR[2] + np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "    \n",
    "    refined_keypoints_right.append([np.rint(x), np.rint(y)])\n",
    "    \n",
    "    #ii\n",
    "# X = x / hmL.shape[0] * row.left_crop_metadata['width']\n",
    "# Y = y / hmL.shape[1] * row.left_crop_metadata['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.exp(hm[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_keypoints_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.where(hm == hm.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sum(np.exp(hm[ii]) * ii[1]) / np.sum(np.exp(hm[ii]))\n",
    "y = np.sum(np.exp(hm[ii]) * ii[0]) / np.sum(np.exp(hm[ii]))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm[112, 1174], hm[111, 1154], hm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.arange(0, len(KP), 1):\n",
    "    hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "    print(KP[c], hm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpL, kpR, im1ps, im2ps, final_stage_heatmapL, final_stage_heatmapR = get_keypoints(df2.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, os\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "\n",
    "def display_crops(left_image_f, right_image_f, ann, overlay_keypoints=True, show_labels=False, secondary = False, custom_kps_left = {}, custom_kps_right = {}):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    left_ann, right_ann = ann['leftCrop'], ann['rightCrop']\n",
    "    \n",
    "    if secondary is False:\n",
    "        left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in left_ann}\n",
    "        right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in right_ann}\n",
    "    else:\n",
    "        left_keypoints = {item['keypointType']: [item['xCropNew'], item['yCropNew']] for item in left_ann}\n",
    "        right_keypoints = {item['keypointType']: [item['xCropNew'], item['yCropNew']] for item in right_ann}\n",
    "        \n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in custom_kps_left.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='cyan', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='cyan')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in custom_kps_right.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='cyan', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='cyan')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[24]\n",
    "\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "ann, cm = row.keypoints, row.camera_metadata\n",
    "\n",
    "# left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "# ann, cm = row.annotation, row.camera_metadata\n",
    "\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "wkps1 = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oDists = {}\n",
    "nDists = {}\n",
    "oldAkpdScore = {}\n",
    "akpdScore = {}\n",
    "akpdScoreAvg = {}\n",
    "akpdScoreMax = {}\n",
    "\n",
    "for kp in KP:\n",
    "    oDists[kp] = []\n",
    "    nDists[kp] = []\n",
    "    oldAkpdScore[kp] = []\n",
    "    akpdScore[kp] = []\n",
    "    akpdScoreAvg[kp] = []\n",
    "    akpdScoreMax[kp] = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if cnt % 500  == 0:\n",
    "        print(cnt)\n",
    "        \n",
    "    oldScore = row['akpd_score']\n",
    "        \n",
    "    for i in np.arange(0, len(KP)):\n",
    "        keypoints = ast.literal_eval(row['keypoints'])\n",
    "        keypoints_new = row['keypoints_new_crop']#ast.literal_eval(row['keypoints_new_crop'])\n",
    "        \n",
    "        newKeypointLeft = [kp for kp in keypoints_new['leftCrop'] if kp['keypointType'] == KP[i]][0]\n",
    "        newKeypointRight = [kp for kp in keypoints_new['rightCrop'] if kp['keypointType'] == KP[i]][0]\n",
    "    \n",
    "        gtKeypoint = [kp for kp in keypoints['leftCrop'] if kp['keypointType'] == KP[i]][0]\n",
    "        gtX = gtKeypoint['xCrop']\n",
    "        gtY = gtKeypoint['yCrop']\n",
    "\n",
    "        oX = newKeypointLeft['xCrop']\n",
    "        oY = newKeypointLeft['yCrop']\n",
    "\n",
    "        nX = newKeypointLeft['xCropNew']\n",
    "        nY = newKeypointLeft['yCropNew']\n",
    "        \n",
    "        score = newKeypointLeft['score']\n",
    "        scoreAvg = newKeypointLeft['scoreAvg']\n",
    "        scoreMax = newKeypointLeft['scoreMax']\n",
    "        \n",
    "        oDist = np.abs(gtX - oX) + np.abs(gtY - oY)\n",
    "        nDist = np.abs(gtX - nX) + np.abs(gtY - nY)\n",
    "        \n",
    "#         if oDist > 1000:\n",
    "#             print(KP[i], index, gtX, oX, gtY, oY)\n",
    "#             stop = True\n",
    "\n",
    "        oDists[KP[i]].append(oDist)\n",
    "        nDists[KP[i]].append(nDist)\n",
    "        oldAkpdScore[KP[i]].append(oldScore)\n",
    "        akpdScore[KP[i]].append(score)\n",
    "        akpdScoreAvg[KP[i]].append(scoreAvg)\n",
    "        akpdScoreMax[KP[i]].append(scoreMax)\n",
    "\n",
    "        gtKeypoint = [kp for kp in keypoints['rightCrop'] if kp['keypointType'] == KP[i]][0]\n",
    "        gtX = gtKeypoint['xCrop']\n",
    "        gtY = gtKeypoint['yCrop']\n",
    "\n",
    "        oX = newKeypointRight['xCrop']\n",
    "        oY = newKeypointRight['yCrop']\n",
    "\n",
    "        nX = newKeypointRight['xCropNew']\n",
    "        nY = newKeypointRight['yCropNew']\n",
    "        \n",
    "        score = newKeypointRight['score']\n",
    "        scoreAvg = newKeypointRight['scoreAvg']\n",
    "        scoreMax = newKeypointRight['scoreMax']\n",
    "\n",
    "        oDist = np.abs(gtX - oX) + np.abs(gtY - oY)\n",
    "        nDist = np.abs(gtX - nX) + np.abs(gtY - nY)\n",
    "\n",
    "        oDists[KP[i]].append(oDist)\n",
    "        nDists[KP[i]].append(nDist)\n",
    "        oldAkpdScore[KP[i]].append(oldScore)\n",
    "        akpdScore[KP[i]].append(score)\n",
    "        akpdScoreAvg[KP[i]].append(scoreAvg)\n",
    "        akpdScoreMax[KP[i]].append(scoreMax)\n",
    "\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "#     if cnt >= 449:\n",
    "#         break\n",
    "#     np.mean(oDists), np.mean(nDists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = KP[0]\n",
    "\n",
    "plt.scatter(akpdScore[kp], nDists[kp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = oldAkpdScore[kp]\n",
    "X = sm.add_constant(X)\n",
    "y = nDists[kp]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = akpdScoreMax[kp]\n",
    "X = sm.add_constant(X)\n",
    "y = oDists[kp]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = akpdScoreMax[kp]\n",
    "X = sm.add_constant(X)\n",
    "y = nDists[kp]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kp in KP:\n",
    "    oData = np.array(oDists[kp])\n",
    "    nData = np.array(nDists[kp])\n",
    "    diff = oData - nData\n",
    "    \n",
    "    print(kp, np.median(oData), np.median(nData), np.median(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[24]\n",
    "\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = ast.literal_eval(row.keypoints), ast.literal_eval(row.camera_metadata)\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "# ann, cm = ast.literal_eval(row.keypoints_new), ast.literal_eval(row.camera_metadata)\n",
    "ann, cm = row.keypoints_new_crop, ast.literal_eval(row.camera_metadata)\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oL, oR, kpL, kpR, kpLScore, kpRScore, kpLScoreAvg, kpRScoreAvg, kpLScoreMax, kpRScoreMax = get_keypoints_with_crop(row)\n",
    "\n",
    "left_crop_metadata = ast.literal_eval(row.left_crop_metadata)\n",
    "right_crop_metadata = ast.literal_eval(row.right_crop_metadata)\n",
    "\n",
    "newKeypoints = {\n",
    "    'leftCrop': [],\n",
    "    'rightCrop': []\n",
    "}\n",
    "\n",
    "for i in np.arange(0, len(KP), 1):\n",
    "    newKeypoints['leftCrop'].append({\n",
    "        'xCrop': oL[i][0],\n",
    "        'yCrop': oL[i][1],\n",
    "        'xCropNew': kpL[i][0],\n",
    "        'yCropNew': kpL[i][1],\n",
    "        'xFrame': oL[i][0] + left_crop_metadata['x_coord'],\n",
    "        'yFrame': oL[i][1] + left_crop_metadata['y_coord'],\n",
    "        'xFrameNew': kpL[i][0] + left_crop_metadata['x_coord'],\n",
    "        'yFrameNew': kpL[i][1] + left_crop_metadata['y_coord'],\n",
    "        'score': kpLScore[i],\n",
    "        'scoreAvg': kpLScoreAvg[i],\n",
    "        'scoreMax': kpLScoreMax[i],\n",
    "        'keypointType': KP[i]\n",
    "    })\n",
    "\n",
    "    newKeypoints['rightCrop'].append({\n",
    "        'xCrop': oR[i][0],\n",
    "        'yCrop': oR[i][1],\n",
    "        'xCropNew': kpR[i][0],\n",
    "        'yCropNew': kpR[i][1],\n",
    "        'xFrame': oR[i][0] + right_crop_metadata['x_coord'],\n",
    "        'yFrame': oR[i][1] + right_crop_metadata['y_coord'],\n",
    "        'xFrameNew': kpR[i][0] + right_crop_metadata['x_coord'],\n",
    "        'yFrameNew': kpR[i][1] + right_crop_metadata['y_coord'],\n",
    "        'score': kpRScore[i],\n",
    "        'scoreAvg': kpRScoreAvg[i],\n",
    "        'scoreMax': kpRScoreMax[i],\n",
    "        'keypointType': KP[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imL = row['left_image_url']\n",
    "imR = row['right_image_url']\n",
    "lco = row['left_crop_metadata']\n",
    "rco = row['right_crop_metadata']\n",
    "meta = row['camera_metadata']\n",
    "\n",
    "imageL = url_to_image(imL)\n",
    "imageR = url_to_image(imR)\n",
    "\n",
    "img1 = enhance(imageL)\n",
    "img2 = enhance(imageR)\n",
    "\n",
    "heightL, widthL, _ = img1.shape\n",
    "img_input = image_resize(img1, FLAGS)\n",
    "with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "    predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "\n",
    "heightR, widthR, _ = img2.shape\n",
    "img_input = image_resize(img2, FLAGS)\n",
    "with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "    predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "final_stage_heatmapR = predict_heatmap.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KP = [\"TAIL_NOTCH\", \"ADIPOSE_FIN\", \"UPPER_LIP\", \"ANAL_FIN\", \"PELVIC_FIN\", \"EYE\", \"PECTORAL_FIN\", \"DORSAL_FIN\"]\n",
    "\n",
    "fig, axes = plt.subplots(len(KP), 2, figsize=(2 * 5, len(KP) * 5))\n",
    "\n",
    "for i in np.arange(0, len(KP), 1):\n",
    "    axes[i, 0].imshow(final_stage_heatmapL[:,:,i], cmap='hot', interpolation='nearest')\n",
    "    axes[i, 0].set_title('%s %s' % (KP[i], 'Left'))\n",
    "    axes[i, 1].imshow(final_stage_heatmapR[:,:,i], cmap='hot', interpolation='nearest')\n",
    "    axes[i, 1].set_title('%s %s' % (KP[i], 'Right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
