{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "from report_generation.report_generator import generate_ts_data, SamplingFilter\n",
    "from research.utils.datetime_utils import add_days\n",
    "from report_generation.report_generator import gen_pm_base\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values, ValidationError\n",
    "from filter_optimization.filter_optimization_task import _add_date_hour_columns\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = [\n",
    "    'seglberget_pen_id_66_2020-05-13_2020-06-13',\n",
    "    'bolaks_pen_id_88_2020-02-28_2020-03-10',\n",
    "    'langoy_pen_id_108_2020-05-07_2020-05-17',\n",
    "    'tittelsnes_pen_id_37_2020-06-10_2020-06-24',\n",
    "    'aplavika_pen_id_95_2020-07-10_2020-07-26',\n",
    "#     'kjeppevikholmen_pen_id_5_2019-06-18_2019-07-02',\n",
    "    'silda_pen_id_86_2020-07-02_2020-07-19',\n",
    "    'vikane_pen_id_60_2020-08-10_2020-08-30',\n",
    "    'eldviktaren_pen_id_164_2020-09-21_2020-10-08',\n",
    "#     'habranden_pen_id_100_2020-08-10_2020-08-31',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'dale_pen_id_143_2020-10-07_2020-10-21',\n",
    "    'djubawik_pen_id_153_2020-11-10_2020-11-26',\n",
    "    'leivsethamran_pen_id_165_2020-10-18_2020-11-13',\n",
    "    'movikodden_pen_id_114_2020-11-03_2020-11-25',\n",
    "    'movikodden_pen_id_167_2020-10-13_2020-10-30',\n",
    "    'slapoya_pen_id_116_2020-10-18_2020-11-08',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'varholmen_pen_id_151_2020-10-02_2020-10-17',\n",
    "    'varholmen_pen_id_186_2020-10-18_2020-11-02'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/seglberget_pen_id_66_2020-05-13_2020-06-13/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/bolaks_pen_id_88_2020-02-28_2020-03-10/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/langoy_pen_id_108_2020-05-07_2020-05-17/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/tittelsnes_pen_id_37_2020-06-10_2020-06-24/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/aplavika_pen_id_95_2020-07-10_2020-07-26/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/silda_pen_id_86_2020-07-02_2020-07-19/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/vikane_pen_id_60_2020-08-10_2020-08-30/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/eldviktaren_pen_id_164_2020-09-21_2020-10-08/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/varholmen_pen_id_131_2020-08-15_2020-08-30/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/dale_pen_id_143_2020-10-07_2020-10-21/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/djubawik_pen_id_153_2020-11-10_2020-11-26/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/leivsethamran_pen_id_165_2020-10-18_2020-11-13/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/movikodden_pen_id_114_2020-11-03_2020-11-25/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/movikodden_pen_id_167_2020-10-13_2020-10-30/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/slapoya_pen_id_116_2020-10-18_2020-11-08/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/varholmen_pen_id_131_2020-08-15_2020-08-30/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/varholmen_pen_id_151_2020-10-02_2020-10-17/ground_truth_metadata.json\n",
      "https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets/varholmen_pen_id_186_2020-10-18_2020-11-02/ground_truth_metadata.json\n"
     ]
    }
   ],
   "source": [
    "batch_name = 'test'\n",
    "\n",
    "ROOT_DIR = '/root/data/alok/biomass_estimation/playground'\n",
    "dfs, gt_metadatas = {}, {}\n",
    "for cohort_name in cohort_names:\n",
    "    s3_dir = os.path.join(\n",
    "        'https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets',\n",
    "        cohort_name\n",
    "    )\n",
    "\n",
    "    ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata.json')\n",
    "    ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata.json')\n",
    "#     ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata_validated.json')\n",
    "#     ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata_validated.json')\n",
    "    ground_truth_f = os.path.join(ROOT_DIR, ground_truth_key_base)\n",
    "    print(ground_truth_metadata_url)\n",
    "    s3.download_from_url(ground_truth_metadata_url, custom_location=ground_truth_f)\n",
    "    gt_metadata = json.load(open(ground_truth_f))\n",
    "    gt_metadatas[cohort_name] = gt_metadata\n",
    "    \n",
    "    data_url = os.path.join(s3_dir, 'annotation_dataset.csv')\n",
    "    data_f, _, _= s3.download_from_url(data_url)\n",
    "    df = pd.read_csv(data_f)\n",
    "    df = _add_date_hour_columns(df)\n",
    "    dfs[cohort_name] = df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\"\"\"This module contains utility helper functions for the WeightEstimator class.\"\"\"\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from research.weight_estimation.keypoint_utils import body_parts\n",
    "\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m',\n",
    "                             'pixel_count_width', 'pixel_count_height', 'image_sensor_width',\n",
    "                             'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in body_parts.core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def normalize_left_right_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Tuple:\n",
    "    \"\"\"Normalizes input left and right key-point arrays. The normalization involves (1) 2D\n",
    "    translation of all keypoints such that they are centered, (2) rotation of the 2D coordiantes\n",
    "    about the center such that the line passing through UPPER_LIP and fish center is horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    # translate key-points, perform reflection if necessary\n",
    "    upper_lip_idx = body_parts.core_body_parts.index(body_parts.UPPER_LIP)\n",
    "    tail_notch_idx = body_parts.core_body_parts.index(body_parts.TAIL_NOTCH)\n",
    "    if X_left[upper_lip_idx, 0] > X_left[tail_notch_idx, 0]:\n",
    "        X_center = 0.5 * (np.max(X_left, axis=0) + np.min(X_left, axis=0))\n",
    "        X_left_centered = X_left - X_center\n",
    "        X_right_centered = X_right - X_center\n",
    "    else:\n",
    "        X_center = 0.5 * (np.max(X_right, axis=0) + np.min(X_right, axis=0))\n",
    "        X_left_centered = X_right - X_center\n",
    "        X_right_centered = X_left - X_center\n",
    "        X_left_centered[:, 0] = -X_left_centered[:, 0]\n",
    "        X_right_centered[:, 0] = -X_right_centered[:, 0]\n",
    "\n",
    "    # rotate key-points\n",
    "    upper_lip_x, upper_lip_y = tuple(X_left_centered[upper_lip_idx])\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    D = X_left_centered - X_right_centered\n",
    "    X_left_rot = np.dot(X_left_centered, R)\n",
    "    X_right_rot = X_left_rot - D\n",
    "    return X_left_rot, X_right_rot\n",
    "\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world\n",
    "\n",
    "\n",
    "def stabilize_keypoints(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transforms world coordinate array so that neural network inputs are stabilized\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    X_new[:, 0] = 0.5 * X[:, 0] / X[:, 1]\n",
    "    X_new[:, 1] = 0.5 * X[:, 2] / X[:, 1]\n",
    "    X_new[:, 2] = 0.05 / X[:, 1]\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return nn_input\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This module contains the WeightEstimator class for estimating fish weight (g), length (mm), and\n",
    "k-factor given input keypoint coordinates and camera metadata.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WeightEstimator:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb'\n",
    "\n",
    "weight_model_f, _, _ = s3.download_from_url(model_url)\n",
    "kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/playground/kf_predictor_v2.pb')\n",
    "\n",
    "weight_estimator = WeightEstimator(weight_model_f, kf_model_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsf = pd.read_csv('/root/data/bryton/gtsf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>left_url</th>\n",
       "      <th>fish_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>data</th>\n",
       "      <th>stereo_parameters_url</th>\n",
       "      <th>ts_created</th>\n",
       "      <th>ts_updated</th>\n",
       "      <th>data_collection_type_id</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>camera_metadata</th>\n",
       "      <th>captured_at</th>\n",
       "      <th>is_obscured_floy_tag</th>\n",
       "      <th>is_floy_tag_not_present</th>\n",
       "      <th>world_keypoints</th>\n",
       "      <th>median_depth</th>\n",
       "      <th>k_factor</th>\n",
       "      <th>akpd_score</th>\n",
       "      <th>raw_keypoint_arr</th>\n",
       "      <th>centered_keypoint_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010048_bolaks-mjanes</td>\n",
       "      <td>4976</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:53.137423+00:00</td>\n",
       "      <td>2019-08-09 04:51:53.137423+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513838</td>\n",
       "      <td>...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:17:33.444000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'UPPER_LIP': array([-0.24470074,  0.62729652,...</td>\n",
       "      <td>0.650968</td>\n",
       "      <td>1.327622</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>[[ 0.29665902  0.65370901  0.0371452 ]\\n [ 0.2...</td>\n",
       "      <td>[[-0.2200682   0.68251286  0.0496789 ]\\n [-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010041_bolaks-mjanes</td>\n",
       "      <td>5571</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:53.761697+00:00</td>\n",
       "      <td>2019-08-09 04:51:53.761697+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513974</td>\n",
       "      <td>...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 10:51:19.235000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'EYE': array([-0.202985  ,  0.61124366, -0.10...</td>\n",
       "      <td>0.644215</td>\n",
       "      <td>1.524106</td>\n",
       "      <td>0.991292</td>\n",
       "      <td>[[ 0.21614698  0.64689954  0.12005937]\\n [ 0.2...</td>\n",
       "      <td>[[-0.23040524  0.64973057  0.06615438]\\n [-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010041_bolaks-mjanes</td>\n",
       "      <td>5571</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:51:58.764858+00:00</td>\n",
       "      <td>2019-08-09 04:51:58.764858+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513938</td>\n",
       "      <td>...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:00:31.233000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'DORSAL_FIN': array([0.07129592, 0.63240688, ...</td>\n",
       "      <td>0.629841</td>\n",
       "      <td>1.524106</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>[[ 0.23102901  0.62984134 -0.09269089]\\n [ 0.1...</td>\n",
       "      <td>[[-0.20120857  0.64450776  0.05282977]\\n [-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010004_bolaks-mjanes</td>\n",
       "      <td>4963</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:52:00.015111+00:00</td>\n",
       "      <td>2019-08-09 04:52:00.015111+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513945</td>\n",
       "      <td>...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 08:07:37.747000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'EYE': array([-0.19309489,  0.60528612,  0.03...</td>\n",
       "      <td>0.637601</td>\n",
       "      <td>1.628168</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>[[ 0.263826    0.63760119  0.07350241]\\n [ 0.2...</td>\n",
       "      <td>[[-2.06731951e-01  6.60805292e-01  4.62634596e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://s3-eu-west-1.amazonaws.com/aquabyte-cr...</td>\n",
       "      <td>190607010045_bolaks-mjanes</td>\n",
       "      <td>4760</td>\n",
       "      <td>{'species': 'salmon', 'location': 'Generic', '...</td>\n",
       "      <td>https://aquabyte-stereo-parameters.s3-eu-west-...</td>\n",
       "      <td>2019-08-09 04:52:01.264800+00:00</td>\n",
       "      <td>2019-08-09 04:52:01.264800+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514005</td>\n",
       "      <td>...</td>\n",
       "      <td>{'baseline': 0.12693501988129197, 'focalLength...</td>\n",
       "      <td>2019-06-07 11:12:22.538000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'UPPER_LIP': array([-0.26499333,  0.6160948 ,...</td>\n",
       "      <td>0.638913</td>\n",
       "      <td>1.575576</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>[[ 0.23513952  0.63891313  0.04152812]\\n [ 0.1...</td>\n",
       "      <td>[[-0.21537457  0.64401304  0.06392314]\\n [-0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           left_url  \\\n",
       "0           0  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "1           1  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "2           2  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "3           3  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "4           4  https://s3-eu-west-1.amazonaws.com/aquabyte-cr...   \n",
       "\n",
       "                      fish_id  weight  \\\n",
       "0  190607010048_bolaks-mjanes    4976   \n",
       "1  190607010041_bolaks-mjanes    5571   \n",
       "2  190607010041_bolaks-mjanes    5571   \n",
       "3  190607010004_bolaks-mjanes    4963   \n",
       "4  190607010045_bolaks-mjanes    4760   \n",
       "\n",
       "                                                data  \\\n",
       "0  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "1  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "2  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "3  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "4  {'species': 'salmon', 'location': 'Generic', '...   \n",
       "\n",
       "                               stereo_parameters_url  \\\n",
       "0  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "1  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "2  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "3  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "4  https://aquabyte-stereo-parameters.s3-eu-west-...   \n",
       "\n",
       "                         ts_created                        ts_updated  \\\n",
       "0  2019-08-09 04:51:53.137423+00:00  2019-08-09 04:51:53.137423+00:00   \n",
       "1  2019-08-09 04:51:53.761697+00:00  2019-08-09 04:51:53.761697+00:00   \n",
       "2  2019-08-09 04:51:58.764858+00:00  2019-08-09 04:51:58.764858+00:00   \n",
       "3  2019-08-09 04:52:00.015111+00:00  2019-08-09 04:52:00.015111+00:00   \n",
       "4  2019-08-09 04:52:01.264800+00:00  2019-08-09 04:52:01.264800+00:00   \n",
       "\n",
       "   data_collection_type_id      id  ...  \\\n",
       "0                      NaN  513838  ...   \n",
       "1                      NaN  513974  ...   \n",
       "2                      NaN  513938  ...   \n",
       "3                      NaN  513945  ...   \n",
       "4                      NaN  514005  ...   \n",
       "\n",
       "                                     camera_metadata  \\\n",
       "0  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "1  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "2  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "3  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "4  {'baseline': 0.12693501988129197, 'focalLength...   \n",
       "\n",
       "                        captured_at  is_obscured_floy_tag  \\\n",
       "0  2019-06-07 11:17:33.444000+00:00                   NaN   \n",
       "1  2019-06-07 10:51:19.235000+00:00                   NaN   \n",
       "2  2019-06-07 11:00:31.233000+00:00                   NaN   \n",
       "3  2019-06-07 08:07:37.747000+00:00                   NaN   \n",
       "4  2019-06-07 11:12:22.538000+00:00                   NaN   \n",
       "\n",
       "   is_floy_tag_not_present                                    world_keypoints  \\\n",
       "0                      NaN  {'UPPER_LIP': array([-0.24470074,  0.62729652,...   \n",
       "1                      NaN  {'EYE': array([-0.202985  ,  0.61124366, -0.10...   \n",
       "2                      NaN  {'DORSAL_FIN': array([0.07129592, 0.63240688, ...   \n",
       "3                      NaN  {'EYE': array([-0.19309489,  0.60528612,  0.03...   \n",
       "4                      NaN  {'UPPER_LIP': array([-0.26499333,  0.6160948 ,...   \n",
       "\n",
       "   median_depth  k_factor  akpd_score  \\\n",
       "0      0.650968  1.327622    0.983300   \n",
       "1      0.644215  1.524106    0.991292   \n",
       "2      0.629841  1.524106    0.998707   \n",
       "3      0.637601  1.628168    0.996094   \n",
       "4      0.638913  1.575576    0.994926   \n",
       "\n",
       "                                    raw_keypoint_arr  \\\n",
       "0  [[ 0.29665902  0.65370901  0.0371452 ]\\n [ 0.2...   \n",
       "1  [[ 0.21614698  0.64689954  0.12005937]\\n [ 0.2...   \n",
       "2  [[ 0.23102901  0.62984134 -0.09269089]\\n [ 0.1...   \n",
       "3  [[ 0.263826    0.63760119  0.07350241]\\n [ 0.2...   \n",
       "4  [[ 0.23513952  0.63891313  0.04152812]\\n [ 0.1...   \n",
       "\n",
       "                               centered_keypoint_arr  \n",
       "0  [[-0.2200682   0.68251286  0.0496789 ]\\n [-0.1...  \n",
       "1  [[-0.23040524  0.64973057  0.06615438]\\n [-0.1...  \n",
       "2  [[-0.20120857  0.64450776  0.05282977]\\n [-0.1...  \n",
       "3  [[-2.06731951e-01  6.60805292e-01  4.62634596e...  \n",
       "4  [[-0.21537457  0.64401304  0.06392314]\\n [-0.1...  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtsf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = gtsf.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                 0\n",
       "left_url                   https://s3-eu-west-1.amazonaws.com/aquabyte-cr...\n",
       "fish_id                                           190607010048_bolaks-mjanes\n",
       "weight                                                                  4976\n",
       "data                       {'species': 'salmon', 'location': 'Generic', '...\n",
       "stereo_parameters_url      https://aquabyte-stereo-parameters.s3-eu-west-...\n",
       "ts_created                                  2019-08-09 04:51:53.137423+00:00\n",
       "ts_updated                                  2019-08-09 04:51:53.137423+00:00\n",
       "data_collection_type_id                                                  NaN\n",
       "id                                                                    513838\n",
       "fish_detection_id                                                        NaN\n",
       "annotated_by_email                                      bati4@cogitotech.com\n",
       "is_qa                                                                   True\n",
       "is_skipped                                                             False\n",
       "is_blurry                                                                NaN\n",
       "is_dark                                                                  NaN\n",
       "is_occluded                                                              NaN\n",
       "is_bad_orientation                                                       NaN\n",
       "is_partial                                                               NaN\n",
       "direction                                                               LEFT\n",
       "keypoints                  {'version': 2, 'leftCrop': [{'xCrop': 168, 'yC...\n",
       "work_duration_left_ms                                                  58180\n",
       "work_duration_right_ms                                                 48546\n",
       "created_at                                  2019-07-20 07:19:49.888219+00:00\n",
       "updated_at                                  2019-07-20 07:19:49.888219+00:00\n",
       "site_id                                                                   35\n",
       "pen_id                                                                    48\n",
       "left_image_url             https://s3-eu-west-1.amazonaws.com/aquabyte-cr...\n",
       "right_image_url            https://s3-eu-west-1.amazonaws.com/aquabyte-cr...\n",
       "left_crop_metadata         {'width': 2958, 'height': 887, 'x_coord': 925,...\n",
       "right_crop_metadata        {'width': 2972, 'height': 896, 'x_coord': 531,...\n",
       "camera_metadata            {'baseline': 0.12693501988129197, 'focalLength...\n",
       "captured_at                                 2019-06-07 11:17:33.444000+00:00\n",
       "is_obscured_floy_tag                                                     NaN\n",
       "is_floy_tag_not_present                                                  NaN\n",
       "world_keypoints            {'UPPER_LIP': array([-0.24470074,  0.62729652,...\n",
       "median_depth                                                        0.650968\n",
       "k_factor                                                             1.32762\n",
       "akpd_score                                                            0.9833\n",
       "raw_keypoint_arr           [[ 0.29665902  0.65370901  0.0371452 ]\\n [ 0.2...\n",
       "centered_keypoint_arr      [[-0.2200682   0.68251286  0.0496789 ]\\n [-0.1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050.0065088272095\n"
     ]
    }
   ],
   "source": [
    "annotation = json.loads(row.keypoints.replace(\"'\", '\"'))\n",
    "camera_metadata = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "\n",
    "camera_metadata_obj = CameraMetadata(\n",
    "    focal_length=camera_metadata['focalLength'],\n",
    "    focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "    baseline_m=camera_metadata['baseline'],\n",
    "    pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "    pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "    image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "    image_sensor_height=camera_metadata['imageSensorHeight']\n",
    ")\n",
    "\n",
    "weight, length, kf = weight_estimator.predict(annotation, camera_metadata_obj)\n",
    "\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b81da4ea04fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# translation experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_world_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_world\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_left_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_right_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_left_right_kps_from_w_kps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_world_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_left_new_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_right_new_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_left_right_keypoint_arrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'disp' is not defined"
     ]
    }
   ],
   "source": [
    "X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "# X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "X_world = convert_to_world_point_arr(X_left, X_right, camera_metadata_obj)\n",
    "\n",
    "# translation experiment\n",
    "X_world_new = X_world + disp\n",
    "X_left_new, X_right_new = get_left_right_kps_from_w_kps(X_world_new)\n",
    "X_left_new_norm, X_right_new_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "X_world_new_norm = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata_obj)\n",
    "\n",
    "stabilized = stabilizie_keypoints(X_world_new_norm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_world' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2d4cae31813d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_world\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_world' is not defined"
     ]
    }
   ],
   "source": [
    "X_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflected = -1 * X_world\n",
    "\n",
    "reflected2 = X_world.copy()\n",
    "reflected2[:, 0], reflected2[:, 2] = reflected2[:, 2], reflected2[:, 0].copy()\n",
    "\n",
    "reflected3 = X_world.copy()\n",
    "reflected3[:, 1] = reflected3[:, 1] + 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflected3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_model = Network()\n",
    "weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "weight_model.eval()\n",
    "\n",
    "X = stabilize_keypoints(X_world)\n",
    "nn_input = torch.from_numpy(np.array([X])).float()\n",
    "weight = 1e4 * weight_model(nn_input).item()\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stabilize_keypoints(reflected3)\n",
    "nn_input = torch.from_numpy(np.array([X])).float()\n",
    "weight = 1e4 * weight_model(nn_input).item()\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stabilize_keypoints(reflected2)\n",
    "nn_input = torch.from_numpy(np.array([X])).float()\n",
    "weight = 1e4 * weight_model(nn_input).item()\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_world' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3f609731401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mreflected3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mreflected3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreflected3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_world' is not defined"
     ]
    }
   ],
   "source": [
    "dists = np.arange(-0.5, 1, 0.1)\n",
    "weights = []\n",
    "\n",
    "for dist in dists:\n",
    "    reflected3 = X_world.copy()\n",
    "    reflected3[:, 1] = reflected3[:, 1] + dist\n",
    "    \n",
    "    X = stabilize_keypoints(reflected3)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    weight = 1e4 * weight_model(nn_input).item()\n",
    "    weights.append(weight)\n",
    "    \n",
    "plt.plot(dists, weights)\n",
    "plt.xlabel('Depth translation')\n",
    "plt.ylabel('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.arange(-0.5, 1, 0.1)\n",
    "weights = []\n",
    "\n",
    "for dist in dists:\n",
    "    reflected3 = X_world.copy()\n",
    "    reflected3[:, 0] = reflected3[:, 0] + dist\n",
    "    \n",
    "    X = stabilize_keypoints(reflected3)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    weight = 1e4 * weight_model(nn_input).item()\n",
    "    weights.append(weight)\n",
    "    \n",
    "plt.plot(dists, weights)\n",
    "plt.xlabel('X translation')\n",
    "plt.ylabel('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.arange(-0.5, 1, 0.1)\n",
    "weights = []\n",
    "\n",
    "for dist in dists:\n",
    "    reflected3 = X_world.copy()\n",
    "    reflected3[:, 2] = reflected3[:, 2] + dist\n",
    "    \n",
    "    X = stabilize_keypoints(reflected3)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    weight = 1e4 * weight_model(nn_input).item()\n",
    "    weights.append(weight)\n",
    "    \n",
    "plt.plot(dists, weights)\n",
    "plt.xlabel('Depth translation')\n",
    "plt.ylabel('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
