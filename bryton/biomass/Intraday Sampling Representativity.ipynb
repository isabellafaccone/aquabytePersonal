{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from research.utils.datetime_utils import day_difference, add_days\n",
    "from research.utils.datetime_utils import get_dates_in_range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 56\n",
    "start_date = '2020-04-25'\n",
    "end_date = '2020-05-25'\n",
    "# pen_id = 66\n",
    "# start_date = '2020-05-20'\n",
    "# end_date = '2020-06-10'\n",
    "akpd_filter = 0.99\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM (\n",
    "      (SELECT * FROM prod.crop_annotation cas\n",
    "      INNER JOIN prod.annotation_state pas on pas.id=cas.annotation_state_id\n",
    "      WHERE cas.service_id = (SELECT ID FROM prod.service where name='BATI')\n",
    "      AND cas.annotation_state_id = 3\n",
    "      AND cas.pen_id=%i) a\n",
    "    RIGHT JOIN \n",
    "      (SELECT left_crop_url, estimated_weight_g, akpd_score FROM prod.biomass_computations\n",
    "      WHERE prod.biomass_computations.captured_at >= '%s'\n",
    "      AND prod.biomass_computations.captured_at <= '%s'\n",
    "      AND prod.biomass_computations.akpd_score > %0.4f) bc \n",
    "    ON \n",
    "      (a.left_crop_url=bc.left_crop_url)\n",
    "    ) x\n",
    "    WHERE x.captured_at >= '%s'\n",
    "    AND x.captured_at <= '%s'\n",
    "    AND x.pen_id = %i\n",
    "    AND x.group_id = '%i';\n",
    "\"\"\" % (pen_id, start_date, end_date, akpd_filter, start_date, end_date, pen_id, pen_id)\n",
    "\n",
    "if query in queryCache:\n",
    "    df = queryCache[query].copy()\n",
    "else:\n",
    "    df = rds_access_utils.extract_from_database(query)\n",
    "    \n",
    "    depths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        depths.append(depth)\n",
    "    df['depth'] = depths\n",
    "    \n",
    "    df = df.sort_values('captured_at').copy(deep=True)\n",
    "    df.index = pd.to_datetime(df.captured_at)\n",
    "    dates = df.index.date.astype(str)\n",
    "    df['date'] = dates\n",
    "    df['hour'] = df.index.hour\n",
    "\n",
    "    if 'estimated_k_factor' not in df.columns.tolist():\n",
    "        df['estimated_k_factor'] = 0.0\n",
    "    \n",
    "    queryCache[query] = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "\n",
    "# startDate, startHour = datetime.strptime(df.ix[0]['date'], '%Y-%m-%d'), df.ix[0]['hour']\n",
    "# endDate, endHour = datetime.strptime(df.ix[-1]['date'], '%Y-%m-%d'), df.ix[-1]['hour']\n",
    "\n",
    "startDate = df.index[0]\n",
    "endDate = df.index[-1]\n",
    "\n",
    "maxWeight = max(df['estimated_weight_g'])\n",
    "maxWeightInt = int(maxWeight / 1000)\n",
    "\n",
    "diff = endDate - startDate\n",
    "days, seconds = diff.days, diff.seconds\n",
    "hours = int((days * 24 + seconds // 3600) / 1)\n",
    "\n",
    "a = np.zeros((hours + 1, maxWeightInt + 1))\n",
    "print(a.shape)\n",
    "\n",
    "count = 0\n",
    "\n",
    "dateStrings = []\n",
    "dates = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row.date not in dateStrings:\n",
    "        dateStrings.append(row.date)\n",
    "        dates.append(datetime.strptime(row.date, '%Y-%m-%d'))\n",
    "\n",
    "    diff = idx - startDate\n",
    "    days, seconds = diff.days, diff.seconds\n",
    "    hours = int((days * 24 + seconds // 3600) / 1)\n",
    "    \n",
    "    weight = row['estimated_weight_g']\n",
    "    weightInt = int(weight / 1000)\n",
    "    \n",
    "    a[hours, weightInt] = a[hours, weightInt] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal as ps\n",
    "\n",
    "coefs = []\n",
    "\n",
    "window = 24\n",
    "skip = 24\n",
    "\n",
    "for i in np.arange(window, hours, skip):\n",
    "    b = a[(i - window):i,2:6]\n",
    "    w = ps.lib.weights.lat2W(b.shape[0], b.shape[1])\n",
    "    mi = ps.explore.esda.Moran(b, w)\n",
    "    coefs.append(mi.I)\n",
    "    \n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 20))\n",
    "axes[0].plot(dates[1:], coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ps.lib.weights.lat2W(a.shape[0], a.shape[1])\n",
    "mi = ps.explore.esda.Moran_Local(a, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = np.log(1 + np.mean(a, 1))\n",
    "f = np.mean(a, 1)\n",
    "\n",
    "w = ps.lib.weights.lat2W(f.shape[0], 1)\n",
    "mi = ps.explore.esda.Moran_Local(f, w)\n",
    "\n",
    "plt.plot(mi.Is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(f, mi.Is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 24\n",
    "skip = 24\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for i in np.arange(window, hours, skip):\n",
    "    data = f[(i - window):i]\n",
    "    \n",
    "    if np.sum(data) < 1:\n",
    "        coefs.append(coefs[-1])\n",
    "        continue\n",
    "\n",
    "    a = (np.percentile(data, 90) - np.percentile(data, 10)) / (np.mean(data))\n",
    "    \n",
    "    coefs.append(1 - a / 5)\n",
    "    #coefs.append(np.percentile(data, 95) / np.mean(data))\n",
    "    \n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 20))\n",
    "axes[0].bar(dates[1:], coefs)\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Sampling Representativity')\n",
    "axes[0].set_title('Pen 56 Sampling Representativity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mi.Is.reshape(a.shape)\n",
    "d = np.mean(c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 24\n",
    "skip = 24\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for i in np.arange(window, hours, skip):\n",
    "    coefs.append(np.std(d[(i - window):i]))\n",
    "    \n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 20))\n",
    "axes[0].plot(dates[1:], coefs)\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Sampling Representativity')\n",
    "axes[0].set_title('Pen 60 Sampling Representativity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
