{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 153\n",
    "df_start_date = '2020-10-06'\n",
    "df_end_date = '2020-10-28'\n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df = extract_biomass_data(pen_id, df_start_date, df_end_date, 0.9)\n",
    "    # df = extract_biomass_data(pen_id, '2020-08-24', '2020-09-03', 0.99)\n",
    "\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "#     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "    depths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        depths.append(depth)\n",
    "    df['depth'] = depths\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df } }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "df_7000 = df[df['estimated_weight_g'] > 7000]\n",
    "df_5000 = df[df['estimated_weight_g'] < 5000]\n",
    "print(np.mean(df_7000['depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['date'] == '2020-10-27']\n",
    "df95 = df2[df2['akpd_score'] > 0.95]\n",
    "df99 = df2[df2['akpd_score'] > 0.99]\n",
    "df1_5 = df2[df2['depth'] > 1.5]\n",
    "\n",
    "print(len(df1_5), len(df2))\n",
    "#plt.hist(df2['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "buckets = np.linspace(4000, 7000, 100)\n",
    "\n",
    "results = []\n",
    "\n",
    "def adj_weight(x):\n",
    "    return x ** (2/3)\n",
    "\n",
    "for bucket in buckets:\n",
    "    min_bucket = bucket - 1000\n",
    "    max_bucket = bucket + 1000\n",
    "    mask = (df.estimated_weight_g > min_bucket) & (df.estimated_weight_g < max_bucket)\n",
    "#     mask = (adj_weight(df.estimated_weight_g) > adj_weight(min_bucket)) & (adj_weight(df.estimated_weight_g) < adj_weight(max_bucket))\n",
    "    res = stats.weibull_min.fit(df[mask].depth, floc = 0.7)\n",
    "    results.append(res)\n",
    "    \n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = results[:,0]\n",
    "Y2 = results[:,2]\n",
    "X = buckets\n",
    "X = sm.add_constant(X)\n",
    "model0 = sm.OLS(Y0,X)\n",
    "model2 = sm.OLS(Y2,X)\n",
    "m0 = model0.fit()\n",
    "m2 = model2.fit()\n",
    "# OLSresults = model.fit()\n",
    "# OLSresults.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(depth, weight):\n",
    "    v0 = m0.predict([1, weight])\n",
    "    v1 = 0.7\n",
    "    v2 = m2.predict([1, weight])\n",
    "\n",
    "    prob = stats.weibull_min.pdf(depth, v0, v1, v2)\n",
    "    \n",
    "    return prob\n",
    "\n",
    "weights = df.estimated_weight_g\n",
    "\n",
    "weights_weight = []\n",
    "weights_prob = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    prob = get_prob(row['depth'], row['estimated_weight_g'])\n",
    "    \n",
    "    if prob < 0.01:\n",
    "        print(row['depth'], row['estimated_weight_g'])\n",
    "    else:\n",
    "        weights_weight.append(row['estimated_weight_g'])\n",
    "        weights_prob.append(prob[0])\n",
    "    \n",
    "weights_weight = np.array(weights_weight)\n",
    "weights_prob = np.array(weights_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.mean(weights)\n",
    "w2 = np.sum(weights_weight / weights_prob) / np.sum(1 / weights_prob)\n",
    "\n",
    "print(w1, w2)\n",
    "print((w1 - w2) / w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(adj_weight(buckets), results[:,0])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(buckets, results[:,0])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(adj_weight(buckets), results[:,2])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(buckets, results[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df.estimated_weight_g > 4000) & (df.estimated_weight_g < 6000)\n",
    "mask2 = (df.estimated_weight_g > 6000) & (df.estimated_weight_g < 8000)\n",
    "\n",
    "d1 = df[mask1]\n",
    "d2 = df[mask2]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "x = np.linspace(0, 3, 5000)\n",
    "plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(d1['depth'])))\n",
    "plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(d2['depth'])))\n",
    "# plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(df_5000['depth'])))\n",
    "# plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(df_7000['depth'])))\n",
    "# plt.hist(df['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "# plt.hist(df_5000['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "# plt.hist(df_7000['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(d1['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(d2['depth'], bins = 30, alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.weibull_min.fit(d1['depth'], floc=0.68))\n",
    "print(stats.weibull_min.fit(d1['depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df.estimated_weight_g > 7000]['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(df[df.estimated_weight_g < 5000]['depth'], bins = 30, alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = stats.probplot(df.depth, plot=plt)\n",
    "#res = stats.probplot(df.depth, dist=stats.chi2, sparams=(50, ), plot=plt)\n",
    "# res = stats.probplot(df.depth, dist=stats.weibull_min, sparams=(2, 0, 1.49), plot=plt)\n",
    "res = stats.probplot(df.depth, dist=stats.weibull_min, sparams=stats.weibull_min.fit(df['depth']), plot=plt)\n",
    "# res = stats.probplot(df_5000.depth, dist=stats.weibull_min, sparams=(2, ), plot=plt)\n",
    "# res = stats.probplot(df_7000.depth, dist=stats.weibull_min, sparams=(2, ), plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "density, bins, _ = plt.hist(df2.estimated_weight_g, bins = 30, alpha = 0.5, density = True, color = 'blue')\n",
    "plt.hist(df1_5.estimated_weight_g, bins = bins, alpha = 0.5, density = True, color = 'red')\n",
    "#plt.hist(df99.estimated_weight_g, bins = bins, alpha = 0.5, density = True, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(df2.estimated_weight_g))\n",
    "\n",
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (df2['estimated_weight_g'] > buckets[i]) & (df2['estimated_weight_g'] <= buckets[i + 1])\n",
    "    \n",
    "    print('%i: %0.2f' % (buckets[i], sum(mask1) / len(mask1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.probplot(df2.estimated_weight_g, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
