{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 153\n",
    "# df_start_date = '2020-10-06'\n",
    "# df_end_date = '2020-10-28'\n",
    "# df_start_date = '2020-11-16'\n",
    "# df_end_date = '2020-11-19'\n",
    "df_start_date = '2020-11-18'\n",
    "df_end_date = '2020-11-21'\n",
    "\n",
    "pen_id = \n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df = extract_biomass_data(pen_id, df_start_date, df_end_date, 0.01)\n",
    "    # df = extract_biomass_data(pen_id, '2020-08-24', '2020-09-03', 0.99)\n",
    "\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "#     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "    depths = []\n",
    "    lengths = []\n",
    "    lengths_adj = []\n",
    "    lengths_adj2 = []\n",
    "    coplanarity = []\n",
    "    coangle = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "        \n",
    "        centroid = .5 * (wkps['DORSAL_FIN'] + wkps['PELVIC_FIN'])\n",
    "        angle = np.linalg.norm(np.array(get_angles(wkps['UPPER_LIP'], centroid)) - np.array(get_angles(centroid, wkps['TAIL_NOTCH'])))\n",
    "        a = (wkps['UPPER_LIP'] - centroid) / np.linalg.norm(wkps['UPPER_LIP'] - centroid)\n",
    "        b = (wkps['TAIL_NOTCH'] - centroid) / np.linalg.norm(wkps['TAIL_NOTCH'] - centroid)\n",
    "\n",
    "        lengths_adj.append(np.linalg.norm((wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']) * a))\n",
    "        lengths_adj2.append(np.linalg.norm((wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']) * b))\n",
    "\n",
    "        depths.append(depth)\n",
    "        lengths.append(np.linalg.norm(vector))\n",
    "        coplanarity.append(equation_plane(wkps['TAIL_NOTCH'], wkps['DORSAL_FIN'], wkps['PELVIC_FIN'], wkps['UPPER_LIP']))\n",
    "        coangle.append(angle)\n",
    "    df['depth'] = depths\n",
    "    df['length'] = lengths\n",
    "    df['length_adj'] = lengths_adj\n",
    "    df['length_adj2'] = lengths_adj2\n",
    "    df['coplanarity'] = coplanarity\n",
    "    df['coangle'] = coangle\n",
    "    \n",
    "    df['estimated_weight'] = get_weight(df.length)\n",
    "    df['estimated_weight_adj'] = get_weight(df.length_adj)\n",
    "    df['estimated_weight_adj2'] = get_weight(df.length_adj2)\n",
    "    df['weight_diff'] = df['estimated_weight'] - df['estimated_weight_g']\n",
    "    df['length_diff'] = df['length'] - df['length_adj']\n",
    "    df['length_diff2'] = df['length_adj'] - df['length_adj2']\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df } }\n",
    "\n",
    "add_angles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.akpd_score > 0.95) & (df.hour >= 7) & (df.hour <= 15)]\n",
    "\n",
    "plt.scatter(df1.estimated_weight_g, df1.estimated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df1.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_angles(df1):\n",
    "    thetas = []\n",
    "    phis = []\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        ann1, cm1 = row.annotation, row.camera_metadata\n",
    "        wkps1 = pixel2world(ann1['leftCrop'], ann1['rightCrop'], cm1)\n",
    "\n",
    "        vector = wkps1['PECTORAL_FIN'] - wkps1['ANAL_FIN']\n",
    "        x, y, z = vector / np.linalg.norm(vector)\n",
    "\n",
    "        theta = math.atan(y / x) * np.sign(y)\n",
    "        phi = math.acos(z)\n",
    "        dtheta = math.degrees(theta)\n",
    "        dphi = 90 - math.degrees(phi)\n",
    "        thetas.append(dtheta)\n",
    "        phis.append(dphi)\n",
    "\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.scatter(thetas, phis, color = 'orange', label = 'Normal')\n",
    "#     # plt.scatter(thetas2, phis2, color = 'blue', label = 'Negative')\n",
    "#     plt.xlabel('Theta degree')\n",
    "#     plt.ylabel('Phi degree')\n",
    "#     plt.legend()\n",
    "\n",
    "    df1['theta'] = thetas\n",
    "    df1['phi'] = phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(length):\n",
    "    return (length * 23.6068) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weight(0.65), get_weight(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df.hour >= 7)]\n",
    "# df2 = df[(df.hour >= 7) & (df.length_diff < .1) & (df.length_diff2 < .05) & ((df.length - df.length_adj) / df.length < .2)]\n",
    "# df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2) / df.length < .05) & ((df.length - df.length_adj) / df.length < .1)]\n",
    "# df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2) / df.length < .05) & (df.length - df.length_adj < .1)]\n",
    "df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2) < .01) & (df.length - .5 * (df.length_adj + df.length_adj2) < .01)]\n",
    "\n",
    "print(len(df2) / len(df))\n",
    "\n",
    "np.mean(df2.estimated_weight_g), np.mean(df2.estimated_weight_adj), np.mean(df2.estimated_weight_adj2), np.mean(np.maximum(df2.estimated_weight_adj, df2.estimated_weight_adj2)), np.mean(df2.estimated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 0.05\n",
    "df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2) / df.length < limit) & (df.length < 1) ]\n",
    "# plt.scatter(df2.estimated_weight_g, np.maximum(df2.estimated_weight_adj, df2.estimated_weight_adj2))\n",
    "plt.scatter(df2.estimated_weight_g, df2.estimated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = []\n",
    "pcts = []\n",
    "avg_weights = []\n",
    "\n",
    "# for limit in np.arange(0.01, 0.2, 0.01):\n",
    "for limit in np.arange(1, 1.5, .05):\n",
    "#     df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2)  / df.length < limit) & ((df.length - .5 * (df.length_adj + df.length_adj2)) / df.length < limit)]\n",
    "#     df2 = df[(df.hour >= 7) & ((df.length - .5 * (df.length_adj + df.length_adj2)) / df.length_adj < limit)]\n",
    "#     df2 = df[(df.hour >= 7) & (np.abs(df.length_diff2) / df.length < .1) & (df.length < limit)]\n",
    "    df2 = df[(df.hour >= 7)]\n",
    "    limits.append(limit)\n",
    "    pcts.append(len(df2) / len(df))\n",
    "#     avg_weights.append(np.mean(df2.estimated_weight))\n",
    "#     avg_weights.append(np.mean(df2.estimated_weight_g))\n",
    "    avg_weights.append(np.mean(np.maximum(df2.estimated_weight_adj, df2.estimated_weight_adj2)))\n",
    "    \n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(limits, avg_weights)\n",
    "ax2.plot(limits, pcts, color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df2.estimated_weight, bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df2.estimated_weight_g, bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.maximum(df2.estimated_weight_adj, df2.estimated_weight_adj2), bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, bins, _ = plt.hist(df2.estimated_weight_g, density = True, bins = 30)\n",
    "# count, bins, _ = plt.hist(df2.estimated_weight, density = True, bins = 30)\n",
    "\n",
    "# cdf = np.cumsum(count)\n",
    "# plt.plot(bins[1:], cdf)\n",
    "\n",
    "def get_symmetry(i, l):\n",
    "    bins1 = count[(i-l):i]\n",
    "    bins2 = np.flip(count[i:(i+l)])\n",
    "    \n",
    "#     print(bins1)\n",
    "#     print(bins2)\n",
    "    \n",
    "    return np.corrcoef(bins1, bins2)\n",
    "\n",
    "top_results = []\n",
    "\n",
    "for l in np.arange(5, 15):\n",
    "    for i in np.arange(l, len(count) - l):\n",
    "        symm = get_symmetry(i, l)[0, 1]\n",
    "\n",
    "        result = (i, l, symm)\n",
    "\n",
    "        if len(top_results) < 10:\n",
    "            top_results.append(result)\n",
    "        else:\n",
    "            val, idx = min((val[2], idx) for (idx, val) in enumerate(top_results))\n",
    "            if symm > val:\n",
    "                top_results[idx] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results.sort(key=lambda x: -x[2])\n",
    "\n",
    "for result in top_results:\n",
    "    print(result)\n",
    "\n",
    "reflection_idx, reflection_idx_length = top_results[0][0], top_results[0][1]\n",
    "\n",
    "reflection_point = bins[reflection_idx + 1]\n",
    "reflection_length = bins[reflection_idx + 1 + reflection_idx_length] - reflection_point\n",
    "\n",
    "lower_point = reflection_point - reflection_length\n",
    "upper_point = reflection_point + reflection_length\n",
    "\n",
    "d1 = df2['estimated_weight_g']\n",
    "# d1 = df2['estimated_weight']\n",
    "\n",
    "d = np.concatenate([d1[d1 < upper_point], upper_point + lower_point - d1[d1 < lower_point]])\n",
    "np.mean(d), np.mean(d1), reflection_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[(df2.length < 2)].sort_values('estimated_weight', ascending = False)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df3[['estimated_weight', 'estimated_weight_g', 'length', 'akpd_score']].head(100)\n",
    "\n",
    "df4 = df3[(df3.akpd_score > 0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.abs(df4.coplanarity), df4.length_diff\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "X = x\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "plt.plot(x, results.predict(X), color = 'red')\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df3.estimated_weight_g, df3.estimated_weight)\n",
    "\n",
    "\n",
    "plt.scatter(df4.coplanarity, df4.estimated_weight_g - df4.estimated_weight)\n",
    "\n",
    "x = df4.coplanarity\n",
    "X = x\n",
    "X = sm.add_constant(X)\n",
    "y = df4.estimated_weight_g - df4.estimated_weight\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "plt.plot(x, results.predict(X), color = 'red')\n",
    "\n",
    "print(np.mean(df4.estimated_weight_g), np.mean(get_weight(df4.length)))\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.sort_values('weight_diff', ascending = True)\n",
    "df5\n",
    "df6 = df5[np.abs(df5['weight_diff']) < 10]\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    left_ann, right_ann = ann['leftCrop'], ann['rightCrop']\n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in left_ann}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in right_ann}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df6.iloc[0]\n",
    "print(row.akpd_score)\n",
    "print(row.estimated_weight_g)\n",
    "print(row.estimated_weight)\n",
    "print(row.length)\n",
    "print(row.coplanarity)\n",
    "left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = row.annotation, row.camera_metadata\n",
    "wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df5.iloc[2]\n",
    "print(row.akpd_score)\n",
    "print(row.estimated_weight_g)\n",
    "print(row.estimated_weight)\n",
    "print(row.length)\n",
    "print(row.coplanarity)\n",
    "left_crop_url, right_crop_url = row.left_crop_url, row.right_crop_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = row.annotation, row.camera_metadata\n",
    "wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array([wkps[keypoint] for keypoint in wkps]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".5 * (wkps['DORSAL_FIN'] + wkps['PELVIC_FIN']), .5 * (wkps['ADIPOSE_FIN'] + wkps['PECTORAL_FIN']), .5 * (wkps['DORSAL_FIN'] + wkps['PECTORAL_FIN']), row.depth, np.mean(np.array([wkps[keypoint] for keypoint in wkps]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_wkps = ['UPPER_LIP', 'EYE', 'DORSAL_FIN', 'ADIPOSE_FIN', 'TAIL_NOTCH']\n",
    "\n",
    "for keypoint in ordered_wkps:\n",
    "    print('%s: %0.2f, %0.2f, %0.2f' % (keypoint, wkps[keypoint][0], wkps[keypoint][1], wkps[keypoint][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keypoint in wkps:\n",
    "    print('%s: %0.2f, %0.2f, %0.2f' % (keypoint, wkps[keypoint][0], wkps[keypoint][1], wkps[keypoint][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keypoint in wkps:\n",
    "    print('%s: %0.2f, %0.2f, %0.2f' % (keypoint, wkps[keypoint][0], wkps[keypoint][1], wkps[keypoint][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_wkps = ['UPPER_LIP', 'EYE', 'PECTORAL_FIN', 'PELVIC_FIN', 'ANAL_FIN', 'TAIL_NOTCH']\n",
    "\n",
    "for keypoint in ordered_wkps:\n",
    "    print('%s: %0.2f, %0.2f, %0.2f' % (keypoint, wkps[keypoint][0], wkps[keypoint][1], wkps[keypoint][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_wkps = ['UPPER_LIP', 'EYE', 'DORSAL_FIN', 'ADIPOSE_FIN', 'TAIL_NOTCH']\n",
    "\n",
    "for keypoint in ordered_wkps:\n",
    "    print('%s: %0.2f, %0.2f, %0.2f' % (keypoint, wkps[keypoint][0], wkps[keypoint][1], wkps[keypoint][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = .5 * (wkps['DORSAL_FIN'] + wkps['PELVIC_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keypoint in wkps:\n",
    "    print(keypoint, get_angles(wkps[keypoint], centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keypoint in wkps:\n",
    "    print(keypoint, get_angles(centroid, wkps[keypoint]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_keypoints = ['TAIL_NOTCH', 'ADIPOSE_FIN', 'UPPER_LIP', ''\n",
    "np.mean(np.array([wkps[keypoint] for keypoint in wkps]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = .5 * (wkps['DORSAL_FIN'] + wkps['PELVIC_FIN'])\n",
    "np.linalg.norm(np.array(get_angles(wkps['UPPER_LIP'], centroid)) - np.array(get_angles(centroid, wkps['TAIL_NOTCH'])))\n",
    "\n",
    "a = (wkps['UPPER_LIP'] - centroid) / np.linalg.norm(wkps['UPPER_LIP'] - centroid)\n",
    "\n",
    "np.linalg.norm((wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']) * a), row.length\n",
    "\n",
    "\n",
    "# centroid = .5 * (wkps['ADIPOSE_FIN'] + wkps['PECTORAL_FIN'])\n",
    "# centroid = .5 * (wkps['DORSAL_FIN'] + wkps['PECTORAL_FIN'])\n",
    "# centroid = np.mean(np.array([wkps[keypoint] for keypoint in wkps]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['UPPER_LIP'], wkps['TAIL_NOTCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['EYE'], wkps['TAIL_NOTCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['ANAL_FIN'], wkps['TAIL_NOTCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['ADIPOSE_FIN'], wkps['TAIL_NOTCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['PECTORAL_FIN'], wkps['PELVIC_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['PELVIC_FIN'], wkps['ANAL_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles(wkps['DORSAL_FIN'], wkps['ADIPOSE_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_plane(p1, p2, p3, p4):      \n",
    "    a1 = p2[0] - p1[0] \n",
    "    b1 = p2[1] - p1[1]\n",
    "    c1 = p2[2] - p1[2] \n",
    "    a2 = p3[0] - p1[0] \n",
    "    b2 = p3[1] - p1[1] \n",
    "    c2 = p3[2] - p1[2] \n",
    "    a = b1 * c2 - b2 * c1 \n",
    "    b = a2 * c1 - a1 * c2 \n",
    "    c = a1 * b2 - b1 * a2 \n",
    "    d = (- a * p1[0] - b * p1[1] - c * p1[2]) \n",
    "      \n",
    "    # equation of plane is: a*x + b*y + c*z = 0 # \n",
    "      \n",
    "    # checking if the 4th point satisfies \n",
    "    # the above equation \n",
    "    return a * p4[0] + b * p4[1] + c * p4[2] + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(kp1, kp2):\n",
    "    vector = kp1 - kp2\n",
    "    x, y, z = vector / np.linalg.norm(vector)\n",
    "\n",
    "    theta = math.atan(y / x) * np.sign(y)\n",
    "    phi = math.acos(z)\n",
    "    dtheta = math.degrees(theta)\n",
    "    dphi = 90 - math.degrees(phi)\n",
    "    \n",
    "    return dtheta, dphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_plane(wkps['TAIL_NOTCH'], wkps['DORSAL_FIN'], wkps['PELVIC_FIN'], wkps['UPPER_LIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_plane(wkps['TAIL_NOTCH'], wkps['ADIPOSE_FIN'], wkps['ANAL_FIN'], wkps['UPPER_LIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_plane(wkps['ADIPOSE_FIN'], wkps['DORSAL_FIN'], wkps['ANAL_FIN'], wkps['PELVIC_FIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_plane(wkps['DORSAL_FIN'], wkps['PECTORAL_FIN'], wkps['UPPER_LIP'], wkps['EYE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "df_7000 = df[df['estimated_weight_g'] > 7000]\n",
    "df_5000 = df[df['estimated_weight_g'] < 5000]\n",
    "print(np.mean(df_7000['depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['date'] == '2020-10-27']\n",
    "df95 = df2[df2['akpd_score'] > 0.95]\n",
    "df99 = df2[df2['akpd_score'] > 0.99]\n",
    "df1_5 = df2[df2['depth'] > 1.5]\n",
    "\n",
    "print(len(df1_5), len(df2))\n",
    "#plt.hist(df2['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "buckets = np.linspace(4000, 7000, 100)\n",
    "\n",
    "results = []\n",
    "\n",
    "def adj_weight(x):\n",
    "    return x ** (2/3)\n",
    "\n",
    "for bucket in buckets:\n",
    "    min_bucket = bucket - 1000\n",
    "    max_bucket = bucket + 1000\n",
    "    mask = (df.estimated_weight_g > min_bucket) & (df.estimated_weight_g < max_bucket)\n",
    "#     mask = (adj_weight(df.estimated_weight_g) > adj_weight(min_bucket)) & (adj_weight(df.estimated_weight_g) < adj_weight(max_bucket))\n",
    "    res = stats.weibull_min.fit(df[mask].depth, floc = 0.7)\n",
    "    results.append(res)\n",
    "    \n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = results[:,0]\n",
    "Y2 = results[:,2]\n",
    "X = buckets\n",
    "X = sm.add_constant(X)\n",
    "model0 = sm.OLS(Y0,X)\n",
    "model2 = sm.OLS(Y2,X)\n",
    "m0 = model0.fit()\n",
    "m2 = model2.fit()\n",
    "# OLSresults = model.fit()\n",
    "# OLSresults.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(depth, weight):\n",
    "    v0 = m0.predict([1, weight])\n",
    "    v1 = 0.7\n",
    "    v2 = m2.predict([1, weight])\n",
    "\n",
    "    prob = stats.weibull_min.pdf(depth, v0, v1, v2)\n",
    "    \n",
    "    return prob\n",
    "\n",
    "weights = df.estimated_weight_g\n",
    "\n",
    "weights_weight = []\n",
    "weights_prob = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    prob = get_prob(row['depth'], row['estimated_weight_g'])\n",
    "    \n",
    "    if prob < 0.01:\n",
    "        print(row['depth'], row['estimated_weight_g'])\n",
    "    else:\n",
    "        weights_weight.append(row['estimated_weight_g'])\n",
    "        weights_prob.append(prob[0])\n",
    "    \n",
    "weights_weight = np.array(weights_weight)\n",
    "weights_prob = np.array(weights_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.mean(weights)\n",
    "w2 = np.sum(weights_weight / weights_prob) / np.sum(1 / weights_prob)\n",
    "\n",
    "print(w1, w2)\n",
    "print((w1 - w2) / w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(adj_weight(buckets), results[:,0])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(buckets, results[:,0])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(adj_weight(buckets), results[:,2])\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(buckets, results[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df.estimated_weight_g > 4000) & (df.estimated_weight_g < 6000)\n",
    "mask2 = (df.estimated_weight_g > 6000) & (df.estimated_weight_g < 8000)\n",
    "\n",
    "d1 = df[mask1]\n",
    "d2 = df[mask2]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "x = np.linspace(0, 3, 5000)\n",
    "plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(d1['depth'])))\n",
    "plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(d2['depth'])))\n",
    "# plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(df_5000['depth'])))\n",
    "# plt.plot(x, stats.weibull_min.pdf(x, *stats.weibull_min.fit(df_7000['depth'])))\n",
    "# plt.hist(df['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "# plt.hist(df_5000['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "# plt.hist(df_7000['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(d1['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(d2['depth'], bins = 30, alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.weibull_min.fit(d1['depth'], floc=0.68))\n",
    "print(stats.weibull_min.fit(d1['depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df.estimated_weight_g > 7000]['depth'], bins = 30, alpha = 0.5, density = True)\n",
    "plt.hist(df[df.estimated_weight_g < 5000]['depth'], bins = 30, alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = stats.probplot(df.depth, plot=plt)\n",
    "#res = stats.probplot(df.depth, dist=stats.chi2, sparams=(50, ), plot=plt)\n",
    "# res = stats.probplot(df.depth, dist=stats.weibull_min, sparams=(2, 0, 1.49), plot=plt)\n",
    "res = stats.probplot(df.depth, dist=stats.weibull_min, sparams=stats.weibull_min.fit(df['depth']), plot=plt)\n",
    "# res = stats.probplot(df_5000.depth, dist=stats.weibull_min, sparams=(2, ), plot=plt)\n",
    "# res = stats.probplot(df_7000.depth, dist=stats.weibull_min, sparams=(2, ), plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "density, bins, _ = plt.hist(df2.estimated_weight_g, bins = 30, alpha = 0.5, density = True, color = 'blue')\n",
    "plt.hist(df1_5.estimated_weight_g, bins = bins, alpha = 0.5, density = True, color = 'red')\n",
    "#plt.hist(df99.estimated_weight_g, bins = bins, alpha = 0.5, density = True, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(df2.estimated_weight_g))\n",
    "\n",
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (df2['estimated_weight_g'] > buckets[i]) & (df2['estimated_weight_g'] <= buckets[i + 1])\n",
    "    \n",
    "    print('%i: %0.2f' % (buckets[i], sum(mask1) / len(mask1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.probplot(df2.estimated_weight_g, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
