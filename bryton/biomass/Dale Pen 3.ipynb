{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding = pd.read_csv('dape_pen3_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(temp):\n",
    "    if temp <= 4:\n",
    "        return 0.6\n",
    "    if temp <= 9:\n",
    "        return 0.8\n",
    "    if temp <= 17:\n",
    "        return 1\n",
    "    return 0.8\n",
    "\n",
    "def get_adj2(temp):\n",
    "    if temp <= 4:\n",
    "        return 0.1\n",
    "    if temp <= 6:\n",
    "        return 0.6\n",
    "    if temp <= 8:\n",
    "        return 0.8\n",
    "    if temp <= 10:\n",
    "        return 1\n",
    "    if temp <= 12:\n",
    "        return 1.1\n",
    "    if temp <= 14:\n",
    "        return 1.2\n",
    "    if temp <= 16:\n",
    "        return 1.2\n",
    "    if temp <= 18:\n",
    "        return 0.8\n",
    "    if temp <= 20:\n",
    "        return 0.2\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currWeight1 = 3983.5 - 200 \n",
    "currWeight2 = 3983.5 - 200\n",
    "currWeight3 = 3983.5 - 200\n",
    "\n",
    "feedingWeight1 = []\n",
    "feedingWeight2 = []\n",
    "feedingWeight3 = []\n",
    "\n",
    "for index, row in feeding.iterrows():\n",
    "    feed = row['Feed Amount']\n",
    "    FCR = row['FCR']\n",
    "    numFish = row['Number of fish']\n",
    "    temp = row['Temp']\n",
    "    \n",
    "    FCR1 = 1.2\n",
    "    FCR2 = 1.3\n",
    "    FCR3 = 1.4\n",
    "\n",
    "    adj1 = get_adj(temp)\n",
    "    adj2 = get_adj2(temp)\n",
    "    \n",
    "    feedingWeight1.append(currWeight1)\n",
    "    feedingWeight2.append(currWeight2)\n",
    "    feedingWeight3.append(currWeight3)\n",
    "    \n",
    "    if feed <= 0:\n",
    "        continue\n",
    "        \n",
    "#     amt1 = feed / FCR2 / numFish * 1000\n",
    "#     amt2 = feed / FCR2 / numFish * 1000 * adj1\n",
    "#     amt3 = feed / FCR2 / numFish * 1000 * adj2\n",
    "    \n",
    "    amt1 = feed / FCR / numFish * 1000 * 1.2\n",
    "    amt2 = feed / FCR / numFish * 1000 * adj1 * 1.2\n",
    "    amt3 = feed / FCR / numFish * 1000 * adj2 * 1.2\n",
    "    \n",
    "    currWeight1 = currWeight1 + amt1\n",
    "    currWeight2 = currWeight2 + amt2\n",
    "    currWeight3 = currWeight3 + amt3\n",
    "    \n",
    "feeding['Calculated weight1'] = feedingWeight1\n",
    "feeding['Calculated weight2'] = feedingWeight2\n",
    "feeding['Calculated weight3'] = feedingWeight3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, WeekdayLocator, MONDAY\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(MONDAY))\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%m/%d'))\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.plot(plot_dates, weights1, label = 'Old Model')\n",
    "ax.plot(plot_dates, weights2, label = 'New Model')\n",
    "ax.plot(plot_dates, weights3, label = 'Current Model')\n",
    "ax.plot(plot_dates, feeding['Average weight'], label = 'Feeding Model')\n",
    "ax.plot(plot_dates, feeding['Calculated weight1'], label = 'Calculated Model1')\n",
    "ax.plot(plot_dates, feeding['Calculated weight2'], label = 'Calculated Model2')\n",
    "ax.plot(plot_dates, feeding['Calculated weight3'], label = 'Calculated Model3')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(feeding['Average weight'])\n",
    "plt.plot(feedingWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(feeding['Date'], feeding['Feed Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\"\"\"This module contains utility helper functions for the WeightEstimator class.\"\"\"\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from research.weight_estimation.keypoint_utils import body_parts\n",
    "\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m',\n",
    "                             'pixel_count_width', 'pixel_count_height', 'image_sensor_width',\n",
    "                             'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in body_parts.core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def normalize_left_right_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Tuple:\n",
    "    \"\"\"Normalizes input left and right key-point arrays. The normalization involves (1) 2D\n",
    "    translation of all keypoints such that they are centered, (2) rotation of the 2D coordiantes\n",
    "    about the center such that the line passing through UPPER_LIP and fish center is horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    # translate key-points, perform reflection if necessary\n",
    "    upper_lip_idx = body_parts.core_body_parts.index(body_parts.UPPER_LIP)\n",
    "    tail_notch_idx = body_parts.core_body_parts.index(body_parts.TAIL_NOTCH)\n",
    "    if X_left[upper_lip_idx, 0] > X_left[tail_notch_idx, 0]:\n",
    "        X_center = 0.5 * (np.max(X_left, axis=0) + np.min(X_left, axis=0))\n",
    "        X_left_centered = X_left - X_center\n",
    "        X_right_centered = X_right - X_center\n",
    "    else:\n",
    "        X_center = 0.5 * (np.max(X_right, axis=0) + np.min(X_right, axis=0))\n",
    "        X_left_centered = X_right - X_center\n",
    "        X_right_centered = X_left - X_center\n",
    "        X_left_centered[:, 0] = -X_left_centered[:, 0]\n",
    "        X_right_centered[:, 0] = -X_right_centered[:, 0]\n",
    "\n",
    "    # rotate key-points\n",
    "    upper_lip_x, upper_lip_y = tuple(X_left_centered[upper_lip_idx])\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    D = X_left_centered - X_right_centered\n",
    "    X_left_rot = np.dot(X_left_centered, R)\n",
    "    X_right_rot = X_left_rot - D\n",
    "    return X_left_rot, X_right_rot\n",
    "\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world\n",
    "\n",
    "\n",
    "def stabilize_keypoints(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transforms world coordinate array so that neural network inputs are stabilized\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    X_new[:, 0] = 0.5 * X[:, 0] / X[:, 1]\n",
    "    X_new[:, 1] = 0.5 * X[:, 2] / X[:, 1]\n",
    "    X_new[:, 2] = 0.05 / X[:, 1]\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return nn_input\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This module contains the WeightEstimator class for estimating fish weight (g), length (mm), and\n",
    "k-factor given input keypoint coordinates and camera metadata.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WeightEstimator:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "\n",
    "df = extract_biomass_data(145, '2020-09-01', '2021-02-21', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "\n",
    "model1_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/playground/nn_epoch_798_v2.pb'\n",
    "model2_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb'\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "\n",
    "weight_model1_f, _, _ = s3.download_from_url(model1_url)\n",
    "weight_model2_f, _, _ = s3.download_from_url(model2_url)\n",
    "kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/playground/kf_predictor_v2.pb')\n",
    "\n",
    "weight_estimator1 = WeightEstimator(weight_model1_f, kf_model_f)\n",
    "weight_estimator2 = WeightEstimator(weight_model2_f, kf_model_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = []\n",
    "weights2 = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    count = count + 1\n",
    "    \n",
    "    if count % 10000 == 0:\n",
    "        print(count)\n",
    "    \n",
    "    annotation = row.annotation\n",
    "    if not annotation:\n",
    "        weights.append(None)\n",
    "        continue\n",
    "    camera_metadata = row.camera_metadata\n",
    "\n",
    "    camera_metadata_obj = CameraMetadata(\n",
    "        focal_length=camera_metadata['focalLength'],\n",
    "        focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "        baseline_m=camera_metadata['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "\n",
    "    weight1, length, kf = weight_estimator1.predict(annotation, camera_metadata_obj)\n",
    "    weight2, length, kf = weight_estimator2.predict(annotation, camera_metadata_obj)\n",
    "\n",
    "    weights1.append(weight1)\n",
    "    weights2.append(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weights1'] = weights1\n",
    "df['weights2'] = weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(list(set(list(feeding['Date']))))\n",
    "plot_dates = [ datetime.strptime(d, '%Y-%m-%d') for d in dates ]\n",
    "\n",
    "weights1 = []\n",
    "weights2 = []\n",
    "weights3 = []\n",
    "\n",
    "for date in dates:\n",
    "    mask1 = (df.akpd_score > 0.95) & (df.hour >= 8) & (df.hour <= 16) & (df.date == date)\n",
    "    mask2 = (df.akpd_score > 0.95) & (df.hour >= 8) & (df.hour <= 16) & (df.date == date)\n",
    "    mask3 = (df.akpd_score > 0.95) & (df.hour >= 8) & (df.hour <= 16) & (df.date == date)\n",
    "    \n",
    "    weights1.append(np.mean(df[mask1]['weights1']))\n",
    "    weights2.append(np.mean(df[mask2]['weights2']))\n",
    "    weights3.append(np.mean(df[mask3]['estimated_weight_g']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, WeekdayLocator, MONDAY\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(MONDAY))\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%m/%d'))\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.plot(plot_dates, weights1, label = 'Old Model')\n",
    "ax.plot(plot_dates, weights2, label = 'New Model')\n",
    "ax.plot(plot_dates, weights3, label = 'Current Model')\n",
    "ax.plot(plot_dates, feeding['Average weight'], label = 'Feeding Model')\n",
    "ax.plot(plot_dates, feeding['Calculated weight1'], label = 'Calculated Model1')\n",
    "ax.plot(plot_dates, feeding['Calculated weight2'], label = 'Calculated Model2')\n",
    "ax.plot(plot_dates, feeding['Calculated weight3'], label = 'Calculated Model3')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
