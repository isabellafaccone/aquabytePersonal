{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from weight_estimation.dataset import prepare_gtsf_data, compute_akpd_score\n",
    "from weight_estimation.train import train, augment, normalize, get_data_split, train_model\n",
    "from typing import Dict, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data')\n",
    "akpd_scorer_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/keypoint-detection-scorer/akpd_scorer_model_TF.h5'\n",
    "akpd_scorer_f, _, _ = s3.download_from_url(akpd_scorer_url)\n",
    "df1 = prepare_gtsf_data('2019-03-01', '2019-09-20', akpd_scorer_f, 0.5, 1.0)\n",
    "\n",
    "df2 = prepare_gtsf_data('2020-06-01', '2020-08-20', akpd_scorer_f, 0.5, 1.0)\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_larger_fish(world_keypoints, weight, pct_inflation):\n",
    "    modified_world_keypoints = {}\n",
    "    for body_part in core_body_parts:\n",
    "        kps = world_keypoints[body_part]\n",
    "        modified_kps = (1.0 + pct_inflation) * kps\n",
    "        modified_world_keypoints[body_part] = modified_kps\n",
    "    modified_weight = (1.0 + pct_inflation)**3.0852 * weight\n",
    "    return modified_world_keypoints, modified_weight\n",
    "\n",
    "def get_ann_from_world_keypoints(world_keypoints, cm):\n",
    "    ann = {'leftCrop': [], 'rightCrop': []}\n",
    "    for body_part in core_body_parts:\n",
    "        x, y, z = world_keypoints[body_part]\n",
    "        px_x = round(x * cm['focalLengthPixel'] / y + cm['pixelCountWidth'] / 2.0)\n",
    "        px_y = round(cm['pixelCountHeight'] / 2.0 - z * cm['focalLengthPixel'] / y)\n",
    "        disparity = round(cm['focalLengthPixel'] * cm['baseline'] / y)\n",
    "        \n",
    "        left_item = {\n",
    "            'keypointType': body_part,\n",
    "            'xFrame': px_x,\n",
    "            'yFrame': px_y\n",
    "        }\n",
    "        \n",
    "        right_item = {\n",
    "            'keypointType': body_part,\n",
    "            'xFrame': px_x - disparity,\n",
    "            'yFrame': px_y\n",
    "        }\n",
    "        \n",
    "        ann['leftCrop'].append(left_item)\n",
    "        ann['rightCrop'].append(right_item)\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_estimation.body_parts import core_body_parts\n",
    "from weight_estimation.dataset import prepare_gtsf_data, compute_akpd_score\n",
    "\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "\n",
    "mask = (df.weight >= 7000) & (df.weight <= 9000) \n",
    "max_pct_inflation = 0.15\n",
    "\n",
    "\n",
    "world_keypoints = []\n",
    "for idx, row in df.iterrows():\n",
    "    ann, cm = row.keypoints, row.camera_metadata\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    world_keypoints.append(wkps)\n",
    "    \n",
    "df['world_keypoints'] = world_keypoints\n",
    "\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data')\n",
    "akpd_scorer_url = 'https://aquabyte-models.s3-us-west-1.amazonaws.com/keypoint-detection-scorer/akpd_scorer_model_TF.h5'\n",
    "akpd_scorer_f, _, _ = s3.download_from_url(akpd_scorer_url)\n",
    "from keras.models import load_model\n",
    "akpd_scorer_network = load_model(akpd_scorer_f)\n",
    "\n",
    "modified_ann_list = []\n",
    "modified_weight_list = []\n",
    "modified_akpd_score_list = []\n",
    "cm_list = []\n",
    "\n",
    "for idx, row in df[mask].iterrows():\n",
    "    world_keypoints = row.world_keypoints\n",
    "    cm = row.camera_metadata\n",
    "    weight = row.weight\n",
    "    modified_world_keypoints, modified_weight = simulate_larger_fish(world_keypoints, weight, max_pct_inflation)\n",
    "    modified_ann = get_ann_from_world_keypoints(modified_world_keypoints, cm)\n",
    "    \n",
    "    modified_ann_list.append(modified_ann)\n",
    "    modified_weight_list.append(modified_weight)\n",
    "    modified_akpd_score_list.append(compute_akpd_score(akpd_scorer_network, modified_ann, cm))\n",
    "    cm_list.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.interpolate import interpn\n",
    "from weight_estimation.utils import get_left_right_keypoint_arrs, \\\n",
    "     convert_to_world_point_arr, CameraMetadata\n",
    "from weight_estimation.dataset import prepare_gtsf_data\n",
    "from keras.layers import Input, Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from research_lib.utils.data_access_utils import S3AccessUtils\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor and get final hiddel layer weights.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class NetworkWithDropout(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor and get final hiddel layer weights.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def augment(df: pd.DataFrame, augmentation_config: Dict) -> pd.DataFrame:\n",
    "    counts, edges = np.histogram(df.weight, bins=np.arange(0, 10000, 1000))\n",
    "    trial_values = (5.0 / (counts / np.max(counts))).astype(int)\n",
    "    max_jitter_std = augmentation_config['max_jitter_std']\n",
    "    min_depth = augmentation_config['min_depth']\n",
    "    max_depth = augmentation_config['max_depth']\n",
    "\n",
    "    augmented_data = defaultdict(list)\n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        camera_metadata = row.camera_metadata\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "        \n",
    "        weight = row.weight\n",
    "        trials = trial_values[min(int(weight / 1000), len(trial_values) - 1)]\n",
    "        for _ in range(trials):\n",
    "            \n",
    "            ann = row.keypoints\n",
    "            X_left, X_right = get_left_right_keypoint_arrs(ann)\n",
    "            wkps = convert_to_world_point_arr(X_left, X_right, cm)\n",
    "            original_depth = np.median(wkps[:, 1])\n",
    "            \n",
    "            depth = np.random.uniform(min_depth, max_depth)\n",
    "            scaling_factor = float(original_depth) / depth\n",
    "            \n",
    "            jitter_std = 5 * scaling_factor\n",
    "\n",
    "            # rescale\n",
    "            X_left = X_left * scaling_factor\n",
    "            X_right = X_right * scaling_factor\n",
    "\n",
    "            # add jitter\n",
    "            X_left[:, 0] += np.random.normal(0, jitter_std, X_left.shape[0])\n",
    "            X_right[:, 0] += np.random.normal(0, jitter_std, X_right.shape[0])\n",
    "\n",
    "            # reconstruct annotation\n",
    "            ann = get_ann_from_keypoint_arrs(X_left, X_right)\n",
    "            augmented_data['annotation'].append(ann)\n",
    "            augmented_data['fish_id'].append(row.fish_id)\n",
    "            augmented_data['weight'].append(row.weight)\n",
    "            augmented_data['kf'].append(row.k_factor)\n",
    "            augmented_data['camera_metadata'].append(row.camera_metadata)\n",
    "\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "    return augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "mask = df.weight > 0\n",
    "tdf_original = df.loc[mask, ['keypoints', 'fish_id', 'weight', 'k_factor', 'camera_metadata']].copy(deep=True)\n",
    "\n",
    "annotation_list = []\n",
    "fish_id_list = []\n",
    "weight_list = []\n",
    "kf_list = []\n",
    "akpd_score_list = []\n",
    "camera_metadata_list = []\n",
    "\n",
    "for ann, weight, akpd_score, camera_metadata in zip(modified_ann_list, modified_weight_list, modified_akpd_score_list, cm_list):\n",
    "    if akpd_score < 0.5 or weight < 0:\n",
    "        continue\n",
    "    \n",
    "    annotation_list.append(ann)\n",
    "    fish_id_list.append(uuid.uuid1())\n",
    "    weight_list.append(weight)\n",
    "    kf_list.append(1.0)\n",
    "    akpd_score_list.append(akpd_score)\n",
    "    camera_metadata_list.append(camera_metadata)\n",
    "    \n",
    "tdf_synthetic = pd.DataFrame({\n",
    "    'keypoints': annotation_list,\n",
    "    'fish_id': fish_id_list,\n",
    "    'weight': weight_list,\n",
    "    'k_factor': kf_list,\n",
    "    'akpd_score': akpd_score_list,\n",
    "    'camera_metadata': camera_metadata_list\n",
    "})\n",
    "\n",
    "tdf = pd.concat([tdf_original, tdf_synthetic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_config = dict(\n",
    "    trials=10,\n",
    "    max_jitter_std=5,\n",
    "    min_depth=0.5,\n",
    "    max_depth=2.5\n",
    ")\n",
    "\n",
    "augmented_df3 = augment(tdf, augmentation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains constants representing core & auxiliary fish body parts.\n",
    "\"\"\"\n",
    "\n",
    "UPPER_LIP = 'UPPER_LIP'\n",
    "EYE = 'EYE'\n",
    "PECTORAL_FIN = 'PECTORAL_FIN'\n",
    "DORSAL_FIN = 'DORSAL_FIN'\n",
    "PELVIC_FIN = 'PELVIC_FIN'\n",
    "ADIPOSE_FIN = 'ADIPOSE_FIN'\n",
    "ANAL_FIN = 'ANAL_FIN'\n",
    "TAIL_NOTCH = 'TAIL_NOTCH'\n",
    "UPPER_PRECAUDAL_PIT = 'UPPER_PRECAUDAL_PIT'\n",
    "LOWER_PRECAUDAL_PIT = 'LOWER_PRECAUDAL_PIT'\n",
    "HYPURAL_PLATE = 'HYPURAL_PLATE'\n",
    "\n",
    "core_body_parts = sorted([UPPER_LIP,\n",
    "                          EYE,\n",
    "                          PECTORAL_FIN,\n",
    "                          DORSAL_FIN,\n",
    "                          PELVIC_FIN,\n",
    "                          ADIPOSE_FIN,\n",
    "                          ANAL_FIN,\n",
    "                          TAIL_NOTCH])\n",
    "\n",
    "auxiliary_body_parts = sorted([UPPER_PRECAUDAL_PIT,\n",
    "                               LOWER_PRECAUDAL_PIT,\n",
    "                               HYPURAL_PLATE])\n",
    "\n",
    "all_body_parts = sorted(core_body_parts + auxiliary_body_parts)\n",
    "\n",
    "BODY_PARTS = core_body_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module contains utility helper functions for the WeightEstimator class.\"\"\"\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from research.weight_estimation.keypoint_utils import body_parts\n",
    "\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m',\n",
    "                             'pixel_count_width', 'pixel_count_height', 'image_sensor_width',\n",
    "                             'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in body_parts.core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def normalize_left_right_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Tuple:\n",
    "    \"\"\"Normalizes input left and right key-point arrays. The normalization involves (1) 2D\n",
    "    translation of all keypoints such that they are centered, (2) rotation of the 2D coordiantes\n",
    "    about the center such that the line passing through UPPER_LIP and fish center is horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    # translate key-points, perform reflection if necessary\n",
    "    upper_lip_idx = body_parts.core_body_parts.index(body_parts.UPPER_LIP)\n",
    "    tail_notch_idx = body_parts.core_body_parts.index(body_parts.TAIL_NOTCH)\n",
    "    if X_left[upper_lip_idx, 0] > X_left[tail_notch_idx, 0]:\n",
    "        X_center = 0.5 * (np.max(X_left, axis=0) + np.min(X_left, axis=0))\n",
    "        X_left_centered = X_left - X_center\n",
    "        X_right_centered = X_right - X_center\n",
    "    else:\n",
    "        X_center = 0.5 * (np.max(X_right, axis=0) + np.min(X_right, axis=0))\n",
    "        X_left_centered = X_right - X_center\n",
    "        X_right_centered = X_left - X_center\n",
    "        X_left_centered[:, 0] = -X_left_centered[:, 0]\n",
    "        X_right_centered[:, 0] = -X_right_centered[:, 0]\n",
    "\n",
    "    # rotate key-points\n",
    "    upper_lip_x, upper_lip_y = tuple(X_left_centered[upper_lip_idx])\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    D = X_left_centered - X_right_centered\n",
    "    X_left_rot = np.dot(X_left_centered, R)\n",
    "    X_right_rot = X_left_rot - D\n",
    "    return X_left_rot, X_right_rot\n",
    "\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world\n",
    "\n",
    "\n",
    "def stabilize_keypoints(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transforms world coordinate array so that neural network inputs are stabilized\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    X_new[:, 0] = 0.5 * X[:, 0] / X[:, 1]\n",
    "    X_new[:, 1] = 0.5 * X[:, 2] / X[:, 1]\n",
    "    X_new[:, 2] = 0.05 / X[:, 1]\n",
    "    return X_new\n",
    "\n",
    "# generate the matrix for rotation of angle theta about an axis aligned with unit vector n\n",
    "def generate_rotation_matrix(n, theta):\n",
    "    R = np.array([[\n",
    "        np.cos(theta) + n[0] ** 2 * (1 - np.cos(theta)),\n",
    "        n[0] * n[1] * (1 - np.cos(theta)) - n[2] * np.sin(theta),\n",
    "        n[0] * n[2] * (1 - np.cos(theta)) + n[1] * np.sin(theta)\n",
    "    ], [\n",
    "        n[1] * n[0] * (1 - np.cos(theta)) + n[2] * np.sin(theta),\n",
    "        np.cos(theta) + n[1] ** 2 * (1 - np.cos(theta)),\n",
    "        n[1] * n[2] * (1 - np.cos(theta)) - n[0] * np.sin(theta),\n",
    "    ], [\n",
    "        n[2] * n[0] * (1 - np.cos(theta)) - n[1] * np.sin(theta),\n",
    "        n[2] * n[1] * (1 - np.cos(theta)) + n[0] * np.sin(theta),\n",
    "        np.cos(theta) + n[2] ** 2 * (1 - np.cos(theta))\n",
    "    ]])\n",
    "    return R\n",
    "\n",
    "# apply rotation to keypoint world-coordinates about origin (i.e. left camera focal point) such that\n",
    "# fish centroid is on positive y-axis (i.e. camera is looking straight at it). Once this is complete,\n",
    "# rotate fish about y-axis such that line connecting UPPER_LIP and TAIL_NOTCH is aligned with x-axis.\n",
    "# Finally, perform reflection such that fish is looking towards the positive x direction (if applicable)\n",
    "def center_3d_coordinates(wkps):\n",
    "    v = np.median(wkps[:8], axis=0)\n",
    "    v /= np.linalg.norm(v)\n",
    "    y = np.array([0, 1, 0])\n",
    "    n = np.cross(y, v)\n",
    "    n /= np.linalg.norm(n)\n",
    "    theta = -np.arccos(np.dot(y, v))\n",
    "    R = generate_rotation_matrix(n, theta)\n",
    "    wkps = np.dot(R, wkps.T).T\n",
    "    # rotate about y-axis so that fish is straight\n",
    "    upper_lip_idx = BODY_PARTS.index('UPPER_LIP')\n",
    "    tail_notch_idx = BODY_PARTS.index('TAIL_NOTCH')\n",
    "    v = wkps[upper_lip_idx] - wkps[tail_notch_idx]\n",
    "    n = np.array([0, 1, 0])\n",
    "    theta = np.arctan(v[2] / v[0])\n",
    "    R = generate_rotation_matrix(n, theta)\n",
    "    wkps = np.dot(R, wkps.T).T\n",
    "    # perform reflection so that fish is forced to look right\n",
    "    if wkps[upper_lip_idx][0] < wkps[tail_notch_idx][0]:\n",
    "        R = np.array([\n",
    "            [-1, 0, 0],\n",
    "            [0, 1, 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        wkps = np.dot(R, wkps.T).T\n",
    "    return wkps\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return nn_input \n",
    "\n",
    "def convert_to_nn_input_flat(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "#     X = stabilize_keypoints(X_world)\n",
    "    X = X_world\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return torch.flatten(nn_input) \n",
    "\n",
    "def convert_to_nn_input_new(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "#     X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left, X_right, camera_metadata)\n",
    "    X_world_norm = center_3d_coordinates(X_world)\n",
    "#     X = stabilize_keypoints(X_world_norm)\n",
    "    X = X_world_norm\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return torch.flatten(nn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split(X: np.ndarray, y: np.ndarray, fish_ids: np.ndarray, train_pct: float,\n",
    "                   val_pct: float) -> Tuple:\n",
    "    # select train / test sets such that there are no overlapping fish IDs\n",
    "\n",
    "    test_pct = 1.0 - train_pct - val_pct\n",
    "    unique_fish_ids = np.array(list(set(fish_ids)))\n",
    "    train_cnt, val_cnt, test_cnt = np.random.multinomial(len(unique_fish_ids),\n",
    "                                                         [train_pct, val_pct, test_pct])\n",
    "\n",
    "    assignments = np.array([0] * train_cnt + [1] * val_cnt + [2] * test_cnt)\n",
    "    np.random.shuffle(assignments)\n",
    "    train_fish_ids = unique_fish_ids[np.where(assignments == 0)]\n",
    "    val_fish_ids = unique_fish_ids[np.where(assignments == 1)]\n",
    "    test_fish_ids = unique_fish_ids[np.where(assignments == 2)]\n",
    "\n",
    "    train_mask = np.isin(fish_ids, train_fish_ids)\n",
    "    val_mask = np.isin(fish_ids, val_fish_ids)\n",
    "    test_mask = np.isin(fish_ids, test_fish_ids)\n",
    "\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "def train_model_with_dropout(X_train, y_train, X_val, y_val, train_config):\n",
    "    inputs = Input(shape=(24,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dropout(0.01)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, train_config):\n",
    "    inputs = Input(shape=(24,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pred = Dense(1)(x)\n",
    "    model = Model(inputs, pred)\n",
    "\n",
    "    epochs = train_config['epochs']\n",
    "    batch_size = train_config['batch_size']\n",
    "    lr = train_config['learning_rate']\n",
    "    patience = train_config['patience']\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               min_delta=0,\n",
    "                                               patience=patience,\n",
    "                                               verbose=0,\n",
    "                                               mode='auto')]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "              batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_to_pytorch(model):\n",
    "    pytorch_model = Network()\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    pytorch_model.fc1.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "    pytorch_model.fc1.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "    pytorch_model.fc2.weight.data = torch.from_numpy(np.transpose(weights[2]))\n",
    "    pytorch_model.fc2.bias.data = torch.from_numpy(np.transpose(weights[3]))\n",
    "    pytorch_model.fc3.weight.data = torch.from_numpy(np.transpose(weights[4]))\n",
    "    pytorch_model.fc3.bias.data = torch.from_numpy(np.transpose(weights[5]))\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "    \n",
    "    return pytorch_model\n",
    "\n",
    "def convert_to_pytorch_with_dropout(model):\n",
    "    pytorch_model = NetworkWithDropout()\n",
    "    weights = model.get_weights()\n",
    "\n",
    "    pytorch_model.fc1.weight.data = torch.from_numpy(np.transpose(weights[0]))\n",
    "    pytorch_model.fc1.bias.data = torch.from_numpy(np.transpose(weights[1]))\n",
    "    pytorch_model.fc2.weight.data = torch.from_numpy(np.transpose(weights[2]))\n",
    "    pytorch_model.fc2.bias.data = torch.from_numpy(np.transpose(weights[3]))\n",
    "    pytorch_model.fc3.weight.data = torch.from_numpy(np.transpose(weights[4]))\n",
    "    pytorch_model.fc3.bias.data = torch.from_numpy(np.transpose(weights[5]))\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.transpose(weights[6]))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.transpose(weights[7]))\n",
    "    \n",
    "    return pytorch_model\n",
    "\n",
    "def apply_final_layer_ols(pytorch_model):\n",
    "    X_ols = pytorch_model.forward_intermediate(torch.from_numpy(X_train).float()).detach().numpy()\n",
    "    lr = LinearRegression().fit(X_ols, y_train)\n",
    "    pytorch_model.output.weight.data = torch.from_numpy(np.array(lr.coef_).reshape(1, -1))\n",
    "    pytorch_model.output.bias.data = torch.from_numpy(np.array([lr.intercept_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation, camera_metadata = anns[0], cms[0]\n",
    "\n",
    "cm = CameraMetadata(\n",
    "    focal_length=camera_metadata['focalLength'],\n",
    "    focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "    baseline_m=camera_metadata['baseline'],\n",
    "    pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "    pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "    image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "    image_sensor_height=camera_metadata['imageSensorHeight']\n",
    ")\n",
    "\n",
    "# X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "# #     X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "# X_world = convert_to_world_point_arr(X_left, X_right, cm)\n",
    "# X_world_norm = center_3d_coordinates(X_world)\n",
    "# X = stabilize_keypoints(X_world_norm)\n",
    "# nn_input = torch.from_numpy(np.array([X])).float()\n",
    "\n",
    "X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, cm)\n",
    "X = stabilize_keypoints(X_world)\n",
    "nn_input = torch.from_numpy(np.array([X])).float()\n",
    "\n",
    "nn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_nn_input(annotation, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_nn_input_new(annotation, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = augmented_df3.annotation.values.tolist()\n",
    "cms = augmented_df3.camera_metadata.values.tolist()\n",
    "\n",
    "def normalize(anns: List, camera_metadatas: List) -> np.ndarray:\n",
    "    norm_anns = []\n",
    "    for ann, camera_metadata in zip(anns, camera_metadatas):\n",
    "\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        norm_ann = convert_to_nn_input(ann, cm)\n",
    "        norm_anns.append(norm_ann.numpy())\n",
    "    return np.array(norm_anns)\n",
    "\n",
    "X = normalize(anns, cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = augmented_df3.annotation.values.tolist()\n",
    "cms = augmented_df3.camera_metadata.values.tolist()\n",
    "\n",
    "def normalize_new(anns: List, camera_metadatas: List) -> np.ndarray:\n",
    "    norm_anns = []\n",
    "    for ann, camera_metadata in zip(anns, camera_metadatas):\n",
    "\n",
    "        cm = CameraMetadata(\n",
    "            focal_length=camera_metadata['focalLength'],\n",
    "            focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "            baseline_m=camera_metadata['baseline'],\n",
    "            pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "            pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "            image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "            image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "        )\n",
    "\n",
    "        norm_ann = convert_to_nn_input_new(ann, cm)\n",
    "#         norm_ann = convert_to_nn_input(ann, cm)\n",
    "        norm_anns.append(norm_ann.numpy())\n",
    "    return np.array(norm_anns)\n",
    "\n",
    "X_new = normalize_new(anns, cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# tensorflow.random.set_seed(0)\n",
    "\n",
    "train_config = dict(\n",
    "    train_pct=0.9,\n",
    "    val_pct=0.09,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "y = 1e-4 * augmented_df3.weight.values\n",
    "fish_ids = augmented_df3.fish_id.values\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, train_mask, val_mask, test_mask = get_data_split(X, y, fish_ids,\n",
    "                                                                train_config['train_pct'],\n",
    "                                                                train_config['val_pct'])\n",
    "\n",
    "tf_model = train_model_with_dropout(X_train, y_train, X_val, y_val, train_config)\n",
    "pytorch_model = convert_to_pytorch_with_dropout(tf_model)\n",
    "# apply_final_layer_ols(pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# tensorflow.random.set_seed(0)\n",
    "\n",
    "train_config = dict(\n",
    "    train_pct=0.98,\n",
    "    val_pct=0.01,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "y = 1e-4 * augmented_df3.weight.values\n",
    "fish_ids = augmented_df3.fish_id.values\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, train_mask, val_mask, test_mask = get_data_split(X, y, fish_ids,\n",
    "                                                                train_config['train_pct'],\n",
    "                                                                train_config['val_pct'])\n",
    "\n",
    "tf_model = train_model(X_train, y_train, X_val, y_val, train_config)\n",
    "pytorch_model = convert_to_pytorch(tf_model)\n",
    "apply_final_layer_ols(pytorch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# tensorflow.random.set_seed(0)\n",
    "\n",
    "train_config = dict(\n",
    "    train_pct=0.98,\n",
    "    val_pct=0.01,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    patience=30\n",
    ")\n",
    "\n",
    "y = 1e-4 * augmented_df3.weight.values\n",
    "fish_ids = augmented_df3.fish_id.values\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, train_mask, val_mask, test_mask = get_data_split(X_new, y, fish_ids,\n",
    "                                                                train_config['train_pct'],\n",
    "                                                                train_config['val_pct'])\n",
    "\n",
    "tf_model = train_model(X_train, y_train, X_val, y_val, train_config)\n",
    "pytorch_model = convert_to_pytorch(tf_model)\n",
    "apply_final_layer_ols(pytorch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df3['is_train'] = train_mask.astype(int)\n",
    "augmented_df3['is_val'] = val_mask.astype(int)\n",
    "augmented_df3['is_test'] = test_mask.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "print('Train stats')\n",
    "train_errs = (y_pred[train_mask] - y_train) / y_train\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[train_mask]) - np.mean(y_train)) / np.mean(y_train)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(train_errs))))\n",
    "print('='*20)\n",
    "print('Val stats')\n",
    "val_errs = (y_pred[val_mask] - y_val) / y_val\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[val_mask]) - np.mean(y_val)) / np.mean(y_val)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(val_errs))))\n",
    "print('='*20)\n",
    "print('Test stats')\n",
    "test_errs = (y_pred[test_mask] - y_test) / y_test\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[test_mask]) - np.mean(y_test)) / np.mean(y_test)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(test_errs))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (pytorch_model(torch.from_numpy(X_new).float())).detach().numpy().squeeze()\n",
    "print('Train stats')\n",
    "train_errs = (y_pred[train_mask] - y_train) / y_train\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[train_mask]) - np.mean(y_train)) / np.mean(y_train)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(train_errs))))\n",
    "print('='*20)\n",
    "print('Val stats')\n",
    "val_errs = (y_pred[val_mask] - y_val) / y_val\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[val_mask]) - np.mean(y_val)) / np.mean(y_val)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(val_errs))))\n",
    "print('='*20)\n",
    "print('Test stats')\n",
    "test_errs = (y_pred[test_mask] - y_test) / y_test\n",
    "print('Mean error pct: {}'.format((np.mean(y_pred[test_mask]) - np.mean(y_test)) / np.mean(y_test)))\n",
    "print('Mean absolute error pct: {}'.format(np.mean(np.abs(test_errs))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_per_bucket_error(X, y):\n",
    "    y_pred = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "\n",
    "    buckets = np.arange(0, 10000, 1000) * 1e-4\n",
    "    bucket_strs = []\n",
    "    mean_errs = []\n",
    "    maes = []\n",
    "    for low, high in zip(buckets, buckets[1:]):\n",
    "        bucket_str = '{}-{}'.format(round(1e4 * low), round(1e4 * high))\n",
    "        mask = (y >= low) & (y < high)\n",
    "        mean_err = np.mean((y_pred[mask] - y[mask]) / y[mask])\n",
    "        mae = np.mean(np.abs((y_pred[mask] - y[mask]) / y[mask]))\n",
    "        mean_errs.append(mean_err)\n",
    "        maes.append(mae)\n",
    "        bucket_strs.append(bucket_str)\n",
    "    \n",
    "    return pd.DataFrame({'bucket': bucket_strs, 'mean_err': mean_errs, 'mae': maes})\n",
    "\n",
    "print('Training dataset')\n",
    "print('\\n')\n",
    "print(generate_per_bucket_error(X_train, y_train))\n",
    "print('='*20)\n",
    "print('\\n')\n",
    "print('Testing dataset')\n",
    "print('\\n')\n",
    "print(generate_per_bucket_error(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_per_depth_bucket_error(X, y, d):\n",
    "    predictions = (pytorch_model(torch.from_numpy(X).float())).detach().numpy().squeeze()\n",
    "\n",
    "    depths = np.arange(0.4, 2.6, 0.1)\n",
    "    mean_pct_errs = []\n",
    "    depth_buckets = []\n",
    "    for low_depth, high_depth in zip(depths, depths[1:]):\n",
    "        mask = (d >= low_depth) & (d < high_depth)\n",
    "        depth_bucket = '{}-{}'.format(round(low_depth, 2), round(high_depth, 2))\n",
    "        depth_buckets.append(depth_bucket)\n",
    "        mean_pct_err = np.nanmean((predictions[mask] - y[mask]) / y[mask])\n",
    "        mean_pct_errs.append(mean_pct_err)\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'depth_bucket': depth_buckets, 'mean_err': mean_pct_errs})\n",
    "\n",
    "print('Training dataset')\n",
    "print('\\n')\n",
    "print(generate_per_depth_bucket_error(X_train, y_train, augmented_df3[train_mask].depth.values))\n",
    "print('\\n')\n",
    "print('='*20)\n",
    "print('\\n')\n",
    "print('Testing dataset')\n",
    "print('\\n')\n",
    "print(generate_per_depth_bucket_error(X_test, y_test, augmented_df3[test_mask].depth.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient10.pb'\n",
    "torch.save(pytorch_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "from report_generation.report_generator import generate_ts_data, SamplingFilter\n",
    "from research.utils.datetime_utils import add_days\n",
    "from report_generation.report_generator import gen_pm_base\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values, ValidationError\n",
    "from filter_optimization.filter_optimization_task import _add_date_hour_columns\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = [\n",
    "    'seglberget_pen_id_66_2020-05-13_2020-06-13',\n",
    "    'bolaks_pen_id_88_2020-02-28_2020-03-10',\n",
    "    'langoy_pen_id_108_2020-05-07_2020-05-17',\n",
    "    'tittelsnes_pen_id_37_2020-06-10_2020-06-24',\n",
    "    'aplavika_pen_id_95_2020-07-10_2020-07-26',\n",
    "#     'kjeppevikholmen_pen_id_5_2019-06-18_2019-07-02',\n",
    "    'silda_pen_id_86_2020-07-02_2020-07-19',\n",
    "    'vikane_pen_id_60_2020-08-10_2020-08-30',\n",
    "    'eldviktaren_pen_id_164_2020-09-21_2020-10-08',\n",
    "#     'habranden_pen_id_100_2020-08-10_2020-08-31',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'dale_pen_id_143_2020-10-07_2020-10-21',\n",
    "    'djubawik_pen_id_153_2020-11-10_2020-11-26',\n",
    "    'leivsethamran_pen_id_165_2020-10-18_2020-11-13',\n",
    "    'movikodden_pen_id_114_2020-11-03_2020-11-25',\n",
    "    'movikodden_pen_id_167_2020-10-13_2020-10-30',\n",
    "    'slapoya_pen_id_116_2020-10-18_2020-11-08',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'varholmen_pen_id_151_2020-10-02_2020-10-17',\n",
    "    'varholmen_pen_id_186_2020-10-18_2020-11-02'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_type = {\n",
    "    'seglberget_pen_id_66_2020-05-13_2020-06-13': 'sexton',\n",
    "    'bolaks_pen_id_88_2020-02-28_2020-03-10': 'sexton',\n",
    "    'langoy_pen_id_108_2020-05-07_2020-05-17': 'sexton',\n",
    "    'tittelsnes_pen_id_37_2020-06-10_2020-06-24': 'sexton',\n",
    "    'aplavika_pen_id_95_2020-07-10_2020-07-26': 'sexton',\n",
    "#     'kjeppevikholmen_pen_id_5_2019-06-18_2019-07-02': 'sexton',\n",
    "    'silda_pen_id_86_2020-07-02_2020-07-19': 'sexton',\n",
    "    'vikane_pen_id_60_2020-08-10_2020-08-30': 'atlas',\n",
    "    'eldviktaren_pen_id_164_2020-09-21_2020-10-08': 'atlas',\n",
    "#     'habranden_pen_id_100_2020-08-10_2020-08-31': 'imenco',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30': 'imenco',\n",
    "    'dale_pen_id_143_2020-10-07_2020-10-21': 'atlas',\n",
    "    'djubawik_pen_id_153_2020-11-10_2020-11-26': 'atlas',\n",
    "    'leivsethamran_pen_id_165_2020-10-18_2020-11-13': 'atlas',\n",
    "    'movikodden_pen_id_114_2020-11-03_2020-11-25': 'imenco',\n",
    "    'movikodden_pen_id_167_2020-10-13_2020-10-30': 'imenco',\n",
    "    'slapoya_pen_id_116_2020-10-18_2020-11-08': 'imenco',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30': 'imenco',\n",
    "    'varholmen_pen_id_151_2020-10-02_2020-10-17': 'imenco',\n",
    "    'varholmen_pen_id_186_2020-10-18_2020-11-02': 'atlas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'test'\n",
    "\n",
    "ROOT_DIR = '/root/data/alok/biomass_estimation/playground'\n",
    "dfs, gt_metadatas = {}, {}\n",
    "for cohort_name in cohort_names:\n",
    "    s3_dir = os.path.join(\n",
    "        'https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets',\n",
    "        cohort_name\n",
    "    )\n",
    "\n",
    "    ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata.json')\n",
    "    ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata.json')\n",
    "#     ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata_validated.json')\n",
    "#     ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata_validated.json')\n",
    "    ground_truth_f = os.path.join(ROOT_DIR, ground_truth_key_base)\n",
    "    print(ground_truth_metadata_url)\n",
    "    s3.download_from_url(ground_truth_metadata_url, custom_location=ground_truth_f)\n",
    "    gt_metadata = json.load(open(ground_truth_f))\n",
    "    gt_metadatas[cohort_name] = gt_metadata\n",
    "    \n",
    "    data_url = os.path.join(s3_dir, 'annotation_dataset.csv')\n",
    "    data_f, _, _= s3.download_from_url(data_url)\n",
    "    df = pd.read_csv(data_f)\n",
    "    df = _add_date_hour_columns(df)\n",
    "    dfs[cohort_name] = df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('weight_v1', 'orig1', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient1.pb', False, False, False, False),\n",
    "    ('weight_v2', 'orig2', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient2.pb', False, True, True, False),\n",
    "    ('weight_v3', 'orig1-noNorm', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient3.pb', False, False, True, False),\n",
    "    ('weight_v4', 'orig2-noNorm', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient4.pb', False, True, True, False),\n",
    "    ('weight_v5', 'orig1-noNorm-dropout', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient5.pb', False, False, True, True),\n",
    "    ('weight_v6', 'orig1-noNorm-dropout-noOLS', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient6.pb', False, False, True, True),\n",
    "    ('weight_v7', 'orig1-noNorm-dropout-noOLS0.9', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient7.pb', False, False, True, True),\n",
    "    ('weight_v8', 'orig1-noNorm-dropout0.2-noOLS0.9', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient8.pb', False, False, True, True),\n",
    "    ('weight_v9', 'orig1-noNorm-dropout1-noOLS0.9', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient9.pb', False, False, True, True),\n",
    "    ('weight_v10', 'orig1-noNorm-dropout.01-noOLS0.9', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient10.pb', False, False, True, True)\n",
    "]\n",
    "\n",
    "additional_models = [\n",
    "    ('weight_v10', 'orig1-noNorm-dropout.01-noOLS0.9', '/root/data/alok/biomass_estimation/playground/output_model_bryton_orient10.pb', False, False, True, True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the WeightEstimator class for estimating fish weight (g), length (mm), and\n",
    "k-factor given input keypoint coordinates and camera metadata.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class WeightEstimator:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "#         X = convert_to_nn_input_new(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf\n",
    "    \n",
    "class WeightEstimatorFlat:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input_flat(annotation, camera_metadata)\n",
    "        X = X.reshape(1, 24)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf\n",
    "    \n",
    "\n",
    "class WeightEstimatorNew:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "#         X = convert_to_nn_input(annotation, camera_metadata)\n",
    "        X = convert_to_nn_input_new(annotation, camera_metadata)\n",
    "        X = X.reshape(1, 24)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf\n",
    "    \n",
    "class WeightEstimatorWithDropout:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = NetworkWithDropout()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "#         X = convert_to_nn_input_new(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, tag, model_url, is_url, is_new, is_flat, has_dropout in additional_models:\n",
    "    # weight_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/biomass/trained_models/2020-11-27T00-00-00/weight_model_synthetic_data.pb')\n",
    "    if is_url:\n",
    "        weight_model_f, _, _ = s3.download_from_url(model_url)\n",
    "    else:\n",
    "        weight_model_f = model_url\n",
    "    kf_model_f, _, _ = s3.download_from_url('https://aquabyte-models.s3-us-west-1.amazonaws.com/k-factor/playground/kf_predictor_v2.pb')\n",
    "\n",
    "    if has_dropout:\n",
    "        weight_estimator = WeightEstimatorWithDropout(weight_model_f, kf_model_f)\n",
    "    elif is_new:\n",
    "        weight_estimator = WeightEstimatorNew(weight_model_f, kf_model_f)\n",
    "    elif is_flat:\n",
    "        weight_estimator = WeightEstimatorFlat(weight_model_f, kf_model_f)\n",
    "    else:\n",
    "        weight_estimator = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "\n",
    "    for k, rdf in dfs.items():\n",
    "        print(k)\n",
    "        weights = []\n",
    "        count = 0\n",
    "        for idx, row in rdf.iterrows():\n",
    "            if count % 100 == 0:\n",
    "                print('Percentage completion: {}%'.format(round(100 * count / rdf.shape[0], 2)))\n",
    "                print(count)\n",
    "            count += 1\n",
    "            annotation = json.loads(row.annotation.replace(\"'\", '\"'))\n",
    "            if not annotation:\n",
    "                weights.append(None)\n",
    "                continue\n",
    "            camera_metadata = json.loads(row.camera_metadata.replace(\"'\", '\"'))\n",
    "            if not camera_metadata:\n",
    "                camera_metadata = json.loads(rdf.camera_metadata.iloc[0].replace(\"'\", '\"'))\n",
    "\n",
    "            camera_metadata_obj = CameraMetadata(\n",
    "                focal_length=camera_metadata['focalLength'],\n",
    "                focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "                baseline_m=camera_metadata['baseline'],\n",
    "                pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "                pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "                image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "                image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "            )\n",
    "\n",
    "            weight, length, kf = weight_estimator.predict(annotation, camera_metadata_obj)\n",
    "            weights.append(weight)\n",
    "        rdf[key] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raw_individual_values(pm_base, gt_metadata, start_hour, end_hour, apply_growth_rate, max_day_diff, days_post_feeding, final_days_post_feeding):\n",
    "    last_feeding_date = gt_metadata['last_feeding_date']\n",
    "    date = add_days(last_feeding_date, days_post_feeding)\n",
    "    weights, _ = generate_smart_individual_values(pm_base, date, max_day_diff, True, apply_growth_rate, 0.9)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def generate_average_weight_accuracy(weights, gt_metadata, loss_factor):\n",
    "    avg_weight_prediction = np.mean(weights)\n",
    "    gutted_weight_prediction = avg_weight_prediction * (1.0 - loss_factor)\n",
    "    gt_weight = gt_metadata['gutted_average_weight']\n",
    "    avg_weight_err = (gutted_weight_prediction - gt_weight) / gt_weight\n",
    "    return avg_weight_err, gutted_weight_prediction\n",
    "\n",
    "def generate_distribution_accuracy(weights, gt_metadata, loss_factor):\n",
    "    gutted_weights = weights * (1.0 - loss_factor)\n",
    "    gutted_weight_distribution = gt_metadata['gutted_weight_distribution']\n",
    "    \n",
    "    if gutted_weight_distribution is None:\n",
    "        return []\n",
    "    \n",
    "    count_distribution_errors = []\n",
    "    \n",
    "    for bucket in gutted_weight_distribution:\n",
    "        lower_bound, upper_bound = bucket.split('-')\n",
    "        pct = gutted_weight_distribution[bucket]\n",
    "        mask = (gutted_weights >= float(lower_bound) * 1000) & (gutted_weights < float(upper_bound) * 1000)\n",
    "\n",
    "        pct = np.sum(mask) / len(mask)\n",
    "        gt_pct = gutted_weight_distribution[bucket] / 100\n",
    "        \n",
    "        count_distribution_errors.append(pct - gt_pct)\n",
    "        \n",
    "    return count_distribution_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tdfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key, tag, _, _, _, _, _ in additional_models:\n",
    "    start_hours = [7]\n",
    "    end_hours = [15]\n",
    "    apply_growth_rate = True\n",
    "    max_day_diff = 3\n",
    "    days_post_feeding = 1\n",
    "    final_days_post_feeding = 1\n",
    "    loss_factors = [0.16, 'expected_loss_factor'] # need to determine the right values here\n",
    "    akpd_cutoffs = [0.01, 0.95]\n",
    "\n",
    "    hour_filter_methods = ['manual', 'hour_hist', 'u-shape'] #  'u-shape',\n",
    "\n",
    "    cohort_name_col = []\n",
    "    akpd_cutoff_col = []\n",
    "    hour_filter_method_col = []\n",
    "    start_hour_col = []\n",
    "    end_hour_col = []\n",
    "    loss_factor_col = []\n",
    "    starvation_days_col = []\n",
    "    avg_weight_col = []\n",
    "    gutted_avg_weight_col = []\n",
    "    avg_weight_error_col = []\n",
    "    gt_avg_weight_col = []\n",
    "    count_distribution_error_col = []\n",
    "    camera_col = []\n",
    "\n",
    "    for loss_factor in loss_factors:\n",
    "        avg_weight_error_col.append([])\n",
    "        gutted_avg_weight_col.append([])\n",
    "        count_distribution_error_col.append([])\n",
    "\n",
    "    for cohort_name in sorted(list(dfs.keys())):\n",
    "        print(cohort_name)\n",
    "        \n",
    "        gt_metadata = gt_metadatas[cohort_name]\n",
    "\n",
    "        last_feeding_date = gt_metadata['last_feeding_date']\n",
    "        slaughter_date = gt_metadata['slaughter_date']\n",
    "\n",
    "        if slaughter_date is not None and last_feeding_date is not None:\n",
    "            date_diff = datetime.strptime(slaughter_date, '%Y-%m-%d') - datetime.strptime(last_feeding_date, '%Y-%m-%d')\n",
    "            starvation_days = date_diff.days\n",
    "        else:\n",
    "            starvation_days = None\n",
    "\n",
    "        df = dfs[cohort_name]\n",
    "        df['estimated_weight_g'] = df[key]\n",
    "        final_date_post_feeding = add_days(gt_metadata['last_feeding_date'], final_days_post_feeding)\n",
    "        tdf = df[df.date <= final_date_post_feeding]\n",
    "\n",
    "        start_end_hours = []\n",
    "\n",
    "        for method in hour_filter_methods:\n",
    "            if method == 'manual':\n",
    "                for start_hour in start_hours:\n",
    "                    for end_hour in end_hours:\n",
    "                        start_end_hours.append((method, start_hour, end_hour))\n",
    "            elif method == 'u-shape':\n",
    "                df2 = df[(df.hour >= 3) & (df.hour <= 20)]\n",
    "\n",
    "                #count, bins, _ = plt.hist(df2.hour, density = True, bins = (np.max(df2.hour) - np.min(df2.hour)))\n",
    "\n",
    "                start_hour = np.min(df2.hour)\n",
    "                end_hour = np.max(df2.hour)\n",
    "\n",
    "                bins = np.arange(start_hour, end_hour + 1)\n",
    "\n",
    "                weights = []\n",
    "\n",
    "                for hour in np.arange(start_hour, end_hour + 1):\n",
    "                    avg_weight = np.mean(df2[df2.hour == hour].estimated_weight_g)\n",
    "                    weights.append(avg_weight)\n",
    "\n",
    "                start_index = np.where(bins == 10)[0][0]\n",
    "\n",
    "                lower_index = start_index\n",
    "                upper_index = start_index\n",
    "\n",
    "                is_iterating = True\n",
    "                eps = 3\n",
    "\n",
    "                while is_iterating:\n",
    "                #     print(np.std(weights[lower_index:upper_index]))\n",
    "                    if lower_index > 0 and upper_index < len(weights) - 1 and np.abs(weights[upper_index + 1] - weights[lower_index - 1]) < eps * np.std(weights[lower_index - 1:upper_index + 1]):\n",
    "                        lower_index = lower_index - 1\n",
    "                        upper_index = upper_index + 1\n",
    "                    elif lower_index > 0 and np.abs(weights[upper_index] - weights[lower_index - 1]) < eps * np.std(weights[lower_index - 1:upper_index]):\n",
    "                        lower_index = lower_index - 1\n",
    "                    elif upper_index < len(weights) - 1 and np.abs(weights[upper_index + 1] - weights[lower_index]) < eps * np.std(weights[lower_index:upper_index + 1]):\n",
    "                        upper_index = upper_index + 1\n",
    "                    else:\n",
    "                        is_iterating = False\n",
    "\n",
    "                start_hour, end_hour = bins[lower_index], bins[upper_index]\n",
    "                \n",
    "                start_end_hours.append((method, start_hour, end_hour))\n",
    "            elif method == 'hour_hist':\n",
    "                df2 = df[(df.hour >= 3) & (df.hour <= 20)]\n",
    "\n",
    "                count, bins, _ = plt.hist(df2.hour, density = True, bins = (np.max(df2.hour) - np.min(df2.hour)))\n",
    "\n",
    "                idx_values = np.where(count > 1.0 / 18)[0]\n",
    "\n",
    "                start_index = np.where(bins == 10)[0][0]\n",
    "                start_array = np.where(idx_values == start_index)[0][0]\n",
    "\n",
    "                lower_index = start_array\n",
    "                upper_index = start_array\n",
    "\n",
    "                while lower_index > 0 and (idx_values[lower_index] - idx_values[lower_index - 1] == 1):\n",
    "                    lower_index = lower_index - 1\n",
    "                while upper_index < len(idx_values) - 1 and (idx_values[upper_index + 1] - idx_values[upper_index] == 1):\n",
    "                    upper_index = upper_index + 1\n",
    "\n",
    "                start_hour, end_hour = bins[idx_values[lower_index]], bins[idx_values[upper_index]]\n",
    "\n",
    "                start_end_hours.append((method, start_hour, end_hour))\n",
    "\n",
    "        for akpd_cutoff in akpd_cutoffs:\n",
    "            for method, start_hour, end_hour in start_end_hours:\n",
    "                sampling_filter = SamplingFilter(\n",
    "                    start_hour=start_hour,\n",
    "                    end_hour=end_hour,\n",
    "                    kf_cutoff=0.0,\n",
    "                    akpd_score_cutoff=akpd_cutoff\n",
    "                )\n",
    "\n",
    "                pm_base = gen_pm_base(tdf, sampling_filter)\n",
    "\n",
    "                try:\n",
    "                    weights = generate_raw_individual_values(pm_base, gt_metadata, start_hour, end_hour, apply_growth_rate, max_day_diff, days_post_feeding, final_days_post_feeding)\n",
    "                except ValidationError as err:\n",
    "                    continue\n",
    "\n",
    "                akpd_cutoff_col.append(akpd_cutoff)\n",
    "                cohort_name_col.append(cohort_name)\n",
    "                hour_filter_method_col.append(method)\n",
    "                start_hour_col.append(start_hour)\n",
    "                end_hour_col.append(end_hour)\n",
    "                loss_factor_col.append(gt_metadata['expected_loss_factor'])\n",
    "                starvation_days_col.append(starvation_days)\n",
    "                avg_weight_col.append(np.mean(weights))\n",
    "                gt_avg_weight_col.append(gt_metadata['gutted_average_weight'])\n",
    "                camera_col.append(camera_type[cohort_name])\n",
    "\n",
    "                for index, loss_factor in enumerate(loss_factors):\n",
    "                    if loss_factor == 'expected_loss_factor':\n",
    "                        loss_factor = gt_metadata['expected_loss_factor'] or 0.165\n",
    "\n",
    "                        if loss_factor > 10:\n",
    "                            loss_factor = loss_factor / 100.0\n",
    "\n",
    "                    avg_weight_err, gutted_weight_prediction = generate_average_weight_accuracy(weights, gt_metadata, loss_factor)\n",
    "                    avg_weight_error_col[index].append(avg_weight_err)\n",
    "                    gutted_avg_weight_col[index].append(gutted_weight_prediction)\n",
    "\n",
    "                    count_distribution_errors = generate_distribution_accuracy(weights, gt_metadata, loss_factor)\n",
    "                    count_distribution_error_col[index].append(count_distribution_errors)\n",
    "                    \n",
    "    columns = {\n",
    "        'cohort_name': cohort_name_col,\n",
    "        'hour_filter_method_col': hour_filter_method_col,\n",
    "        'akpd_cutoff_col': akpd_cutoff_col,\n",
    "        'start_hour_col': start_hour_col,\n",
    "        'end_hour_col': end_hour_col,\n",
    "        'loss_factor_col': loss_factor_col,\n",
    "        'starvation_days_col': starvation_days_col,\n",
    "        'avg_weight_col': avg_weight_col,\n",
    "        'gt_avg_weight_col': gt_avg_weight_col,\n",
    "        'camera_col': camera_col\n",
    "    }\n",
    "\n",
    "    for index, loss_factor in enumerate(loss_factors):\n",
    "        if loss_factor == 'expected_loss_factor':\n",
    "            col_name = 'avg_weight_error_exp'\n",
    "            col_gutted_name = 'avg_gutted_weight_exp'\n",
    "            col_abs_name = 'avg_weight_error_abs_exp'\n",
    "            col_abs_dist_name = 'avg_count_dist_error_abs_exp'\n",
    "        else:\n",
    "            col_name = 'avg_weight_error_%0.2f' % (loss_factor,)\n",
    "            col_gutted_name = 'avg_gutted_weight_%0.2f' % (loss_factor,)\n",
    "            col_abs_name = 'avg_weight_error_abs_%0.2f' % (loss_factor,)\n",
    "            col_abs_dist_name = 'avg_count_dist_error_abs_%0.2f' % (loss_factor,)\n",
    "\n",
    "        columns[col_name] = avg_weight_error_col[index]\n",
    "        columns[col_gutted_name] = gutted_avg_weight_col[index]\n",
    "        columns[col_abs_name] = np.abs(avg_weight_error_col[index])\n",
    "        columns[col_abs_dist_name] = [np.mean(np.abs(l)) for l in count_distribution_error_col[index]]\n",
    "\n",
    "    new_tdf = pd.DataFrame(columns)\n",
    "    \n",
    "    all_tdfs.append(new_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight_v9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs1 = []\n",
    "all_dfs2 = []\n",
    "all_dfs3 = []\n",
    "all_dfs4 = []\n",
    "all_dfs5 = []\n",
    "all_dfs6 = []\n",
    "\n",
    "for tdf in all_tdfs:\n",
    "    columns = ['cohort_name',  'starvation_days_col', 'camera_col', 'avg_weight_col', 'avg_gutted_weight_0.16', 'gt_avg_weight_col', 'avg_weight_error_0.16', 'avg_weight_error_exp']\n",
    "    df1 = tdf[(tdf.akpd_cutoff_col == 0.01) & (tdf.hour_filter_method_col == 'manual')][columns]\n",
    "    df2 = tdf[(tdf.akpd_cutoff_col == 0.01) & (tdf.hour_filter_method_col == 'hour_hist')][columns]\n",
    "    df3 = tdf[(tdf.akpd_cutoff_col == 0.01) & (tdf.hour_filter_method_col == 'u-shape')][columns]\n",
    "    df4 = tdf[(tdf.akpd_cutoff_col == 0.95) & (tdf.hour_filter_method_col == 'manual')][columns]\n",
    "    df5 = tdf[(tdf.akpd_cutoff_col == 0.95) & (tdf.hour_filter_method_col == 'hour_hist')][columns]\n",
    "    df6 = tdf[(tdf.akpd_cutoff_col == 0.95) & (tdf.hour_filter_method_col == 'u-shape')][columns]\n",
    "    \n",
    "    all_dfs1.append(df1)\n",
    "    all_dfs2.append(df2)\n",
    "    all_dfs3.append(df3)\n",
    "    all_dfs4.append(df4)\n",
    "    all_dfs5.append(df5)\n",
    "    all_dfs6.append(df6)\n",
    "    \n",
    "all_all_dfs = [\n",
    "    all_dfs1,\n",
    "    all_dfs2,\n",
    "    all_dfs3,\n",
    "    all_dfs4,\n",
    "    all_dfs5,\n",
    "    all_dfs6\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model in enumerate(models):\n",
    "    metric = []\n",
    "\n",
    "    for all_dfs in all_all_dfs:\n",
    "        metric.append(np.sqrt(np.mean((50 * np.abs(all_dfs[index]['avg_weight_error_0.16'])) ** 2)))\n",
    "\n",
    "    print(np.mean(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for all_dfs in all_all_dfs:\n",
    "    metric = []\n",
    "\n",
    "    for index, model in enumerate(models):\n",
    "        metric.append(np.sqrt(np.mean((50 * np.abs(all_dfs[index]['avg_weight_error_0.16'])) ** 2)))\n",
    "\n",
    "    print(np.mean(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = all_dfs2\n",
    "\n",
    "metric = []\n",
    "\n",
    "print('%-*s: 90Pct, 50Pct, Metric, Avg16, AvgAbs16, AvgNormAbs16, AvgAbsExp, Std16' % (25, 'Model'))\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    _, tag, _, _, _, _, _ = model\n",
    "    print('%-*s: %0.2f,  %0.2f,  %0.2f,    %0.2f,  %0.2f,     %0.2f,         %0.2f,       %0.2f' % (25, tag, 100 * np.percentile(np.abs(all_dfs[index]['avg_weight_error_0.16']), 90), 100 * np.percentile(np.abs(all_dfs[index]['avg_weight_error_0.16']), 50), np.sqrt(np.mean((50 * np.abs(all_dfs[index]['avg_weight_error_0.16'])) ** 2)), 100 * np.mean((all_dfs[index]['avg_weight_error_0.16'])), 100 * np.mean(np.abs(all_dfs[index]['avg_weight_error_0.16'])), 100 * np.mean(np.abs(all_dfs[index]['avg_weight_error_0.16'] - np.mean(all_dfs[index]['avg_weight_error_0.16']))), 100 * np.mean(np.abs(all_dfs[index]['avg_weight_error_exp'])), 100 * np.std((all_dfs[index]['avg_weight_error_0.16']))))\n",
    "    metric.append(np.sqrt(np.mean((50 * np.abs(all_dfs[index]['avg_weight_error_0.16'])) ** 2)))\n",
    "    \n",
    "print(np.mean(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "color=iter(cm.rainbow(np.linspace(0,1,len(models))))\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    c = next(color)\n",
    "    \n",
    "    _, tag, _, _, _, _, _ = model\n",
    "    plt.scatter(all_dfs[index].gt_avg_weight_col, all_dfs[index]['avg_weight_error_0.16'], color = c, label=tag)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['vikane_pen_id_60_2020-08-10_2020-08-30'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
