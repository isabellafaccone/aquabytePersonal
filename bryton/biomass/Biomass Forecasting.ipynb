{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from datetime import timedelta, datetime, time\n",
    "\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select p.id as id, s.name as site_name, p.name as pen_name from pens p\n",
    "    left join sites s\n",
    "    on p.site_id = s.id\n",
    "    and p.is_accessible_to_customer is true\n",
    "    order by p.id;\n",
    "\"\"\"\n",
    "\n",
    "df_pens = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "pen_ids = [ 60 ] #56 # 37 # 56, 60,\n",
    "pen_infos = []\n",
    "\n",
    "#print(df_pens)\n",
    "\n",
    "for index, pen in df_pens.iterrows():\n",
    "    if pen.id in pen_ids:\n",
    "            pen_infos.append((pen.id, pen.site_name, pen.pen_name))\n",
    "            \n",
    "print(pen_infos)\n",
    "\n",
    "pen_id, site_name, pen_name = pen_infos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select date, weight_avg, weight_moving_avg\n",
    "    from day_summaries a\n",
    "    where a.pen_id = %i\n",
    "    and a.date >= '2020-04-01';\n",
    "\"\"\" % (pen_id, )\n",
    "\n",
    "day_summaries = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "day_summaries.index = pd.to_datetime(day_summaries['date'])\n",
    "day_summaries = day_summaries.sort_index()\n",
    "\n",
    "#day_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesCombinedOriginal = day_summaries['weight_avg'].fillna(method='ffill')\n",
    "seriesCombinedRolling = day_summaries['weight_moving_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSeriesMultivariate(series, trainSplitPct, predictionDays, isExp, AR):\n",
    "    originalX = series.copy()\n",
    "    X = series.copy()\n",
    "    \n",
    "    if isExp:\n",
    "        X = np.log(X)\n",
    "\n",
    "    diffX = X.diff().dropna()\n",
    "    \n",
    "    startPredictDays = 10\n",
    "\n",
    "    size = int(len(diffX) * trainSplitPct)\n",
    "    train, test = diffX.ix[0:size], diffX.ix[size:len(diffX)]\n",
    "    history = train\n",
    "    predictions = {}\n",
    "    day0Predictions = originalX.ix[0:(size + startPredictDays)]\n",
    "    day0PredictionsLower = originalX.ix[0:(size + startPredictDays)]\n",
    "    day0PredictionsUpper = originalX.ix[0:(size + startPredictDays)]\n",
    "\n",
    "    maxPredictionDay = 0\n",
    "    \n",
    "\n",
    "    for predictionDay in predictionDays:\n",
    "        maxPredictionDay = max(maxPredictionDay, predictionDay)\n",
    "        predictions[predictionDay] = pd.concat([originalX.ix[0:(size + predictionDay)]])\n",
    "        \n",
    "    for t in range(len(test)):\n",
    "        nextDate = originalX.index[size + t + 1]\n",
    "        #print(history)\n",
    "        model = ARIMA(history, order=AR)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        forecast, stderr, conf_int = model_fit.forecast(maxPredictionDay)\n",
    "        output = forecast\n",
    "        output_lower = conf_int[:,0]\n",
    "        output_upper = conf_int[:,1]\n",
    "        \n",
    "#         print(output)\n",
    "#         model_fit = model.fit(maxlags = AR, ic='aic') #model.fit(AR)\n",
    "#         lag_order = model_fit.k_ar\n",
    "#         if lag_order == 0:\n",
    "#             model_fit = model.fit(1)\n",
    "#         output, output_lower, output_upper = model_fit.forecast_interval(history.values[-lag_order:], maxPredictionDay, 0.25)\n",
    "        \n",
    "        for predictionDay in predictionDays:\n",
    "            if t > len(test) - predictionDay:\n",
    "                continue\n",
    "            predictionDate = originalX.index[size + t + predictionDay]\n",
    "            prediction = X.ix[0] + np.sum(history) + np.sum(output[:predictionDay], 0)\n",
    "            \n",
    "            if isExp:\n",
    "                prediction = np.exp(prediction)\n",
    "                \n",
    "            if t == startPredictDays:\n",
    "                #cov = model_fit.forecast_cov(maxPredictionDay)\n",
    "                \n",
    "                for i in range(predictionDay):\n",
    "                    date = originalX.index[size + startPredictDays + i + 1]\n",
    "                    datePrediction = X.ix[0] + np.sum(history) + np.sum(output[:i], 0)\n",
    "                    datePredictionLower = X.ix[0] + np.sum(history) + np.sum(output_lower[:i], 0)\n",
    "                    datePredictionUpper = X.ix[0] + np.sum(history) + np.sum(output_upper[:i], 0)\n",
    "                    \n",
    "                    SE = stderr[i]\n",
    "                    currentCOV = stderr ** 2\n",
    "                    expSE = np.sqrt(np.sum((np.exp(currentCOV) - 1) * np.exp(2 * np.mean(history) + currentCOV), 0))\n",
    "                    \n",
    "                    day0Predictions.loc[date] = datePrediction\n",
    "                    day0PredictionsLower.loc[date] = np.maximum(datePrediction - SE * 1.96, datePredictionLower)\n",
    "                    day0PredictionsUpper.loc[date] = np.minimum(datePrediction + SE * 1.96, datePredictionUpper)\n",
    "                    \n",
    "                    datePredictionExp = np.exp(datePrediction)\n",
    "                    datePredictionLowerExp = np.maximum(np.exp(datePrediction) - expSE * 1.96, np.exp(datePredictionLower))\n",
    "                    datePredictionUpperExp = np.minimum(np.exp(datePrediction) + expSE * 1.96, np.exp(datePredictionUpper))\n",
    "                    \n",
    "                    \n",
    "                    if isExp:\n",
    "                        day0Predictions.loc[date] = datePredictionExp\n",
    "                        day0PredictionsLower.loc[date] = datePredictionLowerExp\n",
    "                        day0PredictionsUpper.loc[date] = datePredictionUpperExp\n",
    "           \n",
    "            predictions[predictionDay].loc[predictionDate] = prediction\n",
    "            \n",
    "#             print(series.ix[0])\n",
    "#             print(history)\n",
    "#             print(np.sum(history))\n",
    "#             print(np.sum(output[:predictionDay], 0))\n",
    "#             print(nextDate, predictionDate)\n",
    "#             print(prediction)\n",
    "\n",
    "        history.loc[nextDate] = test.ix[t]\n",
    "\n",
    "#     for predictionDay in predictionDays:\n",
    "#         for field in isExp:\n",
    "#             predictions[predictionDay][field] = np.exp(predictions[predictionDay][field])\n",
    "\n",
    "    return predictions, day0Predictions, day0PredictionsLower, day0PredictionsUpper\n",
    "    \n",
    "#    return train, test, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSplitPct = 0.5\n",
    "predictionDays = [14]\n",
    "\n",
    "predictions, day0Predictions, day0PredictionsLower, day0PredictionsUpper = testSeriesMultivariate(seriesCombinedRolling, trainSplitPct, predictionDays, True, (4,0,0))\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "fig.set_size_inches(15, 20)\n",
    "\n",
    "i = 7\n",
    "halfI = int((i + 1)/ 2)\n",
    "\n",
    "for index, predictionDay in enumerate(predictionDays):\n",
    "    predictionSeries = predictions[predictionDay]\n",
    "    totalLen = int((len(predictionSeries) - 1) * trainSplitPct) + predictionDay\n",
    "    predictionSeriesRolling = predictionSeries.rolling('%iD' % (i, )).mean().shift(-24 * i / 2, freq='h').resample('D').apply(lambda x:x.tail(1) if x.shape[0] else np.nan)\n",
    "    predictionSeriesRolling.ix[0:halfI] = np.nan\n",
    "    predictionSeriesRolling.ix[halfI:(totalLen + halfI)] = seriesCombinedRolling.values[0:totalLen]\n",
    "    predictionSeriesRolling.ix[halfI:(totalLen + halfI)] = seriesCombinedRolling.values[0:totalLen]\n",
    "\n",
    "    ax[0].plot(predictionSeries.index, predictionSeries, color = 'red', label = '%i Day Original' % (predictionDay, ))\n",
    "    ax[0].plot(predictionSeriesRolling.index, predictionSeriesRolling.values, color = 'blue', label = '%i Day Rolling' % (predictionDay, ))\n",
    "    ax[0].plot(seriesCombinedOriginal.index, seriesCombinedOriginal, color = 'black', linestyle = '--', label = 'Actual')\n",
    "    ax[0].plot(seriesCombinedRolling.index, seriesCombinedRolling, color = 'black', linewidth = 5, label = 'Rolling')\n",
    "    ax[0].plot(day0Predictions.index, day0Predictions, color = 'purple', linewidth = 2, label = 'Daily Predictions')\n",
    "    ax[0].fill_between(day0Predictions.index, day0PredictionsLower, day0PredictionsUpper, color='b', alpha=.1)\n",
    "    ax[0].set_title('%s %s Average Weight (ARIMA)' % (site_name, pen_name))\n",
    "    ax[0].set_xlabel('Date')\n",
    "    ax[0].set_ylabel('Average Weight')\n",
    "    ax[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax[0].axhline(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
