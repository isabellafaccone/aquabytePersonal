{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains constants representing core & auxiliary fish body parts.\n",
    "\"\"\"\n",
    "\n",
    "UPPER_LIP = 'UPPER_LIP'\n",
    "EYE = 'EYE'\n",
    "PECTORAL_FIN = 'PECTORAL_FIN'\n",
    "DORSAL_FIN = 'DORSAL_FIN'\n",
    "PELVIC_FIN = 'PELVIC_FIN'\n",
    "ADIPOSE_FIN = 'ADIPOSE_FIN'\n",
    "ANAL_FIN = 'ANAL_FIN'\n",
    "TAIL_NOTCH = 'TAIL_NOTCH'\n",
    "UPPER_PRECAUDAL_PIT = 'UPPER_PRECAUDAL_PIT'\n",
    "LOWER_PRECAUDAL_PIT = 'LOWER_PRECAUDAL_PIT'\n",
    "HYPURAL_PLATE = 'HYPURAL_PLATE'\n",
    "\n",
    "core_body_parts = sorted([UPPER_LIP,\n",
    "                          EYE,\n",
    "                          PECTORAL_FIN,\n",
    "                          DORSAL_FIN,\n",
    "                          PELVIC_FIN,\n",
    "                          ADIPOSE_FIN,\n",
    "                          ANAL_FIN,\n",
    "                          TAIL_NOTCH])\n",
    "\n",
    "auxiliary_body_parts = sorted([UPPER_PRECAUDAL_PIT,\n",
    "                               LOWER_PRECAUDAL_PIT,\n",
    "                               HYPURAL_PLATE])\n",
    "\n",
    "all_body_parts = sorted(core_body_parts + auxiliary_body_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module contains utility helper functions for the WeightEstimator class.\"\"\"\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m',\n",
    "                             'pixel_count_width', 'pixel_count_height', 'image_sensor_width',\n",
    "                             'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def normalize_left_right_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Tuple:\n",
    "    \"\"\"Normalizes input left and right key-point arrays. The normalization involves (1) 2D\n",
    "    translation of all keypoints such that they are centered, (2) rotation of the 2D coordiantes\n",
    "    about the center such that the line passing through UPPER_LIP and fish center is horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    # translate key-points, perform reflection if necessary\n",
    "    upper_lip_idx = core_body_parts.index(UPPER_LIP)\n",
    "    tail_notch_idx = core_body_parts.index(TAIL_NOTCH)\n",
    "    if X_left[upper_lip_idx, 0] > X_left[tail_notch_idx, 0]:\n",
    "        X_center = 0.5 * (np.max(X_left, axis=0) + np.min(X_left, axis=0))\n",
    "        X_left_centered = X_left - X_center\n",
    "        X_right_centered = X_right - X_center\n",
    "    else:\n",
    "        X_center = 0.5 * (np.max(X_right, axis=0) + np.min(X_right, axis=0))\n",
    "        X_left_centered = X_right - X_center\n",
    "        X_right_centered = X_left - X_center\n",
    "        X_left_centered[:, 0] = -X_left_centered[:, 0]\n",
    "        X_right_centered[:, 0] = -X_right_centered[:, 0]\n",
    "\n",
    "    # rotate key-points\n",
    "    upper_lip_x, upper_lip_y = tuple(X_left_centered[upper_lip_idx])\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    D = X_left_centered - X_right_centered\n",
    "    X_left_rot = np.dot(X_left_centered, R)\n",
    "    X_right_rot = X_left_rot - D\n",
    "    return X_left_rot, X_right_rot\n",
    "\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world\n",
    "\n",
    "\n",
    "def stabilize_keypoints(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transforms world coordinate array so that neural network inputs are stabilized\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    X_new[:, 0] = 0.5 * X[:, 0] / X[:, 1]\n",
    "    X_new[:, 1] = 0.5 * X[:, 2] / X[:, 1]\n",
    "    X_new[:, 2] = 0.05 / X[:, 1]\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return nn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the WeightEstimator class for estimating fish weight (g), length (mm), and\n",
    "k-factor given input keypoint coordinates and camera metadata.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WeightEstimator:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "from research.weight_estimation.keypoint_utils.body_parts import core_body_parts\n",
    "from research.utils.image_utils import Picture\n",
    "from scipy.spatial import Delaunay\n",
    "from itertools import compress\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "def in_hull(p, hull):\n",
    "    hull = Delaunay(hull)\n",
    "    return hull.find_simplex(p) >= 0\n",
    "\n",
    "\n",
    "def apply_convex_hull_filter(kp, des, canonical_kps, bbox):\n",
    "    X_canon_kps = np.array(list(canonical_kps.values()))\n",
    "    X_kp = np.array([x.pt for x in kp]).reshape(-1, 2) + np.array([bbox['x_min'], bbox['y_min']])\n",
    "    is_valid = in_hull(X_kp, X_canon_kps)\n",
    "    kp = list(compress(kp, is_valid))\n",
    "    des = des[is_valid]\n",
    "    return kp, des\n",
    "\n",
    "\n",
    "def get_homography_and_matches(sift, left_patch, right_patch,\n",
    "                               left_kps, right_kps,\n",
    "                               left_bbox, right_bbox,\n",
    "                               good_perc=0.7, min_match_count=3):\n",
    "\n",
    "    kp1, des1 = sift.detectAndCompute(left_patch, None)\n",
    "    kp2, des2 = sift.detectAndCompute(right_patch, None)\n",
    "    try:\n",
    "        if not (des1.any() and des2.any()):\n",
    "            return None, kp1, kp2, None, [0]\n",
    "    except AttributeError:\n",
    "        print(\"None type for detectAndComputer descriptor\")\n",
    "        return None, kp1, kp2, None, [0]\n",
    "    # apply convex hull filter\n",
    "    kp1, des1 = apply_convex_hull_filter(kp1, des1, left_kps, left_bbox)\n",
    "    kp2, des2 = apply_convex_hull_filter(kp2, des2, right_kps, right_bbox)\n",
    "    \n",
    "    print(len(kp1), len(kp2))\n",
    "#     bf = cv2.BFMatcher()\n",
    "#     matches = bf.knnMatch(des1, des2, k=2)\n",
    "    bf = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_BRUTEFORCE_HAMMING)\n",
    "    matches = bf.knnMatch(des1, des2, 2)\n",
    "\n",
    "    H, matches_mask = np.eye(3), []\n",
    "    good = []\n",
    "\n",
    "    # check that matches list contains actual pairs\n",
    "    if len(matches) > 0:\n",
    "        if len(matches[0]) != 2:\n",
    "            print('Aborting: matches list does not contain pairs')\n",
    "            return H, kp1, kp2, good, matches_mask\n",
    "\n",
    "    for m, n in matches:\n",
    "        if m.distance < good_perc * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) >= min_match_count:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    "    return H, kp1, kp2, good, matches_mask\n",
    "\n",
    "\n",
    "def generate_sift_adjustment(bp, left_crop_metadata, left_fish_picture, left_kps, right_crop_metadata,\n",
    "                             right_fish_picture, right_kps, sift):\n",
    "    left_kp, right_kp = left_kps[bp], right_kps[bp]\n",
    "    left_crop, left_bbox = left_fish_picture.generate_crop_given_center(left_kp[0], left_kp[1], 600, 200)\n",
    "    right_crop, right_bbox = right_fish_picture.generate_crop_given_center(right_kp[0], right_kp[1], 600, 200)\n",
    "\n",
    "    H, _, _, _, matches_mask = get_homography_and_matches(sift, left_crop, right_crop,\n",
    "                                                          left_kps, right_kps,\n",
    "                                                          left_bbox, right_bbox)\n",
    "    num_matches = sum(matches_mask)\n",
    "    if H is not None:\n",
    "        local_left_kp = [left_kp[0] - left_bbox['x_min'], left_kp[1] - left_bbox['y_min']]\n",
    "        local_right_kp = cv2.perspectiveTransform(\n",
    "            np.array([local_left_kp[0], local_left_kp[1]]).reshape(-1, 1, 2).astype(float), H).squeeze()\n",
    "        right_kp = [local_right_kp[0] + right_bbox['x_min'], local_right_kp[1] + right_bbox['y_min']]\n",
    "    left_item = {\n",
    "        'keypointType': bp,\n",
    "        'xCrop': left_kp[0],\n",
    "        'yCrop': left_kp[1],\n",
    "        'xFrame': left_crop_metadata['x_coord'] + left_kp[0],\n",
    "        'yFrame': left_crop_metadata['y_coord'] + left_kp[1]\n",
    "    }\n",
    "    right_item = {\n",
    "        'keypointType': bp,\n",
    "        'xCrop': right_kp[0],\n",
    "        'yCrop': right_kp[1],\n",
    "        'xFrame': right_crop_metadata['x_coord'] + right_kp[0],\n",
    "        'yFrame': right_crop_metadata['y_coord'] + right_kp[1]\n",
    "    }\n",
    "    return left_item, right_item, num_matches\n",
    "\n",
    "\n",
    "def generate_refined_keypoints(ann, left_crop_url, right_crop_url):\n",
    "\n",
    "    left_kps = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['leftCrop']}\n",
    "    right_kps = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in ann['rightCrop']}\n",
    "\n",
    "    left_crop_metadata = {\n",
    "        'x_coord': ann['leftCrop'][0]['xFrame'] - ann['leftCrop'][0]['xCrop'],\n",
    "        'y_coord': ann['leftCrop'][0]['yFrame'] - ann['leftCrop'][0]['yCrop']\n",
    "    }\n",
    "    right_crop_metadata = {\n",
    "        'x_coord': ann['rightCrop'][0]['xFrame'] - ann['rightCrop'][0]['xCrop'],\n",
    "        'y_coord': ann['rightCrop'][0]['yFrame'] - ann['rightCrop'][0]['yCrop']\n",
    "    }\n",
    "\n",
    "    left_image = Image.open(left_crop_url)\n",
    "    right_image = Image.open(right_crop_url)\n",
    "#     left_fish_picture = np.array(left_image)#Picture(image_arr=np.array(left_image))\n",
    "#     right_fish_picture = np.array(right_image)#Picture(image_arr=np.array(right_image))\n",
    "    left_fish_picture = Picture(image_arr=np.array(left_image)).image_arr\n",
    "    right_fish_picture = Picture(image_arr=np.array(right_image)).image_arr\n",
    "#     left_fish_picture = Picture(image_url=left_crop_url)\n",
    "#     right_fish_picture = Picture(image_url=right_crop_url)\n",
    "#     left_fish_picture.enhance(in_place=True)\n",
    "#     right_fish_picture.enhance(in_place=True)\n",
    "    \n",
    "    SCALE_PERCENT      = 50\n",
    "    orig_width = left_fish_picture.shape[1]\n",
    "    orig_height = left_fish_picture.shape[0]\n",
    "    width = int(orig_width * SCALE_PERCENT / 100)\n",
    "    height = int(orig_height * SCALE_PERCENT / 100)\n",
    "    dim = (width, height)\n",
    "    left_fish_picture = cv2.resize(left_fish_picture, dim, interpolation = cv2.INTER_AREA)\n",
    "    left_fish_picture = Picture(image_arr=left_fish_picture)\n",
    "    left_fish_picture.enhance(in_place=True)\n",
    "    dim = (orig_width, orig_height)\n",
    "    left_fish_picture = cv2.resize(left_fish_picture.image_arr, dim, interpolation = cv2.INTER_AREA)\n",
    "    left_fish_picture = Picture(image_arr=left_fish_picture)\n",
    "    \n",
    "    orig_width = right_fish_picture.shape[1]\n",
    "    orig_height = right_fish_picture.shape[0]\n",
    "    width = int(orig_width * SCALE_PERCENT / 100)\n",
    "    height = int(orig_height * SCALE_PERCENT / 100)\n",
    "    dim = (width, height)\n",
    "    right_fish_picture = cv2.resize(right_fish_picture, dim, interpolation = cv2.INTER_AREA)\n",
    "    right_fish_picture = Picture(image_arr=right_fish_picture)\n",
    "    right_fish_picture.enhance(in_place=True)\n",
    "    dim = (orig_width, orig_height)\n",
    "    right_fish_picture = cv2.resize(right_fish_picture.image_arr, dim, interpolation = cv2.INTER_AREA)\n",
    "    right_fish_picture = Picture(image_arr=right_fish_picture)\n",
    "    \n",
    "#     sift = cv2.KAZE_create()\n",
    "    sift = cv2.AKAZE_create()\n",
    "    left_items, right_items = [], []\n",
    "#     start = time.time()\n",
    "    for bp in core_body_parts:\n",
    "        left_item, right_item, num_matches = generate_sift_adjustment(bp, left_crop_metadata, left_fish_picture,\n",
    "                                                                      left_kps, right_crop_metadata,\n",
    "                                                                      right_fish_picture, right_kps, sift)\n",
    "        left_items.append(left_item)\n",
    "        right_items.append(right_item)\n",
    "#     end = time.time()\n",
    "#     print(end-start)\n",
    "    modified_ann = {\n",
    "        'leftCrop': left_items,\n",
    "        'rightCrop': right_items\n",
    "    }\n",
    "    return modified_ann\n",
    "\n",
    "# sift               = cv2.AKAZE_create()\n",
    "# SCALE_PERCENT      = 100                                                   # percent\n",
    "# RANSAC_THRESH      = 10.0\n",
    "# INLIER_THRESH      = 30\n",
    "\n",
    "# def get_kp_desc(image):\n",
    "#     width = int(image.shape[1] * SCALE_PERCENT / 100)\n",
    "#     height = int(image.shape[0] * SCALE_PERCENT / 100)\n",
    "#     dim = (width, height)\n",
    "#     image_rz = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "#     img = enhance(image_rz)\n",
    "#     kp1, des1 = sift.detectAndCompute(img, None)\n",
    "#     return (kp1, des1)\n",
    "\n",
    "# def find_matches(im1, im2):\n",
    "#     good = []\n",
    "#     (kp1, des1) = get_kp_desc(im1)\n",
    "#     (kp2, des2) = get_kp_desc(im2)\n",
    "#     matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_BRUTEFORCE_HAMMING)\n",
    "#     matches = matcher.knnMatch(des1, des2, 2)\n",
    "#     # print(\"Raw Matches %d\" % len(matches))\n",
    "#     inliers = 0\n",
    "#     for m, n in matches:\n",
    "#         if m.distance < GOOD_PERC * n.distance:\n",
    "#             good.append(m)\n",
    "#     # print(\"Good Matches %d\" % len(good))\n",
    "#     if len(good) >= MIN_MATCH_COUNT:\n",
    "#         src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "#         dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "#         for j in range(len(src_pts)):\n",
    "#             src_pts[j][0][0] *= 100/SCALE_PERCENT\n",
    "#             src_pts[j][0][1] *= 100/SCALE_PERCENT\n",
    "#         for j in range(len(dst_pts)):\n",
    "#             dst_pts[j][0][0] *= 100/SCALE_PERCENT\n",
    "#             dst_pts[j][0][1] *= 100/SCALE_PERCENT\n",
    "#         _, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, RANSAC_THRESH)\n",
    "#         matches_mask = mask.ravel().tolist()\n",
    "#         inliers = sum(matches_mask)\n",
    "#     else:\n",
    "#         print(\"Not enough matches are found - %d/%d\" % (len(good), MIN_MATCH_COUNT))\n",
    "#         matches_mask = None\n",
    "#     print(\"Final Inlier Matches %d\" % inliers)\n",
    "#     return inliers #> 30\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    s3_access_utils = s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "\n",
    "    rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT * FROM keypoint_annotations\n",
    "        WHERE pen_id=5\n",
    "        AND captured_at BETWEEN '2019-06-05' AND '2019-07-02'\n",
    "        AND keypoints is not null\n",
    "        AND keypoints -> 'leftCrop' is not null\n",
    "        AND keypoints -> 'rightCrop' is not null\n",
    "        AND is_qa = FALSE\n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "\n",
    "    modified_anns = []\n",
    "\n",
    "    df = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # get annotation information\n",
    "        ann = row.keypoints\n",
    "        left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "        left_crop_metadata, right_crop_metadata = row.left_crop_metadata, row.right_crop_metadata\n",
    "\n",
    "        modified_ann = generate_refined_keypoints(ann, left_crop_url, right_crop_url)\n",
    "\n",
    "        modified_anns.append(modified_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('gtsf_data.csv')\n",
    "df = pd.read_csv('/root/data/alok/biomass_estimation/playground/gtsf_akpr2.csv')\n",
    "\n",
    "depths = []\n",
    "depths2 = []\n",
    "depths3 = []\n",
    "lengths = []\n",
    "lengths2 = []\n",
    "lengths3 = []\n",
    "lengths4 = []\n",
    "widths = []\n",
    "widths2 = []\n",
    "\n",
    "lengths_adj = []\n",
    "    \n",
    "modified_depths = []\n",
    "modified_lengths = []\n",
    "modified_widths = []\n",
    "\n",
    "weights = []\n",
    "weights2 = []\n",
    "weights3 = []\n",
    "\n",
    "mask = []\n",
    "\n",
    "weight_model_f = 'weight_model.pb'\n",
    "# weight_model2_f = '/root/data/alok/biomass_estimation/playground/output_model_bryton.pb'\n",
    "# weight_model3_f = '/root/data/alok/biomass_estimation/playground/output_model_bryton2.pb'\n",
    "kf_model_f = 'kf_model.pb'\n",
    "weight_estimator2 = WeightEstimator(weight_model_f, kf_model_f)\n",
    "# weight_estimator3 = WeightEstimator(weight_model2_f, kf_model_f)\n",
    "# weight_estimator4 = WeightEstimator(weight_model3_f, kf_model_f)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "#     print(idx, len(df))\n",
    "    ann, modified_ann, cm = eval(row.keypoints), eval(row.modified_keypoints), eval(row.camera_metadata)\n",
    "    wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "    modified_wkps = pixel2world(modified_ann['leftCrop'], modified_ann['rightCrop'], cm)\n",
    "    \n",
    "    cm_adj = CameraMetadata(\n",
    "        focal_length=cm['focalLength'],\n",
    "        focal_length_pixel=cm['focalLengthPixel'],\n",
    "        baseline_m=cm['baseline'],\n",
    "        pixel_count_width=cm['pixelCountWidth'],\n",
    "        pixel_count_height=cm['pixelCountHeight'],\n",
    "        image_sensor_width=cm['imageSensorWidth'],\n",
    "        image_sensor_height=cm['imageSensorHeight']\n",
    "    )\n",
    "#     print(ann['leftCrop'])\n",
    "#     left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "#     modified_ann = generate_refined_keypoints(ann, left_crop_url, right_crop_url)\n",
    "#     modified_wkps = pixel2world(modified_ann['leftCrop'], modified_ann['rightCrop'], cm)\n",
    "    \n",
    "#     modified_depth = np.median([wkp[1] for wkp in modified_wkps.values()])\n",
    "#     modified_depths.append(modified_depth)\n",
    "#     modified_lengths.append(np.linalg.norm(modified_wkps['UPPER_LIP'] - modified_wkps['TAIL_NOTCH']))\n",
    "#     modified_widths.append(np.linalg.norm(np.linalg.norm(modified_wkps['DORSAL_FIN'] - modified_wkps['PELVIC_FIN'])))\n",
    "    \n",
    "#     centroid = .5 * (wkps['DORSAL_FIN'] + wkps['PELVIC_FIN'])\n",
    "# #     angle = np.linalg.norm(np.array(get_angles(wkps['UPPER_LIP'], centroid)) - np.array(get_angles(centroid, wkps['TAIL_NOTCH'])))\n",
    "#     a = (wkps['UPPER_LIP'] - centroid) / np.linalg.norm(wkps['UPPER_LIP'] - centroid)\n",
    "#     b = (wkps['TAIL_NOTCH'] - centroid) / np.linalg.norm(wkps['TAIL_NOTCH'] - centroid)\n",
    "\n",
    "    new_weight, new_length, new_k_factor = weight_estimator2.predict(ann, cm_adj)\n",
    "    weights.append(new_weight)\n",
    "    new_weight, new_length, new_k_factor = weight_estimator2.predict(modified_ann, cm_adj)\n",
    "    weights2.append(new_weight)\n",
    "#     new_weight, new_length, new_k_factor = weight_estimator4.predict(ann, cm_adj)\n",
    "#     weights3.append(new_weight)\n",
    "        \n",
    "#     wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "#     if 'HYPURAL_PLATE' not in wkps:\n",
    "#         mask.append(False)\n",
    "#         continue\n",
    "#     else:\n",
    "#         mask.append(True)\n",
    "    depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "    depths.append(depth)\n",
    "    depth2 = np.median([wkp[1] for wkp in modified_wkps.values()])\n",
    "    depths2.append(depth2)\n",
    "    depth3 = np.min([wkp[1] for wkp in modified_wkps.values()])\n",
    "    depths3.append(depth3)\n",
    "    \n",
    "    lengths.append(np.linalg.norm(wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']))\n",
    "    lengths2.append(np.linalg.norm(modified_wkps['UPPER_LIP'] - modified_wkps['TAIL_NOTCH']))\n",
    "#     lengths2.append(np.linalg.norm(wkps['UPPER_LIP'] - wkps['HYPURAL_PLATE']))\n",
    "#     lengths3.append(np.linalg.norm(wkps['EYE'] - wkps['TAIL_NOTCH']))\n",
    "#     lengths4.append(np.linalg.norm(wkps['EYE'] - wkps['HYPURAL_PLATE']))\n",
    "    widths.append(np.linalg.norm(wkps['DORSAL_FIN'] - wkps['PELVIC_FIN']))\n",
    "    widths2.append(np.linalg.norm(modified_wkps['DORSAL_FIN'] - modified_wkps['PELVIC_FIN']))\n",
    "#     widths2.append(np.linalg.norm(wkps['ADIPOSE_FIN'] - wkps['PECTORAL_FIN']))\n",
    "#     lengths_adj.append(np.linalg.norm(wkps['UPPER_LIP'] - centroid) + np.linalg.norm(centroid - wkps['TAIL_NOTCH']))\n",
    "    \n",
    "# df = df[mask]\n",
    "\n",
    "df['depth'] = depths\n",
    "df['depth2'] = depths2\n",
    "df['depth3'] = depths3\n",
    "df['length'] = lengths\n",
    "df['length2'] = lengths2\n",
    "# df['length3'] = lengths3\n",
    "# df['length4'] = lengths4\n",
    "# df['length_adj'] = lengths_adj\n",
    "df['width'] = widths\n",
    "df['width2'] = widths2\n",
    "df['weights'] = weights\n",
    "df['weights2'] = weights2\n",
    "# df['weights3'] = weights3\n",
    "# df['modified_depth'] = modified_depths\n",
    "# df['modified_length'] = modified_lengths\n",
    "# df['modified_width'] = modified_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    old = eval(row.keypoints)['rightCrop']\n",
    "    new = eval(row.modified_keypoints)['rightCrop']\n",
    "    \n",
    "    dists = []\n",
    "    \n",
    "    for index, keypoint in enumerate(old):\n",
    "        \n",
    "        new_keypoints = [k for k in new if k['keypointType'] == keypoint['keypointType']]\n",
    "        if len(new_keypoints) == 0:\n",
    "            continue\n",
    "        new_keypoint = new_keypoints[0]\n",
    "        \n",
    "#         print(keypoint['keypointType'], new_keypoint['keypointType'])\n",
    "        \n",
    "        xOld = keypoint['xFrame']\n",
    "        yOld = keypoint['yFrame']\n",
    "        xNew = new_keypoint['xFrame']\n",
    "        yNew = new_keypoint['yFrame']\n",
    "        \n",
    "        print(xOld, yOld, xNew, yNew)\n",
    "        \n",
    "        dist = np.sqrt((xOld - xNew) ** 2 + (yOld - yNew) ** 2)\n",
    "        \n",
    "        dists.append(dist)\n",
    "    \n",
    "    all_dists.append(np.max(dists))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = np.array(all_dists)\n",
    "\n",
    "df['akpr_distance'] = ad\n",
    "\n",
    "plt.hist(ad[ad < 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.weights2[df.depth3 > 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.length2 > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.akpr_distance < 50) & (df.modified_akpd_score > 0.95)\n",
    "df2 = df[mask]\n",
    "\n",
    "plt.scatter(df2.weights, df2.weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df2.weight), np.mean(df2.weights), np.mean(df2.weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df2.length, df2.length2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(df2.weight)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(np.log(df2.weights), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(df2.weight)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(np.log(df2.weights2), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(df2['length'])\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(np.log(df2.weight), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(df2['length2'])\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(np.log(df2.weights2), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(df2.weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.scatter(df2.length, df2.weight, color = 'blue')\n",
    "plt.scatter(df2.length2, df2.weights2, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df.weight, df.weights2, color = 'red')\n",
    "plt.scatter(df2.weight, df2.weights, color = 'blue', alpha = 0.5)\n",
    "plt.scatter(df2.weight, df2.weights2, color = 'green', alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, bins, _ = plt.hist(df2.weights2 - df2.weight, bins = 30, color = 'blue', alpha = 0.5, density = True)\n",
    "count, bins, _ = plt.hist(df2.weights - df2.weight, bins = bins, color = 'red', alpha = 0.5, density = True)\n",
    "# count, bins, _ = plt.hist(df.weights3 - df.weight, bins = bins, color = 'green', alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(df.weights - df.weight)), np.mean(np.abs(df.weights2 - df.weight)), np.mean(np.abs(df.weights3 - df.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.weight), np.mean(df.weights), np.mean(df.weights2), np.mean(df.weights3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets = np.arange(0, 2, 0.1)\n",
    "buckets = np.arange(0, 12000, 2000)\n",
    "\n",
    "for bucket in buckets:\n",
    "    mask = (df.weight > bucket) & (df.weight < bucket + 1000)\n",
    "#     mask = (df2.depth > bucket) & (df2.depth < bucket + 0.1)\n",
    "#     mask2 = (df2.depth2 > bucket) & (df2.depth2 < bucket + 0.1)\n",
    "    df3 = df[mask]\n",
    "#     df4 = df2[mask2]\n",
    "    gt_weight = np.mean(df3.weight)\n",
    "    avg_weight1 = np.mean(df3.weights)\n",
    "    avg_weight2 = np.mean(df3.weights2)\n",
    "    avg_weight3 = np.mean(df3.weights3)\n",
    "#     print('%0.1f, %0.2f, %0.2f, %0.2f' % (bucket, gt_weight, avg_weight1, avg_weight2))\n",
    "    print('%0.1f, %0.2f, %0.2f, %0.2f' % (bucket, 100 * (avg_weight1 - gt_weight) / gt_weight, 100 * (avg_weight2 - gt_weight) / gt_weight, 100 * (avg_weight3 - gt_weight) / gt_weight))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.arange(0, 10000, 1000)\n",
    "bias = []\n",
    "\n",
    "for i in buckets:\n",
    "    mask = (df.weight >= i) & (df.weight < (i + 1000))\n",
    "    df2 = df[mask]\n",
    "    bias.append((np.mean(df2.weights - df2.weight)) / np.mean(df2.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buckets, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _  = plt.hist(df.weight, bins = 20)\n",
    "\n",
    "for index, count in enumerate(counts):\n",
    "    print(count, bins[index])\n",
    "    \n",
    "len(df[df.weight > 7000]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.weights2 > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.loc[1140]\n",
    "modified_ann = eval(row.modified_keypoints)\n",
    "cm = eval(row.camera_metadata)\n",
    "\n",
    "cm_adj = CameraMetadata(\n",
    "    focal_length=cm['focalLength'],\n",
    "    focal_length_pixel=cm['focalLengthPixel'],\n",
    "    baseline_m=cm['baseline'],\n",
    "    pixel_count_width=cm['pixelCountWidth'],\n",
    "    pixel_count_height=cm['pixelCountHeight'],\n",
    "    image_sensor_width=cm['imageSensorWidth'],\n",
    "    image_sensor_height=cm['imageSensorHeight']\n",
    ")\n",
    "\n",
    "modified_wkps = pixel2world(modified_ann['leftCrop'], modified_ann['rightCrop'], cm)\n",
    "np.linalg.norm(modified_wkps['UPPER_LIP'] - modified_wkps['TAIL_NOTCH'])\n",
    "\n",
    "\n",
    "# weight_estimator2.predict(modified_ann, cm_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_wkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.weights, df.weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(df.length, df.weight)\n",
    "plt.scatter(df.length, df.weights)\n",
    "\n",
    "x = np.arange(np.min(df.length), np.max(df.length), 0.01)\n",
    "x2 = np.arange(np.min(df.length), np.max(df.length) + 0.05, 0.01)\n",
    "y = (23.6068 * x) ** 3\n",
    "plt.plot(x, y, color = 'red')\n",
    "y = (22 * x2) ** 3\n",
    "plt.plot(x2, y, color = 'green')\n",
    "y = (25 * x) ** 3\n",
    "plt.plot(x, y, color = 'green')\n",
    "plt.axhline(9000)\n",
    "plt.xlabel('Length (m)')\n",
    "plt.ylabel('Weight (g)')\n",
    "plt.title('GTSF Length vs Weight: w = (23.6068 * l) ^ 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df.length), np.log(df.weight))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(length):\n",
    "    return (length * 23.6068) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.ix[0]\n",
    "print(np.sum(np.abs(df.weight - get_weight(df['length'])) > 3000) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.length, df.weight ** (2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df.length), np.log(df.weight) - np.log(df.length) * 1.6489 - np.log(df.width) * 1.3924 - 11.4894)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.exp(11.4894 + 1.6489 * np.log(df.length) + 1.3924 * np.log(df.width)), np.exp(9.5091 + 3.0856 * np.log(df.length)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.weight, np.exp(11.4894 + 1.6489 * np.log(df.length) + 1.3924 * np.log(df.width)))\n",
    "plt.plot(df.weight, df.weight, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.weight - np.exp(11.4894 + 1.6489 * np.log(df.length) + 1.3924 * np.log(df.width)), bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.weight, np.exp(9.5091 + 3.0856 * np.log(df.length)))\n",
    "plt.plot(df.weight, df.weight, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(df.length), np.log(df.weight) - np.log(df.length) * 3.0856 - 9.5091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.length, df.weight ** (1/3.08) - df.length * 11.9685 - df.width * 41.2623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.length, df.weight ** (1/3.08) - df.length * 23.8999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log(df[['length', 'width']])\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(np.log(df.weight), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "sm.qqplot(results.resid, fit = True, line=\"45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['length', 'width']]\n",
    "# X = sm.add_constant(X)\n",
    "model = sm.OLS(df.weight ** (1 / 3.0856), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "sm.qqplot(results.resid, fit = True, line=\"45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.length\n",
    "model = sm.OLS(df.weight ** (1/3), X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[['length']]\n",
    "X2 = df[['length', 'width']]\n",
    "X3 = df[['length', 'width', 'width2']]\n",
    "# X1 = sm.add_constant(X1)\n",
    "# X2 = sm.add_constant(X2)\n",
    "# X3 = sm.add_constant(X3)\n",
    "model1 = sm.OLS(df.weight ** (1/3), X1)\n",
    "model2 = sm.OLS(df.weight ** (1/3), X2)\n",
    "model3 = sm.OLS(df.weight ** (1/3), X3)\n",
    "results1 = model1.fit()\n",
    "results2 = model2.fit()\n",
    "results3 = model3.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=2.0, fit_intercept=False, normalize = True)\n",
    "model.fit(X2, df.weight ** (1/3))\n",
    "# model.fit(X2 ** 3, df.weight)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(results.resid)), np.percentile(np.abs(results.resid), 99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['width2'] = ((df['width'] * .5) ** 2 * df['length']) ** (1/3)\n",
    "\n",
    "X1 = df[['length', 'length2', 'length3', 'length4']]\n",
    "X2 = df[['length2']]\n",
    "X3 = df[['length3']]\n",
    "X4 = df[['length4']]\n",
    "# X3 = df[['length', 'length2']]\n",
    "model1 = sm.OLS(df.weight ** (1/3), X1)\n",
    "model2 = sm.OLS(df.weight ** (1/3), X2)\n",
    "model3 = sm.OLS(df.weight ** (1/3), X3)\n",
    "model4 = sm.OLS(df.weight ** (1/3), X4)\n",
    "results1 = model1.fit()\n",
    "results2 = model2.fit()\n",
    "results3 = model3.fit()\n",
    "results4 = model4.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = np.abs(df.weight - results1.predict(X1) ** 3)\n",
    "df['diff1'] = diff1\n",
    "np.mean(diff1), np.percentile(diff1, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = np.abs(df.weight - results2.predict(X2) ** 3)\n",
    "df['diff2'] = diff2\n",
    "\n",
    "np.mean(diff2), np.percentile(diff2, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff2 = np.abs(df.weight - model.predict(X2) ** 3)\n",
    "\n",
    "# np.mean(diff2), np.percentile(diff2, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff3 = np.abs(df.weight - results3.predict(X3) ** 3)\n",
    "df['diff3'] = diff3\n",
    "\n",
    "np.mean(diff3), np.percentile(diff3, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff4 = np.abs(df.weight - results4.predict(X4) ** 3)\n",
    "df['diff4'] = diff4\n",
    "\n",
    "np.mean(diff4), np.percentile(diff4, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(diff3 > 1000) | (diff3 < 0)].groupby(['fish_id']).size().reset_index(name='count').sort_values(['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.predict([.805, .22]) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.fish_id == '190710-2dcdda0c-502d-4bfc-9ce4-6ebb343e3f52']\n",
    "df2 = df2.sort_values(['diff3'])\n",
    "# df2['diff'] = df2.weight - results.predict(df2[['length', 'width']]) ** 3\n",
    "# df2[df2.diff1 < 500].head()\n",
    "df2.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_crops(left_image_f, right_image_f, ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    left_ann, right_ann = ann['leftCrop'], ann['rightCrop']\n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in left_ann}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in right_ann}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df2.loc[9535]\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = ast.literal_eval(row.keypoints), ast.literal_eval(row.camera_metadata)\n",
    "wkps1 = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wkps1['EYE'], wkps1['TAIL_NOTCH'], np.linalg.norm(wkps1['EYE'] - wkps1['TAIL_NOTCH']))\n",
    "print(wkps2['EYE'], wkps2['TAIL_NOTCH'], np.linalg.norm(wkps2['EYE'] - wkps2['TAIL_NOTCH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df2.loc[9535]\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = ast.literal_eval(row.modified_keypoints), ast.literal_eval(row.camera_metadata)\n",
    "wkps2 = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "row = df2.iloc[0]\n",
    "# left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "# print(left_crop_url)\n",
    "# print(right_crop_url)\n",
    "left_crop_url, right_crop_url = 'left_frame.jpg', 'right_frame.jpg'\n",
    "\n",
    "\n",
    "# left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "# right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "# ann, cm = ast.literal_eval(row.keypoints), ast.literal_eval(row.camera_metadata)\n",
    "modified_ann = generate_refined_keypoints(ann, left_crop_url, right_crop_url)\n",
    "wkps = pixel2world(modified_ann['leftCrop'], modified_ann['rightCrop'], cm)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "\n",
    "print(total)\n",
    "\n",
    "# display_crops(left_crop_url, right_crop_url, modified_ann, True, True)\n",
    "# display_crops(left_crop_url, right_crop_url, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df2.iloc[-1]\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = ast.literal_eval(row.keypoints), ast.literal_eval(row.camera_metadata)\n",
    "modified_ann = generate_refined_keypoints(ann, left_crop_url, right_crop_url)\n",
    "wkps = pixel2world(modified_ann['leftCrop'], modified_ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, modified_ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row = df2.iloc[-1]\n",
    "left_crop_url, right_crop_url = row.left_image_url, row.right_image_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "ann, cm = ast.literal_eval(row.keypoints), ast.literal_eval(row.camera_metadata)\n",
    "wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "\n",
    "\n",
    "display_crops(left_crop_f, right_crop_f, ann, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kp in wkps:\n",
    "    print(kp, wkps[kp][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df2.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df2.weight, results.predict(df2[['length', 'width']]) ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.weight, results.predict(X) ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "# plt.scatter(df.weight, results2.predict(X2) ** 3, color = 'red')\n",
    "plt.scatter(df.weight, results3.predict(X3) ** 3, color = 'red')\n",
    "plt.scatter(df.weight, results4.predict(X4) ** 3, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(df.weight, results.predict(X) ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 60\n",
    "df_start_date = '2020-08-24'\n",
    "df_end_date = '2020-08-26'\n",
    "# pen_id = 116\n",
    "# df_start_date = '2020-10-26'\n",
    "# df_end_date = '2020-10-30'\n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df = extract_biomass_data(pen_id, df_start_date, df_end_date, 0)\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "\n",
    "    depths = []\n",
    "    lengths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "        depths.append(depth)\n",
    "        lengths.append(np.linalg.norm(vector))\n",
    "    df['depth'] = depths\n",
    "    df['length'] = lengths\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.akpd_score > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.scatter(df.length, df.estimated_weight_g)\n",
    "\n",
    "x = np.arange(np.min(df.length), np.max(df.length), 0.01)\n",
    "x2 = np.arange(np.min(df.length), np.max(df.length) + 0.05, 0.01)\n",
    "y = (23.6068 * x) ** 3\n",
    "plt.plot(x, y, color = 'red')\n",
    "y = (22 * x2) ** 3\n",
    "plt.plot(x2, y, color = 'green')\n",
    "y = (25 * x) ** 3\n",
    "plt.plot(x, y, color = 'orange')\n",
    "plt.axhline(9000)\n",
    "plt.xlabel('Length (m)')\n",
    "plt.ylabel('Weight (g)')\n",
    "plt.title('Slapoya Length vs Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[((df.hour >= 7) & (df.hour <= 15))].copy()\n",
    "df3 = df[((df.hour >= 7) & (df.hour <= 15))].copy()\n",
    "a = df3[df3.estimated_weight_g >= 5000].estimated_weight_g\n",
    "b = (23.6068 * df3[df3.estimated_weight_g < 5000].length) ** 3\n",
    "print(np.mean(df2.estimated_weight_g), np.mean(df3.estimated_weight_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((23.6068 * df2.length) ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean(a) * len(a) + np.mean(b) * len(b)) / (len(a) + len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
