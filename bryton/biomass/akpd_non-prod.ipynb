{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKPD Non-Production Interface\n",
    "import boto3\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "\n",
    "# load config\n",
    "import json\n",
    "\n",
    "#config_path = '/root/data/bati/model/config.json' \n",
    "config_path = '/root/data/bati/model/config_bak.json'\n",
    "#checkpoint_path = '/root/data/bati/model/model.pb'\n",
    "checkpoint_path = '/root/data/bati/model/model_20.pb'\n",
    "config = json.load(open(config_path))\n",
    "\n",
    "class FLAGS(object):\n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    stages = config[\"cpm_stages\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    crop = config[\"crop\"]\n",
    "    augmentation = None\n",
    "    \n",
    "import csv\n",
    "# with open('/root/data/depth_values_gt_eye_depth.csv') as csv_file:\n",
    "with open('/root/data/yolo_matches.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(row)\n",
    "#             imL=data[i][0]\n",
    "#             imR=data[i][1]\n",
    "#             lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "#             rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "#             meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "#             gtdata=json.loads(data[i][6].replace(\"'\", '\"'))\n",
    "            data.append([row[4],row[5],row[6],row[7],row[8]])\n",
    "            # data.append([row[50],row[51],row[52],row[53],row[54],row[64],row[43]])\n",
    "            line_count += 1\n",
    "#     print(line_count)\n",
    "\n",
    "# imL=data[i][0]                                      # 17\n",
    "# imR=data[i][1]                                      # 5\n",
    "# lco=json.loads(data[i][2].replace(\"'\", '\"'))        # 6\n",
    "# rco=json.loads(data[i][3].replace(\"'\", '\"'))        # 7\n",
    "# meta=json.loads(data[i][4].replace(\"'\", '\"'))       # 8\n",
    "# gtdata=json.loads(data[i][6].replace(\"'\", '\"'))     # \n",
    "# gtkeypointsL = load_gt_keypoints(FLAGS, lco['x_coord'], lco['y_coord'], gtdata, True)\n",
    "# gtkeypointsR = load_gt_keypoints(FLAGS, rco['x_coord'], rco['y_coord'], gtdata, False)\n",
    "\n",
    "client = boto3.client(\"sagemaker-runtime\", region_name=\"eu-west-1\", aws_access_key_id=\"AKIAUFQLGRHU7YGONOQO\", aws_secret_access_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-production research code evaluation\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "# from models.nets import fish_test\n",
    "# from utils import cpm_utils\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "config_path = '/root/data/bati/model/config_bak.json' # config_4_stage.json # config_bak.json (for deployed May model) # config.json (for all data Sept)\n",
    "checkpoint_path = '/root/data/bati/model/model_20.pb' # all-hi-res=model_49.pb #fish_test-6' #model_6.pb' # 25/199 for Sept all # 99 for Sept # model_20 for May\n",
    "pca_model_path = '/root/data/bati/model/model.pkl' \n",
    "biomass_out_path = '/root/data/bati/model/biomass.csv'\n",
    "\n",
    "config = json.load(open(config_path))\n",
    "print(config)\n",
    "\n",
    "class FLAGS(object):\n",
    "    stages = 3\n",
    "    crop = False    \n",
    "    input_size = tuple(config[\"input_size\"])\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    joints = config[\"num_of_joints\"]\n",
    "    model_path = checkpoint_path\n",
    "    cmap_radius = config[\"center_radius\"]\n",
    "    keypoints_order = config[\"keypoints_order\"]\n",
    "    normalize = config[\"normalize\"]\n",
    "    heatmap_size = config[\"heatmap_size\"]\n",
    "    joint_gaussian_variance = config[\"joint_gaussian_variance\"]\n",
    "    augmentation = None\n",
    "    \n",
    "def load_pb(path_to_pb):\n",
    "    with tf.io.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, input_map=None,\n",
    "                                return_elements=None,\n",
    "                                name=\"\",\n",
    "                                op_dict=None,\n",
    "                                producer_op_list=None)\n",
    "        graph_nodes=[n for n in graph_def.node]\n",
    "        for t in graph_nodes:\n",
    "            print(t.name)\n",
    "        return graph\n",
    "\n",
    "mod=load_pb(checkpoint_path)\n",
    "print(mod)\n",
    "print(checkpoint_path)\n",
    "\n",
    "with open(pca_model_path, \"rb\") as f:\n",
    "    pca_model = pickle.load(f)\n",
    "    \n",
    "# print(pca_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def image_resize(image, FLAGS):\n",
    "    height, width, _ = image.shape\n",
    "    ratio_width = width / FLAGS.input_size[0]\n",
    "    ratio_height = height / FLAGS.input_size[1]\n",
    "    image = cv2.resize(image, FLAGS.input_size)\n",
    "    image  = image / 255.0 - 0.5\n",
    "    image = image[np.newaxis, ...]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "sess.graph.as_default()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "tf_device = '/gpu:0'\n",
    "with tf.device(tf_device):\n",
    "    model = mod\n",
    "\n",
    "print(model)\n",
    "print(FLAGS.model_path)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from utils.utils import DataGenerator, load_image_keypoints\n",
    "\n",
    "\n",
    "\n",
    "def load_gt_keypoints(FLAGS, xoff, yoff, gtdata, left):\n",
    "    \"\"\"from gt load keypoints\"\"\"\n",
    "    gtkeypoints = []\n",
    "    for i in range(FLAGS.joints):\n",
    "        for j in range(FLAGS.joints):\n",
    "            if left==True and FLAGS.keypoints_order[i]==gtdata['leftCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['leftCrop'][j]['xFrame']\n",
    "                valueY = gtdata['leftCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "            elif left==False and FLAGS.keypoints_order[i]==gtdata['rightCrop'][j]['keypointType']:\n",
    "                valueX = gtdata['rightCrop'][j]['xFrame']\n",
    "                valueY = gtdata['rightCrop'][j]['yFrame']\n",
    "                gtkeypoints.append([int(valueX-xoff), int(valueY-yoff)]) \n",
    "                break\n",
    "    gtkeypoints = np.array(gtkeypoints) \n",
    "    return gtkeypoints\n",
    "\n",
    "def enhance(image, clip_limit=5):\n",
    "    # convert image to LAB color model\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # split the image into L, A, and B channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "    # apply CLAHE to lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    merged_channels = cv2.merge((cl, a_channel, b_channel))\n",
    "\n",
    "    # convert image from LAB color model back to RGB color model\n",
    "    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)\n",
    "    return final_image \n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, matchesMask, color=None, drawFeatures=True): \n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    if drawFeatures==False:\n",
    "        return new_img\n",
    "\n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 15\n",
    "    thickness = 3\n",
    "    if color:\n",
    "        c = color\n",
    "    i=0\n",
    "    for m in matches:\n",
    "        i=i+1\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = tuple([int(x) for x in c])        \n",
    "        if matchesMask[i-1]==0: \n",
    "            continue\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img\n",
    "\n",
    "def coord2biomass(world_keypoints, model):\n",
    "    \"\"\"from coordinates to biomass\"\"\"\n",
    "\n",
    "    mean = model['mean']\n",
    "    std= model['std']\n",
    "    PCA_components = model['PCA_components']\n",
    "    reg_coef = model['reg_coef']\n",
    "    reg_intercept = model['reg_intercept']\n",
    "    body_parts = model['body_parts']\n",
    "    # calculate pairwise distances for production coord\n",
    "    # based on the exact ordering reflected in the body_parts\n",
    "    # variable above\n",
    "\n",
    "    pairwise_distances = []\n",
    "    for i in range(len(body_parts)-1):\n",
    "        for j in range(i+1, len(body_parts)):\n",
    "            dist = euclidean_distance(world_keypoints[body_parts[i]], world_keypoints[body_parts[j]])\n",
    "            pairwise_distances.append(dist)\n",
    "\n",
    "    interaction_values_quadratic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            dist1 = pairwise_distances[i]\n",
    "            dist2 = pairwise_distances[j]\n",
    "            interaction_values_quadratic.append(dist1 * dist2)\n",
    "\n",
    "    interaction_values_cubic = []\n",
    "    for i in range(len(pairwise_distances)):\n",
    "        for j in range(i, len(pairwise_distances)):\n",
    "            for k in range(j, len(pairwise_distances)):\n",
    "                dist1 = pairwise_distances[i]\n",
    "                dist2 = pairwise_distances[j]\n",
    "                dist3 = pairwise_distances[k]\n",
    "                interaction_values_cubic.append(dist1 * dist2 * dist3)\n",
    "\n",
    "\n",
    "    X = np.array(pairwise_distances + interaction_values_quadratic + interaction_values_cubic)\n",
    "\n",
    "    X_normalized = (X - model['mean']) / model['std']\n",
    "    X_transformed = np.dot(X_normalized, model['PCA_components'].T)\n",
    "    prediction = np.dot(X_transformed, reg_coef) + reg_intercept\n",
    "    return prediction\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stage_heatmapL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "GOOD_PERC = 0.7\n",
    "sift = cv2.KAZE_create()\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "    \n",
    "config['input_name']='input_placeholder:0'\n",
    "config['output_name']='stage_3/mid_conv7/BiasAdd:0'\n",
    "\n",
    "np3_sum=0\n",
    "np3_results=[]\n",
    "np3_kps_all=[]\n",
    "np3_est_depth=[]\n",
    "np3_mean_dists=[]\n",
    "np3_ind_dists=[[] for i in range(FLAGS.joints)]\n",
    "np3_biomass=[]\n",
    "for i in range(10): #len(data)):\n",
    "    imL=data[i][0]\n",
    "    imR=data[i][1]\n",
    "    lco=json.loads(data[i][2].replace(\"'\", '\"'))\n",
    "    rco=json.loads(data[i][3].replace(\"'\", '\"'))\n",
    "    meta=json.loads(data[i][4].replace(\"'\", '\"'))\n",
    "#     gtdata=json.loads(data[i][6].replace(\"'\", '\"'))\n",
    "#     gtkeypointsL = load_gt_keypoints(FLAGS, lco['x_coord'], lco['y_coord'], gtdata, True)\n",
    "#     gtkeypointsR = load_gt_keypoints(FLAGS, rco['x_coord'], rco['y_coord'], gtdata, False)\n",
    "\n",
    "    imageL = url_to_image(imL)\n",
    "    heightL, widthL, _ = imageL.shape\n",
    "    img_input = image_resize(imageL, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapL = predict_heatmap.squeeze()\n",
    "    \n",
    "    imageR = url_to_image(imR)\n",
    "    heightR, widthR, _ = imageR.shape\n",
    "    img_input = image_resize(imageR, FLAGS)\n",
    "    with tf.compat.v1.Session(graph=model) as sess, tf.device(tf_device):\n",
    "        predict_heatmap = sess.run(config['output_name'], feed_dict = {config['input_name']: img_input})\n",
    "    final_stage_heatmapR = predict_heatmap.squeeze()\n",
    "    \n",
    "    # SIFT matching\n",
    "    img1 = enhance(imageL)\n",
    "    img2 = enhance(imageR)\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < GOOD_PERC*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>=MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "    \n",
    "#     img3 = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,False)\n",
    "#     img3o = draw_matches(img1,kp1,img2,kp2,good,matchesMask,matchColor,True)\n",
    "#     alpha = 0.3  # Transparency factor.\n",
    "#     img3 = cv2.addWeighted(img3o, alpha, img3, 1 - alpha, 0)\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(img3)\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    " \n",
    "    man_dists=[]\n",
    "    kpL = []\n",
    "    kpR = []    \n",
    "    kpL2R = []\n",
    "    kpR2L = [] \n",
    "    im1ps = []\n",
    "    im2ps = []\n",
    "    gtL2R = []\n",
    "    gtR2L = [] \n",
    "    gt1ps = []\n",
    "    gt2ps = []\n",
    "    Hx=M\n",
    "    Hy=np.linalg.inv(M)\n",
    "    for c in range(FLAGS.joints):\n",
    "        hm = cv2.resize(final_stage_heatmapL[..., c], (widthL, heightL))\n",
    "        hm_maxL = list(np.where(hm == hm.max()))   \n",
    "        kpL.append([int(hm_maxL[1][0]), int(hm_maxL[0][0])]) \n",
    "        ptx=np.array([kpL[c][0],kpL[c][1],1])\n",
    "        zx=np.dot(Hx,ptx)\n",
    "        kpL2R.append([int(zx[0]/zx[2]), int(zx[1]/zx[2])]) \n",
    "        gtx=np.array([gtkeypointsL[c][0],gtkeypointsL[c][1],1])\n",
    "        gzx=np.dot(Hx,gtx)\n",
    "        gtL2R.append([int(gzx[0]/gzx[2]), int(gzx[1]/gzx[2])]) \n",
    "        hm = cv2.resize(final_stage_heatmapR[..., c], (widthR, heightR))\n",
    "        hm_maxR = np.where(hm == hm.max())\n",
    "        kpR.append([int(hm_maxR[1][0]), int(hm_maxR[0][0])])\n",
    "        pty=np.array([kpR[c][0],kpR[c][1],1])\n",
    "        zy=np.dot(Hy,pty)\n",
    "        kpR2L.append([int(zy[0]/zy[2]), int(zy[1]/zy[2])]) \n",
    "        gty=np.array([gtkeypointsR[c][0],gtkeypointsR[c][1],1])\n",
    "        gzy=np.dot(Hy,gty)\n",
    "        gtR2L.append([int(gzy[0]/gzy[2]), int(gzy[1]/gzy[2])])\n",
    "    \n",
    "        im1ps.append([int((kpL[c][0]+kpR2L[c][0])/2), int((kpL[c][1]+kpR2L[c][1])/2)]) \n",
    "        im2ps.append([int((kpR[c][0]+kpL2R[c][0])/2), int((kpR[c][1]+kpL2R[c][1])/2)]) \n",
    "        gt1ps.append([int((gtkeypointsL[c][0]+gtR2L[c][0])/2), int((gtkeypointsL[c][1]+kpR2L[c][1])/2)]) \n",
    "        gt2ps.append([int((gtkeypointsR[c][0]+gtL2R[c][0])/2), int((gtkeypointsR[c][1]+gtL2R[c][1])/2)]) \n",
    "        man_distL = np.sqrt(pow(im1ps[c][0] - gt1ps[c][0],2) + pow(im1ps[c][1] - gt1ps[c][1],2))\n",
    "        man_dists.append(man_distL)\n",
    "        # print(\"Left crop Manhattan distance between pred and gt {} for {}\".format(man_distL, FLAGS.keypoints_order[c]))\n",
    "        man_distR = np.sqrt(pow(im2ps[c][0] - gt2ps[c][0],2) + pow(im2ps[c][1] - gt2ps[c][1],2))\n",
    "        man_dists.append(man_distR)\n",
    "        # print(\"Right crop Manhattan distance between pred and gt {} for {}\".format(man_distR, FLAGS.keypoints_order[c]))\n",
    "        np3_ind_dists[c].append((man_distL+man_distR)/2)  \n",
    "    \n",
    "    np3_mean_dists.append(np.mean(man_dists))\n",
    "    kpL = np.array(kpL) \n",
    "    kpR = np.array(kpR) \n",
    "    kpL2R = np.array(kpL2R) \n",
    "    kpR2L = np.array(kpR2L)\n",
    "    im1ps = np.array(im1ps)\n",
    "    im2ps = np.array(im2ps)\n",
    "    gt1ps = np.array(gt1ps)\n",
    "    gt2ps = np.array(gt2ps)\n",
    "    \n",
    "    kpsL=[];\n",
    "    kpsR=[];\n",
    "    for c in range(FLAGS.joints):\n",
    "        kpsiL={}\n",
    "        kpsiL['xCrop']=im1ps[c,0]\n",
    "        kpsiL['yCrop']=im1ps[c,1]\n",
    "        kpsiL['xFrame']=im1ps[c,0]+lco['x_coord']\n",
    "        kpsiL['yFrame']=im1ps[c,1]+lco['y_coord']\n",
    "        kpsiL['keypointType']=FLAGS.keypoints_order[c]\n",
    "        kpsL.append(kpsiL)\n",
    "        kpsiR={}\n",
    "        kpsiR['xCrop']=im2ps[c,0]\n",
    "        kpsiR['yCrop']=im2ps[c,1]\n",
    "        kpsiR['xFrame']=im2ps[c,0]+rco['x_coord']\n",
    "        kpsiR['yFrame']=im2ps[c,1]+rco['y_coord']\n",
    "        kpsiR['keypointType']=FLAGS.keypoints_order[c]\n",
    "        kpsR.append(kpsiR)\n",
    "\n",
    "    wp=pixel2world(kpsL, kpsR, meta)\n",
    "    biomass = coord2biomass(wp, pca_model)\n",
    "    np3_biomass.append(biomass)\n",
    "\n",
    "    print(\"Mean error for frame {} of {} is {} with biomass {}\".format(i, len(data), np3_mean_dists[i], np3_biomass[i]))\n",
    "    \n",
    "#     height, width, _ = imageL.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(imageL)\n",
    "#     plt.scatter(gt1ps[:, 0], gt1ps[:, 1], c=\"b\")\n",
    "#     plt.scatter(im1ps[:, 0], im1ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     height, width, _ = imageR.shape\n",
    "#     f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "#     ax.imshow(imageR)\n",
    "#     plt.scatter(gt2ps[:, 0], gt2ps[:, 1], c=\"b\")\n",
    "#     plt.scatter(im2ps[:, 0], im2ps[:, 1], c=\"r\")\n",
    "#     ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     body='[{\"leftCropUrl\": \"'+imL+'\", \"rightCropUrl\": \"'+imR+'\", \"leftCropMetadata\": {\"x_coord\": '+str(lco['x_coord'])+', \"y_coord\": '+str(lco['y_coord'])+'}, \"rightCropMetadata\": {\"x_coord\": '+str(rco['x_coord'])+', \"y_coord\": '+str(rco['x_coord'])+'}, \"id\": \"1\"}]'\n",
    "#     resp = client.invoke_endpoint(EndpointName='auto-keypoints', ContentType='application/json', Body=body)\n",
    "#     kp=resp['Body'].read()\n",
    "#     kps=json.loads(kp.decode(\"utf-8\"))\n",
    "#     wp=pixel2world(kps[0]['leftCrop'], kps[0]['rightCrop'], meta)\n",
    "#     diff=abs(float(data[i][5])-float(wp['EYE'][1]))\n",
    "\n",
    "print(\"Mean error for all data is {}\".format(np.mean(np3_mean_dists)))\n",
    "np.savetxt(biomass_out_path, np3_biomass, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Manhattan error for all data is {} and median is {}\".format(np.mean(np3_mean_dists),np.median(np3_mean_dists)))\n",
    "plt.hist(np.array(np3_mean_dists),bins=100)\n",
    "plt.show()\n",
    "for i in range(FLAGS.joints):\n",
    "    plt.hist(np.array(np3_ind_dists[i]),bins=100)\n",
    "    print(\"Error distribution for {}\".format(FLAGS.keypoints_order[i]))\n",
    "    plt.show()\n",
    "    \n",
    "np.savetxt(biomass_out_path, np3_biomass, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, _ = imageL.shape\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(imageL)\n",
    "plt.scatter(gt1ps[:, 0], gt1ps[:, 1], c=\"b\")\n",
    "plt.scatter(im1ps[:, 0], im1ps[:, 1], c=\"r\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "height, width, _ = imageR.shape\n",
    "f, ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(imageR)\n",
    "plt.scatter(gt2ps[:, 0], gt2ps[:, 1], c=\"b\")\n",
    "plt.scatter(im2ps[:, 0], im2ps[:, 1], c=\"r\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#{'yFrame': 845, 'xCrop': 93, 'keypointType': 'TAIL_NOTCH', 'xFrame': 1450, 'yCrop': 471}\n",
    "kpsL=[];\n",
    "kpsR=[];\n",
    "for c in range(FLAGS.joints):\n",
    "    kpsiL={}\n",
    "    kpsiL['xCrop']=im1ps[c,0]\n",
    "    kpsiL['yCrop']=im1ps[c,1]\n",
    "    kpsiL['xFrame']=im1ps[c,0]+lco['x_coord']\n",
    "    kpsiL['yFrame']=im1ps[c,1]+lco['y_coord']\n",
    "    kpsiL['keypointType']=FLAGS.keypoints_order[c]\n",
    "    kpsL.append(kpsiL)\n",
    "    kpsiR={}\n",
    "    kpsiR['xCrop']=im2ps[c,0]\n",
    "    kpsiR['yCrop']=im2ps[c,1]\n",
    "    kpsiR['xFrame']=im2ps[c,0]+rco['x_coord']\n",
    "    kpsiR['yFrame']=im2ps[c,1]+rco['y_coord']\n",
    "    kpsiR['keypointType']=FLAGS.keypoints_order[c]\n",
    "    kpsR.append(kpsiR)\n",
    "    \n",
    "print(kpsL)\n",
    "print(kpsR)\n",
    "print(meta)\n",
    "wp=pixel2world(kpsL, kpsR, meta)\n",
    "print(wp)\n",
    "biomass = coord2biomass(wp, pca_model)\n",
    "print(biomass)\n",
    "#     diff=abs(float(data[i][5])-float(wp['EYE'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
