{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "from report_generation.report_generator import generate_ts_data, SamplingFilter\n",
    "from research.utils.datetime_utils import add_days\n",
    "from report_generation.report_generator import gen_pm_base\n",
    "from population_metrics.smart_metrics import generate_smart_avg_weight, generate_smart_individual_values, ValidationError\n",
    "from filter_optimization.filter_optimization_task import _add_date_hour_columns\n",
    "from research.weight_estimation.keypoint_utils.optics import pixel2world\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_names = [\n",
    "    'aplavika_pen_id_95_2020-07-10_2020-07-26',\n",
    "    'bolaks_pen_id_88_2020-02-28_2020-03-10',\n",
    "    'dale_pen_id_143_2020-10-07_2020-10-21',\n",
    "    'djubawik_pen_id_153_2020-11-10_2020-11-26',\n",
    "    'eldviktaren_pen_id_164_2020-09-21_2020-10-08',\n",
    "    'langoy_pen_id_108_2020-05-07_2020-05-17',\n",
    "    'leivsethamran_pen_id_165_2020-10-18_2020-11-13',\n",
    "    'movikodden_pen_id_114_2020-11-03_2020-11-25',\n",
    "    'movikodden_pen_id_167_2020-10-13_2020-10-30',\n",
    "    'seglberget_pen_id_66_2020-05-13_2020-06-13',\n",
    "    'silda_pen_id_86_2020-07-02_2020-07-19',\n",
    "    'slapoya_pen_id_116_2020-10-18_2020-11-08',\n",
    "    'tittelsnes_pen_id_37_2020-06-10_2020-06-24',\n",
    "    'varholmen_pen_id_131_2020-08-15_2020-08-30',\n",
    "    'varholmen_pen_id_151_2020-10-02_2020-10-17',\n",
    "    'varholmen_pen_id_186_2020-10-18_2020-11-02',\n",
    "    'vikane_pen_id_60_2020-08-10_2020-08-30',\n",
    "#     'kjeppevikholmen_pen_id_5_2019-06-18_2019-07-02',\n",
    "#     'habranden_pen_id_100_2020-08-10_2020-08-31'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = 'test'\n",
    "\n",
    "ROOT_DIR = '/root/data/alok/biomass_estimation/playground'\n",
    "dfs, gt_metadatas = {}, {}\n",
    "for cohort_name in cohort_names:\n",
    "    s3_dir = os.path.join(\n",
    "        'https://aquabyte-images-adhoc.s3-eu-west-1.amazonaws.com/alok/production_datasets',\n",
    "        cohort_name\n",
    "    )\n",
    "\n",
    "    ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata.json')\n",
    "    ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata.json')\n",
    "#     ground_truth_metadata_url = os.path.join(s3_dir, 'ground_truth_metadata_validated.json')\n",
    "#     ground_truth_key_base = os.path.join(batch_name, cohort_name, 'ground_truth_metadata_validated.json')\n",
    "    ground_truth_f = os.path.join(ROOT_DIR, ground_truth_key_base)\n",
    "    print(ground_truth_metadata_url)\n",
    "    s3.download_from_url(ground_truth_metadata_url, custom_location=ground_truth_f)\n",
    "    gt_metadata = json.load(open(ground_truth_f))\n",
    "    gt_metadatas[cohort_name] = gt_metadata\n",
    "    \n",
    "    data_url = os.path.join(s3_dir, 'annotation_dataset.csv')\n",
    "    data_f, _, _= s3.download_from_url(data_url)\n",
    "    df = pd.read_csv(data_f)\n",
    "    df = _add_date_hour_columns(df)\n",
    "    dfs[cohort_name] = df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_metadatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Generate average weight accuracy </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raw_individual_values(pm_base, gt_metadata, start_hour, end_hour, apply_growth_rate, max_day_diff, days_post_feeding, final_days_post_feeding):\n",
    "    last_feeding_date = gt_metadata['last_feeding_date']\n",
    "    date = add_days(last_feeding_date, days_post_feeding)\n",
    "    weights, _ = generate_smart_individual_values(pm_base, date, max_day_diff, True, apply_growth_rate, 0.9)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def generate_average_weight_accuracy(weights, gt_metadata, loss_factor):\n",
    "    avg_weight_prediction = np.mean(weights)\n",
    "    gutted_weight_prediction = avg_weight_prediction * (1.0 - loss_factor)\n",
    "    gt_weight = gt_metadata['gutted_average_weight']\n",
    "    avg_weight_err = (gutted_weight_prediction - gt_weight) / gt_weight\n",
    "    return avg_weight_err\n",
    "\n",
    "def generate_distribution_accuracy(weights, gt_metadata, loss_factor):\n",
    "    gutted_weights = weights * (1.0 - loss_factor)\n",
    "    gutted_weight_distribution = gt_metadata['gutted_weight_distribution']\n",
    "    \n",
    "    if gutted_weight_distribution is None:\n",
    "        return []\n",
    "    \n",
    "    count_distribution_errors = []\n",
    "    \n",
    "    for bucket in gutted_weight_distribution:\n",
    "        lower_bound, upper_bound = bucket.split('-')\n",
    "        pct = gutted_weight_distribution[bucket]\n",
    "        mask = (gutted_weights >= float(lower_bound) * 1000) & (gutted_weights < float(upper_bound) * 1000)\n",
    "\n",
    "        pct = np.sum(mask) / len(mask)\n",
    "        gt_pct = gutted_weight_distribution[bucket] / 100\n",
    "        \n",
    "        count_distribution_errors.append(pct - gt_pct)\n",
    "        \n",
    "    return count_distribution_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hours = [7]\n",
    "end_hours = [15]\n",
    "apply_growth_rate = True\n",
    "max_day_diff = 3\n",
    "days_post_feeding = 1\n",
    "final_days_post_feeding = 3\n",
    "loss_factors = [0.14, 0.16] # need to determine the right values here\n",
    "\n",
    "cohort_name_col = []\n",
    "start_hour_col = []\n",
    "end_hour_col = []\n",
    "loss_factor_col = []\n",
    "avg_weight_error_col = []\n",
    "count_distribution_error_col = []\n",
    "\n",
    "for loss_factor in loss_factors:\n",
    "    avg_weight_error_col.append([])\n",
    "    count_distribution_error_col.append([])\n",
    "\n",
    "for cohort_name in sorted(list(dfs.keys())):\n",
    "    print(cohort_name)\n",
    "    gt_metadata = gt_metadatas[cohort_name]\n",
    "    for start_hour in start_hours:\n",
    "        for end_hour in end_hours:\n",
    "            sampling_filter = SamplingFilter(\n",
    "                start_hour=start_hour,\n",
    "                end_hour=end_hour,\n",
    "                kf_cutoff=0.0,\n",
    "                akpd_score_cutoff=0.95\n",
    "            )\n",
    "            df = dfs[cohort_name]\n",
    "            final_date_post_feeding = add_days(gt_metadata['last_feeding_date'], final_days_post_feeding)\n",
    "            tdf = df[df.date <= final_date_post_feeding]\n",
    "            pm_base = gen_pm_base(tdf, sampling_filter)\n",
    "            \n",
    "            try:\n",
    "                weights = generate_raw_individual_values(pm_base, gt_metadata, start_hour, end_hour, apply_growth_rate, max_day_diff, days_post_feeding, final_days_post_feeding)\n",
    "            except ValidationError as err:\n",
    "                continue\n",
    "            \n",
    "            cohort_name_col.append(cohort_name)\n",
    "            start_hour_col.append(start_hour)\n",
    "            end_hour_col.append(end_hour)\n",
    "            loss_factor_col.append(loss_factor)\n",
    "                   \n",
    "            for index, loss_factor in enumerate(loss_factors):\n",
    "                avg_weight_err = generate_average_weight_accuracy(weights, gt_metadata, loss_factor)\n",
    "                avg_weight_error_col[index].append(avg_weight_err)\n",
    "                \n",
    "                count_distribution_errors = generate_distribution_accuracy(weights, gt_metadata, loss_factor)\n",
    "                count_distribution_error_col[index].append(count_distribution_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'cohort_name': cohort_name_col,\n",
    "    'start_hour_col': start_hour_col,\n",
    "    'end_hour_col': end_hour_col\n",
    "}\n",
    "\n",
    "for index, loss_factor in enumerate(loss_factors):\n",
    "    col_name = 'avg_weight_error_%0.2f' % (loss_factor,)\n",
    "    col_abs_name = 'avg_weight_error_abs_%0.2f' % (loss_factor,)\n",
    "    columns[col_name] = avg_weight_error_col[index]\n",
    "    columns[col_abs_name] = np.abs(avg_weight_error_col[index])\n",
    "    \n",
    "    col_abs_name = 'avg_count_dist_error_abs_%0.2f' % (loss_factor,)\n",
    "    columns[col_abs_name] = [np.mean(np.abs(l)) for l in count_distribution_error_col[index]]\n",
    "\n",
    "tdf = pd.DataFrame(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "loss_factor = loss_factors[index]\n",
    "col_abs_name = 'avg_weight_error_abs_%0.2f' % (loss_factor,)\n",
    "error = tdf[col_abs_name]\n",
    "\n",
    "print('Loss factor', loss_factor)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Average Weight Error')\n",
    "print('Avg %0.1f' % (np.mean(error) * 100, ))\n",
    "print('90th Pct %0.1f' % (np.percentile(error, 90) * 100, ))\n",
    "print('Max %0.1f' % (np.max(error) * 100, ))\n",
    "\n",
    "print()\n",
    "\n",
    "dist_errors = [item for sublist in count_distribution_error_col[index] for item in sublist]\n",
    "\n",
    "print('Count Distribution Error')\n",
    "print('Avg %0.1f' % (np.mean(np.abs(dist_errors)) * 100, ))\n",
    "print('90th Pct %0.1f' % (np.percentile(np.abs(dist_errors), 90) * 100, ))\n",
    "print('Max %0.1f' % (np.max(np.abs(dist_errors)) * 100, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cohort_name in cohort_names:\n",
    "#     mask = tdf.cohort_name == cohort_name\n",
    "#     print(tdf[mask].sort_values('avg_weight_error_abs', ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_metadatas['vikane_pen_id_60_2020-08-05_2020-08-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.cohort_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.cohort_name == 'tittelsnes_pen_id_37_2020-05-23_2020-06-24') & (tdf.days_post_feeding == 1) & (tdf.final_days_post_feeding == 1) & (tdf.max_day_diff == 3) & (tdf.loss_factor == 0.17)\n",
    "tdf[mask].sort_values('avg_weight_error_abs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.start_hour_col == 6) & (tdf.days_post_feeding == 1) & (tdf.final_days_post_feeding == 1) & (tdf.max_day_diff == 3)\n",
    "tdf[mask].avg_weight_error_abs.median()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tdf.start_hour_col == 7) & (tdf.days_post_feeding == 1) & (tdf.final_days_post_feeding == 1) & (tdf.max_day_diff == 3)\n",
    "tdf[mask].avg_weight_error_abs.median()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_name_col = []\n",
    "start_hour_col = []\n",
    "end_hour_col = []\n",
    "apply_growth_rate_col = []\n",
    "max_day_diff_col = []\n",
    "days_post_feeding_col = []\n",
    "final_days_post_feeding_col = []\n",
    "loss_factor_col = []\n",
    "std_avg_weight_error_col = []\n",
    "abs_avg_weight_error_col = []\n",
    "mean_avg_weight_error_col = []\n",
    "\n",
    "for start_hour in start_hours:\n",
    "    for end_hour in end_hours:\n",
    "        for apply_growth_rate in apply_growth_rate_list:\n",
    "            for max_day_diff in max_day_diff_list:\n",
    "                for days_post_feeding in days_post_feeding_list:\n",
    "                    for final_days_post_feeding in final_days_post_feeding_list:\n",
    "                        for loss_factor in loss_factors:\n",
    "                            mask = (tdf.start_hour_col == start_hour) & \\\n",
    "                            (tdf.end_hour_col == end_hour) & \\\n",
    "                            (tdf.apply_growth_rate == apply_growth_rate) & \\\n",
    "                            (tdf.max_day_diff == max_day_diff) & \\\n",
    "                            (tdf.days_post_feeding == days_post_feeding) & \\\n",
    "                            (tdf.final_days_post_feeding == final_days_post_feeding) & \\\n",
    "                            (tdf.loss_factor == loss_factor)\n",
    "                            \n",
    "                            start_hour_col.append(start_hour)\n",
    "                            end_hour_col.append(end_hour)\n",
    "                            apply_growth_rate_col.append(apply_growth_rate)\n",
    "                            max_day_diff_col.append(max_day_diff)\n",
    "                            days_post_feeding_col.append(days_post_feeding)\n",
    "                            final_days_post_feeding_col.append(final_days_post_feeding)\n",
    "                            loss_factor_col.append(loss_factor)\n",
    "                            std_avg_weight_error_col.append(tdf[mask].avg_weight_error.std())\n",
    "                            abs_avg_weight_error_col.append(tdf[mask].avg_weight_error_abs.mean())\n",
    "                            mean_avg_weight_error_col.append(tdf[mask].avg_weight_error.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame({\n",
    "    'start_hour_col': start_hour_col,\n",
    "    'end_hour_col': end_hour_col,\n",
    "    'apply_growth_rate': apply_growth_rate_col,\n",
    "    'max_day_diff': max_day_diff_col,\n",
    "    'days_post_feeding': days_post_feeding_col,\n",
    "    'final_days_post_feeding': final_days_post_feeding_col,\n",
    "    'loss_factor': loss_factor_col,\n",
    "    'abs_avg_weight_error': abs_avg_weight_error_col,\n",
    "    'std_avg_weight_error': std_avg_weight_error_col,\n",
    "    'mean_avg_weight_error': mean_avg_weight_error_col,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (rdf.loss_factor == 0.16)\n",
    "rdf[mask].sort_values('abs_avg_weight_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv('/root/data/alok/biomass_estimation/playground/smart_average_param_grid_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[(tdf.cohort_name == 'bolaks_pen_id_88_2020-02-10_2020-03-10')].sort_values('avg_weight_error_abs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Vikane average weight and distribution error - explore basic parameters\n",
    "\n",
    "ground_truth_metadata = json.load(open(ground_truth_f))\n",
    "day_after_feeding_stop = add_days(ground_truth_metadata['last_feeding_date'], 1)\n",
    "start_date, end_date = add_days(day_after_feeding_stop, -2), add_days(day_after_feeding_stop, -1)\n",
    "tdf = df[(df.date >= start_date) & (df.date <= end_date)].copy(deep=True)\n",
    "\n",
    "sampling_filter = SamplingFilter(\n",
    "    start_hour=7,\n",
    "    end_hour=15,\n",
    "    akpd_score_cutoff=0.95,\n",
    "    kf_cutoff=0.0\n",
    ")\n",
    "pm_base = gen_pm_base(tdf, sampling_filter)\n",
    "weights, _ = generate_smart_individual_values(pm_base, day_after_feeding_stop, 3, True, True, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
