{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains constants representing core & auxiliary fish body parts.\n",
    "\"\"\"\n",
    "\n",
    "UPPER_LIP = 'UPPER_LIP'\n",
    "EYE = 'EYE'\n",
    "PECTORAL_FIN = 'PECTORAL_FIN'\n",
    "DORSAL_FIN = 'DORSAL_FIN'\n",
    "PELVIC_FIN = 'PELVIC_FIN'\n",
    "ADIPOSE_FIN = 'ADIPOSE_FIN'\n",
    "ANAL_FIN = 'ANAL_FIN'\n",
    "TAIL_NOTCH = 'TAIL_NOTCH'\n",
    "UPPER_PRECAUDAL_PIT = 'UPPER_PRECAUDAL_PIT'\n",
    "LOWER_PRECAUDAL_PIT = 'LOWER_PRECAUDAL_PIT'\n",
    "HYPURAL_PLATE = 'HYPURAL_PLATE'\n",
    "\n",
    "core_body_parts = sorted([UPPER_LIP,\n",
    "                          EYE,\n",
    "                          PECTORAL_FIN,\n",
    "                          DORSAL_FIN,\n",
    "                          PELVIC_FIN,\n",
    "                          ADIPOSE_FIN,\n",
    "                          ANAL_FIN,\n",
    "                          TAIL_NOTCH])\n",
    "\n",
    "auxiliary_body_parts = sorted([UPPER_PRECAUDAL_PIT,\n",
    "                               LOWER_PRECAUDAL_PIT,\n",
    "                               HYPURAL_PLATE])\n",
    "\n",
    "all_body_parts = sorted(core_body_parts + auxiliary_body_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module contains utility helper functions for the WeightEstimator class.\"\"\"\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "CameraMetadata = namedtuple('CameraMetadata',\n",
    "                            ['focal_length', 'focal_length_pixel', 'baseline_m',\n",
    "                             'pixel_count_width', 'pixel_count_height', 'image_sensor_width',\n",
    "                             'image_sensor_height'])\n",
    "\n",
    "\n",
    "def get_left_right_keypoint_arrs(annotation: Dict[str, List[Dict]]) -> Tuple:\n",
    "    \"\"\"Gets numpy array of left and right keypoints given input keypoint annotation.\n",
    "    Args:\n",
    "        annotation: dict with keys 'leftCrop' and 'rightCrop'. Values are lists where each element\n",
    "        is a dict with keys 'keypointType', 'xCrop' (num pixels from crop left edge),\n",
    "        'yCrop' (num pixels from crop top edge), 'xFrame' (num pixels from full frame left edge),\n",
    "        and 'yFrame' (num pixels from full frame top edge).\n",
    "    Returns:\n",
    "        X_left: numpy array containing left crop (xFrame, yFrame) for each key-point ordered\n",
    "        alphabetically.\n",
    "        X_right: same as above, but for right crop.\n",
    "    \"\"\"\n",
    "\n",
    "    left_keypoints, right_keypoints = {}, {}\n",
    "    for item in annotation['leftCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        left_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    for item in annotation['rightCrop']:\n",
    "        body_part = item['keypointType']\n",
    "        right_keypoints[body_part] = (item['xFrame'], item['yFrame'])\n",
    "\n",
    "    left_keypoint_arr, right_keypoint_arr = [], []\n",
    "    for body_part in core_body_parts:\n",
    "        left_keypoint_arr.append(left_keypoints[body_part])\n",
    "        right_keypoint_arr.append(right_keypoints[body_part])\n",
    "\n",
    "    X_left = np.array(left_keypoint_arr)\n",
    "    X_right = np.array(right_keypoint_arr)\n",
    "    return X_left, X_right\n",
    "\n",
    "\n",
    "def normalize_left_right_keypoint_arrs(X_left: np.ndarray, X_right: np.ndarray) -> Tuple:\n",
    "    \"\"\"Normalizes input left and right key-point arrays. The normalization involves (1) 2D\n",
    "    translation of all keypoints such that they are centered, (2) rotation of the 2D coordiantes\n",
    "    about the center such that the line passing through UPPER_LIP and fish center is horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    # translate key-points, perform reflection if necessary\n",
    "    upper_lip_idx = core_body_parts.index(UPPER_LIP)\n",
    "    tail_notch_idx = core_body_parts.index(TAIL_NOTCH)\n",
    "    if X_left[upper_lip_idx, 0] > X_left[tail_notch_idx, 0]:\n",
    "        X_center = 0.5 * (np.max(X_left, axis=0) + np.min(X_left, axis=0))\n",
    "        X_left_centered = X_left - X_center\n",
    "        X_right_centered = X_right - X_center\n",
    "    else:\n",
    "        X_center = 0.5 * (np.max(X_right, axis=0) + np.min(X_right, axis=0))\n",
    "        X_left_centered = X_right - X_center\n",
    "        X_right_centered = X_left - X_center\n",
    "        X_left_centered[:, 0] = -X_left_centered[:, 0]\n",
    "        X_right_centered[:, 0] = -X_right_centered[:, 0]\n",
    "\n",
    "    # rotate key-points\n",
    "    upper_lip_x, upper_lip_y = tuple(X_left_centered[upper_lip_idx])\n",
    "    theta = np.arctan(upper_lip_y / upper_lip_x)\n",
    "    R = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "    D = X_left_centered - X_right_centered\n",
    "    X_left_rot = np.dot(X_left_centered, R)\n",
    "    X_right_rot = X_left_rot - D\n",
    "    return X_left_rot, X_right_rot\n",
    "\n",
    "\n",
    "def convert_to_world_point_arr(X_left: np.ndarray, X_right: np.ndarray,\n",
    "                               camera_metadata: CameraMetadata) -> np.ndarray:\n",
    "    \"\"\"Converts input left and right normalized keypoint arrays into world coordinate array.\"\"\"\n",
    "\n",
    "    y_world = camera_metadata.focal_length_pixel * camera_metadata.baseline_m / \\\n",
    "              (X_left[:, 0] - X_right[:, 0])\n",
    "\n",
    "    # Note: the lines commented out below are technically the correct formula for conversion\n",
    "    # x_world = X_left[:, 0] * y_world / camera_metadata.focal_length_pixel\n",
    "    # z_world = -X_left[:, 1] * y_world / camera_metadata.focal_length_pixel\n",
    "    x_world = ((X_left[:, 0] * camera_metadata.image_sensor_width / camera_metadata.pixel_count_width) * y_world) / (camera_metadata.focal_length)\n",
    "    z_world = (-(X_left[:, 1] * camera_metadata.image_sensor_height / camera_metadata.pixel_count_height) * y_world) / (camera_metadata.focal_length)\n",
    "    X_world = np.vstack([x_world, y_world, z_world]).T\n",
    "    return X_world\n",
    "\n",
    "\n",
    "def stabilize_keypoints(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Transforms world coordinate array so that neural network inputs are stabilized\"\"\"\n",
    "    X_new = np.zeros(X.shape)\n",
    "    X_new[:, 0] = 0.5 * X[:, 0] / X[:, 1]\n",
    "    X_new[:, 1] = 0.5 * X[:, 2] / X[:, 1]\n",
    "    X_new[:, 2] = 0.05 / X[:, 1]\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def convert_to_nn_input(annotation: Dict[str, List[Dict]], camera_metadata: CameraMetadata) \\\n",
    "        -> torch.Tensor:\n",
    "    \"\"\"Convrts input keypoint annotation and camera metadata into neural network tensor input.\"\"\"\n",
    "    X_left, X_right = get_left_right_keypoint_arrs(annotation)\n",
    "    X_left_norm, X_right_norm = normalize_left_right_keypoint_arrs(X_left, X_right)\n",
    "    X_world = convert_to_world_point_arr(X_left_norm, X_right_norm, camera_metadata)\n",
    "    X = stabilize_keypoints(X_world)\n",
    "    nn_input = torch.from_numpy(np.array([X])).float()\n",
    "    return nn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the WeightEstimator class for estimating fish weight (g), length (mm), and\n",
    "k-factor given input keypoint coordinates and camera metadata.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \"\"\"Network class defines neural-network architecture for both weight and k-factor estimation\n",
    "    (currently both neural networks share identical architecture).\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(24, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run inference on input keypoint tensor.\"\"\"\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WeightEstimator:\n",
    "    \"\"\"WeightEstimator class is used to predict fish weight, k-factor, and length\n",
    "    given input keypoint annotations and camera metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, weight_model_f: str, kf_model_f: str) -> None:\n",
    "        \"\"\"Initializes class with input weight and k-factor neural-networks.\"\"\"\n",
    "        self.weight_model = Network()\n",
    "        self.weight_model.load_state_dict(torch.load(weight_model_f))\n",
    "        self.weight_model.eval()\n",
    "\n",
    "        self.kf_model = Network()\n",
    "        self.kf_model.load_state_dict(torch.load(kf_model_f))\n",
    "        self.kf_model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_model_input(annotation: Dict, camera_metadata: CameraMetadata) -> torch.Tensor:\n",
    "        \"\"\"Generates neural-network input tensor given annotation and camera_metadata.\"\"\"\n",
    "        X = convert_to_nn_input(annotation, camera_metadata)\n",
    "        return X\n",
    "\n",
    "    def predict_weight(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates weight prediction given input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        weight = 1e4 * self.weight_model(X).item()\n",
    "        return weight\n",
    "\n",
    "    def predict_kf(self, annotation: Dict, camera_metadata: CameraMetadata) -> float:\n",
    "        \"\"\"Generates k-factor prediction gievn input annotation and camera metadata.\"\"\"\n",
    "        X = self._get_model_input(annotation, camera_metadata)\n",
    "        kf = self.kf_model(X).item()\n",
    "        return kf\n",
    "\n",
    "    def predict(self, annotation: Dict, camera_metadata: CameraMetadata) -> Tuple:\n",
    "        \"\"\"Generates weight, k-factor, and length predictions given input annotation and camera\n",
    "        metadata.\"\"\"\n",
    "        weight = self.predict_weight(annotation, camera_metadata)\n",
    "        kf = self.predict_kf(annotation, camera_metadata)\n",
    "        if weight * kf > 0:\n",
    "            length = (1e5 * weight / kf) ** (1.0 / 3)\n",
    "        else:\n",
    "            length = 0\n",
    "        return weight, length, kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta, time\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import AutoDateFormatter, AutoDateLocator\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_params_f, _, _ = s3_access_utils.download_from_url(cm_old['stereoParametersUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPenDF(pen):\n",
    "    query = \"\"\"\n",
    "       SELECT * FROM prod.biomass_computations\n",
    "        WHERE prod.biomass_computations.captured_at >= '%s'\n",
    "        AND prod.biomass_computations.captured_at <= '%s'\n",
    "        AND prod.biomass_computations.group_id = '%s';\n",
    "    \"\"\" % (pen['start_date'], pen['end_date'], pen['group_id'])\n",
    "    \n",
    "    if query in queryCache:\n",
    "        df = queryCache[query].copy()\n",
    "    else:\n",
    "        df = rds_access_utils.extract_from_database(query)\n",
    "        queryCache[query] = df.copy()\n",
    "\n",
    "    df = df.sort_values('captured_at').copy(deep=True)\n",
    "    df.index = pd.to_datetime(df.captured_at)\n",
    "    dates = df.index.date.astype(str)\n",
    "    df['date'] = dates\n",
    "    df['hour'] = df.index.hour\n",
    "    \n",
    "    return df\n",
    "    \n",
    "pen1 = {\n",
    "    'group_id': '151',\n",
    "    'start_date': '2020-10-01',\n",
    "    'end_date': '2020-10-16'\n",
    "}\n",
    "\n",
    "pen2 = {\n",
    "    'group_id': '151-ENGALL-1455',\n",
    "    'start_date': '2020-10-01',\n",
    "    'end_date': '2020-10-16'\n",
    "}\n",
    "\n",
    "df1 = getPenDF(pen1)\n",
    "df2 = getPenDF(pen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_old = df1.iloc[0].camera_metadata\n",
    "cm_new = df2.iloc[0].camera_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_access_utils = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(params):\n",
    "    print(\"Loading params...\")\n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "\n",
    "    imageSize = (4096, 3000)\n",
    "\n",
    "    # perform rectification\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T, None, None, None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "\n",
    "    print(\"Params loaded.\")\n",
    "    return left_maps, right_maps\n",
    "\n",
    "IMAGE_WIDTH = 4096\n",
    "IMAGE_HEIGHT = 3000\n",
    "\n",
    "def get_camera_parameters(params: dict) -> Tuple:\n",
    "    \"\"\"Return individual camera parameters from JSON stereo parameters contents.\"\"\"\n",
    "    \n",
    "    cameraMatrix1 = np.array(params['CameraParameters1']['IntrinsicMatrix']).transpose()\n",
    "    cameraMatrix2 = np.array(params['CameraParameters2']['IntrinsicMatrix']).transpose()\n",
    "\n",
    "    distCoeffs1 = params['CameraParameters1']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters1']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters1']['RadialDistortion'][2]]\n",
    "    distCoeffs1 = np.array(distCoeffs1)\n",
    "\n",
    "    distCoeffs2 = params['CameraParameters2']['RadialDistortion'][0:2] + \\\n",
    "                   params['CameraParameters2']['TangentialDistortion'] + \\\n",
    "                   [params['CameraParameters2']['RadialDistortion'][2]]\n",
    "    distCoeffs2 = np.array(distCoeffs2)\n",
    "\n",
    "    R = np.array(params['RotationOfCamera2']).transpose()\n",
    "    T = np.array(params['TranslationOfCamera2']).transpose()\n",
    "    \n",
    "    imageSize = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    (R1, R2, P1, P2, Q, leftROI, rightROI) = cv2.stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, \n",
    "                                                               distCoeffs2, imageSize, R, T, None, None, \n",
    "                                                               None, None, None, cv2.CALIB_ZERO_DISPARITY, 0)\n",
    "    left_maps = cv2.initUndistortRectifyMap(cameraMatrix1, distCoeffs1, R1, P1, imageSize, cv2.CV_16SC2)\n",
    "    right_maps = cv2.initUndistortRectifyMap(cameraMatrix2, distCoeffs2, R2, P2, imageSize, cv2.CV_16SC2)\n",
    "    \n",
    "    return left_maps, right_maps, cameraMatrix1, distCoeffs1, R1, P1, cameraMatrix2, distCoeffs2, R2, P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm_old['stereoParametersUrl'])\n",
    "print(cm_new['stereoParametersUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "old_params_f, _, _ = s3_access_utils.download_from_url(cm_old['stereoParametersUrl'])\n",
    "new_params_f, _, _ = s3_access_utils.download_from_url(cm_new['stereoParametersUrl'])\n",
    "\n",
    "old_params = json.load(open(old_params_f))\n",
    "new_params = json.load(open(new_params_f))\n",
    "\n",
    "left_maps_m, right_maps_m, cameraMatrix1_m, distCoeffs1_m, R1_m, P1_m, cameraMatrix2_m, distCoeffs2_m, R2_m, P2_m = get_camera_parameters(old_params)\n",
    "left_maps_c, right_maps_c, cameraMatrix1_c, distCoeffs1_c, R1_c, P1_c, cameraMatrix2_c, distCoeffs2_c, R2_c, P2_c = get_camera_parameters(new_params)\n",
    "\n",
    "weight_model_f = 'nn_epoch_798_v2.pb'\n",
    "kf_model_f = 'kf_model.pb'\n",
    "weight_estimator2 = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "cm_old_adj = CameraMetadata(\n",
    "    focal_length=cm_old['focalLength'],\n",
    "    focal_length_pixel=cm_old['focalLengthPixel'],\n",
    "    baseline_m=cm_old['baseline'],\n",
    "    pixel_count_width=cm_old['pixelCountWidth'],\n",
    "    pixel_count_height=cm_old['pixelCountHeight'],\n",
    "    image_sensor_width=cm_old['imageSensorWidth'],\n",
    "    image_sensor_height=cm_old['imageSensorHeight']\n",
    ")\n",
    "\n",
    "cm_new_adj = CameraMetadata(\n",
    "    focal_length=cm_new['focalLength'],\n",
    "    focal_length_pixel=cm_new['focalLengthPixel'],\n",
    "    baseline_m=cm_new['baseline'],\n",
    "    pixel_count_width=cm_new['pixelCountWidth'],\n",
    "    pixel_count_height=cm_new['pixelCountHeight'],\n",
    "    image_sensor_width=cm_new['imageSensorWidth'],\n",
    "    image_sensor_height=cm_new['imageSensorHeight']\n",
    ")\n",
    "\n",
    "new_keypoints = []\n",
    "\n",
    "new_weights = []\n",
    "new_lengths = []\n",
    "new_k_factors = []\n",
    "new_weights2 = []\n",
    "new_lengths2 = []\n",
    "new_k_factors2 = []\n",
    "\n",
    "for idx, row in df1.iterrows():\n",
    "    ann_m = row.annotation\n",
    "    \n",
    "    # un-rectify with matlab params, re-rectify with circular params\n",
    "    ann_m_mp_c = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann_m[side]:\n",
    "            bp = item['keypointType']\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            if side == 'leftCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[left_maps_m[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix1_c, distCoeffs1_c, R=R1_c, P=P1_c)[0][0]\n",
    "            elif side == 'rightCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[right_maps_m[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix2_c, distCoeffs2_c, R=R2_c, P=P2_c)[0][0]\n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            ann_m_mp_c[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new\n",
    "            })\n",
    "#         for item in ann_m[side]:\n",
    "#             bp = item['keypointType']\n",
    "#             x, y = item['xFrame'], item['yFrame']\n",
    "#             if side == 'leftCrop':\n",
    "#                 x_new, y_new = cv2.undistortPoints(np.array([[left_maps_m[0][y, x]]]).astype(float), \n",
    "#                                     cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "#             elif side == 'rightCrop':\n",
    "#                 x_new, y_new = cv2.undistortPoints(np.array([[right_maps_m[0][y, x]]]).astype(float), \n",
    "#                                     cameraMatrix2_m, distCoeffs2_m, R=R2_m, P=P2_m)[0][0]\n",
    "#             x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "#             ann_m_mp_c[side].append({\n",
    "#                 'keypointType': bp,\n",
    "#                 'xFrame': x_new,\n",
    "#                 'yFrame': y_new\n",
    "#             })\n",
    "    \n",
    "#     ann_m_mp_c_new = {'leftCrop': [], 'rightCrop': []}\n",
    "#     for side in ['leftCrop', 'rightCrop']:\n",
    "#         for item in ann_m_mp_c[side]:\n",
    "#             bp = item['keypointType']\n",
    "#             x, y = item['xFrame'], item['yFrame']\n",
    "#             maps = left_maps_c if side == 'leftCrop' else right_maps_c\n",
    "#             x_new, y_new = cv2.undistortPoints(np.array([[maps[0][y, x]]]).astype(float), \n",
    "#                                 cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "#             x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "#             ann_m_mp_c_new[side].append({\n",
    "#                 'keypointType': bp,\n",
    "#                 'xFrame': x_new,\n",
    "#                 'yFrame': y_new\n",
    "#             })\n",
    "    new_keypoints.append(ann_m_mp_c)\n",
    "#     new_keypoints.append(ann_m_mp_c_new)\n",
    "    \n",
    "    new_weight, new_length, new_k_factor = weight_estimator2.predict(ann_m_mp_c, cm_old_adj)\n",
    "    new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(ann_m_mp_c, cm_new_adj)\n",
    "#     new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(ann_m_mp_c_new, cm_new_adj)\n",
    "#     new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(row.annotation, cm_old_adj)\n",
    "    \n",
    "    new_weights.append(new_weight)\n",
    "    new_lengths.append(new_length)\n",
    "    new_k_factors.append(new_k_factor)\n",
    "    new_weights2.append(new_weight2)\n",
    "    new_lengths2.append(new_length2)\n",
    "    new_k_factors2.append(new_k_factor2)\n",
    "    \n",
    "_new_keypoints = []\n",
    "\n",
    "_new_weights = []\n",
    "_new_lengths = []\n",
    "_new_k_factors = []\n",
    "_new_weights2 = []\n",
    "_new_lengths2 = []\n",
    "_new_k_factors2 = []\n",
    "    \n",
    "for idx, row in df2.iterrows():\n",
    "    ann_m = row.annotation\n",
    "    \n",
    "    # un-rectify with matlab params, re-rectify with circular params\n",
    "    ann_m_mp_c = {'leftCrop': [], 'rightCrop': []}\n",
    "    for side in ['leftCrop', 'rightCrop']:\n",
    "        for item in ann_m[side]:\n",
    "            bp = item['keypointType']\n",
    "            x, y = item['xFrame'], item['yFrame']\n",
    "            maps = left_maps_c if side == 'leftCrop' else right_maps_c\n",
    "            \n",
    "            if side == 'leftCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[left_maps_c[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix1_m, distCoeffs1_m, R=R1_m, P=P1_m)[0][0]\n",
    "            elif side == 'rightCrop':\n",
    "                x_new, y_new = cv2.undistortPoints(np.array([[right_maps_c[0][y, x]]]).astype(float), \n",
    "                                    cameraMatrix2_m, distCoeffs2_m, R=R2_m, P=P2_m)[0][0]\n",
    "            x_new, y_new = int(round(x_new)), int(round(y_new))\n",
    "            ann_m_mp_c[side].append({\n",
    "                'keypointType': bp,\n",
    "                'xFrame': x_new,\n",
    "                'yFrame': y_new\n",
    "            })\n",
    "    _new_keypoints.append(ann_m_mp_c)\n",
    "    \n",
    "    new_weight, new_length, new_k_factor = weight_estimator2.predict(ann_m_mp_c, cm_old_adj)\n",
    "    new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(ann_m_mp_c, cm_new_adj)\n",
    "    \n",
    "    _new_weights.append(new_weight)\n",
    "    _new_lengths.append(new_length)\n",
    "    _new_k_factors.append(new_k_factor)\n",
    "    _new_weights2.append(new_weight2)\n",
    "    _new_lengths2.append(new_length2)\n",
    "    _new_k_factors2.append(new_k_factor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['new_keypoints'] = new_keypoints\n",
    "df1['new_weights'] = new_weights\n",
    "df1['new_lengths'] = new_lengths\n",
    "df1['new_k_factors'] = new_k_factors\n",
    "df1['new_weights2'] = new_weights2\n",
    "df1['new_lengths2'] = new_lengths2\n",
    "df1['new_k_factors2'] = new_k_factors2\n",
    "\n",
    "df2['new_keypoints'] = _new_keypoints\n",
    "df2['new_weights'] = _new_weights\n",
    "df2['new_lengths'] = _new_lengths\n",
    "df2['new_k_factors'] = _new_k_factors\n",
    "df2['new_weights2'] = _new_weights2\n",
    "df2['new_lengths2'] = _new_lengths2\n",
    "df2['new_k_factors2'] = _new_k_factors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1[df1.akpd_score > 0.01].estimated_weight_g, df1[df1.akpd_score > 0.01].new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1[df1.akpd_score > 0.01].estimated_weight_g, df1[df1.akpd_score > 0.01].new_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df1[df1.akpd_score > 0.01].estimated_weight_g), np.mean(df1[df1.akpd_score > 0.01].new_weights), np.mean(df1[df1.akpd_score > 0.01].new_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df2[df2.akpd_score > 0.01].estimated_weight_g), np.mean(df2[df2.akpd_score > 0.01].new_weights), np.mean(df2[df2.akpd_score > 0.01].new_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "\n",
    "df1['diff'] = df1.estimated_weight_g - df1.new_weights\n",
    "df4 = df1[df1.akpd_score > 0.01].sort_values(['diff'])\n",
    "\n",
    "print(df4.iloc[idx]['diff'])\n",
    "\n",
    "ann1 = df4.iloc[idx].annotation\n",
    "\n",
    "new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(ann1, cm_old_adj)\n",
    "print(new_weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ann2 = df4.iloc[idx].new_keypoints\n",
    "\n",
    "new_weight2, new_length2, new_k_factor2 = weight_estimator2.predict(ann2, cm_old_adj)\n",
    "print(new_weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1['rightCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann2['rightCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df1[df1.akpd_score > 0.01].estimated_weight_g, df1[df1.akpd_score > 0.01].new_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.iloc[0].left_crop_url_adjusted)\n",
    "print(df1.iloc[0].left_crop_url)\n",
    "\n",
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop_url_adjusteds = []\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    left_crop_url_adjusteds.append(row.left_crop_url.replace('production', 'dev'))\n",
    "    \n",
    "df1['left_crop_url_adjusted'] = left_crop_url_adjusteds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df1[df1.left_crop_url == 'https://aquabyte-crops.s3.eu-west-1.amazonaws.com/environment=production/site-id=62/pen-id=151/date=2020-10-05/hour=22/at=2020-10-05T22:30:03.540743000Z/left_frame_crop_844_1661_4076_2867.jpg']\n",
    "\n",
    "\n",
    "# for index, row in rows.iterrows():\n",
    "#     rows.loc[index, 'left_crop_url_adjusted'] = row.left_crop_url.replace('production', 'dev')\n",
    "# df1.update(rows)\n",
    "\n",
    "row = df1[df1.left_crop_url == 'https://aquabyte-crops.s3.eu-west-1.amazonaws.com/environment=production/site-id=62/pen-id=151/date=2020-10-12/hour=10/at=2020-10-12T10:35:54.611253000Z/left_frame_crop_0_378_3292_1601.jpg'].iloc[0]\n",
    "\n",
    "print(row.left_crop_url)\n",
    "print(row.left_crop_url_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['left_crop_url_adjusted'] = df2['left_crop_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on='left_crop_url_adjusted')\n",
    "df3['diff'] = df3.new_weights2_x - df3.estimated_weight_g_y\n",
    "df3_f = df3[(df3.akpd_score_x > 0.95) & (df3.akpd_score_y > 0.95)]\n",
    "len(df3_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3_f.estimated_weight_g_y, df3_f.new_weights_y)\n",
    "plt.plot(df3_f.estimated_weight_g_y, df3_f.estimated_weight_g_y, color = 'red')\n",
    "\n",
    "np.mean(df3_f.estimated_weight_g_y), np.mean(df3_f.new_weights_y), np.mean(df3_f.new_weights2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3_f.estimated_weight_g_x, df3_f.estimated_weight_g_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3_f.estimated_weight_g_x, df3_f.new_weights_x)\n",
    "plt.plot(df3_f.estimated_weight_g_x, df3_f.estimated_weight_g_x, color = 'red')\n",
    "\n",
    "np.mean(df3_f.estimated_weight_g_x), np.mean(df3_f.new_weights_x), np.mean(df3_f.new_weights2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3_f.new_weights2_x, df3_f.estimated_weight_g_y)\n",
    "plt.plot(df3_f.new_weights2_x, df3_f.new_weights2_x, color = 'red')\n",
    "\n",
    "np.mean(df3_f.estimated_weight_g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3_f.new_weights2_y, df3_f.estimated_weight_g_x)\n",
    "plt.plot(df3_f.new_weights2_y, df3_f.new_weights2_y, color = 'red')\n",
    "\n",
    "np.mean(df3_f.estimated_weight_g_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_f['diff'] = df1_f.new_weights2 - df2_f.estimated_weight_g\n",
    "\n",
    "df4 = df3_f.sort_values(['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.iloc[0].left_crop_url_adjusted)\n",
    "print(df4.iloc[0].left_crop_url_x)\n",
    "print(df4.iloc[0].left_crop_url_y)\n",
    "\n",
    "df4.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_model_f = 'weight_model.pb'\n",
    "weight_model_f = 'nn_epoch_798_v2.pb'\n",
    "kf_model_f = 'kf_model.pb'\n",
    "weight_estimator2 = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "# weight_model_f = 'weight_model.pb'\n",
    "# kf_model_f = 'kf_model.pb'\n",
    "# weight_estimator3 = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "# weight_model_f = 'weight_model_synthetic_data.pb'\n",
    "# kf_model_f = 'kf_model.pb'\n",
    "# weight_estimator4 = WeightEstimator(weight_model_f, kf_model_f)\n",
    "\n",
    "weights2 = []\n",
    "weights3 = []\n",
    "weights4 = []\n",
    "weights5 = []\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    ann, camera_metadata = row.annotation, row.camera_metadata\n",
    "    \n",
    "    df1.loc[index, 'left_crop_url_adjusted'] = row.left_crop_url.replace('production', 'dev')\n",
    "    \n",
    "    cm2 = CameraMetadata(\n",
    "        focal_length=cm_new['focalLength'],\n",
    "        focal_length_pixel=camera_metadata['focalLengthPixel'],\n",
    "        baseline_m=cm_new['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    cm3 = CameraMetadata(\n",
    "        focal_length=camera_metadata['focalLength'],\n",
    "        focal_length_pixel=cm_new['focalLengthPixel'],\n",
    "        baseline_m=cm_new['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    cm4 = CameraMetadata(\n",
    "        focal_length=cm_new['focalLength'],\n",
    "        focal_length_pixel=cm_new['focalLengthPixel'],\n",
    "        baseline_m=camera_metadata['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    cm5 = CameraMetadata(\n",
    "        focal_length=cm_new['focalLength'],\n",
    "        focal_length_pixel=cm_new['focalLengthPixel'],\n",
    "        baseline_m=cm_new['baseline'],\n",
    "        pixel_count_width=camera_metadata['pixelCountWidth'],\n",
    "        pixel_count_height=camera_metadata['pixelCountHeight'],\n",
    "        image_sensor_width=camera_metadata['imageSensorWidth'],\n",
    "        image_sensor_height=camera_metadata['imageSensorHeight']\n",
    "    )\n",
    "    \n",
    "    weight2, length, kf = weight_estimator2.predict(row.annotation, cm2)\n",
    "    weight3, length, kf = weight_estimator2.predict(row.annotation, cm3)\n",
    "    weight4, length, kf = weight_estimator2.predict(row.annotation, cm4)\n",
    "    weight5, length, kf = weight_estimator2.predict(row.annotation, cm5)\n",
    "    \n",
    "    weights2.append(weight2)\n",
    "    weights3.append(weight3)\n",
    "    weights4.append(weight4)\n",
    "    weights5.append(weight5)\n",
    "    \n",
    "df1['weights2'] = weights2\n",
    "df1['weights3'] = weights3\n",
    "df1['weights4'] = weights4\n",
    "df1['weights5'] = weights5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['left_crop_url_adjusted'] = df2.left_crop_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on='left_crop_url_adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_filtered = df1[(df1.akpd_score > 0.01) & (df2.akpd_score > 0.01)]\n",
    "df2_filtered = df2[(df1.akpd_score > 0.01) & (df2.akpd_score > 0.01)]\n",
    "\n",
    "df1_filtered[['estimated_weight_g', 'weights2', 'weights3', 'weights4', 'akpd_score']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1_filtered.weights2 - df1_filtered.estimated_weight_g)\n",
    "plt.title('focalLength + baseline after - before')\n",
    "np.mean(df1_filtered.weights2 - df1_filtered.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1_filtered.weights3 - df1_filtered.estimated_weight_g)\n",
    "plt.title('focalLengthPixel + baseline after - before')\n",
    "np.mean(df1_filtered.weights3 - df1_filtered.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1_filtered.weights4 - df1_filtered.estimated_weight_g)\n",
    "plt.title('focaLength + focalLengthPixel after - before')\n",
    "np.mean(df1_filtered.weights4 - df1_filtered.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df1_filtered.weights5 - df1_filtered.estimated_weight_g)\n",
    "plt.title('focaLength + focalLengthPixel + baseline after - before')\n",
    "np.mean(df1_filtered.weights5 - df1_filtered.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(df1_filtered.estimated_weight_g, bins = 40, alpha = 0.5, color = 'red', density = True)\n",
    "plt.hist(df1_filtered.weights2, bins = bins, alpha = 0.5, color = 'blue', density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0].annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0].annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "df4.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filtered.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.iloc[1].annotation['leftCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_filtered.iloc[1].annotation['leftCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1 = df1_filtered.iloc[5].annotation['leftCrop']\n",
    "left2 = df2_filtered.iloc[5].annotation['leftCrop']\n",
    "\n",
    "tail_notch_index = 0\n",
    "upper_lip_index = 2\n",
    "\n",
    "x1, y1 = left1[tail_notch_index]['xFrame'], left1[tail_notch_index]['yFrame']\n",
    "x2, y2 = left2[tail_notch_index]['xFrame'], left2[tail_notch_index]['yFrame']\n",
    "    \n",
    "a1, b1 = left1[upper_lip_index]['xFrame'], left1[upper_lip_index]['yFrame']\n",
    "a2, b2 = left2[upper_lip_index]['xFrame'], left2[upper_lip_index]['yFrame']\n",
    "    \n",
    "print(x1, y1, np.sqrt((x1 - x2) ** 2  + (y1 - y2) ** 2))\n",
    "print(x2, y2)\n",
    "    \n",
    "print()\n",
    "\n",
    "print(a1, b1, np.sqrt((a1 - a2) ** 2  + (b1 - b2) ** 2))\n",
    "print(a2, b2)\n",
    "    \n",
    "print()\n",
    "    \n",
    "print(x1 - a1, y1 - b1, np.sqrt((x1 - a1) ** 2  + (y1 - b1) ** 2))\n",
    "print(x2 - a2, y2 - b2, np.sqrt((x2 - a2) ** 2  + (y2 - b2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_crops_l(left_image_f, right_image_f, left_ann, right_ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "    left_ann, right_ann = left_ann['leftCrop'], right_ann['leftCrop']\n",
    "#     left_ann, right_ann = left_ann['rightCrop'], right_ann['rightCrop']\n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in left_ann}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in right_ann}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_crops(left_image_f, right_image_f, left_ann, right_ann, overlay_keypoints=True, show_labels=False):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(20, 20))\n",
    "    left_image = plt.imread(left_image_f)\n",
    "    right_image = plt.imread(right_image_f)\n",
    "    axes[0].imshow(left_image)\n",
    "    axes[1].imshow(right_image)\n",
    "#     left_ann, right_ann = left_ann['leftCrop'], right_ann['leftCrop']\n",
    "    left_ann, right_ann = left_ann['rightCrop'], right_ann['rightCrop']\n",
    "    left_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in left_ann}\n",
    "    right_keypoints = {item['keypointType']: [item['xCrop'], item['yCrop']] for item in right_ann}\n",
    "    if overlay_keypoints:\n",
    "        for bp, kp in left_keypoints.items():\n",
    "            axes[0].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[0].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "        for bp, kp in right_keypoints.items():\n",
    "            axes[1].scatter([kp[0]], [kp[1]], color='red', s=10)\n",
    "            if show_labels:\n",
    "                axes[1].annotate(bp, (kp[0], kp[1]), color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.iloc[0].left_crop_url_x)\n",
    "print(df4.iloc[0].left_crop_url_y)\n",
    "df4.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df4.iloc[idx]\n",
    "row2 = df4.iloc[idx]\n",
    "left_crop_url, right_crop_url = row1.left_crop_url_x, row2.left_crop_url_y\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation_x\n",
    "right_ann = row2.annotation_y\n",
    "display_crops_l(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df4.iloc[idx]\n",
    "row2 = df4.iloc[idx]\n",
    "left_crop_url, right_crop_url = row1.right_crop_url_x, row2.right_crop_url_y\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation_x\n",
    "right_ann = row2.annotation_y\n",
    "display_crops(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4.iloc[idx].left_crop_url_adjusted)\n",
    "print(df4.iloc[idx].left_crop_url_x)\n",
    "print(df4.iloc[idx].left_crop_url_y)\n",
    "print(df4.iloc[idx].new_weights2)\n",
    "print(df4.iloc[idx].estimated_weight_g_y)\n",
    "print(df4.iloc[idx].akpd_score_x)\n",
    "print(df4.iloc[idx].akpd_score_y)\n",
    "\n",
    "df4.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df4.iloc[1]\n",
    "row2 = df4.iloc[1]\n",
    "left_crop_url, right_crop_url = row1.left_crop_url_x, row2.left_crop_url_y\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation_x\n",
    "right_ann = row2.annotation_y\n",
    "display_crops(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df1_filtered.iloc[1]\n",
    "row2 = df2_filtered.iloc[1]\n",
    "\n",
    "print(row1.akpd_score, row2.akpd_score)\n",
    "\n",
    "left_crop_url, right_crop_url = row1.right_crop_url, row2.right_crop_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation\n",
    "right_ann = row2.annotation\n",
    "display_crops(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df1_filtered.iloc[6]\n",
    "row2 = df2_filtered.iloc[6]\n",
    "left_crop_url, right_crop_url = row1.left_crop_url, row2.left_crop_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation\n",
    "right_ann = row2.annotation\n",
    "display_crops(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.utils.data_access_utils import S3AccessUtils\n",
    "s3 = S3AccessUtils('/root/data', json.load(open(os.environ['AWS_CREDENTIALS'])))\n",
    "row1 = df1_filtered.iloc[6]\n",
    "row2 = df2_filtered.iloc[6]\n",
    "\n",
    "print(row1.akpd_score, row2.akpd_score)\n",
    "\n",
    "left_crop_url, right_crop_url = row1.right_crop_url, row2.right_crop_url\n",
    "left_crop_f, _, _ = s3.download_from_url(left_crop_url)\n",
    "right_crop_f, _, _ = s3.download_from_url(right_crop_url)\n",
    "left_ann = row1.annotation\n",
    "right_ann = row2.annotation\n",
    "display_crops(left_crop_f, right_crop_f, left_ann, right_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[df3.akpd_score_x > 0.99]\n",
    "plt.scatter(df4.estimated_weight_g_x, df4.estimated_weight_g_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket in np.arange(0, 10000, 1000):\n",
    "    df5 = df4[(df4.estimated_weight_g_x > bucket)& (df4.estimated_weight_g_x < (bucket + 1000))]\n",
    "    \n",
    "#     print(np.mean(df5.estimated_weight_g_x), np.mean(df5.estimated_weight_g_y), np.mean(df5.estimated_weight_g_y) / np.mean(df5.estimated_weight_g_x))\n",
    "    print('%i %i %i, %0.2f, %0.2f' % (len(df5.estimated_weight_g_x), np.sum(df5.estimated_weight_g_y < bucket), np.sum(df5.estimated_weight_g_y > (bucket + 1000)), np.sum(df5.estimated_weight_g_y < bucket) / len(df5.estimated_weight_g_x), np.sum(df5.estimated_weight_g_y > (bucket + 1000)) / len(df5.estimated_weight_g_x)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
