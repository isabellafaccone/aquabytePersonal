{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "import pytz \n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select p.id as id, s.name as site_name, p.name as pen_name from customer.pens p\n",
    "    left join customer.sites s\n",
    "    on p.site_id = s.id\n",
    "    order by p.id;\n",
    "\"\"\"\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "df_pens = rds_access_utils.extract_from_database(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startDate1 = '2020-04-21'\n",
    "# endDate1 = '2020-04-22'\n",
    "\n",
    "# startDate2 = '2020-05-04'\n",
    "# endDate2 = '2020-05-05'\n",
    "\n",
    "# penIds = [95, 66, 56, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = len(penIds), ncols = 1, figsize = (10, 5 * len(penIds)))\n",
    "\n",
    "# for index, penId in enumerate(penIds):\n",
    "#     print(penId)\n",
    "    \n",
    "#     foundPenData = df_pens[df_pens.id == penId].values\n",
    "    \n",
    "#     if len(foundPenData) > 0:\n",
    "#         foundPen = foundPenData[0]\n",
    "#         siteName = foundPen[1]\n",
    "#         penName = foundPen[2]\n",
    "#     else:\n",
    "#         siteName = 'N/A'\n",
    "#         penName = 'N/A'\n",
    "\n",
    "#     query1 = \"\"\"\n",
    "#         select captured_at, estimated_weight_g from prod.biomass_computations bc\n",
    "#         where bc.pen_id = %i\n",
    "#         and bc.akpd_score > 0.99\n",
    "#         and bc.captured_at > '%s'\n",
    "#         and bc.captured_at < '%s';\n",
    "#     \"\"\" % (penId, startDate1, endDate1)\n",
    "\n",
    "#     query2 = \"\"\"\n",
    "#         select captured_at, estimated_weight_g from prod.biomass_computations bc\n",
    "#         where bc.pen_id = %i\n",
    "#         and bc.akpd_score > 0.99\n",
    "#         and bc.captured_at > '%s'\n",
    "#         and bc.captured_at < '%s';\n",
    "#     \"\"\" % (penId, startDate2, endDate2)\n",
    "\n",
    "#     if query1 in queryCache:\n",
    "#         weights1 = queryCache[query1].copy()\n",
    "#     else:\n",
    "#         weights1 = rds_access_utils.extract_from_database(query1)\n",
    "#         queryCache[query1] = weights1.copy()\n",
    "        \n",
    "#     if query2 in queryCache:\n",
    "#         weights2 = queryCache[query2].copy()\n",
    "#     else:\n",
    "#         weights2 = rds_access_utils.extract_from_database(query2)\n",
    "#         queryCache[query2] = weights2.copy()\n",
    "\n",
    "#     weights1.index = weights1['captured_at']\n",
    "#     weights1 = weights1.sort_index()\n",
    "\n",
    "#     weights2.index = weights2['captured_at']\n",
    "#     weights2 = weights2.sort_index()\n",
    "    \n",
    "#     axes[index].hist(weights1['estimated_weight_g'], bins = 20, density = True, facecolor = 'blue', alpha = 0.5)\n",
    "#     axes[index].hist(weights2['estimated_weight_g'], bins = 20, density = True, facecolor = 'red', alpha = 0.5)\n",
    "#     axes[index].set_title('%s %s (%i) Image Score Analysis' % (siteName, penName, penId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(weights1['estimated_weight_g'], bins = 20, density = True, facecolor = 'blue', alpha = 0.5)\n",
    "# plt.hist(weights2['estimated_weight_g'], bins = 20, density = True, facecolor = 'red', alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import animation, rc\n",
    "# from IPython.display import HTML\n",
    "# plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "\n",
    "# # generate 4 random variables from the random, gamma, exponential, and uniform distribution\n",
    "# # x1 = np.random.normal(-2.5, 1, 10000)\n",
    "# # x2 = np.random.gamma(2, 1.5, 10000)\n",
    "# # x3 = np.random.exponential(2, 10000)+7\n",
    "# # x4 = np.random.uniform(14,20, 10000)\n",
    "\n",
    "# # fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "# # print(x1)\n",
    "\n",
    "# # def updateData(curr):\n",
    "# #     a = curr + 1\n",
    "    \n",
    "# #     print(a)\n",
    "    \n",
    "# #     if curr == 100: \n",
    "# #         return\n",
    "    \n",
    "# #     for ax in (ax1, ax2, ax3, ax4):\n",
    "# #         ax.clear()\n",
    "    \n",
    "# #     h1 = ax1.hist(x1[:a], normed=True, bins=np.linspace(-6,1, num=21), alpha=0.5)\n",
    "# #     h2 = ax2.hist(x2[:a], normed=True, bins=np.linspace(0,15,num=21), alpha=0.5)\n",
    "# #     h3 = ax3.hist(x3[:a], normed=True, bins=np.linspace(7,20,num=21), alpha=0.5)\n",
    "# #     h4 = ax4.hist(x4[:a], normed=True, bins=np.linspace(14,20,num=21), alpha=0.5)\n",
    "    \n",
    "# #     return h1, h2, h3, h4\n",
    "    \n",
    "\n",
    "# # anim = animation.FuncAnimation(fig, updateData, frames = 100, interval = 20, blit=True)\n",
    "\n",
    "# # HTML(anim.to_jshtml())\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.set_xlim(( 0, 2))\n",
    "# ax.set_ylim((-2, 2))\n",
    "\n",
    "# line = ax.bar([], [])\n",
    "\n",
    "# def init():\n",
    "#     line.set_data([], [])\n",
    "#     return (line,)\n",
    "\n",
    "# def animate(i):\n",
    "#     x = np.linspace(0, 2, 1000)\n",
    "#     y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
    "#     line.set_data(x, y)\n",
    "#     return (line,)\n",
    "\n",
    "\n",
    "# anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "#                                frames=100, interval=20, \n",
    "#                                blit=True)\n",
    "\n",
    "# HTML(anim.to_html5_video())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "startDate = '2020-04-01'\n",
    "endDate = '2020-06-01'\n",
    "penId = 95\n",
    "\n",
    "foundPenData = df_pens[df_pens.id == penId].values\n",
    "    \n",
    "if len(foundPenData) > 0:\n",
    "    foundPen = foundPenData[0]\n",
    "    siteName = foundPen[1]\n",
    "    penName = foundPen[2]\n",
    "else:\n",
    "    siteName = 'N/A'\n",
    "    penName = 'N/A'\n",
    "\n",
    "query = \"\"\"\n",
    "        select captured_at, estimated_weight_g from prod.biomass_computations bc\n",
    "        where bc.pen_id = %i\n",
    "        and bc.akpd_score > 0.99\n",
    "        and bc.captured_at > '%s'\n",
    "        and bc.captured_at < '%s';\n",
    "    \"\"\" % (penId, startDate, endDate)\n",
    "\n",
    "if query in queryCache:\n",
    "    weights = queryCache[query].copy()\n",
    "else:\n",
    "    weights = rds_access_utils.extract_from_database(query)\n",
    "    queryCache[query] = weights.copy()\n",
    "\n",
    "weights.index = weights['captured_at']\n",
    "weights['date'] = weights.index.date.astype(str)\n",
    "weights = weights.sort_index()\n",
    "    \n",
    "dates = np.unique(weights['date'])\n",
    "numDates = len(dates)\n",
    "\n",
    "lookbackDays = 7\n",
    "\n",
    "goodDates = (weights.index > dates[0]) & (weights.index < dates[0 + lookbackDays])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram our data with numpy\n",
    "#data = weights[weights['date'] == dates[0]]['estimated_weight_g']\n",
    "data = weights[goodDates]['estimated_weight_g']\n",
    "n, bins = np.histogram(data, bins = 20, density = True)\n",
    "\n",
    "# get the corners of the rectangles for the histogram\n",
    "left = np.array(bins[:-1])\n",
    "right = np.array(bins[1:])\n",
    "bottom = np.zeros(len(left))\n",
    "top = bottom + n\n",
    "nrects = len(left)\n",
    "\n",
    "nverts = nrects * (1 + 3 + 1)\n",
    "verts = np.zeros((nverts, 2))\n",
    "codes = np.ones(nverts, int) * path.Path.LINETO\n",
    "codes[0::5] = path.Path.MOVETO\n",
    "codes[4::5] = path.Path.CLOSEPOLY\n",
    "verts[0::5, 0] = left\n",
    "verts[0::5, 1] = bottom\n",
    "verts[1::5, 0] = left\n",
    "verts[1::5, 1] = top\n",
    "verts[2::5, 0] = right\n",
    "verts[2::5, 1] = top\n",
    "verts[3::5, 0] = right\n",
    "verts[3::5, 1] = bottom\n",
    "\n",
    "patch = None\n",
    "line = None\n",
    "text = None\n",
    "\n",
    "def animate(i):\n",
    "    # simulate new data coming in\n",
    "    goodDates = (weights.index > dates[i]) & (weights.index < dates[i + lookbackDays])\n",
    "    \n",
    "    data = weights[goodDates]['estimated_weight_g']\n",
    "    n, bins = np.histogram(data, bins = 20, density = True)\n",
    "    top = bottom + n\n",
    "#     verts[1::5, 1] = top\n",
    "#     verts[2::5, 1] = top\n",
    "    \n",
    "    left = np.array(bins[:-1])\n",
    "    right = np.array(bins[1:])\n",
    "    \n",
    "    verts[0::5, 0] = left\n",
    "    verts[0::5, 1] = bottom\n",
    "    verts[1::5, 0] = left\n",
    "    verts[1::5, 1] = top\n",
    "    verts[2::5, 0] = right\n",
    "    verts[2::5, 1] = top\n",
    "    verts[3::5, 0] = right\n",
    "    verts[3::5, 1] = bottom\n",
    "    \n",
    "    avgWeight = np.mean(weights[goodDates]['estimated_weight_g'])\n",
    "    \n",
    "    ax.lines = []\n",
    "    line = ax.axvline(avgWeight, color = 'red')\n",
    "    \n",
    "    text.set_text('%0.0fg' % (avgWeight, ))\n",
    "    text.set_position((avgWeight, 0))\n",
    "    \n",
    "    ax.set_title('%s %s (%i) Biomass: %s to %s (n = %i)' % (siteName, penName, penId, dates[i], dates[i + lookbackDays], len(data)))\n",
    "    ax.set_xlabel('Weight (grams): %s to %s (n = %i)' % (dates[i], dates[i + lookbackDays], len(data)))\n",
    "\n",
    "    return [patch, line, text]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "\n",
    "barpath = path.Path(verts, codes)\n",
    "patch = patches.PathPatch(barpath, facecolor='green', edgecolor = 'yellow', alpha=0.5)\n",
    "ax.add_patch(patch)\n",
    "\n",
    "avgWeight = np.mean(weights[goodDates]['estimated_weight_g'])\n",
    "\n",
    "line = ax.axvline(avgWeight, color = 'red')\n",
    "\n",
    "text = ax.text('%0.0fg' % (avgWeight, ), 0, '')\n",
    "\n",
    "margin = 100\n",
    "bottomLimit = np.percentile(weights['estimated_weight_g'], 0.1) - margin\n",
    "upperLimit = np.percentile(weights['estimated_weight_g'], 99.9) + margin\n",
    "\n",
    "# ax.set_xlim(left[0], right[-1])\n",
    "ax.set_xlim(bottomLimit, upperLimit)\n",
    "ax.set_ylim(bottom.min(), top.max())\n",
    "\n",
    "ax.set_title('%s %s (%i) Biomass: %s to %s (n = %i)' % (siteName, penName, penId, dates[0], dates[0 + lookbackDays], len(data)))\n",
    "ax.set_xlabel('Weight (grams): %s to %s (n = %i)' % (dates[0], dates[0 + lookbackDays], len(data)))\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames = len(dates) - lookbackDays, interval = 200, repeat = False, blit=True)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
