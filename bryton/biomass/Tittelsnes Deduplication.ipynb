{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta, time\n",
    "from research.utils.data_access_utils import RDSAccessUtils\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import AutoDateFormatter, AutoDateLocator\n",
    "\n",
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = pd.read_csv('tittelsnes_p37_duplicate.csv')\n",
    "\n",
    "duplicates = duplicates.sort_values('captured_at').copy(deep=True)\n",
    "duplicates.index = pd.to_datetime(duplicates.captured_at)\n",
    "dates = duplicates.index.date.astype(str)\n",
    "duplicates['date'] = dates\n",
    "duplicates['hour'] = duplicates.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = pd.read_csv('blom_vikane_singleweights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (duplicates['is_duplicate'] == 1)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "\n",
    "plt.hist(duplicates[mask]['hour'], alpha = 0.5, color = 'blue', density = True, bins = 24)\n",
    "plt.hist(duplicates[~mask]['hour'], alpha = 0.5, color = 'red', density = True, bins = 24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "thetas = []\n",
    "phis = []\n",
    "\n",
    "for index, row in duplicates.iterrows():\n",
    "    ann1, cm1 = ast.literal_eval(row.annotation), ast.literal_eval(row.camera_metadata)\n",
    "    \n",
    "    wkps1 = pixel2world(ann1['leftCrop'], ann1['rightCrop'], cm1)\n",
    "\n",
    "    vector = wkps1['PECTORAL_FIN'] - wkps1['ANAL_FIN']\n",
    "    x, y, z = vector / np.linalg.norm(vector)\n",
    "    \n",
    "    theta = math.atan(y / x) * np.sign(y)\n",
    "    phi = math.acos(z)\n",
    "    dtheta = math.degrees(theta)\n",
    "    dphi = 90 - math.degrees(phi)\n",
    "    thetas.append(dtheta)\n",
    "    phis.append(dphi)\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(thetas, phis, color = 'orange', label = 'Normal')\n",
    "# plt.scatter(thetas2, phis2, color = 'blue', label = 'Negative')\n",
    "plt.xlabel('Theta degree')\n",
    "plt.ylabel('Phi degree')\n",
    "plt.legend()\n",
    "\n",
    "duplicates['theta'] = thetas\n",
    "duplicates['phi'] = phis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm\n",
    "\n",
    "mask0 = (duplicates['captured_at'] > '2020-06-20') & (duplicates['captured_at'] < '2020-06-23')\n",
    "\n",
    "#mask1 = mask0 & (np.abs(duplicates['theta']) < 10) & (np.abs(duplicates['phi']) < 10)\n",
    "mask1 = mask0 & (np.abs(duplicates['hour']) > 7) & (np.abs(duplicates['hour']) < 17)\n",
    "mask2 = mask1 & (duplicates['is_duplicate'] == 0)\n",
    "\n",
    "print(sum(mask0), sum(mask1), sum(mask2))\n",
    "\n",
    "dist1 = duplicates[mask1]\n",
    "dist2 = duplicates[mask2]\n",
    "\n",
    "# df, mean, std = t.fit(dist1['estimated_weight_g'])\n",
    "# df2, mean2, std2 = t.fit(dist2['estimated_weight_g'])\n",
    "# gt_df, gt_mean, gt_std = t.fit(gt_weights)\n",
    "mean, std = norm.fit(dist1['estimated_weight_g'])\n",
    "mean2, std2 = norm.fit(dist2['estimated_weight_g'])\n",
    "# gt_mean, gt_std = norm.fit(gt_weights)\n",
    "\n",
    "print(len(dist1), len(dist2))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.hist(dist1['estimated_weight_g'], color = 'blue', alpha = 0.5, density = True, bins = 30)\n",
    "plt.hist(dist2['estimated_weight_g'], color = 'red', alpha = 0.5, density = True, bins = 30)\n",
    "# plt.hist(gt_weights, color = 'red', alpha = 0.5, density = True, bins = 30)\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "#y = t.pdf(x, df, mean, std)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.plot(x, y)\n",
    "y2 = norm.pdf(x, mean2, std2)\n",
    "# plt.plot(x, y2)\n",
    "#plt.plot(x, y + 10 * (y - y2), color = 'green', linestyle = '-')\n",
    "\n",
    "new_x = x - 5 * (np.mean(dist1['estimated_weight_g']) - np.mean(dist2['estimated_weight_g']))\n",
    "plt.plot(new_x, y + 10 * (y - y2), color = 'red', linestyle = '-')\n",
    "\n",
    "# gt_x = np.linspace(xmin, xmax, 1000)\n",
    "# #gt_y = t.pdf(gt_x, gt_df, gt_mean, gt_std)\n",
    "# gt_y = norm.pdf(gt_x, gt_mean, gt_std)\n",
    "# plt.plot(gt_x, gt_y, color = 'black', linewidth = 4)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(dist1['estimated_weight_g'], color = 'blue', alpha = 0.5, density = True, bins = 30)\n",
    "# plt.hist(gt_weights, color = 'red', alpha = 0.5, density = True, bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "density, bins, _ = plt.hist(dist1['estimated_weight_g'] * (1 - loss_factor), alpha = 0, density = True, bins = 30)\n",
    "density2, bins, _ = plt.hist(dist2['estimated_weight_g'] * (1 - loss_factor), bins = bins, alpha = 0, density = True)\n",
    "\n",
    "print(density)\n",
    "\n",
    "bin_width = bins[1] - bins[0]\n",
    "\n",
    "factor = 0.5\n",
    "\n",
    "new_density = density + factor * (density - density2)\n",
    "new_density[new_density < 0] = 0\n",
    "\n",
    "_bins_adj = []\n",
    "for i, end_bin in enumerate(bins[1:]):\n",
    "    start_bin = bins[i]\n",
    "    _mask = (dist1['estimated_weight_g'] * (1 - loss_factor) > start_bin) & (dist1['estimated_weight_g'] * (1 - loss_factor) <= end_bin)\n",
    "    _bins_adj.append(np.mean(dist1['estimated_weight_g'][_mask] * (1 - loss_factor)))\n",
    "    \n",
    "#bins_adj = bins[1:] - bin_width / 2\n",
    "bins_adj = np.array(_bins_adj)\n",
    "\n",
    "factor2 = factor * -0.5\n",
    "#factor2 = 0\n",
    "\n",
    "new_bins_adj = bins_adj - factor2 * (np.mean(dist1['estimated_weight_g'] * (1 - loss_factor)) - np.mean(dist2['estimated_weight_g'] * (1 - loss_factor)))\n",
    "\n",
    "plt.bar(new_bins_adj, new_density, color = 'blue', alpha = 0.5, width = bin_width)\n",
    "# gt_density, gt_bins, _ = plt.hist(gt_weights, bins = bins, color = 'red', alpha = 0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(new_bins_adj, (density - density2) / np.sum(new_density), color = 'blue', alpha = 0.5, width = bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[1:])\n",
    "gt_pcts = [0, 0.0174, .1711, .3285, .2777, .1459, .0477, .0104, .0013, .0001]\n",
    "\n",
    "d1 = dist1['estimated_weight_g'] * (1 - loss_factor)\n",
    "d2 = dist2['estimated_weight_g'] * (1 - loss_factor)\n",
    "new_density_adj = new_density / np.sum(new_density)\n",
    "\n",
    "new_pcts = []\n",
    "pcts1 = []\n",
    "pcts2 = []\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "    mask2 = (d2 > buckets[i]) & (d2 <= buckets[i + 1])\n",
    "    mask_new = (new_bins_adj > buckets[i]) & (new_bins_adj <= buckets[i + 1])\n",
    "    gt_pct = gt_pcts[i]\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "\n",
    "    new_pcts.append(np.sum(new_density_adj[mask_new]))\n",
    "    pct1 = np.sum(mask1) / len(mask1)\n",
    "    pcts1.append(pct1)\n",
    "    pct2 = np.sum(mask2) / len(mask2)\n",
    "    pcts2.append(pct2)\n",
    "#     print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(new_density_adj[mask1]) - gt_pct, np.sum(new_density_adj[mask1]), gt_pct))\n",
    "\n",
    "pcts1 = np.array(pcts1)\n",
    "pcts2 = np.array(pcts2)\n",
    "\n",
    "gt_avg = 4944.34\n",
    "\n",
    "result = np.sum(new_bins_adj * new_density_adj) \n",
    "(result - gt_avg) / gt_avg\n",
    "print(result, gt_avg)\n",
    "print((result - gt_avg) / gt_avg)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(x_buckets - 300, new_pcts, color = 'orange', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets - 150, pcts1, color = 'red', width = 150, label = 'Original')\n",
    "plt.bar(x_buckets + 150, pcts2, color = 'blue', width = 150, label = 'Dedup')\n",
    "plt.bar(x_buckets + 300, 10 * (pcts1 - pcts2), color = 'purple', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets, gt_pcts, color = 'green', width = 150, label = 'Ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "pcts = [0, 0.0174, .1711, .3285, .2777, .1459, .0477, .0104, .0013, .0001]\n",
    "\n",
    "new_density_adj = new_density / np.sum(new_density)\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (new_bins_adj > buckets[i]) & (new_bins_adj <= buckets[i + 1])\n",
    "    pct2 = pcts[i]\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "    \n",
    "    print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(new_density_adj[mask1]) - pct2, np.sum(new_density_adj[mask1]), pct2))\n",
    "\n",
    "gt_avg = 3892\n",
    "\n",
    "result = np.sum(new_bins_adj * new_density_adj) \n",
    "(result - gt_avg) / gt_avg\n",
    "print(result, gt_avg)\n",
    "print((result - gt_avg) / gt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "pcts = [0, 0.0174, .1711, .3285, .2777, .1459, .0477, .0104, .0013, .0001]\n",
    "\n",
    "density_adj = density / np.sum(density)\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (new_bins_adj > buckets[i]) & (new_bins_adj <= buckets[i + 1])\n",
    "    pct2 = pcts[i]\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "    \n",
    "    print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(density_adj[mask1]) - pct2, np.sum(density_adj[mask1]), pct2))\n",
    "\n",
    "gt_avg = 3892\n",
    "\n",
    "result = np.sum(new_bins_adj * density_adj) \n",
    "(result - gt_avg) / gt_avg\n",
    "print(result, gt_avg)\n",
    "print((result - gt_avg) / gt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "pcts = [0, 0.0174, .1711, .3285, .2777, .1459, .0477, .0104, .0013, .0001]\n",
    "\n",
    "density_adj = density2 / np.sum(density2)\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (new_bins_adj > buckets[i]) & (new_bins_adj <= buckets[i + 1])\n",
    "    pct2 = pcts[i]\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "    \n",
    "    print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(density_adj[mask1]) - pct2, np.sum(density_adj[mask1]), pct2))\n",
    "\n",
    "gt_avg = 3892\n",
    "\n",
    "result = np.sum(new_bins_adj * density_adj) \n",
    "(result - gt_avg) / gt_avg\n",
    "print(result, gt_avg)\n",
    "print((result - gt_avg) / gt_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_new_pdf = y + 15 * (y - y2)\n",
    "_new_pdf[_new_pdf < 0] = 0\n",
    "new_pdf = _new_pdf / np.sum(_new_pdf)\n",
    "\n",
    "new_x = x - 7.5 * (np.mean(dist1['estimated_weight_g']) - np.mean(dist2['estimated_weight_g']))\n",
    "\n",
    "result = np.sum(new_x * new_pdf) \n",
    "(result - np.mean(gt_weights)) / np.mean(gt_weights)\n",
    "print(result, np.mean(dist1['estimated_weight_g']), np.mean(gt_weights))\n",
    "print((result - np.mean(gt_weights)) / np.mean(gt_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (new_x > buckets[i]) & (new_x <= buckets[i + 1])\n",
    "    mask2 = (gt_weights > buckets[i]) & (gt_weights <= buckets[i + 1])\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "    \n",
    "    print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(new_pdf[mask1]) - sum(mask2) / len(mask2), np.sum(new_pdf[mask1]), sum(mask2) / len(mask2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (dist1['estimated_weight_g'] > buckets[i]) & (dist1['estimated_weight_g'] <= buckets[i + 1])\n",
    "    mask2 = (gt_weights > buckets[i]) & (gt_weights <= buckets[i + 1])\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "    \n",
    "    print('%i: %0.2f, %0.2f vs %0.2f' % (buckets[i], sum(mask1) / len(mask1) - sum(mask2) / len(mask2), sum(mask1) / len(mask1), sum(mask2) / len(mask2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (dist2['estimated_weight_g'] > buckets[i]) & (dist2['estimated_weight_g'] <= buckets[i + 1])\n",
    "    mask2 = (gt_weights > buckets[i]) & (gt_weights <= buckets[i + 1])\n",
    "    \n",
    "    print('%i: %0.2f, %0.2f vs %0.2f' % (buckets[i], sum(mask1) / len(mask1) - sum(mask2) / len(mask2), sum(mask1) / len(mask1), sum(mask2) / len(mask2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (dist1['estimated_weight_g'] > buckets[i]) & (dist1['estimated_weight_g'] <= buckets[i + 1])\n",
    "    mask2 = (dist2['estimated_weight_g'] > buckets[i]) & (dist2['estimated_weight_g'] <= buckets[i + 1])\n",
    "#     mask_gt = (gt_weights > buckets[i]) & (gt_weights <= buckets[i + 1])\n",
    "    \n",
    "    print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], (sum(mask1) / len(mask1) - sum(mask2) / len(mask2)), sum(mask1) / len(mask1), sum(mask2) / len(mask2)))\n",
    "   # print('%i: %0.2f, %0.2f vs %0.2f' % (buckets[i], sum(mask1) / len(mask1) - sum(mask_gt) / len(mask_gt), sum(mask1) / len(mask1), sum(mask_gt) / len(mask_gt)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (dist1['estimated_weight_g'] > buckets[i]) & (dist1['estimated_weight_g'] <= buckets[i + 1])\n",
    "    mask2 = (dist2['estimated_weight_g'] > buckets[i]) & (dist2['estimated_weight_g'] <= buckets[i + 1])\n",
    "    mask_gt = (gt_weights > buckets[i]) & (gt_weights <= buckets[i + 1])\n",
    "    \n",
    "    print('%i: %0.2f, %0.2f vs %0.2f' % (buckets[i], sum(mask1) / len(mask1) - sum(mask_gt) / len(mask_gt) + 10 * (sum(mask1) / len(mask1) - sum(mask2) / len(mask2)), sum(mask1) / len(mask1) + 10 * (sum(mask1) / len(mask1) - sum(mask2) / len(mask2)), sum(mask_gt) / len(mask_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(dist1['estimated_weight_g']), mean, np.mean(dist2['estimated_weight_g']), np.mean(gt_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.mean(dist1['estimated_weight_g']) - np.mean(gt_weights)) / np.mean(gt_weights))\n",
    "print((np.mean(dist2['estimated_weight_g']) - np.mean(gt_weights)) / np.mean(gt_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 95\n",
    "df_start_date = '2020-07-21'\n",
    "df_end_date = '2020-07-24'\n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df2 = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df2 = extract_biomass_data(pen_id, df_start_date, df_end_date, 0.95)\n",
    "    # df = extract_biomass_data(pen_id, '2020-08-24', '2020-09-03', 0.99)\n",
    "\n",
    "    df2.date = pd.to_datetime(df2.date)\n",
    "#     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "    depths = []\n",
    "    new_lengths = []\n",
    "    for idx, row in df2.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "        depths.append(depth)\n",
    "        new_lengths.append(np.linalg.norm(vector))\n",
    "    df2['depth'] = depths\n",
    "    df2['new_lengths'] = new_lengths\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df2 } }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df2.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 = df2[((df2.hour >= 5) & (df2.hour <= 15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[((df2.hour >= 5) & (df2.hour <= 15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = df2['estimated_weight_g']\n",
    "e2 = df2.estimated_weight_g[df2.depth > np.percentile(df2.depth, 75)]\n",
    "e4 = np.concatenate([e1[e1 < np.median(e2)], np.median(e2) + (np.median(e2) - e1[e1 < np.median(e2)])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.mean(e1) * (1 - 0.1753)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a1 - 4949) / 4949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 167\n",
    "df_start_date = '2020-10-20'\n",
    "df_end_date = '2020-10-23'\n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df2 = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df2 = extract_biomass_data(pen_id, df_start_date, df_end_date, 0.95)\n",
    "    # df = extract_biomass_data(pen_id, '2020-08-24', '2020-09-03', 0.99)\n",
    "\n",
    "    df2.date = pd.to_datetime(df2.date)\n",
    "#     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "    depths = []\n",
    "    new_lengths = []\n",
    "    for idx, row in df2.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "        depths.append(depth)\n",
    "        new_lengths.append(np.linalg.norm(vector))\n",
    "    df2['depth'] = depths\n",
    "    df2['new_lengths'] = new_lengths\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df2 } }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(df2.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[((df2.hour >= 7) & (df2.hour <= 12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = df2['estimated_weight_g']\n",
    "e2 = df2.estimated_weight_g[df2.depth > np.percentile(df2.depth, 75)]\n",
    "e4 = np.concatenate([e1[e1 < np.median(e2)], np.median(e2) + (np.median(e2) - e1[e1 < np.median(e2)])])\n",
    "\n",
    "print(np.mean(e1), np.mean(e1) * (1 - 0.18), np.mean(e4) * (1 - 0.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4192 - 4330) / 4330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ]\n",
    "\n",
    "\n",
    "# new_pcts = []\n",
    "pcts1 = []\n",
    "pcts2 = []\n",
    "pcts3 = []\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (e1 > buckets[i]) & (e1 <= buckets[i + 1])\n",
    "    mask2 = (e2 > buckets[i]) & (e2 <= buckets[i + 1])\n",
    "    mask3 = (e4 > buckets[i]) & (e4 <= buckets[i + 1])\n",
    "    gt_pct = gt_pcts[i]\n",
    "\n",
    "    pct1 = np.sum(mask1) / len(mask1)\n",
    "    pcts1.append(pct1)\n",
    "    pct2 = np.sum(mask2) / len(mask2)\n",
    "    pcts2.append(pct2)\n",
    "    pct3 = np.sum(mask3) / len(mask3)\n",
    "    pcts3.append(pct3)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "# plt.bar(x_buckets - 300, new_pcts, color = 'orange', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets - 150, pcts1, color = 'red', width = 150, label = 'Original')\n",
    "plt.bar(x_buckets + 300, pcts2, color = 'blue', width = 150, label = 'Dedup')\n",
    "plt.bar(x_buckets + 150, pcts3, color = 'purple', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets, gt_pcts, color = 'green', width = 150, label = 'Ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
