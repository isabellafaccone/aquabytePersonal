{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen5 = pd.read_csv('blom_vikane_singleweights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pen5.weight * 1000 / .83), np.std(pen5.weight * 1000 / .83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_from_weight(weight):\n",
    "    return y ** (1/3) / 23.6068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pen_id = 95\n",
    "# df_start_date = '2020-07-21'\n",
    "# df_end_date = '2020-07-24'\n",
    "pen_id = 60\n",
    "df_start_date = '2020-08-24'\n",
    "df_end_date = '2020-08-26'\n",
    "\n",
    "if pen_id in queryCache and df_start_date in queryCache[pen_id] and df_end_date in queryCache[pen_id][df_start_date]:\n",
    "    df = queryCache[pen_id][df_start_date][df_end_date]\n",
    "else:\n",
    "    df = extract_biomass_data(pen_id, df_start_date, df_end_date, 0.01)\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "\n",
    "    depths = []\n",
    "    lengths = []\n",
    "    for idx, row in df.iterrows():\n",
    "        ann, cm = row.annotation, row.camera_metadata\n",
    "        wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "        depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "        vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "        depths.append(depth)\n",
    "        lengths.append(np.linalg.norm(vector))\n",
    "    df['depth'] = depths\n",
    "    df['length'] = lengths\n",
    "    \n",
    "    queryCache[pen_id] = { df_start_date: { df_end_date: df } }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.hour, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "pen5['length'] = (pen5['weight'] * 1000 / 0.83) ** (1/3) / 23.6068\n",
    "\n",
    "avg_weight, raw_weight = get_weight_for_fov(55, 10, pen5)\n",
    "\n",
    "# counts, bins, _ = plt.hist(pen5.weight * 1000 / 0.83, bins = 50, density = True)\n",
    "counts, bins, _ = plt.hist(np.array(raw_weight) * 1000 / 0.83, bins = 50, density = True)\n",
    "plt.hist(df.estimated_weight_g[mask2], bins = bins, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weight2, raw_weight2 = get_weight_for_fov(55, 5, pen5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weight3, raw_weight3 = get_weight_for_fov(55, 6, pen5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weight4, raw_weight4 = get_weight_for_fov(55, 7, pen5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "\n",
    "counts, bins, _ = plt.hist(df.estimated_weight_g[mask2], bins = 20, density = True, alpha = 0.5, color = 'red')\n",
    "plt.hist(np.array(raw_weight2) * 1000 / 0.83, bins = bins, density = True, alpha = 0.5, color = 'blue')\n",
    "\n",
    "print(np.mean(np.array(raw_weight2) * 1000 / 0.83), np.mean(df.estimated_weight_g[mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, percentileofscore\n",
    "from statsmodels.sandbox.distributions.extras import pdf_mvsk\n",
    "\n",
    "# res = stats.probplot(pen5.weight, dist=stats.norm, plot=plt)\n",
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "\n",
    "# res = stats.probplot(df.estimated_weight_g[mask2], dist=stats.norm, plot=plt)\n",
    "# res = stats.probplot(raw_weight2, dist=stats.norm, plot=plt)\n",
    "# res = stats.probplot(pen5.weight, dist=stats.t, sparams=100, plot=plt)\n",
    "# res = stats.probplot(sinh_archsinh_transformation(Î©, 0, -.01), dist=stats.norm, plot=plt)\n",
    "# https://github.com/gregversteeg/gaussianize\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "vec = np.arange(start=-3,stop=3+0.001,step=0.001)\n",
    "# vec2 = vec * np.std(pen5.weight) + np.mean(pen5.weight)\n",
    "vec2 = np.arange(start=0, stop = 10000, step = .01)\n",
    "vec3 = np.arange(start=0, stop = 10, step = .01)\n",
    "# dist = sinh_archsinh_transformation(vec, 0, -.05)\n",
    "my_dist = pdf_mvsk([0, 1, 0, 1])\n",
    "dist = my_dist(vec)\n",
    "cdf = np.cumsum(dist)\n",
    "cdf = cdf / cdf[-1]\n",
    "dist2 = norm.pdf(vec)\n",
    "\n",
    "my_dist2 = pdf_mvsk([np.mean(pen5.weight) * 1000 / .83, (np.std(df.estimated_weight_g[mask2]) / 1.06) ** 2, 0, 1])\n",
    "# my_dist2 = pdf_mvsk([np.mean(pen5.weight) * 1000 / .83, np.std(pen5.weight * 1000 / .83) ** 2, 0, 1])\n",
    "dist3 = my_dist2(vec2)\n",
    "\n",
    "my_dist3 = pdf_mvsk([np.mean(pen5.weight), np.std(pen5.weight) ** 2, 0, 1])\n",
    "dist4 = my_dist3(vec3)\n",
    "\n",
    "for i in np.arange(1, 99, 1):\n",
    "    x.append(np.percentile(pen5.weight, i))\n",
    "    y.append(np.percentile(vec, percentileofscore(cdf, i / 100)))\n",
    "    \n",
    "# plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "X = x\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "plt.plot(x, results.predict(X), color = 'red')\n",
    "# plt.plot(vec, dist)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist((pen5.weight - np.mean(pen5.weight)) / np.std(pen5.weight), density = True, bins = 50)\n",
    "plt.plot(vec, dist)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(pen5.weight, density = True, bins = 50)\n",
    "plt.plot(vec3, dist4)\n",
    "# plt.plot(vec, dist2, color = 'green')\n",
    "\n",
    "# def sinh_archsinh_transformation(x,epsilon,delta):\n",
    "#     return norm.pdf(np.sinh(delta*np.arcsinh(x)-epsilon))*delta*np.cosh(delta*np.arcsinh(x)-epsilon)/np.sqrt(1+np.power(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(pen5.weight * 1000 / .83, density = True, alpha = 0.5, bins = 50)\n",
    "# plt.hist(df.estimated_weight_g[mask2], density = True, alpha = 0.5, bins = 50)\n",
    "plt.plot(vec2, stats.norm.pdf(vec2, *stats.norm.fit(pen5.weight * 1000 / .83)), color = 'red')\n",
    "plt.plot(vec2, dist3, lw = 4, color = 'green')\n",
    "\n",
    "print(np.std(df.estimated_weight_g[mask2]), np.std(pen5.weight * 1000 / .83), np.std(df.estimated_weight_g[mask2]) / np.std(pen5.weight * 1000 / .83), np.mean(df.estimated_weight_g[mask2]) / np.mean(pen5.weight * 1000 / .83))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "\n",
    "counts, bins, _ = plt.hist(df.estimated_weight_g[mask2], bins = 20, density = True, alpha = 0.5, color = 'red')\n",
    "plt.hist(np.array(raw_weight4) * 1000 / 0.83, bins = bins, density = True, alpha = 0.5, color = 'blue')\n",
    "\n",
    "print(np.mean(np.array(raw_weight4) * 1000 / 0.83), np.mean(df.estimated_weight_g[mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "\n",
    "counts, bins, _ = plt.hist(df.estimated_weight_g[mask2], bins = 20, density = True, alpha = 0.5, color = 'red')\n",
    "plt.hist(np.array(raw_weight3) * 1000 / 0.83, bins = bins, density = True, alpha = 0.5, color = 'blue')\n",
    "\n",
    "print(np.mean(np.array(raw_weight3) * 1000 / 0.83), np.mean(df.estimated_weight_g[mask2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "smart_pcts = [0.0 ,\n",
    "0.010945273631840797 ,\n",
    "0.06998341625207297 ,\n",
    "0.35190713101160864 ,\n",
    "0.417910447761194 ,\n",
    "0.12802653399668326 ,\n",
    "0.020895522388059702 ,\n",
    "0.0003316749585406302 ,\n",
    "0.0 ,\n",
    "0.0]\n",
    "\n",
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "d4 = df.estimated_weight_g[mask2]\n",
    "d2 = np.array(raw_weight2) * 1000 / 0.83\n",
    "d3 = pen5.weight * 1000 / 0.83\n",
    "\n",
    "pcts1 = []\n",
    "pcts2 = []\n",
    "pcts3 = []\n",
    "pcts4 = []\n",
    "\n",
    "errors1 = []\n",
    "errors2 = []\n",
    "errors3 = []\n",
    "errors4 = []\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (d4 > buckets[i]) & (d4 <= buckets[i + 1])\n",
    "    mask2 = (d2 > buckets[i]) & (d2 <= buckets[i + 1])\n",
    "    mask3 = (d3 > buckets[i]) & (d3 <= buckets[i + 1])\n",
    "    \n",
    "    pct1 = np.sum(mask1) / len(mask1)\n",
    "    pcts1.append(pct1)\n",
    "    pct2 = np.sum(mask2) / len(mask2)\n",
    "    pcts2.append(pct2)\n",
    "    pct3 = np.sum(mask3) / len(mask3)\n",
    "    pcts3.append(pct3)\n",
    "    \n",
    "    print(pct3)\n",
    "    \n",
    "    pct4 = np.sum(dist3[(vec2 > buckets[i]) & (vec2 <= buckets[i + 1])]) / np.sum(dist3)\n",
    "    pcts4.append(pct4)\n",
    "    \n",
    "    errors1.append(np.abs(100 * (pct1 - pct2)))\n",
    "    errors2.append(np.abs(100 * (pct1 - pct3)))\n",
    "    errors3.append(np.abs(100 * (smart_pcts[i] - pct2)))\n",
    "    errors4.append(np.abs(100 * (pct4 - pct3)))\n",
    "    \n",
    "#     print('%i: %0.2f%%' % (buckets[i], 100 * (pct4 - pct3)))\n",
    "\n",
    "print(np.max(errors1), np.max(errors2), np.max(errors3), np.max(errors4))\n",
    "print(np.mean(errors1), np.mean(errors2), np.mean(errors3), np.mean(errors4))\n",
    "print((np.mean(d3) - np.mean(d4)), np.mean(d2) - np.mean(d4))\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(x_buckets - 150, pcts1, color = 'red', width = 150, label = 'Original')\n",
    "plt.bar(x_buckets, pcts2, color = 'blue', width = 150, label = 'Dedup')\n",
    "plt.bar(x_buckets + 150, pcts3, color = 'green', width = 150, label = 'Original')\n",
    "plt.bar(x_buckets + 300, pcts4, color = 'purple', width = 150, label = 'Original')\n",
    "# plt.bar(x_buckets + 300, smart_pcts, color = 'purple', width = 150, label = 'Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pct = []\n",
    "y_pct = []\n",
    "\n",
    "for i in np.arange(1, 99, 1):\n",
    "    x_pct.append(np.percentile(df.estimated_weight_g[mask2], i))\n",
    "    y_pct.append(np.percentile(np.array(raw_weight2) * 1000 / 0.83, i))\n",
    "    \n",
    "plt.scatter(x_pct, y_pct)\n",
    "plt.plot(x_pct, x_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = (df.hour >= 5) & (df.hour <= 15)\n",
    "counts, bins, _ = plt.hist(pen5.weight * 1000 / 0.83, bins = 30, density = True, alpha = 0.5, color = 'green')\n",
    "plt.hist(df.estimated_weight_g[mask2] + 170, bins = bins, density = True, alpha = 0.5, color = 'red')\n",
    "np.mean(pen5.weight * 1000 / 0.83), np.mean(df.estimated_weight_g[mask2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pct = []\n",
    "y_pct = []\n",
    "\n",
    "for i in np.arange(1, 99, 1):\n",
    "    x_pct.append(np.percentile(df.estimated_weight_g[mask2], i))\n",
    "    y_pct.append(np.percentile(pen5.weight * 1000 / 0.83, i))\n",
    "    \n",
    "plt.scatter(x_pct, y_pct)\n",
    "plt.plot(x_pct, x_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(pen5.weight * 1000 / 0.83, bins = 50, density = True, alpha = 0.5, color = 'green')\n",
    "plt.hist(np.array(raw_weight2) * 1000 / 0.83, bins = bins, density = True, alpha = 0.5, color = 'blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(pen5.weight * 1000 / 0.83, bins = 50, density = True, alpha = 0.5, color = 'green')\n",
    "plt.hist(np.array(raw_weight) * 1000 / 0.83, bins = bins, density = True, alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bins, _ = plt.hist(pen5.weight * 1000 / 0.83, bins = 50, density = True, alpha = 0.5, color = 'green')\n",
    "plt.hist(df.estimated_weight_g[mask2], bins = bins, density = True, alpha = 0.5, color = 'red')\n",
    "np.mean(pen5.weight * 1000 / 0.83), np.mean(df.estimated_weight_g[mask2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_for_fov(degrees, density, df):\n",
    "    fov = degrees * np.pi / 180\n",
    "    params_depth = 2\n",
    "    camera_location = 5\n",
    "    total_length = 10\n",
    "\n",
    "    all_weights = []\n",
    "\n",
    "    num_samples = int(total_length * density)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while(len(all_weights) < 3000 and count < 20000):\n",
    "        count = count + 1\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "\n",
    "        results = df.sample(n = num_samples, replace = True)\n",
    "\n",
    "        x = []\n",
    "\n",
    "        for index, row in results.iterrows():\n",
    "            location = np.random.uniform(0, total_length)\n",
    "            depth = np.random.uniform(0, params_depth)\n",
    "\n",
    "            x.append([location, row.length, depth, row.weight])\n",
    "            #x.append([location, row.length, depth, row.estimated_weight_g])\n",
    "\n",
    "        a = np.array(x)\n",
    "        b = a[np.argsort(a[:, 2])]\n",
    "\n",
    "        all_segments = []\n",
    "        curr_segments = []\n",
    "        curr_depth = 0\n",
    "\n",
    "        for row in b:\n",
    "            curr_depth = row[2]\n",
    "\n",
    "            band = np.tan(fov / 2) * curr_depth\n",
    "\n",
    "            lower_bound = camera_location - band\n",
    "            upper_bound = camera_location + band\n",
    "            \n",
    "            if not ((row[0] > lower_bound) and (row[0] + row[1] < upper_bound)):\n",
    "                if (row[0] > lower_bound) and (row[0] < upper_bound):\n",
    "                    all_segments.append(row)\n",
    "                elif ((row[0] + row[1]) > lower_bound) and ((row[0] + row[1]) < upper_bound):\n",
    "                    all_segments.append(row)\n",
    "                continue\n",
    "\n",
    "            is_occluded = False\n",
    "\n",
    "            for seg in all_segments:\n",
    "                lower_adj_segment = camera_location + (row[0] - camera_location) * curr_depth / seg[2]\n",
    "                upper_adj_segment = camera_location + ((row[0] + row[1]) - camera_location) * curr_depth / seg[2]\n",
    "\n",
    "                if not ((row[0] + row[1]) < lower_adj_segment or row[0] > upper_adj_segment):\n",
    "                    is_occluded = True\n",
    "\n",
    "            if not is_occluded:\n",
    "                all_weights.append(row[3])\n",
    "                \n",
    "            all_segments.append(row)\n",
    "\n",
    "    return np.mean(all_weights), all_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = []\n",
    "weights = []\n",
    "raw_weights = []\n",
    "\n",
    "for degree in np.arange(10, 180, 10):\n",
    "    avg_weight, raw_weight = get_weight_for_fov(degree)\n",
    "    fovs.append(degree)\n",
    "    weights.append(avg_weight)\n",
    "    raw_weights.append(raw_weight)\n",
    "    print(degree, avg_weight, len(raw_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = []\n",
    "weights = []\n",
    "raw_weights = []\n",
    "\n",
    "for density in np.arange(0.25, 5, 0.25):\n",
    "    avg_weight, raw_weight = get_weight_for_fov(55, density)\n",
    "    fovs.append(density)\n",
    "    weights.append(avg_weight)\n",
    "    raw_weights.append(raw_weight)\n",
    "    print(density, avg_weight, len(raw_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, density in enumerate(np.arange(8, 20, 2)):\n",
    "    print(density, weights[index], len(raw_weights[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "counts, bins, _ = plt.hist(df.estimated_weight_g, density = True, alpha = 0.5, color = 'red', bins = 20)\n",
    "counts2, bins, _ = plt.hist(raw_weights[3], density = True, alpha = 0.5, color = 'blue', bins = bins)\n",
    "\n",
    "(np.array(counts2) / np.sum(counts)) / (np.array(counts) / np.sum(counts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mean, std = stats.norm.fit(df.estimated_weight_g)\n",
    "mean2, std2 = stats.norm.fit(raw_weights[3])\n",
    "\n",
    "print(mean, std)\n",
    "\n",
    "# stats.probplot(raw_weights[3], plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df.estimated_weight_g, plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    mean, std = stats.norm.fit(raw_weights[i])\n",
    "    print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5632.671352371154 / 5483.3882774105505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1098.5482565591922 / 1025.0008784912347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_weights[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(raw_weights[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 5, 1), weights / np.mean(df.estimated_weight_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5500 / 5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_weights), np.mean(df.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_weights) / np.mean(df.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fovs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fovs, np.array(weights) / np.mean(df.estimated_weight_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
