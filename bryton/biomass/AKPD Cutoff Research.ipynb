{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from filter_optimization.filter_optimization_task import extract_biomass_data, _add_date_hour_columns\n",
    "from research.weight_estimation.keypoint_utils.optics import euclidean_distance, pixel2world, depth_from_disp, convert_to_world_point\n",
    "\n",
    "from research.utils.data_access_utils import S3AccessUtils, RDSAccessUtils\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(pen_id, start_date, end_date, akpd_cutoff):\n",
    "    if pen_id in queryCache and start_date in queryCache[pen_id] and end_date in queryCache[pen_id][start_date] and akpd_cutoff in queryCache[pen_id][start_date][end_date]:\n",
    "        df = queryCache[pen_id][start_date][end_date][akpd_cutoff]\n",
    "    else:\n",
    "        df = extract_biomass_data(pen_id, start_date, df_end_date, akpd_cutoff)\n",
    "\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "    #     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "        depths = []\n",
    "        new_lengths = []\n",
    "        for idx, row in df.iterrows():\n",
    "            ann, cm = row.annotation, row.camera_metadata\n",
    "            wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "            depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "            vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "            depths.append(depth)\n",
    "            new_lengths.append(np.linalg.norm(vector))\n",
    "        df['depth'] = depths\n",
    "        df['new_lengths'] = new_lengths\n",
    "\n",
    "        queryCache[pen_id] = { start_date: { end_date: { akpd_cutoff: df } } }\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCache2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDS = RDSAccessUtils(json.load(open(os.environ['DATA_WAREHOUSE_SQL_CREDENTIALS'])))\n",
    "\n",
    "def get_df2(pen_id, group_id, start_date, end_date, akpd_cutoff):\n",
    "    if pen_id in queryCache2 and start_date in queryCache2[pen_id] and end_date in queryCache2[pen_id][start_date] and akpd_cutoff in queryCache2[pen_id][start_date][end_date]:\n",
    "        df = queryCache2[pen_id][start_date][end_date][akpd_cutoff]\n",
    "    else:\n",
    "        query = '''\n",
    "        SELECT * FROM\n",
    "            prod.biomass_computations bc\n",
    "            WHERE bc.pen_id={}\n",
    "            AND bc.group_id ='{}'\n",
    "            AND bc.akpd_score >= {}\n",
    "            AND bc.captured_at BETWEEN '{}' and '{}'\n",
    "            AND bc.estimated_weight_g > 0.0\n",
    "        '''.format(pen_id, group_id, akpd_cutoff, start_date, end_date)\n",
    "\n",
    "        df = RDS.extract_from_database(query)\n",
    "        df = df.loc[:, ~df.columns.duplicated()]\n",
    "        df = _add_date_hour_columns(df)\n",
    "\n",
    "        df.date = pd.to_datetime(df.date)\n",
    "    #     df['week'] = df.date.apply(lambda x: x.weekofyear)\n",
    "\n",
    "        depths = []\n",
    "        new_lengths = []\n",
    "        for idx, row in df.iterrows():\n",
    "            ann, cm = row.annotation, row.camera_metadata\n",
    "            wkps = pixel2world(ann['leftCrop'], ann['rightCrop'], cm)\n",
    "            depth = np.median([wkp[1] for wkp in wkps.values()])\n",
    "            vector = wkps['UPPER_LIP'] - wkps['TAIL_NOTCH']\n",
    "            depths.append(depth)\n",
    "            new_lengths.append(np.linalg.norm(vector))\n",
    "        df['depth'] = depths\n",
    "        df['new_lengths'] = new_lengths\n",
    "\n",
    "        queryCache2[pen_id] = { start_date: { end_date: { akpd_cutoff: df } } }\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 60\n",
    "start_date = '2020-08-21'\n",
    "end_date = '2020-08-25'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.hist(df.hour, bins = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "mask = df.akpd_score > 0.01\n",
    "\n",
    "plt.scatter(df[mask].estimated_weight_g, df[mask].akpd_score)\n",
    "\n",
    "X = df[mask][['estimated_weight_g', 'depth']]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(df[mask].akpd_score, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen5 = pd.read_csv('blom_vikane_singleweights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 60\n",
    "start_date = '2020-08-21'\n",
    "end_date = '2020-08-25'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "mask = (df.hour >= 7) & (df.hour <= 17)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 3490\n",
    "\n",
    "loss_factor = 0.17\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        gt_mask = (pen5.weight > buckets[i] / 1000) & (pen5.weight <= buckets[i + 1] / 1000)\n",
    "        gt_pct = np.sum(gt_mask) / len(gt_mask)\n",
    "        errors1.append(pct1 - gt_pct)\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append((np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Vikane Pen 5 - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 186\n",
    "start_date = '2020-10-26'\n",
    "end_date = '2020-10-29'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "mask = (df.hour >= 6) & (df.hour <= 14)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 4550\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append((np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "# plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Varholmen Pen 12 - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 124\n",
    "start_date = '2020-09-23'\n",
    "end_date = '2020-09-27'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "# mask = (df.hour >= 6) & (df.hour <= 15)\n",
    "\n",
    "# df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 5326\n",
    "\n",
    "loss_factor = 0\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append((np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "# plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Mowi Huenquillahue Pen 1 - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 125\n",
    "start_date = '2020-09-25'\n",
    "end_date = '2020-09-29'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "# mask = (df.hour >= 6) & (df.hour <= 15)\n",
    "\n",
    "# df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 5237\n",
    "\n",
    "loss_factor = 0\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append((np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "# plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Mowi Huenquillahue Pen 2 - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 143\n",
    "start_date = '2020-10-13'\n",
    "end_date = '2020-10-17'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "# mask = (df.hour >= 6) & (df.hour <= 15)\n",
    "\n",
    "# df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0.01, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 3440\n",
    "\n",
    "loss_factor = 0.13\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append((np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "# plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Grieg Dale - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 164\n",
    "start_date = '2020-09-27'\n",
    "end_date = '2020-10-01'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "mask = (df.hour >= 6) & (df.hour <= 15)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, .0062, .2281, .6490, .1143, .0023, .0001, 0, 0, 0 ] \n",
    "\n",
    "gt_avg_weight = 3365.32\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append(np.abs(np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Eldviktaren - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 116\n",
    "start_date = '2020-10-26'\n",
    "end_date = '2020-10-30'\n",
    "\n",
    "df = get_df(pen_id, start_date, end_date, 0)\n",
    "\n",
    "mask = (df.hour >= 7) & (df.hour <= 15)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, 0, .0055, .0410, .1686, .3253, .2729, .1323, .0411, .0133]\n",
    "\n",
    "gt_avg_weight = 5860\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append(np.abs(np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "# plt.plot(percentages, errors)\n",
    "plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Slapoya - AKPD Cutoff vs Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.akpd_score > 0.01]\n",
    "np.max(df1.estimated_weight_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_id = 151\n",
    "start_date = '2020-10-08'\n",
    "end_date = '2020-10-12'\n",
    "\n",
    "df = get_df2(pen_id, '151-ENGALL-1455', start_date, end_date, 0)\n",
    "\n",
    "mask = (df.hour >= 7) & (df.hour <= 17)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "akpd_cutoffs = np.arange(0, 1, 0.01)\n",
    "\n",
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, 0.0039, .0216, .1490, .3591, .3284, .1163, .0200, .0016, .0001]\n",
    "\n",
    "gt_avg_weight = 4932.62\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "percentages = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "errors01 = []\n",
    "errors95 = []\n",
    "\n",
    "for akpd_cutoff in akpd_cutoffs:\n",
    "    d1 = df.estimated_weight_g[df.akpd_score >= akpd_cutoff] * (1 - loss_factor)\n",
    "    errors1 = []\n",
    "    for i in range(len(buckets) - 1):\n",
    "        mask1 = (d1 > buckets[i]) & (d1 <= buckets[i + 1])\n",
    "        pct1 = np.sum(mask1) / len(mask1)\n",
    "        errors1.append(pct1 - gt_pcts[i])\n",
    "        \n",
    "        if np.abs(akpd_cutoff - 0.01) < .001:\n",
    "            errors01.append(pct1)\n",
    "        elif np.abs(akpd_cutoff - 0.95) < .001:\n",
    "            errors95.append(pct1)\n",
    "    percentages.append(len(d1) / len(df))\n",
    "#     print(len(d1) / len(df))\n",
    "    errors.append(np.mean(np.abs(np.array(errors1))))\n",
    "    mean_errors.append(np.abs(np.mean(d1) - gt_avg_weight) / gt_avg_weight)\n",
    "    if np.abs(akpd_cutoff - 0.01) < .001:\n",
    "        print(akpd_cutoff, len(d1))\n",
    "    elif np.abs(akpd_cutoff - 0.95) < .001:\n",
    "        print(akpd_cutoff, len(d1))\n",
    "\n",
    "# plt.plot(percentages, errors)\n",
    "plt.plot(akpd_cutoffs, errors, label = 'Distribution Error')\n",
    "plt.plot(akpd_cutoffs, mean_errors, label = 'Avg Weight Error')\n",
    "plt.xlabel('AKPD Cutoff')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Varholmen P5 - AKPD Cutoff vs Error')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(x_buckets - 300, errors01, color = 'orange', width = 150, label = 'AKPD = 0.01')\n",
    "plt.bar(x_buckets - 150, errors95, color = 'red', width = 150, label = 'AKPD = 0.95')\n",
    "plt.bar(x_buckets, gt_pcts, color = 'green', width = 150, label = 'Ground truth')\n",
    "plt.legend()\n",
    "\n",
    "# for index, akpd_cutoff in enumerate(akpd_cutoffs):\n",
    "#     print(akpd_cutoff, mean_errors[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "x_buckets = np.array(buckets[:-1])\n",
    "gt_pcts = [0, 0, .0055, .0410, .1686, .3253, .2729, .1323, .0411, .0133]\n",
    "\n",
    "loss_factor = 0.16\n",
    "\n",
    "d1 = df['estimated_weight_g'] * (1 - loss_factor)\n",
    "d2 = df2['estimated_weight_g'] * (1 - loss_factor)\n",
    "d3 = df3['estimated_weight_g'] * (1 - loss_factor)\n",
    "# d2 = df.estimated_weight_g[df.depth > np.percentile(df.depth, 75)] * (1 - loss_factor)\n",
    "# d3 = np.concatenate([d1[d1 < np.mean(d2)], np.mean(d2) + (np.mean(d2) - d1[d1 < np.mean(d2)])])\n",
    "# d4 = np.concatenate([d1[d1 < np.median(d2)], np.median(d2) + (np.median(d2) - d1[d1 < np.median(d2)])])\n",
    "# d2 = dist2['estimated_weight_g'] * (1 - loss_factor)\n",
    "# new_density_adj = new_density / np.sum(new_density)\n",
    "\n",
    "print(np.mean(d1), np.mean(d2), np.mean(d3), np.mean(d4))\n",
    "\n",
    "# new_pcts = []\n",
    "pcts1 = []\n",
    "pcts2 = []\n",
    "pcts3 = []\n",
    "\n",
    "for i in range(len(buckets) - 1):\n",
    "    mask1 = (d4 > buckets[i]) & (d4 <= buckets[i + 1])\n",
    "    mask2 = (d2 > buckets[i]) & (d2 <= buckets[i + 1])\n",
    "    mask3 = (d3 > buckets[i]) & (d3 <= buckets[i + 1])\n",
    "#     mask_new = (new_bins_adj > buckets[i]) & (new_bins_adj <= buckets[i + 1])\n",
    "    gt_pct = gt_pcts[i]\n",
    "#     dist = dist1['estimated_weight_g'][mask1]\n",
    "#     gt = gt_weights[mask2]\n",
    "\n",
    "#     new_pcts.append(np.sum(new_density_adj[mask_new]))\n",
    "    pct1 = np.sum(mask1) / len(mask1)\n",
    "    pcts1.append(pct1)\n",
    "    pct2 = np.sum(mask2) / len(mask2)\n",
    "    pcts2.append(pct2)\n",
    "    pct3 = np.sum(mask3) / len(mask3)\n",
    "    pcts3.append(pct3)\n",
    "#     print('%i: %0.3f, %0.3f vs %0.3f' % (buckets[i], np.sum(new_density_adj[mask1]) - gt_pct, np.sum(new_density_adj[mask1]), gt_pct))\n",
    "\n",
    "# pcts1 = np.array(pcts1)\n",
    "# pcts2 = np.array(pcts2)\n",
    "\n",
    "# gt_avg = 4944.34\n",
    "\n",
    "# result = np.sum(new_bins_adj * new_density_adj) \n",
    "# (result - gt_avg) / gt_avg\n",
    "# print(result, gt_avg)\n",
    "# print((result - gt_avg) / gt_avg)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "# plt.bar(x_buckets - 300, new_pcts, color = 'orange', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets - 150, pcts1, color = 'red', width = 150, label = 'Original')\n",
    "plt.bar(x_buckets + 300, pcts2, color = 'blue', width = 150, label = 'Dedup')\n",
    "plt.bar(x_buckets + 150, pcts3, color = 'purple', width = 150, label = 'Dedup diff')\n",
    "plt.bar(x_buckets, gt_pcts, color = 'green', width = 150, label = 'Ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
