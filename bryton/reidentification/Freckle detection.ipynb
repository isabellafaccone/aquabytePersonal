{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation  \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/root/data/small_pen_data_collection/freckles.csv', names=['id', 'file', 'eye_coordinate', 'freckle_coordinates'])\n",
    "df = pd.read_csv('/root/data/reidentification/freckles.csv', names=['id', 'file', 'eye_coordinate', 'freckle_coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_counts():\n",
    "    fish_ids = np.unique(df['id'])\n",
    "\n",
    "    id_count = {}\n",
    "\n",
    "    for id in fish_ids:\n",
    "        coordinates = df[df['id'] == id]['freckle_coordinates']\n",
    "        non_zero_coordinates = [coordinate for coordinate in coordinates if len(json.loads(coordinate)) > 0]\n",
    "        avg_coordinate_length = np.mean([ len(json.loads(coordinate)) for coordinate in non_zero_coordinates])\n",
    "        coordinate_10 = np.percentile([ len(json.loads(coordinate)) for coordinate in non_zero_coordinates], 10)\n",
    "        coordinate_90 = np.percentile([ len(json.loads(coordinate)) for coordinate in non_zero_coordinates], 90)\n",
    "        id_count[id] = (len(df[df['id'] == id]), avg_coordinate_length, coordinate_10, coordinate_90)\n",
    "        \n",
    "        print('%i, %i, %i, %i' % (id, avg_coordinate_length, coordinate_10, coordinate_90))\n",
    "\n",
    "    return id_count\n",
    "\n",
    "get_id_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_fish = df[df['id'] == 181016010007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for datum in same_fish:\n",
    "\n",
    "datum = same_fish.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_coordinate = json.loads(datum['eye_coordinate'])\n",
    "freckle_coordinates = json.loads(datum['freckle_coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(freckle_coordinates)\n",
    "\n",
    "components = pca.components_\n",
    "\n",
    "newEyeCoordinates = np.dot(eye_coordinate, components.T)\n",
    "newFreckleCoordinates = np.dot(freckle_coordinates, components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newEyeCoordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativeCoordinates = newFreckleCoordinates - newEyeCoordinates\n",
    "\n",
    "mean = np.mean(relativeCoordinates, axis=0)\n",
    "stdev = np.std(relativeCoordinates, axis=0)\n",
    "\n",
    "normalizedCoordinates = (relativeCoordinates - mean) / stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(normalizedCoordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb;\n",
    "\n",
    "def generate_data(n_clusters, lower_thresh, higher_thresh):\n",
    "    data = None\n",
    "    ids = []\n",
    "\n",
    "    for index, datum in df.iterrows():\n",
    "        if index % 500 == 0:\n",
    "            print('Processing %i out of %i' % (index, len(df)))\n",
    "            \n",
    "        eye_coordinate = json.loads(datum['eye_coordinate'])\n",
    "        freckle_coordinates = json.loads(datum['freckle_coordinates'])\n",
    "\n",
    "        if len(freckle_coordinates) < lower_thresh or len(freckle_coordinates) > higher_thresh:\n",
    "            continue\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "\n",
    "        pca.fit(freckle_coordinates)\n",
    "\n",
    "        components = pca.components_\n",
    "\n",
    "        newEyeCoordinates = np.dot(eye_coordinate, components.T)\n",
    "        newFreckleCoordinates = np.dot(freckle_coordinates, components.T)\n",
    "\n",
    "        relativeCoordinates = newFreckleCoordinates - newEyeCoordinates\n",
    "\n",
    "        mean = np.mean(relativeCoordinates, axis=0)\n",
    "        stdev = np.std(relativeCoordinates, axis=0)\n",
    "\n",
    "        normalizedCoordinates = (relativeCoordinates - mean) / stdev\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters).fit(normalizedCoordinates)\n",
    "\n",
    "        if data is None:\n",
    "            data = kmeans.cluster_centers_.flatten()\n",
    "        else:\n",
    "            data = np.vstack((data, kmeans.cluster_centers_.flatten()))\n",
    "\n",
    "        ids.append((datum['id'], len(freckle_coordinates)))\n",
    "    \n",
    "#     all_ids = np.array([id[0] for id in ids])\n",
    "#     unique_ids = np.unique(all_ids)\n",
    "#     max_id_count = 0\n",
    "#     for id in unique_ids:\n",
    "#         id_counts = np.sum(all_ids == id)\n",
    "#         if id_counts > max_id_count:\n",
    "#             max_id_count = id_counts\n",
    "            \n",
    "#     for id in unique_ids:\n",
    "#         print('Augmenting id %i' % (id, ))\n",
    "\n",
    "#         id_indices = all_ids == id\n",
    "#         found_ids = [ myId for myId in ids if myId[0] == id ]\n",
    "        \n",
    "#         id_counts = np.sum(all_ids == id)\n",
    "#         multiplier = max_id_count * 1.0 / id_counts #(1.0 / len(unique_ids)) / (id_counts * 1.0 / len(df))\n",
    "        \n",
    "#         for i in range(1, int(multiplier)):\n",
    "#             data = np.vstack((data, data[np.where(id_indices)[0], :]))\n",
    "#             ids = np.concatenate((ids, found_ids))\n",
    "    \n",
    "    return (data, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_data(4, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_freckle_detection(n_clusters, max_n_neighbors):\n",
    "    print('Generating dataset...')\n",
    "    \n",
    "    X, y = generate_data(n_clusters, 20, 100)\n",
    "    \n",
    "    error = []\n",
    "    \n",
    "    for i in range(1, max_n_neighbors): \n",
    "        print('Running for %i neighbors' % (i, ))\n",
    "        \n",
    "        total_error = []\n",
    "        \n",
    "        for j in range(1, 50):\n",
    "            X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "            y_train_id = np.array([ y[0] for y in y_train ])\n",
    "            y_test_id = np.array([ y[0] for y in y_test ])\n",
    "            y_test_len = np.array([ y[1] for y in y_test ])\n",
    "\n",
    "            # Calculating error for K values between 1 and 40\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=i)\n",
    "            knn.fit(X_train, y_train_id)\n",
    "            pred_i = knn.predict(X_test)\n",
    "            total_error.append(np.mean(pred_i != y_test_id))\n",
    "        \n",
    "        error.append(np.mean(total_error))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  \n",
    "    plt.plot(range(1, max_n_neighbors), error, color='red', linestyle='dashed', marker='o',  \n",
    "             markerfacecolor='blue', markersize=10)\n",
    "    plt.title('Error Rate K Value')  \n",
    "    plt.xlabel('K Value')  \n",
    "    plt.ylabel('Mean Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_freckle_detection(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_data(4, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_test_id = []\n",
    "all_y_pred = []\n",
    "\n",
    "#for i in range(1, 40):\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "y_train_id = np.array([ y[0] for y in y_train ])\n",
    "y_test_id = np.array([ y[0] for y in y_test ])\n",
    "y_test_len = np.array([ y[1] for y in y_test ])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "#knn = RandomForestClassifier()\n",
    "knn.fit(X_train, y_train_id)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "all_y_test_id = np.concatenate((all_y_test_id, y_test_id))\n",
    "all_y_pred = np.concatenate((all_y_pred, y_pred))\n",
    "    \n",
    "#y_pred == y_test_id\n",
    "\n",
    "success_failure = y_pred == y_test_id\n",
    "success_lens = y_test_len[success_failure == True]\n",
    "failure_lens = y_test_len[success_failure == False]\n",
    "\n",
    "\n",
    "#print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(all_y_test_id, all_y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.vstack((y_pred, y_test_id, success_failure, y_test_len)).T)\n",
    "\n",
    "np.sum(all_y_test_id == all_y_pred)\n",
    "len(all_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_count = {}\n",
    "\n",
    "for myY in y:\n",
    "    id = myY[0]\n",
    "    \n",
    "    if id in id_count:\n",
    "        id_count[id] = id_count[id] + 1\n",
    "    else:\n",
    "        id_count[id] = 1\n",
    "        \n",
    "pp.pprint(id_count)\n",
    "\n",
    "pp.pprint(get_id_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test_len, y_pred == y_test_id)\n",
    "plt.show()\n",
    "\n",
    "percentiles = []\n",
    "success_percentiles = []\n",
    "failure_percentiles = []\n",
    "\n",
    "for i in range(0, 100, 5):\n",
    "    p1 = np.percentile(success_lens, i) # return 50th percentile, e.g median.\n",
    "    p2 = np.percentile(failure_lens, i) # return 50th percentile, e.g median.\n",
    "    \n",
    "    percentiles.append(i)\n",
    "    success_percentiles.append(p1)\n",
    "    failure_percentiles.append(p2)\n",
    "    \n",
    "    print('%0.2f: %0.2f, %0.2f' % (i, p1, p2))\n",
    "    \n",
    "plt.plot(percentiles, success_percentiles)\n",
    "plt.plot(percentiles, failure_percentiles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
