{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "from aquabyte.data_access_utils import RDSAccessUtils\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_access_utils = RDSAccessUtils(json.load(open(os.environ['PROD_SQL_CREDENTIALS'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliestDate = '2019-12-01'\n",
    "allFields = [ 'female_avg', 'moving_avg' ]\n",
    "rollingMADays = 5\n",
    "halfRollingMADays = int((rollingMADays + 1)/ 2)\n",
    "maxAR = 3\n",
    "\n",
    "def getTrainingAndTestSeries(inputJSON):    \n",
    "    penId = inputJSON['penId']\n",
    "    date = datetime.strptime(inputJSON['date'], '%Y-%m-%d')\n",
    "\n",
    "    query = \"\"\"\n",
    "        select date, female_avg, moving_avg\n",
    "        from day_summaries a\n",
    "        where a.pen_id = %i\n",
    "        and a.date <= '%s'\n",
    "        and a.date >= '%s';\n",
    "    \"\"\" % (penId, date, earliestDate)\n",
    "\n",
    "    day_summaries = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "    day_summaries.index = pd.to_datetime(day_summaries['date'])\n",
    "    day_summaries = day_summaries.sort_index()\n",
    "\n",
    "    day_summaries_rolling = day_summaries.rolling('%iD' % (rollingMADays, )).mean().shift(-24 * rollingMADays / 2, freq='h').resample('D').apply(lambda x:x.tail(1) if x.shape[0] else np.nan)\n",
    "    day_summaries_rolling.ix[0:halfRollingMADays] = np.nan\n",
    "    day_summaries_rolling = day_summaries_rolling.dropna()\n",
    "\n",
    "    query = \"\"\"\n",
    "        select event_type, started_at, ended_at from event_logs \n",
    "        where pen_id = %i\n",
    "        and started_at <= '%s'\n",
    "        and ended_at >= '%s'\n",
    "        and event_type = 'WELLBOAT_TREATMENT'\n",
    "        order by started_at asc;\n",
    "    \"\"\" % (penId, date, earliestDate)\n",
    "\n",
    "    allEvents = rds_access_utils.extract_from_database(query)\n",
    "\n",
    "    eligiblePeriods = []\n",
    "    lastEndedAt = day_summaries_rolling.index[0]\n",
    "\n",
    "    for index, event in allEvents.iterrows():\n",
    "        if abs((lastEndedAt - event['started_at'].replace(tzinfo=None)).days) > 30:\n",
    "            eligiblePeriods.append((lastEndedAt, event['started_at'].replace(tzinfo=None)))\n",
    "            print('Adding period from %s to %s' % (lastEndedAt, event['started_at']))\n",
    "        else:\n",
    "            print('Cannot add period from %s to %s' % (lastEndedAt, event['started_at']))\n",
    "\n",
    "        if event['ended_at'] is not None:\n",
    "            if lastEndedAt is None:\n",
    "                lastEndedAt = event['ended_at']\n",
    "            lastEndedAt = max(lastEndedAt, event['ended_at'].replace(tzinfo=None))\n",
    "        else:\n",
    "            print('Treatment still in progress')\n",
    "\n",
    "    lastDay = day_summaries_rolling.index[-1]\n",
    "\n",
    "    if abs((lastEndedAt - lastDay).days) > 30:\n",
    "        eligiblePeriods.append((lastEndedAt, lastDay))  \n",
    "    else:\n",
    "        print('Cannot add period from %s to %s' % (lastEndedAt, lastDay))\n",
    "\n",
    "    lastEligiblePeriod = None\n",
    "\n",
    "    if len(eligiblePeriods) > 0:\n",
    "        lastEligiblePeriod = eligiblePeriods[-1]\n",
    "    else:\n",
    "        print('No eligible training periods')\n",
    "\n",
    "    if abs((lastEndedAt - lastDay).days) < maxAR + 1:\n",
    "        print('Not enough data to generate AR series')\n",
    "\n",
    "    print('Using period from %s to %s to train' % (lastEligiblePeriod[0], lastEligiblePeriod[1]))\n",
    "\n",
    "    goodTrainingPeriod = (day_summaries_rolling.index > lastEligiblePeriod[0]) & (day_summaries_rolling.index < lastEligiblePeriod[1].replace(minute=0, hour=0, second=0, microsecond=0))\n",
    "    trainingSeries = day_summaries_rolling[goodTrainingPeriod]\n",
    "    testSeries = day_summaries_rolling.ix[-(maxAR + 1):]\n",
    "    \n",
    "    return trainingSeries, testSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestFutureLiceModel(inputJSON, trainingSeries, testSeries):\n",
    "    forecastPeriodDays = inputJSON['forecastPeriodDays']\n",
    "    \n",
    "    exponentialFields = []\n",
    "\n",
    "    trainingX = trainingSeries.copy()\n",
    "    logTrainingX = np.log(trainingX)\n",
    "    trainingDiffX = trainingX.diff().dropna()\n",
    "    logTrainingDiffX = logTrainingX.diff().dropna()\n",
    "\n",
    "    testX = testSeries.copy()\n",
    "    logTestX = np.log(testX)\n",
    "    testDiffX = testX.diff().dropna()\n",
    "    logTestDiffX = logTestX.diff().dropna()\n",
    "\n",
    "    #size = min(30, len(trainingDiffX))\n",
    "    size = len(trainingDiffX)\n",
    "\n",
    "    for field in allFields:\n",
    "        k2, p = stats.normaltest(logTrainingDiffX[field][-size:])\n",
    "        #print(field, p)\n",
    "        if p > .05 and field == 'female_avg':\n",
    "            print('Adding %s exponential: %0.2f' % (field, p))\n",
    "            exponentialFields.append(field)\n",
    "            trainingDiffX[field] = logTrainingDiffX[field]\n",
    "            testX[field] = logTestX[field]\n",
    "            testDiffX[field] = logTestDiffX[field]\n",
    "        else:\n",
    "            print('Keeping %s non-exponential: %0.2f' % (field, p))\n",
    "\n",
    "    predictions = {}\n",
    "    predictionsSeries = testSeries.copy()\n",
    "    predictionsSeriesLower = testSeries.copy()\n",
    "    predictionsSeriesUpper = testSeries.copy()\n",
    "\n",
    "    model = VAR(trainingDiffX[-size:])\n",
    "    model_fit = model.fit(maxlags = maxAR, ic = 'aic') #model.fit(AR)\n",
    "    lag_order = model_fit.k_ar\n",
    "    if lag_order == 0:\n",
    "        model_fit = model.fit(1)\n",
    "\n",
    "    output, output_lower, output_upper = model_fit.forecast_interval(testDiffX.values[-lag_order:], forecastPeriodDays + halfRollingMADays, 0.25)\n",
    "\n",
    "    convertedField = {\n",
    "        'female_avg': 'adultFemale',\n",
    "        'moving_avg': 'mobile'\n",
    "    }\n",
    "\n",
    "    cov = model_fit.forecast_cov(forecastPeriodDays + halfRollingMADays)\n",
    "\n",
    "    currentDate = testX.index[-1]\n",
    "    currentValue = testX.ix[-1]\n",
    "\n",
    "    for i in range(forecastPeriodDays + halfRollingMADays):\n",
    "        predictionDate = currentDate + timedelta(days = i + 1)\n",
    "        predictionDateString = predictionDate.strftime('%Y-%m-%d')\n",
    "        datePrediction = currentValue + np.sum(output[:i], 0)\n",
    "        datePredictionLower = currentValue + np.sum(output_lower[:i], 0)\n",
    "        datePredictionUpper = currentValue + np.sum(output_upper[:i], 0)\n",
    "\n",
    "        SE = np.sqrt(np.diagonal(np.sum(cov[:i,:,:], 0)))\n",
    "        currentCOV = np.diagonal(cov[i,:,:])\n",
    "        expSE = np.sqrt(np.sum((np.exp(currentCOV) - 1) * np.exp(2 * np.mean(trainingDiffX) + currentCOV), 0))\n",
    "\n",
    "        if i >= halfRollingMADays:\n",
    "            predictions[predictionDateString] = {}\n",
    "\n",
    "        for field in allFields:\n",
    "            datePredictionValue = datePrediction[field]\n",
    "            datePredictionLowerValue = datePredictionLower[field]\n",
    "            datePredictionUpperValue = datePredictionUpper[field]\n",
    "\n",
    "            if i >= halfRollingMADays:\n",
    "                predictions[predictionDateString][convertedField[field]] = {\n",
    "                    'smartAvg': np.maximum(datePredictionValue, 0.0),\n",
    "                    'smartAvgLowerThreshold': np.maximum(np.maximum(datePredictionValue - SE[1] * 1.96, datePredictionLowerValue), 0.0),\n",
    "                    'smartAvgUpperThreshold': np.maximum(np.minimum(datePredictionValue + SE[1] * 1.96, datePredictionUpperValue), 0.0)\n",
    "                }\n",
    "\n",
    "            predictionsSeries.loc[predictionDate] = np.maximum(datePrediction, 0.0)\n",
    "            predictionsSeriesLower.loc[predictionDate] = np.maximum(np.maximum(datePrediction - SE * 1.96, datePredictionLower), 0.0)\n",
    "            predictionsSeriesUpper.loc[predictionDate] = np.maximum(np.minimum(datePrediction + SE * 1.96, datePredictionUpper), 0.0)\n",
    "\n",
    "\n",
    "        datePredictionExp = np.maximum(np.exp(datePrediction), 0.0)\n",
    "        datePredictionLowerExp = np.maximum(np.maximum(np.exp(datePrediction) - expSE * 1.96, np.exp(datePredictionLower)), 0.0)\n",
    "        datePredictionUpperExp = np.maximum(np.minimum(np.exp(datePrediction) + expSE * 1.96, np.exp(datePredictionUpper)), 0.0)\n",
    "\n",
    "        for field in exponentialFields:\n",
    "            datePredictionValue = datePredictionExp[field]\n",
    "            datePredictionLowerValue = datePredictionLowerExp[field]\n",
    "            datePredictionUpperValue = datePredictionUpperExp[field]\n",
    "\n",
    "            if i >= halfRollingMADays:\n",
    "                predictions[predictionDateString][convertedField[field]] = {\n",
    "                    'smartAvg': datePredictionValue,\n",
    "                    'smartAvgLowerThreshold': datePredictionLowerValue,\n",
    "                    'smartAvgUpperThreshold': datePredictionUpperValue\n",
    "                }\n",
    "\n",
    "            predictionsSeries.loc[predictionDate, field] = datePredictionValue\n",
    "            predictionsSeriesLower.loc[predictionDate, field] = datePredictionLowerValue\n",
    "            predictionsSeriesUpper.loc[predictionDate, field] = datePredictionUpperValue\n",
    "\n",
    "    return predictions, predictionsSeries, predictionsSeriesLower, predictionsSeriesUpper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def futureLiceLevels(inputJSON):\n",
    "    trainingSeries, testSeries = getTrainingAndTestSeries(inputJSON)\n",
    "    \n",
    "    predictions, _ , _ , _ = trainAndTestFutureLiceModel(inputJSON, trainingSeries, testSeries)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputJSON = {\n",
    "  \"penId\": 56,\n",
    "  \"date\": \"2020-04-08\",\n",
    "  \"forecastPeriodDays\": 14\n",
    "}\n",
    "\n",
    "predictions = futureLiceLevels(inputJSON)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "\n",
    "pp.pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def futureLiceLevelsPlot(inputJSON):\n",
    "    trainingSeries, testSeries = getTrainingAndTestSeries(inputJSON)\n",
    "    \n",
    "    _ , predictionsSeries, predictionsSeriesLower, predictionsSeriesUpper = trainAndTestFutureLiceModel(inputJSON, trainingSeries, testSeries)\n",
    "    \n",
    "    return testSeries, predictionsSeries, predictionsSeriesLower, predictionsSeriesUpper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputJSON = {\n",
    "  \"penId\": 56,\n",
    "  \"date\": \"2020-04-08\",\n",
    "  \"forecastPeriodDays\": 14\n",
    "}\n",
    "\n",
    "testSeries, predictionsSeries, predictionsSeriesLower, predictionsSeriesUpper = futureLiceLevelsPlot(inputJSON)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "fig.set_size_inches(15, 20)\n",
    "\n",
    "ax[0].plot(testSeries.index, testSeries['female_avg'], color = 'black', linewidth = 5, label = 'Rolling')\n",
    "ax[0].plot(predictionsSeries.index, predictionsSeries['female_avg'], color = 'purple', linewidth = 2, label = 'Daily Predictions')\n",
    "ax[0].fill_between(predictionsSeries.index, predictionsSeriesLower['female_avg'], predictionsSeriesUpper['female_avg'], color='b', alpha=.1)\n",
    "ax[0].set_xlabel('Date')\n",
    "ax[0].set_ylabel('Adult Female Count')\n",
    "#ax[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "#ax[0].axhline(0)\n",
    "\n",
    "ax[1].plot(testSeries.index, testSeries['moving_avg'], color = 'black', linewidth = 5, label = 'Rolling')\n",
    "ax[1].plot(predictionsSeries.index, predictionsSeries['moving_avg'], color = 'purple', linewidth = 2, label = 'Daily Predictions')\n",
    "ax[1].fill_between(predictionsSeries.index, predictionsSeriesLower['moving_avg'], predictionsSeriesUpper['moving_avg'], color='b', alpha=.1)\n",
    "ax[1].set_xlabel('Date')\n",
    "ax[1].set_ylabel('Moving Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
