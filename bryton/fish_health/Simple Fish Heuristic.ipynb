{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures = pd.read_csv('bolaks_pen_id_88_2020-02-10_2020-03-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('bolaks_data_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures.captured_at = pd.to_datetime(captures['captured_at'])\n",
    "pairs.p1_captured_at = pd.to_datetime(pairs['p1_captured_at'])\n",
    "pairs.p2_captured_at = pd.to_datetime(pairs['p2_captured_at'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps = captures['captured_at'].diff()\n",
    "\n",
    "np.mean(gaps < datetime.timedelta(seconds=0.5)), np.mean(gaps < datetime.timedelta(seconds=1.5)), np.mean(gaps < datetime.timedelta(seconds=2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(11, 20):\n",
    "    daily_captures = (captures['captured_at'] > datetime(2020, 2, i, tzinfo=timezone.utc)) & (captures['captured_at'] < datetime(2020, 2, i + 1, tzinfo=timezone.utc))\n",
    "    daily_pairs = (pairs['p1_captured_at'] > datetime(2020, 2, i, tzinfo=timezone.utc)) & (pairs['p1_captured_at'] < datetime(2020, 2, i + 1, tzinfo=timezone.utc))\n",
    "\n",
    "    print(i, np.sum(daily_captures), np.sum(daily_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_pairs = []\n",
    "\n",
    "for i in np.arange(11, 20):\n",
    "    mask = (captures['captured_at'] > datetime(2020, 2, i, tzinfo=timezone.utc)) & (captures['captured_at'] < datetime(2020, 2, i + 1, tzinfo=timezone.utc))\n",
    "\n",
    "    old_captured_ats = []\n",
    "    old_ids = []\n",
    "    old_tails = []\n",
    "    old_eyes = []\n",
    "\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    for index, row in captures[mask].iterrows():\n",
    "        current_captured_at = row.captured_at\n",
    "\n",
    "        # Delete old captures\n",
    "        old_captured_at_indices = [i for i, ca in enumerate(old_captured_ats) if current_captured_at - ca < timedelta(seconds=10)]\n",
    "        old_captured_ats = [ca for ca in old_captured_ats if current_captured_at - ca < timedelta(seconds=10)]\n",
    "        old_ids = [_id for j, _id in enumerate(old_ids) if j in old_captured_at_indices ]\n",
    "        old_tails = [row for j, row in enumerate(old_tails) if j in old_captured_at_indices ]\n",
    "        old_eyes = [row for j, row in enumerate(old_eyes) if j in old_captured_at_indices ]\n",
    "\n",
    "        # Check captures\n",
    "        left_crops = json.loads(row['annotation'].replace(\"\\'\", \"\\\"\"))['leftCrop']\n",
    "        left_tail = [crop for crop in left_crops if crop['keypointType'] == 'ANAL_FIN'][0]\n",
    "        left_eye = [crop for crop in left_crops if crop['keypointType'] == 'EYE'][0]\n",
    "    #     right_crops = json.loads(row['annotation'].replace(\"\\'\", \"\\\"\"))['rightCrop']\n",
    "    #     right_eye = [crop for crop in right_crops if crop['keypointType'] == 'EYE'][0]\n",
    "\n",
    "        for i, old_eye in enumerate(old_eyes):\n",
    "            ca = old_captured_ats[i]\n",
    "            old_tail = old_tails[i]\n",
    "            if left_tail['xFrame'] < left_eye['xFrame']:\n",
    "                horizontal_condition = old_tail['xFrame'] < old_eye['xFrame'] and old_eye['xFrame'] < left_eye['xFrame'] and old_tail['xFrame'] < left_tail['xFrame']\n",
    "                vertical_condition = np.abs(old_eye['yFrame'] - left_eye['yFrame']) < 100\n",
    "\n",
    "                if horizontal_condition and vertical_condition:\n",
    "                    count = count + 1\n",
    "\n",
    "                    if np.sum((pairs.p2 == index) & (pairs.p1 == old_ids[i])) > 0:\n",
    "                        correct_count = correct_count + 1\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    found_pairs.append([old_ids[i], index, np.sum((pairs.p2 == index) & (pairs.p1 == old_ids[i])) > 0, (current_captured_at - ca).total_seconds(), np.abs(old_eye['xFrame'] - left_eye['xFrame']), np.abs(old_eye['yFrame'] - left_eye['yFrame']), np.abs(old_tail['xFrame'] - left_tail['xFrame']), np.abs(old_tail['yFrame'] - left_tail['yFrame']), old_eye['xFrame'], old_eye['yFrame'], old_tail['xFrame'], old_tail['yFrame'], left_eye['xFrame'], left_eye['yFrame'], left_tail['xFrame'], left_tail['yFrame']])\n",
    "                        #print(index, old_ids[i])\n",
    "                #print(index, old_ids[i])\n",
    "                #print(left_eye['xFrame'])\n",
    "            else:\n",
    "                horizontal_condition = old_tail['xFrame'] > old_eye['xFrame'] and old_eye['xFrame'] > left_eye['xFrame'] and old_tail['xFrame'] > left_tail['xFrame']\n",
    "                vertical_condition = np.abs(old_eye['yFrame'] - left_eye['yFrame']) < 100\n",
    "\n",
    "                if horizontal_condition and vertical_condition:\n",
    "                    count = count + 1\n",
    "\n",
    "                    if np.sum((pairs.p2 == index) & (pairs.p1 == old_ids[i])) > 0:\n",
    "                        correct_count = correct_count + 1\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    found_pairs.append([old_ids[i], index, np.sum((pairs.p2 == index) & (pairs.p1 == old_ids[i])) > 0, (current_captured_at - ca).total_seconds(), np.abs(old_eye['xFrame'] - left_eye['xFrame']), np.abs(old_eye['yFrame'] - left_eye['yFrame']), np.abs(old_tail['xFrame'] - left_tail['xFrame']), np.abs(old_tail['yFrame'] - left_tail['yFrame']), old_eye['xFrame'], old_eye['yFrame'], old_tail['xFrame'], old_tail['yFrame'], left_eye['xFrame'], left_eye['yFrame'], left_tail['xFrame'], left_tail['yFrame']])\n",
    "\n",
    "        old_captured_ats.append(current_captured_at)\n",
    "        old_ids.append(index)\n",
    "        old_tails.append(left_tail)\n",
    "        old_eyes.append(left_eye)\n",
    "\n",
    "    print(count, correct_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('duplicate_detections.csv', 'w') as outcsv:   \n",
    "    writer = csv.writer(outcsv, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    writer.writerow(['p1', 'p2', 'paired_before', 'timedelta', 'eye_to_eye_xFrame', 'eye_to_eye_yFrame', 'tail_to_tail_xFrame', 'tail_to_tail_yFrame', 'old_eye_xFrame', 'old_eye_yFrame', 'old_tail_xFrame', 'old_tail_yFrame', 'left_eye_xFrame', 'left_eye_yFrame', 'left_tail_xFrame', 'left_tail_yFrame'])\n",
    "    for item in found_pairs:\n",
    "        writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detections = pd.read_csv('duplicate_detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_detections.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(duplicate_detections['eye_to_eye_xFrame'] - duplicate_detections['tail_to_tail_xFrame'] < 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs.sort_values(by=['p1']).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pairs.p1_captured_at == pairs.p2_captured_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pair = (53, 52)\n",
    "\n",
    "np.sum((pairs.p1 == wrong_pair[0]) & (pairs.p2 == wrong_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=captures.ix[wrong_pair[0], 'left_crop_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=captures.ix[wrong_pair[1], 'left_crop_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(captures.ix[13050, 'annotation'].replace(\"\\'\", \"\\\"\"))['leftCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(captures.ix[13051, 'annotation'].replace(\"\\'\", \"\\\"\"))['leftCrop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures.ix[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
