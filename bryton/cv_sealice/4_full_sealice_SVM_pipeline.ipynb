{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gets candidate points\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.utils as utils\n",
    "import lib.features as features\n",
    "import lib.detections as detections\n",
    "\n",
    "font_file = '/root/bryton/aquabyte_sealice/Helvetica-Regular.ttf'\n",
    "font = ImageFont.truetype(font_file, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_thresh = 100\n",
    "bbox_halfwidth = 24\n",
    "area_min = 100\n",
    "area_max = 200\n",
    "ecc_min = 0.7\n",
    "ecc_max = 0.99\n",
    "\n",
    "base_directory = '/root/bryton/aquabyte_sealice'\n",
    "\n",
    "annotations_file = '%s/annotations.csv' % (base_directory, )\n",
    "#svm_model_filepath = '%s/models/sealice_detection_ORB_SVM_model.yml' % (base_directory, )\n",
    "svm_model_filepath = '%s/models/sealice_detection_ORB_SVM_model_20180506-162646.yml' % (base_directory, )\n",
    "\n",
    "svm_pipeline_output_directory = '/root/bryton/aquabyte_sealice/svm_pipeline_output'\n",
    "\n",
    "try: \n",
    "    os.makedirs(svm_pipeline_output_directory)\n",
    "except OSError:\n",
    "    if not os.path.isdir(svm_pipeline_output_directory):\n",
    "        raise\n",
    "\n",
    "# load the saved SVM model\n",
    "svm_model = cv2.ml.SVM_load(svm_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ORB instance\n",
    "orb_descriptor = cv2.ORB_create()\n",
    "\n",
    "annotations = utils.get_lice_annotations_from_file(annotations_file)[0:20]\n",
    "\n",
    "f, ax = plt.subplots(10, 1, figsize=(50, 100))\n",
    "\n",
    "processed_index = -1\n",
    "\n",
    "# for each frame detect keypoints\n",
    "for annotation_index, annotation in enumerate(annotations):\n",
    "    if annotation_index % 10 == 0:\n",
    "        print 'Processing annotation %i of %i' % (annotation_index, len(annotations))\n",
    "\n",
    "    image_filename, x1, y1, x2, y2, label = annotation\n",
    "\n",
    "    split_name = image_filename.split('/')\n",
    "        \n",
    "    image = Image.open(image_filename)\n",
    "    frame = np.array(image)\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "        \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh_mask = cv2.threshold(gray_frame, mask_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    candidate_kps = features.extract_sealice_candidate_kps(thresh_mask, bbox_halfwidth, area_min, area_max, ecc_min, ecc_max)\n",
    "\n",
    "    #print candidate_kps\n",
    "\n",
    "    kps, orb_descriptors = orb_descriptor.compute(frame, candidate_kps)\n",
    "    orb_descriptors = np.asfarray(orb_descriptors, dtype = 'float32')\n",
    "\n",
    "    if len(orb_descriptors) > 1:\n",
    "        processed_index = processed_index + 1\n",
    "\n",
    "        prediction = svm_model.predict(orb_descriptors, True, 1)\n",
    "        #print prediction\n",
    "        predicted_labels = prediction[1]\n",
    "        \n",
    "        raw_lice_detections = []\n",
    "\n",
    "        for i, predicted_label in enumerate(predicted_labels):\n",
    "            x1 = np.int(kps[i].pt[0] - 28)\n",
    "            y1 = np.int(kps[i].pt[1] - 28)\n",
    "            x2 = np.int(kps[i].pt[0] + 28)\n",
    "            y2 = np.int(kps[i].pt[1] + 28)\n",
    "            \n",
    "            top_left_point_elevated = (x1, y1 - 25) \n",
    "            top_left_point = (x1, y1) \n",
    "            bottom_right_point = (x2, y2)\n",
    "            \n",
    "            confidence = 1.0 / (1.0 + np.exp(- predicted_label[0]));\n",
    "\n",
    "            if confidence > 0.6:\n",
    "                confidence_text = '%0.2f%%' % (confidence * 100, )\n",
    "                cv2.putText(frame, confidence_text, top_left_point, cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                cv2.rectangle(frame, top_left_point, bottom_right_point, (0, 255, 0), 3)\n",
    "                \n",
    "                draw.text(top_left_point_elevated, confidence_text, (255,255,0), font = font)\n",
    "                draw.rectangle((top_left_point, bottom_right_point), outline = 'green')\n",
    "                \n",
    "                output_file = '%s/%s.jpg' % (svm_pipeline_output_directory, split_name[6].split('.')[0])\n",
    "    \n",
    "                image.save(output_file)\n",
    "        \n",
    "                raw_lice_detections.append({ 'x1': x1, 'y1': y2, 'x2': x2, 'y2': y2, 'confidence': confidence })\n",
    "        \n",
    "        output = detections.create_fish_detection(None, raw_lice_detections)\n",
    "    \n",
    "        output_json = {\n",
    "            'fish_detection': output['fish_detection'],\n",
    "            'lice_detections': output['lice_detections']\n",
    "        }\n",
    "        \n",
    "        # Alok / Thomas - this is what you can use\n",
    "        #print output_json\n",
    "\n",
    "    if processed_index < 10:\n",
    "        ax[processed_index].imshow(frame)\n",
    "\n",
    "print 'Wait for the images...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
