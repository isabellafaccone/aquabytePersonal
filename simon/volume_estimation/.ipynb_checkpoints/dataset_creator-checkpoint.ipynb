{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import os \n",
    "from os.path import dirname\n",
    "import re\n",
    "import json \n",
    "from torch.utils.data import Dataset\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Create csv containing files names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(dataset_name,\n",
    "               datas_list=['stereo_images', 'mask', 'depth_map', 'annotations']):\n",
    "    \"\"\"\n",
    "    Creates a dataframe containing all files names for the dataset\n",
    "    Input:\n",
    "       - datas_list: list datas from the dataset to include in the\n",
    "       dataframe\n",
    "       - dataset_name: name of the dataset\n",
    "    Output:\n",
    "        - dataframe object\n",
    "    \"\"\"\n",
    "    dataset_path = dirname(os.getcwd()) + '/data/' + str(dataset_name) + '/'\n",
    "    regex = re.compile(r'\\d+')\n",
    "    datas = {}\n",
    "    # Getting the files\n",
    "    for data_type in datas_list:\n",
    "        files = os.listdir(dataset_path + data_type)\n",
    "        if data_type in ['mask', 'stereo_images']:\n",
    "            right_files = [f for f in files if 'right' in f]\n",
    "            if 'right' in right_files:\n",
    "                right_files.remove('right')\n",
    "            right_id = [int(regex.findall(f)[0]) for f in right_files]\n",
    "            left_files = [f for f in files if 'left' in f]\n",
    "            if 'left' in left_files:\n",
    "                left_files.remove('left')\n",
    "            left_id = [int(regex.findall(f)[0]) for f in left_files] \n",
    "            datas[data_type + '_left'] = (left_files, left_id)\n",
    "            datas[data_type + '_right'] = (right_files, right_id)\n",
    "        else:\n",
    "            files_id = [int(regex.findall(f)[0]) for f in files]\n",
    "            datas[data_type] = ((files, files_id))\n",
    "    size = len(datas[datas.keys()[0]][0])\n",
    "    dataset = pd.DataFrame(index=range(size), columns=datas.keys())\n",
    "    \n",
    "    # Let's fill the dataframe now\n",
    "    for key in datas.keys():\n",
    "        for ix in range(size):\n",
    "            dataset[key][datas[key][1][ix]] = datas[key][0][ix]\n",
    "    dataset.to_csv(dataset_name + '.csv')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'blender_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = create_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, train_split):\n",
    "    \"\"\"\n",
    "    Split a dataframe randomly into train & test set\n",
    "    \"\"\"\n",
    "    train_ix = random.sample(range(len(df)), int(train_split * len(df)))\n",
    "    test_ix = list(set(df.index) - set(train_ix))\n",
    "    train_df = df.iloc[train_ix, :].reset_index(drop=True)\n",
    "    test_df = df.iloc[test_ix, :].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(datas, train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_map</th>\n",
       "      <th>mask_right</th>\n",
       "      <th>annotations</th>\n",
       "      <th>stereo_images_left</th>\n",
       "      <th>mask_left</th>\n",
       "      <th>stereo_images_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depth_map_3270.npy</td>\n",
       "      <td>right_3270.npy</td>\n",
       "      <td>annot_3270.json</td>\n",
       "      <td>left_3270.png</td>\n",
       "      <td>left_3270.npy</td>\n",
       "      <td>right_3270.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depth_map_2061.npy</td>\n",
       "      <td>right_2061.npy</td>\n",
       "      <td>annot_2061.json</td>\n",
       "      <td>left_2061.png</td>\n",
       "      <td>left_2061.npy</td>\n",
       "      <td>right_2061.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depth_map_3256.npy</td>\n",
       "      <td>right_3256.npy</td>\n",
       "      <td>annot_3256.json</td>\n",
       "      <td>left_3256.png</td>\n",
       "      <td>left_3256.npy</td>\n",
       "      <td>right_3256.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depth_map_82.npy</td>\n",
       "      <td>right_82.npy</td>\n",
       "      <td>annot_82.json</td>\n",
       "      <td>left_82.png</td>\n",
       "      <td>left_82.npy</td>\n",
       "      <td>right_82.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depth_map_1818.npy</td>\n",
       "      <td>right_1818.npy</td>\n",
       "      <td>annot_1818.json</td>\n",
       "      <td>left_1818.png</td>\n",
       "      <td>left_1818.npy</td>\n",
       "      <td>right_1818.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            depth_map      mask_right      annotations stereo_images_left  \\\n",
       "0  depth_map_3270.npy  right_3270.npy  annot_3270.json      left_3270.png   \n",
       "1  depth_map_2061.npy  right_2061.npy  annot_2061.json      left_2061.png   \n",
       "2  depth_map_3256.npy  right_3256.npy  annot_3256.json      left_3256.png   \n",
       "3    depth_map_82.npy    right_82.npy    annot_82.json        left_82.png   \n",
       "4  depth_map_1818.npy  right_1818.npy  annot_1818.json      left_1818.png   \n",
       "\n",
       "       mask_left stereo_images_right  \n",
       "0  left_3270.npy      right_3270.png  \n",
       "1  left_2061.npy      right_2061.png  \n",
       "2  left_3256.npy      right_3256.png  \n",
       "3    left_82.npy        right_82.png  \n",
       "4  left_1818.npy      right_1818.png  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_map</th>\n",
       "      <th>mask_right</th>\n",
       "      <th>annotations</th>\n",
       "      <th>stereo_images_left</th>\n",
       "      <th>mask_left</th>\n",
       "      <th>stereo_images_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depth_map_2048.npy</td>\n",
       "      <td>right_2048.npy</td>\n",
       "      <td>annot_2048.json</td>\n",
       "      <td>left_2048.png</td>\n",
       "      <td>left_2048.npy</td>\n",
       "      <td>right_2048.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depth_map_4096.npy</td>\n",
       "      <td>right_4096.npy</td>\n",
       "      <td>annot_4096.json</td>\n",
       "      <td>left_4096.png</td>\n",
       "      <td>left_4096.npy</td>\n",
       "      <td>right_4096.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depth_map_2.npy</td>\n",
       "      <td>right_2.npy</td>\n",
       "      <td>annot_2.json</td>\n",
       "      <td>left_2.png</td>\n",
       "      <td>left_2.npy</td>\n",
       "      <td>right_2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depth_map_2052.npy</td>\n",
       "      <td>right_2052.npy</td>\n",
       "      <td>annot_2052.json</td>\n",
       "      <td>left_2052.png</td>\n",
       "      <td>left_2052.npy</td>\n",
       "      <td>right_2052.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depth_map_4738.npy</td>\n",
       "      <td>right_4738.npy</td>\n",
       "      <td>annot_4738.json</td>\n",
       "      <td>left_4738.png</td>\n",
       "      <td>left_4738.npy</td>\n",
       "      <td>right_4738.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            depth_map      mask_right      annotations stereo_images_left  \\\n",
       "0  depth_map_2048.npy  right_2048.npy  annot_2048.json      left_2048.png   \n",
       "1  depth_map_4096.npy  right_4096.npy  annot_4096.json      left_4096.png   \n",
       "2     depth_map_2.npy     right_2.npy     annot_2.json         left_2.png   \n",
       "3  depth_map_2052.npy  right_2052.npy  annot_2052.json      left_2052.png   \n",
       "4  depth_map_4738.npy  right_4738.npy  annot_4738.json      left_4738.png   \n",
       "\n",
       "       mask_left stereo_images_right  \n",
       "0  left_2048.npy      right_2048.png  \n",
       "1  left_4096.npy      right_4096.png  \n",
       "2     left_2.npy         right_2.png  \n",
       "3  left_2052.npy      right_2052.png  \n",
       "4  left_4738.npy      right_4738.png  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Wrap everything into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load a dataset for Volume estimation.\n",
    "    \n",
    "    Args:\n",
    "       - dataset_name\n",
    "       - datas_list: datas to keep in the dataset\n",
    "       - size: float between 0 & 1 (ex 0.7)\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, dataset_name,\n",
    "                 datas_list, size, target='volume'):\n",
    "        self.csv_file = csv_file\n",
    "        self.dataset_name = dataset_name\n",
    "        self.datas_list = datas_list\n",
    "        self.size = size\n",
    "        self.target = target\n",
    "        \n",
    "        # Create the csv file needed\n",
    "        if '.csv' not in csv_file:\n",
    "            csv_file + '.csv'\n",
    "        self.dataset = pd.read_csv(csv_file, index_col=0)\n",
    "        self.dataset = self.dataset[datas_list]\n",
    "        self.subsample_dataset()\n",
    "    \n",
    "    def subsample_dataset(self):\n",
    "        \"\"\"\n",
    "        Subsample dataset to a give size ratio of the whole dataset\n",
    "        \"\"\"\n",
    "        num_examples = int(self.size * len(self.dataset))\n",
    "        self.dataset = self.dataset.sample(num_examples).reset_index(drop=True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        input = {}\n",
    "        dataset_dir = '../data/' + self.dataset_name \n",
    "        for data in self.dataset.columns:\n",
    "            file_name = self.dataset.loc[index, data]\n",
    "            if '_right' in data : \n",
    "                file_path = dataset_dir + '/' + data.replace('_right', '') + '/' + file_name\n",
    "            elif '_left' in data:\n",
    "                file_path = dataset_dir + '/' + data.replace('_left', '') + '/' + file_name\n",
    "            else: \n",
    "                file_path = dataset_dir + '/' + data + '/' + file_name\n",
    "            if 'npy' in file_name:\n",
    "                if data == 'depth_map':\n",
    "                    input[data] = np.load(file_path).T\n",
    "                else:\n",
    "                    input[data] = np.load(file_path)\n",
    "            elif 'png' in file_name:\n",
    "                input[data] = cv2.imread(file_path)\n",
    "            elif 'json' in file_name:\n",
    "                with open(file_path) as f:\n",
    "                    label = json.load(f)[self.target]\n",
    "            \n",
    "        return input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'blender_v3.csv'\n",
    "dataset_name = 'blender_v3'\n",
    "datas_list = ['depth_map', 'mask_right', 'annotations']\n",
    "size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VolumeDataset(csv_file=csv_file,\n",
    "                              dataset_name=dataset_name, \n",
    "                              datas_list=datas_list, \n",
    "                              size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = train_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
