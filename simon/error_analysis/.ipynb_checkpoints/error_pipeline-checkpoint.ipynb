{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from utils import crop_and_mask\n",
    "from obb import OBB\n",
    "import cv2\n",
    "from error_analysor import convert_to_world_point, compute_length, compute_segmentation_error\n",
    "import sys\n",
    "sys.path.append(\"/root/simon/volume_estimation/\")\n",
    "# from data_loader import DataGenerator\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Gound truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_path = '/root/data/blender/blender_test/Image0028_L.png'\n",
    "right_path = '/root/data/blender/blender_test/Image0028_R.png'\n",
    "ground_truth_depth_path = '/root/data/blender/blender_test/true_depth.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground truth mask + segmentation\n",
    "mask = crop_and_mask(Image.open(left_path))\n",
    "ground_truth_depth = np.load(ground_truth_depth_path)\n",
    "mdepth = ground_truth_depth * mask\n",
    "x, y = np.nonzero(mdepth>10)\n",
    "for (i,j) in zip(x,y):\n",
    "    mask[i,j] = 0\n",
    "mdepth = ground_truth_depth * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "plt.imshow(ground_truth_depth)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(mdepth)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_length = compute_length(mask, ground_truth_depth)\n",
    "print('True length: {}'.format(true_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Mask perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Mask erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 11):\n",
    "    if s > 0:\n",
    "        kernel = np.ones((s, s))\n",
    "        eroded_mask = cv2.erode(mask, kernel)\n",
    "    else:\n",
    "        eroded_mask = mask\n",
    "    plt.imshow(eroded_mask)\n",
    "    plt.show()\n",
    "    segmentation_error = compute_segmentation_error(eroded_mask, mask)\n",
    "    errors.append(segmentation_error)\n",
    "    pred_length = compute_length(eroded_mask, ground_truth_depth)\n",
    "    relative_error = np.abs(pred_length- true_length) / true_length\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Segmentation error (erosion)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Mask dilatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 11):\n",
    "    if s > 0:\n",
    "        kernel = np.ones((s, s))\n",
    "        dilated_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        dilated_mask = mask\n",
    "    plt.imshow(dilated_mask)\n",
    "    plt.show()\n",
    "    segmentation_error = compute_segmentation_error(dilated_mask, mask)\n",
    "    errors.append(segmentation_error)\n",
    "    pred_length = compute_length(dilated_mask, ground_truth_depth)\n",
    "    relative_error = np.abs(pred_length - true_length) / true_length\n",
    "    print('pred length : {}, ground truth: {}'.format(pred_length, true_length))\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Segmentation error (dilatation)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Depth map perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 -  Same noise per pixel of the fish - translation of the depth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 11):\n",
    "    print(s)\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        noise = np.ones(new_depth.shape) * (s * 0.4)\n",
    "        print('gaussian nosie: {}'.format(float(np.unique(noise))))\n",
    "        new_depth += noise * mask\n",
    "    plt.imshow(new_depth)\n",
    "    plt.show()\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    errors.append(depth_relative_error)\n",
    "    pred_length = compute_length(mask, new_depth)\n",
    "    relative_error = np.abs(pred_length - true_length) / true_length\n",
    "    print('pred length : {}, ground truth: {}'.format(pred_length, true_length))\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors[:3], lengths[:3])\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 -  Different Gaussian noise per pixel of the fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 11):\n",
    "    print(s)\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1) * s)\n",
    "        new_depth += noise * mask\n",
    "    plt.imshow(new_depth)\n",
    "    plt.show()\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    errors.append(depth_relative_error)\n",
    "    pred_length = compute_length(mask, new_depth)\n",
    "    relative_error = np.abs(pred_length - true_length) / true_length\n",
    "    print('pred length : {}, ground truth: {}'.format(pred_length, true_length))\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Different Gaussian noise per region of the fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from error_analysor import computes_noised_sliced_dmap, get_bb_from_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_of_regions = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, x2, y2 = get_bb_from_mask(mask)\n",
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 11):\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0.0:\n",
    "        new_depth = computes_noised_sliced_dmap(new_depth, mask, x1, x2, s, nb_of_regions)\n",
    "        plt.imshow(new_depth)\n",
    "        plt.show()\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth * mask - mdepth) / mdepth)\n",
    "    errors.append(depth_relative_error)\n",
    "    pred_length = compute_length(mask, new_depth)\n",
    "    relative_error = np.abs(pred_length - true_length) / true_length\n",
    "    print('pred length : {}, ground truth: {}'.format(pred_length, true_length))\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 - Different Gaussian noise per region of the fish & noise to background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1, x2, y2 = get_bb_from_mask(mask)\n",
    "lengths = []\n",
    "errors = []\n",
    "background = np.where(mask==0)\n",
    "for s in range(0, 11):\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0.0:\n",
    "        new_depth = computes_noised_sliced_dmap(new_depth, mask, x1, x2, s, nb_of_regions)\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1)*s)\n",
    "        new_depth[background[0], background[1]] += noise[background[0], background[1]]\n",
    "    plt.imshow(new_depth)\n",
    "    plt.show()\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth * mask - mdepth) / mdepth)\n",
    "    errors.append(depth_relative_error)\n",
    "    pred_length = compute_length(mask, new_depth)\n",
    "    relative_error = np.abs(pred_length - true_length) / true_length\n",
    "    print('pred length : {}, ground truth: {}'.format(pred_length, true_length))\n",
    "    lengths.append(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors[:3], lengths[:3])\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualisation and if we look at the prediction of our models we can see that dilatation is more realistic than erosion. \n",
    "Regarding the noise for the depth map, noise per region with noise added to the background is obviously better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Dilatation + Translation of dmap on fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the discussion with Bryton, this will be our reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((44, 44))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "\n",
    "for size in range(0, 44):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size, size))\n",
    "        new_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    total = new_mask + mask\n",
    "    intersection = np.count_nonzero(total[total==2])\n",
    "    union = np.count_nonzero(total[total>0])\n",
    "    iou = intersection*100 / union\n",
    "    #print('Intersection over Union: {}'.format(intersection/float(union)))\n",
    "    print('Segmentation Error: {}'.format(1 - intersection/float(union)))\n",
    "    errors_mask.append(100 - iou)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(0, 44):\n",
    "\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        noise = np.ones(new_depth.shape) * (s * 0.1)\n",
    "        #print('gaussian nosie: {}'.format(float(np.unique(noise))))\n",
    "        new_depth += noise * mask\n",
    "        \n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    print('Depth error : {}'.format(depth_relative_error))\n",
    "    errors_depth.append(depth_relative_error*100)\n",
    "    \n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "        pred_length = compute_length(new_mask, new_depth)\n",
    "        relative_error = np.abs(pred_length-true_length) / true_length\n",
    "        #print('Relative error {}'.format(relative_error))\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lengths, index=errors_mask, columns=errors_depth)\n",
    "ax = sns.heatmap(df)\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth map error %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter heatmap given target_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_error = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df[df < 40])\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth map error %')\n",
    "ax.set_title = 'Filtered heat map : {}'.format(target_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Dilatation + Noise on fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((44, 44))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "\n",
    "for size in range(0, 44):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size, size))\n",
    "        new_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    total = new_mask + mask\n",
    "    intersection = np.count_nonzero(total[total==2])\n",
    "    union = np.count_nonzero(total[total>0])\n",
    "    iou = intersection * 100 / union\n",
    "    # print('Intersection over Union: {}'.format(intersection/float(union)))\n",
    "    print('Segmentation Error: {}'.format(1 - intersection/float(union)))\n",
    "    errors_mask.append(100 - iou)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(0, 44):\n",
    "    \n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        # creat some noise\n",
    "        noise = np.zeros((512, 1024), np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1)*s*0.2)\n",
    "        new_depth += noise\n",
    "        \n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    print('Depth error: {}'.format(depth_relative_error))\n",
    "    errors_depth.append(depth_relative_error*100)\n",
    "    \n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "        pred_length = compute_length(new_mask, new_depth)\n",
    "        relative_error = np.abs(pred_length-true_length) / true_length\n",
    "        #print('Length error : {}'.format(relative_error))\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lengths, index=errors_mask, columns=errors_depth)\n",
    "ax = sns.heatmap(df)\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth map error %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter heatmap given target error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_error = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df[df < 40])\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth map error %')\n",
    "ax.set_title = 'Filtered heat map : {}'.format(target_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Dilatation + Noise per region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((11, 11))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "\n",
    "for size in range(0, 11):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size, size))\n",
    "        new_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    total = new_mask + mask\n",
    "    intersection = np.count_nonzero(total[total==2])\n",
    "    union = np.count_nonzero(total[total>0])\n",
    "    iou = intersection*100 / union\n",
    "    print('Segmentation error: {}'.format(1 - intersection/float(union)))\n",
    "    errors_mask.append(100 - iou)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(0, 11):\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0.0:\n",
    "        new_depth = computes_noised_sliced_dmap(new_depth, mask, x1, x2, s, nb_of_regions)\n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    print('Depth map error: {}'.format(depth_relative_error))\n",
    "    errors_depth.append(depth_relative_error*100)\n",
    "    \n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "        pred_length = compute_length(new_mask, new_depth)\n",
    "        relative_error = np.abs(pred_length-true_length) / true_length\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lengths, index=errors_mask, columns=errors_depth)\n",
    "ax = sns.heatmap(df)\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth map error %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter heatmap given target error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Dilatation + Noise per region + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((11, 11))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "background = np.where(mask==0)\n",
    "\n",
    "for size in range(0, 11):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size, size))\n",
    "        new_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    total = new_mask + mask\n",
    "    intersection = np.count_nonzero(total[total==2])\n",
    "    union = np.count_nonzero(total[total>0])\n",
    "    iou = intersection*100 / union\n",
    "    # print('Intersection over Union: {}'.format(intersection/float(union)))\n",
    "    # print('Error: {}'.format(1 - intersection/float(union)))\n",
    "    errors_mask.append(100 - iou)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(0, 11):\n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0.0:\n",
    "        new_depth = computes_noised_sliced_dmap(new_depth, mask, x1, x2, s, nb_of_regions)\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1)*s)\n",
    "        new_depth[background[0], background[1]] += noise[background[0], background[1]]\n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs(new_depth*mask-mdepth) / mdepth)\n",
    "    # print(depth_relative_error)\n",
    "    errors_depth.append(depth_relative_error*100)\n",
    "    \n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "\n",
    "        # calculate ground truth length\n",
    "        y, x = np.nonzero(new_depth*new_mask)\n",
    "        wx, wy, wz = convert_to_world_point(x, y, new_depth)\n",
    "        cloud = []\n",
    "        pred_length = compute_length(new_mask, new_depth)\n",
    "        \n",
    "        \n",
    "        # print(pred_length)\n",
    "        # print('True length: {}'.format(pred_length))\n",
    "        relative_error = np.abs(pred_length-true_length) / true_length\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(errors_mask, errors_depth, lengths, levels=range(0, int(lengths.max())+50, 50))\n",
    "plt.xlabel('Segmentation error (%)')\n",
    "plt.ylabel('Depth relative error (%)')\n",
    "plt.title('Dilatation + noise per region & background')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, s, 1) * np.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
