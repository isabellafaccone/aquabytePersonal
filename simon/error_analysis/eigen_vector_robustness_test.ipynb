{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a robust method for length estimation and computes the mean error on a synthetic dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Create csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from data_utils import create_csv\n",
    "from data_generator import DataGenerator\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'blender_v3'\n",
    "size = None # has to be less or equal to 5000\n",
    "dataset_path = '/root/data/blender/blender_v3/'\n",
    "datas = create_csv(dataset_name=dataset_name,\n",
    "                   dataset_path=dataset_path,\n",
    "                   datas_list=['depth_map', 'annotations', 'mask'])\n",
    "datas_list = ['depth_map', 'annotations', 'mask_left']\n",
    "data_generator = DataGenerator(dataframe=datas,\n",
    "                          size=size,\n",
    "                          dataset_name=dataset_name,\n",
    "                          datas_list=datas_list,\n",
    "                          target_list=['length', 'width', 'height', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Visualize random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ix = random.randint(0, len(data_generator))\n",
    "ix = 3458\n",
    "mask = data_generator[ix][0]['mask_left']\n",
    "dmap = data_generator[ix][0]['depth_map']\n",
    "mdepth = dmap * mask\n",
    "gt_length = data_generator[ix][1]['length']\n",
    "print('Ground truth length : {} for {}-th image in dataset'.format(gt_length, ix))\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "plt.imshow(dmap)\n",
    "plt.show()\n",
    "plt.imshow(mdepth)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick hack because the crop and mask function is not optimal\n",
    "x, y = np.nonzero(mdepth>10)\n",
    "for (i,j) in zip(x,y):\n",
    "    mask[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask * mdepth)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Compute base line length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_world_point\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from lenght_estimator import pca_length_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_length = pca_length_estimation(dmap=dmap, mask=mask, width_ratio=0.05)\n",
    "print('Base line length : {}, Ground_truth length : {}'.format(baseline_length, gt_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = np.nonzero(mask)\n",
    "wx, wy, wz = convert_to_world_point(x, y, dmap * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(wx, wy, wz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_cloud = np.array([wx, wy, wz]).T\n",
    "fish_cloud -= np.mean(fish_cloud, axis=0)\n",
    "pca = decomposition.PCA(n_components=1)\n",
    "pca.fit(fish_cloud)\n",
    "X = pca.transform(fish_cloud)\n",
    "plt.plot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.sort(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = int(len(X) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_start = X[:width]\n",
    "X_end = X[-width:]\n",
    "norm = []\n",
    "for i in range(len(X_start)):\n",
    "    print(np.sqrt((X_start[i]-X_end[-(i+1)])**2))\n",
    "    norm.append(np.sqrt((X_start[i]-X_end[-(i+1)])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_length = sum(norm) / len(norm)\n",
    "pred_length, gt_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Length error on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors = []\n",
    "#for ix in trange(len(data_generator)):\n",
    "#    mask = data_generator[ix][0]['mask_left']\n",
    "#    dmap = data_generator[ix][0]['depth_map']\n",
    "#    x, y = np.nonzero(mdepth>10)\n",
    "#    for (i,j) in zip(x,y):\n",
    "#        mask[i,j] = 0\n",
    "#    mdepth = dmap * mask\n",
    "#    gt_length = data_generator[ix][1]['length']\n",
    "#    pred_length = pca_length_estimation(dmap=dmap, mask=mask, width_ratio=0.05)\n",
    "#    errors.append(np.abs(pred_length - gt_length) / gt_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Mean error on dataset : {}'.format(sum(errors)/len(errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Mask perturbations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Mask erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import compute_segmentation_error\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(1, 22):\n",
    "    if s > 0:\n",
    "        kernel = np.ones((s * 2, s))\n",
    "        eroded_mask = cv2.erode(mask, kernel)\n",
    "    else:\n",
    "        eroded_mask = mask\n",
    "    segmentation_error = compute_segmentation_error(eroded_mask, mask)\n",
    "    errors.append(segmentation_error)\n",
    "    pred_length = pca_length_estimation(dmap=dmap, mask=eroded_mask, width_ratio=0.1)\n",
    "    if s == 1 or s == 21:\n",
    "        plt.imshow(eroded_mask)\n",
    "        plt.show()\n",
    "        print('Pred length: {}, Segmentation error : {}'.format(pred_length, segmentation_error))\n",
    "    relative_error = np.abs(pred_length - baseline_length) / baseline_length\n",
    "    print('Mask error : {}, Length error : {}'.format(segmentation_error, relative_error*100))\n",
    "    lengths.append(relative_error * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Segmentation error % (erosion)')\n",
    "plt.ylabel('Length relative  % error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Mask dilatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 22):\n",
    "    if s > 0:\n",
    "        kernel = np.ones((s, s*2))\n",
    "        eroded_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        eroded_mask = mask\n",
    "    segmentation_error = compute_segmentation_error(eroded_mask, mask)\n",
    "    errors.append(segmentation_error)\n",
    "    pred_length = pca_length_estimation(dmap=dmap, mask=eroded_mask, width_ratio=0.05)\n",
    "    if s == 1 or s == 21:\n",
    "        plt.imshow(eroded_mask)\n",
    "        plt.show()\n",
    "        print('Pred length: {}, Segmentation error : {}'.format(pred_length, segmentation_error))\n",
    "    relative_error = np.abs(pred_length - baseline_length) / baseline_length\n",
    "    print('Mask error : {}, Length error : {}'.format(segmentation_error, relative_error*100))\n",
    "    lengths.append(relative_error * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Segmentation error % (dilatation)')\n",
    "plt.ylabel('Length relative  % error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Depth map perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "errors = []\n",
    "for s in range(0, 22):\n",
    "    new_depth = copy.deepcopy(dmap)\n",
    "    if s > 0:\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1) * s * 0.7)\n",
    "        new_depth += noise * mask\n",
    "    depth_relative_error = np.nanmean(np.abs((new_depth * mask) - mdepth) / mdepth)\n",
    "    errors.append(depth_relative_error * 100)\n",
    "    pred_length = pca_length_estimation(dmap=new_depth, mask=mask, width_ratio=0.05)\n",
    "    if s == 0 or s == 21:\n",
    "        plt.imshow(new_depth)\n",
    "        plt.show()\n",
    "        print('pred length : {}, ground truth: {}'.format(pred_length, baseline_length))\n",
    "    relative_error = np.abs(pred_length-baseline_length) / baseline_length\n",
    "    print('Depth error : {}, Length error : {}'.format(depth_relative_error * 100, relative_error * 100))\n",
    "    lengths.append(relative_error * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors, lengths)\n",
    "plt.xlabel('Depth map error (noise)')\n",
    "plt.ylabel('Length relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Depth map + mask perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Gaussian noise + erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_with_dmap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((21, 21))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "\n",
    "for size in range(1, 22):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size * 2, size))\n",
    "        new_mask = cv2.erode(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    segmentation_error = compute_segmentation_error(new_mask, mask)\n",
    "    errors_mask.append(segmentation_error)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(1, 22): \n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        # creat some noise\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1) * s * 0.7)\n",
    "        new_depth += noise * mask\n",
    "        \n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs((new_depth * mask) - mdepth) / mdepth)\n",
    "    errors_depth.append(depth_relative_error * 100)\n",
    "\n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "        if filter_with_dmap == True:\n",
    "            x, y = np.nonzero((new_depth * new_mask)>10)\n",
    "            for (m,n) in zip(x,y):\n",
    "                new_mask[m,n] = 0\n",
    "        pred_length = pca_length_estimation(dmap=new_depth, mask=new_mask, width_ratio=0.05)\n",
    "        relative_error = np.abs(pred_length-baseline_length) / baseline_length\n",
    "        print(i, j)\n",
    "        print('Mask error : {}, Depth error : {}, Length errror : {}'.format(errors_mask[i], errors_depth[j], relative_error * 100))\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lengths.T, index=errors_mask, columns=errors_depth)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df)\n",
    "ax.set_ylabel('mask error (erosion) %')\n",
    "ax.set_xlabel('segmentation error %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_error = 10\n",
    "ix_to_keep = df.columns < 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df[df.loc[:, ix_to_keep] < target_error])\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth error %')\n",
    "ax.set_title = 'Filtered heat map : {}'.format(target_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Gaussian noise + dilatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_with_dmap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.zeros((21, 21))\n",
    "errors_mask = []\n",
    "errors_depth = []\n",
    "all_masks = []\n",
    "all_depth = []\n",
    "\n",
    "for size in range(1, 22):\n",
    "    if size > 0:\n",
    "        kernel = np.ones((size, size*2))\n",
    "        new_mask = cv2.dilate(mask, kernel)\n",
    "    else:\n",
    "        new_mask = mask\n",
    "            \n",
    "    segmentation_error = compute_segmentation_error(new_mask, mask)\n",
    "    errors_mask.append(segmentation_error)\n",
    "    all_masks.append(new_mask)\n",
    "    \n",
    "for s in range(1, 22): \n",
    "    new_depth = copy.deepcopy(mdepth)\n",
    "    if s > 0:\n",
    "        # creat some noise\n",
    "        noise = np.zeros(new_depth.shape, np.uint8)\n",
    "        cv2.randn(noise, np.array(0), np.ones(1) * s * 0.7)\n",
    "        new_depth += noise * mask\n",
    "        \n",
    "    all_depth.append(new_depth)\n",
    "    depth_relative_error = np.nanmean(np.abs((new_depth * mask) - mdepth) / mdepth)\n",
    "    errors_depth.append(depth_relative_error * 100)\n",
    "\n",
    "for (i,new_mask) in enumerate(all_masks):\n",
    "    for (j, new_depth) in enumerate(all_depth):\n",
    "        if filter_with_dmap == True:\n",
    "            x, y = np.nonzero((new_depth * new_mask)>10)\n",
    "            for (m,n) in zip(x,y):\n",
    "                new_mask[m,n] = 0\n",
    "        pred_length = pca_length_estimation(dmap=new_depth, mask=new_mask, width_ratio=0.05)\n",
    "        relative_error = np.abs(pred_length-baseline_length) / baseline_length\n",
    "        print(i, j)\n",
    "        print('Mask error : {}, Depth error : {}, Length errror : {}'.format(errors_mask[i], errors_depth[j], relative_error * 100))\n",
    "        lengths[j, i] = relative_error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lengths.T, index=errors_mask, columns=errors_depth)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df)\n",
    "ax.set_ylabel('mask error (dilatation) %')\n",
    "ax.set_xlabel('segmentation error %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_error = 20\n",
    "ix_to_keep = df.columns < 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df[df.loc[:, ix_to_keep] < target_error])\n",
    "ax.set_ylabel('segmentation error %')\n",
    "ax.set_xlabel('depth error %')\n",
    "ax.set_title = 'Filtered heat map : {}'.format(target_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_error = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.insert(5, mask_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(columns=df.columns.insert(2, mask_error)).interpolate(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
