{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train & test data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Generate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_utils import create_instance_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/root/data/aquabyte-images/erko/'\n",
    "annotations_dir = 'instance_labels'\n",
    "frames_dir = 'frames'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create csv base file from instance masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_instance_csv(dataset_path, annotations_dir, frames_dir,\n",
    "#                    target_path='/root/data/erko/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('/root/data/erko/annotations.csv', header=None)\n",
    "#split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msk = np.random.rand(len(dataset)) < split\n",
    "#train_dataset = dataset[msk]\n",
    "#train_dataset.to_csv('/root/data/erko/annotations_train.csv', header=None)\n",
    "#test_dataset = dataset[~msk]\n",
    "#test_dataset.to_csv('/root/data/erko/annotations_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.transform import random_transform_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_data_file = '/root/data/aquabyte-images/erko/annotations_train.csv'\n",
    "csv_test_data_file = '/root/data/aquabyte-images/erko/annotations_test.csv'\n",
    "classID_file = '/root/data/aquabyte-images/erko/classID.csv'\n",
    "batch_size = 4\n",
    "# transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "transform_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CSVGenerator(\n",
    "        csv_train_data_file,\n",
    "        classID_file,\n",
    "        transform_generator=transform_generator,\n",
    "        batch_size=batch_size,\n",
    "        image_min_side=800,\n",
    "        image_max_side=1500\n",
    "    )\n",
    "test_generator = CSVGenerator(\n",
    "       csv_test_data_file,\n",
    "       classID_file,\n",
    "       transform_generator=transform_generator,\n",
    "       batch_size=batch_size,\n",
    "       image_min_side=800,\n",
    "       image_max_side=1500\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Visualise a random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.anchors import anchors_for_shape\n",
    "from keras_retinanet.utils.visualization import draw_annotations, draw_boxes\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "i = randint(0, generator.size())\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generator.load_image(i)\n",
    "image.shape\n",
    "generator.image_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_annotations(i).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generator.load_image(i)\n",
    "annotations = generator.load_annotations(i)\n",
    "anchors = anchors_for_shape(image.shape)\n",
    "labels_batch, regression_batch, boxes_batch = generator.compute_anchor_targets(anchors, [image], [annotations], generator.num_classes())\n",
    "anchor_states = labels_batch[0, :, -1]\n",
    "draw_boxes(image, boxes_batch[0, anchor_states == 1, :], (0, 255, 0), thickness=1)\n",
    "draw_annotations(image, annotations, color=(0, 0, 255), label_to_name=generator.label_to_name)\n",
    "draw_boxes(image, boxes_batch[0, anchor_states == 1, :], (0, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_train_data_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = df[df[0] == generator.image_names[i]]\n",
    "len(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(test_img[0].iloc[i]))[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = np.array(Image.open(test_img[6].iloc[i]))[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0, x_1, y_1 = test_img[1].iloc[i], test_img[2].iloc[i], test_img[3].iloc[i], test_img[4].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0, x_1, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mask[y_0:y_1, x_0:x_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[y_0:y_1, x_0:x_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet import models\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.bin.train import create_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_name = 'resnet50'\n",
    "freeze_backbone = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.backbone(backbone_name)\n",
    "weights = backbone.download_imagenet()\n",
    "model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=backbone.retinanet,\n",
    "            num_classes=train_generator.num_classes(),\n",
    "            multi_gpu=1,\n",
    "            weights=weights,\n",
    "            freeze_backbone=freeze_backbone\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_retinanet.losses import smooth_l1, focal\n",
    "from custom_metrics import jaccard_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : smooth_l1(),\n",
    "            'classification': focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_callbacks import step_decay, SaveHistory, MAP_eval\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./erko_bigger_0907.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/erko/detection/', 'retinanet_erko_bigger_0907_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             save_best_only=True, \n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metric = MAP_eval(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "history = training_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=train_generator.size()//batch_size,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data= test_generator,\n",
    "        validation_steps= test_generator.size() // batch_size,\n",
    "        callbacks=[lr_scheduler, saveh, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "history = json.load(open('./erko_0907.json'))\n",
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = '/root/data/models/gopro/detection/weight_retinanet/new_go_pro/detection_19.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(model_in, convert=True, backbone_name=backbone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.eval import evaluate\n",
    "# Threshold score to filter detections with\n",
    "iou_threshold = 0.6\n",
    "score_threshold = 0.2\n",
    "max_detections = 30\n",
    "save_path = '/root/data/models/gopro/detection/results_retinanet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precisions = evaluate(\n",
    "    test_data_generator,\n",
    "    model,\n",
    "    iou_threshold=iou_threshold,\n",
    "    score_threshold=score_threshold,\n",
    "    max_detections=max_detections,\n",
    "    save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_classes = 0\n",
    "precision = 0\n",
    "for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "          test_data_generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
    "    if num_annotations > 0:\n",
    "        present_classes += 1\n",
    "        precision       += average_precision\n",
    "print('mAP: {:.4f}'.format(precision / present_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_generator import get_detections, get_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = get_detections(\n",
    "    generator=test_data_generator, \n",
    "    model=model, \n",
    "    score_threshold=0., \n",
    "    max_detections=max_detections\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = get_annotations(test_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0][1].shape, detections[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator.image_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/blender_v4/training/test_low_rez/labels.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test.txt', 'w')\n",
    "f.write('hello \\nlol \\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
