{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train & test data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Generate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_utils import create_instance_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/root/data/aquabyte-images/erko/'\n",
    "annotations_dir = 'instance_labels'\n",
    "frames_dir = 'frames'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create csv base file from instance masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_instance_csv(dataset_path, annotations_dir, frames_dir,\n",
    "#                    target_path='/root/data/erko/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('/root/data/erko/annotations.csv', header=None)\n",
    "#split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msk = np.random.rand(len(dataset)) < split\n",
    "#train_dataset = dataset[msk]\n",
    "#train_dataset.to_csv('/root/data/erko/annotations_train.csv', header=None)\n",
    "#test_dataset = dataset[~msk]\n",
    "#test_dataset.to_csv('/root/data/erko/annotations_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.transform import random_transform_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_data_file = '/root/data/aquabyte-images/erko/annotations_train.csv'\n",
    "csv_test_data_file = '/root/data/aquabyte-images/erko/annotations_test.csv'\n",
    "classID_file = '/root/data/aquabyte-images/erko/classID.csv'\n",
    "batch_size = 4\n",
    "# transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "transform_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CSVGenerator(\n",
    "        csv_train_data_file,\n",
    "        classID_file,\n",
    "        transform_generator=transform_generator,\n",
    "        batch_size=batch_size,\n",
    "        image_min_side=800,\n",
    "        image_max_side=1500\n",
    "    )\n",
    "test_generator = CSVGenerator(\n",
    "       csv_test_data_file,\n",
    "       classID_file,\n",
    "       transform_generator=transform_generator,\n",
    "       batch_size=batch_size,\n",
    "       image_min_side=800,\n",
    "       image_max_side=1500\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Visualise a random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet import models\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.bin.train import create_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Create model & load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_name = 'resnet50'\n",
    "freeze_backbone = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.backbone(backbone_name)\n",
    "weights = backbone.download_imagenet()\n",
    "model, training_model, prediction_model = create_models(\n",
    "            backbone_retinanet=backbone.retinanet,\n",
    "            num_classes=train_generator.num_classes(),\n",
    "            multi_gpu=1,\n",
    "            weights=weights,\n",
    "            freeze_backbone=freeze_backbone\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_retinanet.losses import smooth_l1, focal\n",
    "from custom_metrics import jaccard_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : smooth_l1(),\n",
    "            'classification': focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_callbacks import step_decay, SaveHistory, MAP_eval\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./erko_5k_0909.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/erko/detection/', 'retinanet_5k_0909_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             save_best_only=True, \n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_metric = MAP_eval(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "history = training_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=train_generator.size()//batch_size,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data= test_generator,\n",
    "        validation_steps= test_generator.size() // batch_size,\n",
    "        callbacks=[lr_scheduler, saveh, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "history = json.load(open('./erko_0907.json'))\n",
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in = '/root/data/models/gopro/detection/weight_retinanet/new_go_pro/detection_19.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(model_in, convert=True, backbone_name=backbone_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.eval import evaluate\n",
    "# Threshold score to filter detections with\n",
    "iou_threshold = 0.6\n",
    "score_threshold = 0.2\n",
    "max_detections = 30\n",
    "save_path = '/root/data/models/gopro/detection/results_retinanet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(generator, model, score_threshold=0.05, max_detections=100, save_path=None):\n",
    "    \"\"\" Get the detections from the model using the generator.\n",
    "\n",
    "    The result is a list of lists such that the size is:\n",
    "        all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]\n",
    "\n",
    "    # Arguments\n",
    "        generator       : The generator used to run images through the model.\n",
    "        model           : The model to run on the images.\n",
    "        score_threshold : The score confidence threshold to use.\n",
    "        max_detections  : The maximum number of detections to use per image.\n",
    "        save_path       : The path to save the images with visualized detections to.\n",
    "    # Returns\n",
    "        A list of lists containing the detections for each image in the generator.\n",
    "    \"\"\"\n",
    "    all_detections = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
    "\n",
    "    for i in range(generator.size()):\n",
    "        raw_image    = generator.load_image(i)\n",
    "        image        = generator.preprocess_image(raw_image.copy())\n",
    "        image, scale = generator.resize_image(image)\n",
    "\n",
    "        # run network\n",
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))[:3]\n",
    "\n",
    "        # correct boxes for image scale\n",
    "        boxes /= scale\n",
    "\n",
    "        # select indices which have a score above the threshold\n",
    "        indices = np.where(scores[0, :] > score_threshold)[0]\n",
    "\n",
    "        # select those scores\n",
    "        scores = scores[0][indices]\n",
    "\n",
    "        # find the order with which to sort the scores\n",
    "        scores_sort = np.argsort(-scores)[:max_detections]\n",
    "\n",
    "        # select detections\n",
    "        image_boxes      = boxes[0, indices[scores_sort], :]\n",
    "        image_scores     = scores[scores_sort]\n",
    "        image_labels     = labels[0, indices[scores_sort]]\n",
    "        image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "\n",
    "        #if save_path is not None:\n",
    "            #draw_annotations(raw_image, generator.load_annotations(i), label_to_name=generator.label_to_name)\n",
    "            #draw_detections(raw_image, image_boxes, image_scores, image_labels, label_to_name=generator.label_to_name)\n",
    "\n",
    "            #cv2.imwrite(os.path.join(save_path, '{}.png'.format(i)), raw_image)\n",
    "\n",
    "        # copy detections to all_detections\n",
    "        for label in range(generator.num_classes()):\n",
    "            all_detections[i][label] = image_detections[image_detections[:, -1] == label, :-1]\n",
    "\n",
    "\n",
    "    return all_detections\n",
    "\n",
    "\n",
    "def get_annotations(generator):\n",
    "    \"\"\" Get the ground truth annotations from the generator.\n",
    "\n",
    "    The result is a list of lists such that the size is:\n",
    "        all_detections[num_images][num_classes] = annotations[num_detections, 5]\n",
    "\n",
    "    # Arguments\n",
    "        generator : The generator used to retrieve ground truth annotations.\n",
    "    # Returns\n",
    "        A list of lists containing the annotations for each image in the generator.\n",
    "    \"\"\"\n",
    "    all_annotations = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
    "\n",
    "    for i in range(generator.size()):\n",
    "        # load the annotations\n",
    "        annotations = generator.load_annotations(i)\n",
    "\n",
    "        # copy detections to all_annotations\n",
    "        for label in range(generator.num_classes()):\n",
    "            all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
    "\n",
    "\n",
    "    return all_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_retinanet.utils.visualization import draw_detections, draw_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_detections     = get_detections(test_generator, model, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations    = get_annotations(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_detections[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = test_generator.load_annotations(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image    = generator.load_image(i)\n",
    "image        = generator.preprocess_image(raw_image.copy())\n",
    "image, scale = generator.resize_image(image)\n",
    "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))[:3]\n",
    "\n",
    "        # correct boxes for image scale\n",
    "        boxes /= scale\n",
    "\n",
    "        # select indices which have a score above the threshold\n",
    "        indices = np.where(scores[0, :] > score_threshold)[0]\n",
    "\n",
    "        # select those scores\n",
    "        scores = scores[0][indices]\n",
    "\n",
    "        # find the order with which to sort the scores\n",
    "        scores_sort = np.argsort(-scores)[:max_detections]\n",
    "\n",
    "        # select detections\n",
    "        image_boxes      = boxes[0, indices[scores_sort], :]\n",
    "        image_scores     = scores[scores_sort]\n",
    "        image_labels     = labels[0, indices[scores_sort]]\n",
    "        image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_classes = 0\n",
    "precision = 0\n",
    "for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "          test_data_generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
    "    if num_annotations > 0:\n",
    "        present_classes += 1\n",
    "        precision       += average_precision\n",
    "print('mAP: {:.4f}'.format(precision / present_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result_generator import get_detections, get_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = get_detections(\n",
    "    generator=test_data_generator, \n",
    "    model=model, \n",
    "    score_threshold=0., \n",
    "    max_detections=max_detections\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = get_annotations(test_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0][1].shape, detections[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator.image_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/blender_v4/training/test_low_rez/labels.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test.txt', 'w')\n",
    "f.write('hello \\nlol \\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
