{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165fac6c",
   "metadata": {},
   "source": [
    "# Evaluation of Yolo TensorRT Zoo\n",
    "\n",
    "For [ENGALL-2424](https://aquabyte.atlassian.net/browse/ENGALL-2424) we seek to understand the TensorRT-accelerated inference time (latency) of YoloV3 on the Jetson TX2.  \n",
    "\n",
    "This page was generated from [this notebook](https://github.com/aquabyte-new/research-exploration/blob/pwais/tx2-yolo-zoo-0/pwais/mft-pg/notebooks/darknet_yolo_trt_zoo_eval.ipynb).\n",
    "\n",
    "The results below study:\n",
    " * A zoo of YoloV3 models [with architectures that are nearly identical to the production detector](https://github.com/aquabyte-new/research-exploration/blob/ba35c6356ed44ddd1145008f2e0eeaaf7d958378/pwais/mft-pg/detection/models/README.md#available-models).  We only vary the input size.  All models have square inputs.\n",
    " * Each model has been trained and tested on ~750 images from a GoPro video feed. [Details](https://github.com/aquabyte-new/research-exploration/tree/ba35c6356ed44ddd1145008f2e0eeaaf7d958378/pwais/mft-pg/datasets#mft-pg-datasets).\n",
    " * The `GeForce.RTX.2070` platform is a Lambda Labs Tensorbook with a RTX 2070 (8GB memory).\n",
    " * The `Tegra.X2` platform is a Jetson TX2 NVidia Devkit.  [Photo](https://drive.google.com/file/d/1Ycx2VLA5_y-s6nEoseHPstOnLElBulXj/view?usp=sharing)\n",
    " \n",
    "Notes on TX2 Tests:\n",
    " * The TX2 generally remained under 40C operating temperature for the duration of the study.  [Pic of JTOP](https://drive.google.com/file/d/1nFlXunwwnOoIz_LA2ydk3BapYSFy4Ucj/view?usp=sharing).\n",
    " * During the inference test, there was time for the GPU to rest while the next image was being resized.  [Pic of JTOP GPU during an inference run](https://drive.google.com/file/d/1aFW6kTwcp5JbHZEkXUT0vWs2Gq7dPL28/view?usp=sharing).\n",
    " * System memory usage during the inference test was about 4GB; unclear what the actual GPU memory usage was.  [Pic of JTOP during an inference run](https://drive.google.com/file/d/123iIBGbByS2FNNb2P3TErex8AzYMtIqV/view?usp=sharing).\n",
    " \n",
    "\n",
    "Reproducing these results:\n",
    " * From scratch: use this branch of [this repo](https://github.com/aquabyte-new/research-exploration): `pwais/tx2-yolo-zoo-0`\n",
    "   See also this Pull Request: https://github.com/aquabyte-new/research-exploration/pull/3\n",
    " * This report: use the `mlruns` directory persisted to S3:\n",
    "    ```\n",
    "    aws s3 sync --size-only s3://aquabyte-research/pwais/mlruns-tx2-yolo-zoo-0/ ./mlruns/\n",
    "    ```\n",
    "   And start jupyter using the `mft-cli`: `$ ./mft-cli --jupyter-ui`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/mft-pg')\n",
    "\n",
    "# The first Yolo zoo didn't have run ID tracking set up right.  Here are the\n",
    "# MLFlow Run Ids for that zoo\n",
    "FIRST_YOLO_ZOO_RUN_IDS = (\n",
    "  '90fafa4fb2194c70ab5e99bf94964587',\n",
    "  '3771d3357f534c689a31f7278f2fe60e',\n",
    "  '86d0fbfae7d9432bb15b17113bf3f291',\n",
    "  '058730c05f8f4dd8a3299fb10dece255',\n",
    "  '32779f411bbd4c1dafe483ca8a636601',\n",
    "  'e10cae25a3884f75919c2b6212e4824f',\n",
    "  '3b33e4f6bc45466c9a1d35ee839a0c75',\n",
    "  'b18e9351ef4b4da9b788cc135339f457',\n",
    "  'e235ff91d5c043979f31b8ce92c1e7a5',\n",
    "  'c114c649c02349389b54810c526bdc7f',\n",
    "  '95a388e4809d4e24870e4d147140c356',\n",
    "  '95d86a448acc4d86ba2d3714795453a2',\n",
    "  'ea283b03af834744a616fa740b4f303a',\n",
    "  'f231ff83d1dd494fa6269916cc0b1ab3',\n",
    "  '1ab6658a60a7402ba0398cf445ba22d2',\n",
    "  '2de468aed4e445a6a352db4b15fd703c',\n",
    "  '71058625298a4b99a91f5099fd8c7cd4',\n",
    "  '2176e2dd712949c5bb7e1c25abc3b278',\n",
    "  '4ff330ca02054a1db9eff79abb06841a',\n",
    "  '3a10b05bc3344922b0b953f27e61b07b',\n",
    "  'd7e6b25641e34edd913c66d0e6725a6b',\n",
    "  'f0af1e307acc4d19b13b89ab3025ccf6',\n",
    "  '81fe7f4ff374481198a0aa1e94ebe3a1',\n",
    "  '10a236b73ea64e84b0f7628fa3c6f0f6',\n",
    "  'e4297a980b7e43ac8099454601895c0a',\n",
    "  '0053813569944f2ca919993ed3bea4f9',\n",
    "  '5f7c3d1b1e0c49e1a52b25ec0bf6d316',\n",
    "  '4e3232e14ae6472a86717be9ce8572a7',\n",
    ")\n",
    "\n",
    "print('len(FIRST_YOLO_ZOO_RUN_IDS)', len(FIRST_YOLO_ZOO_RUN_IDS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f68de5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri('/opt/mft-pg/mlruns')\n",
    "mlflow_df = mlflow.search_runs()\n",
    "mlflow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b18e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mft_utils.bbox2d import BBox2D\n",
    "\n",
    "stat_df_rows = []\n",
    "\n",
    "artifact_uris = mlflow_df[mlflow_df['run_id'].isin(FIRST_YOLO_ZOO_RUN_IDS)]['artifact_uri']\n",
    "\n",
    "for artifact_dir in artifact_uris:\n",
    "    # Trim the 'file://' thing for os.path\n",
    "    artifact_dir = artifact_dir.replace('file://', '')\n",
    "    # print(artifact_dir)\n",
    "    \n",
    "    trt_tx2_engine_path = os.path.join(artifact_dir, 'yolov3.NVIDIA.Tegra.X2.trt')\n",
    "    trt_rtx_engine_path = os.path.join(artifact_dir, 'yolov3.GeForce.RTX.2070.with.Max-Q.Design.trt')\n",
    "\n",
    "    trt_tx2_df_path = os.path.join(artifact_dir, 'YoloTRTRunner.NVIDIA.Tegra.X2.detections_df.pkl')\n",
    "    trt_rtx_df_path = os.path.join(artifact_dir, 'YoloTRTRunner.GeForce.RTX.2070.with.Max-Q.Design.detections_df.pkl')\n",
    "    \n",
    "    yolo_config_path = os.path.join(artifact_dir, 'yolov3.cfg')\n",
    "    \n",
    "    from mft_utils import misc as mft_misc\n",
    "    w, h = mft_misc.darknet_get_yolo_input_wh(yolo_config_path)\n",
    "    \n",
    "    img_width = w\n",
    "    \n",
    "    if os.path.exists(trt_tx2_df_path):\n",
    "        det_df = pd.read_pickle(trt_tx2_df_path)\n",
    "        stat_df_rows.append({\n",
    "            'platform': 'Tegra.X2',\n",
    "            'img_width': img_width,\n",
    "            'latencies': det_df['latency_sec'].to_numpy(),\n",
    "            'trt_engine_size_bytes': os.path.getsize(trt_tx2_engine_path),\n",
    "            'trt_load_time': det_df['extra'][0]['trt_engine_load_time_sec'],\n",
    "            'mean_resize_time_ms': 1e3*np.array([\n",
    "                float(det_df['extra'][i]['resize_time_sec']) for i in range(len(det_df))]).mean(),\n",
    "        })\n",
    "    \n",
    "    if os.path.exists(trt_rtx_df_path):\n",
    "        det_df = pd.read_pickle(trt_rtx_df_path)\n",
    "        stat_df_rows.append({\n",
    "            'platform': 'GeForce.RTX.2070',\n",
    "            'img_width': img_width,\n",
    "            'latencies': det_df['latency_sec'].to_numpy(),\n",
    "            'trt_engine_size_bytes': os.path.getsize(trt_rtx_engine_path),\n",
    "            'trt_load_time': det_df['extra'][0]['trt_engine_load_time_sec'],\n",
    "            'mean_resize_time_ms': 1e3*np.array([\n",
    "                float(det_df['extra'][i]['resize_time_sec']) for i in range(len(det_df))]).mean(),\n",
    "        })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(stat_df_rows)\n",
    "print('len(results_df)', len(results_df))\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7592ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure \n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(\n",
    "        title=\"Inference Latencies for YoloV3 Fish Detector\",\n",
    "        plot_width=950,\n",
    "        y_axis_label=\"Latency (milliseconds)\",\n",
    "        x_axis_label=\"Network input width (pixels)\")\n",
    "\n",
    "for row in results_df.to_dict(orient='records'):\n",
    "    ys = 1e3 * row['latencies']\n",
    "    xs = [row['img_width']] * len(ys)\n",
    "    color = 'blue' if 'Tegra' in row['platform'] else 'orange'\n",
    "    fig.scatter(xs, ys, fill_alpha=0.25, color=color, legend_label=row['platform'])\n",
    "\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70136e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.transform import transform\n",
    "from bokeh.models import ColumnDataSource\n",
    "results_src = ColumnDataSource(results_df)\n",
    "results_src.data['trt_engine_size_MBytes'] = 1e-6*results_src.data['trt_engine_size_bytes']\n",
    "\n",
    "fig2 = figure(\n",
    "        title=\"TensorRT Engine Sizes for YoloV3 Fish Detector\",\n",
    "        plot_width=950,\n",
    "        y_axis_label=\"Engine size (MBytes)\",\n",
    "        x_axis_label=\"Network input width (pixels)\")\n",
    "fig2.scatter(\n",
    "    source=results_src,\n",
    "    x='img_width',\n",
    "    y='trt_engine_size_MBytes',\n",
    "    fill_alpha=0.25,\n",
    "    color=factor_cmap(\n",
    "            field_name='platform',\n",
    "            palette=['blue', 'orange'],\n",
    "            factors=results_df['platform'].unique()),\n",
    "    legend_field='platform')\n",
    "show(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = figure(\n",
    "        title=\"TensorRT Engine Load Time for YoloV3 Fish Detector\",\n",
    "        plot_width=950,\n",
    "        y_axis_label=\"Load Time (seconds)\",\n",
    "        x_axis_label=\"Network input width (pixels)\")\n",
    "fig3.scatter(\n",
    "    source=results_src,\n",
    "    x='img_width',\n",
    "    y='trt_load_time',\n",
    "    fill_alpha=0.25,\n",
    "    color=factor_cmap(\n",
    "            field_name='platform',\n",
    "            palette=['blue', 'orange'],\n",
    "            factors=results_df['platform'].unique()),\n",
    "    legend_field='platform')\n",
    "show(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15089184",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = figure(\n",
    "        title=\"Mean Image Resize Time (OpenCV CPU) for YoloV3 Fish Detector\",\n",
    "        plot_width=950,\n",
    "        y_axis_label=\"Resize Time (milliseconds)\",\n",
    "        x_axis_label=\"Network input width (pixels)\")\n",
    "fig4.scatter(\n",
    "    source=results_src,\n",
    "    x='img_width',\n",
    "    y='mean_resize_time_ms',\n",
    "    fill_alpha=0.25,\n",
    "    color=factor_cmap(\n",
    "            field_name='platform',\n",
    "            palette=['blue', 'orange'],\n",
    "            factors=results_df['platform'].unique()),\n",
    "    legend_field='platform')\n",
    "show(fig4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a12b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7acb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bda038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
