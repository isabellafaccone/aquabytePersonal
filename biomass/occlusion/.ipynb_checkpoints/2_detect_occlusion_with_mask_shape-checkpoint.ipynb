{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a bunch of masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.mask import decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "labels = json.load(open('/root/data/blender_v2/training/train_low_rez/labels.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = decode(labels[0]['masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(masks[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(np.sum(masks,axis=2))# [200:, :500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset of masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some crops \n",
    "crop_folder = '/root/data/blender_v3/crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = [os.path.join(crop_folder, f) for f in os.listdir(crop_folder) if f.endswith('.png') and f[:4] == 'left']\n",
    "print(\"{} crops found\".format(len(crops)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('/root/data/mask_dataset'):\n",
    "    os.makedirs('/root/data/mask_dataset/train/occluded')\n",
    "    os.makedirs('/root/data/mask_dataset/train/full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # create the full crops\n",
    "# x_full = np.zeros((train_size, 28, 28, 1))\n",
    "# for (i, crop) in enumerate(crops):\n",
    "#     if i % 100 ==0 : print('{}/{}'.format(i, train_size))\n",
    "#     mask = np.expand_dims(np.asarray(Image.open(crop).resize((28, 28)))[...,3], axis=2)\n",
    "#     x_full[i,...] = mask\n",
    "# plt.imshow(np.squeeze(x_full[np.random.randint(train_size),...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/root/data/mask_dataset/train/full/train_full', x_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create occluded dataset\n",
    "for i in range(train_size):\n",
    "    fish1 = np.asarray(Image.open(np.random.choice(crops)).resize((28, 28)))[...,3]\n",
    "    fish1.flags.writeable = True\n",
    "    fish1[fish1 > 0] = 1\n",
    "    fish2 = np.asarray(Image.open(np.random.choice(crops)).resize((28, 28)))[...,3]\n",
    "    fish2.flags.writeable = True\n",
    "    fish2[fish2 > 0] = 1\n",
    "    overlap = fish1 + fish2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_folder = '/root/data/blender_v3/crop/'\n",
    "crops = [os.path.join(crop_folder, f) for f in os.listdir(crop_folder) if f.endswith('.png') and f[:4] == 'left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['full', 'occluded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "input_shape = (28, 28, 1)\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(x_train.shape)\n",
    "# plt.imshow(x_train[0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# x_train = x_train.astype('float32')\n",
    "# plt.imshow(x_train[0,...,0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# plt.imshow(x_train[0,...,0])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fish occlusion function\n",
    "def occlude(path1, path2):\n",
    "    \"\"\"take one fish and occlude it with the other\"\"\"\n",
    "    # create the binary masks\n",
    "    fish1 = np.asarray(Image.open(path1).resize((28, 28)))[...,3]\n",
    "    fish1.flags.writeable = True\n",
    "    fish1[fish1 > 0] = 1\n",
    "    fish2 = np.asarray(Image.open(path2).resize((28, 28)))[...,3]\n",
    "    fish2.flags.writeable = True\n",
    "    fish2[fish2 > 0] = 1\n",
    "    \n",
    "#     # randomly sample upper left\n",
    "#     upper_x = np.random.randint(14)\n",
    "#     upper_y = np.random.randint(14)\n",
    "    overlap = fish1 + fish2\n",
    "    fish1[overlap==2] =0\n",
    "    return fish1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5b8dd23d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlap = occlude(np.random.choice(crops), np.random.choice(crops))\n",
    "plt.imshow(overlap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1_hot(y, classes):\n",
    "    return np.squeeze(keras.utils.to_categorical(y, len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentation\n",
    "seq = iaa.Sequential([\n",
    "    iaa.CoarseDropout(0.5, size_percent=0.001)\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(crops, classes, batch_size):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((batch_size, 28, 28, 1))\n",
    "        y_batch = np.empty((batch_size, len(classes)))\n",
    "        for index in range(batch_size):\n",
    "            coin = np.random.rand()\n",
    "            if coin > 0.5:\n",
    "                # add a non occluded fish\n",
    "                fish = np.random.choice(crops)\n",
    "                x_batch[index, ...] = np.expand_dims(np.asarray(Image.open(fish).resize((28, 28)))[...,3], axis=2)\n",
    "                y_batch[index, ...] = get_1_hot(0, classes)\n",
    "            else:\n",
    "                # add an occluded fish\n",
    "                # either occlude with squares\n",
    "                fish = np.random.choice(crops)\n",
    "                x_batch[index, ...] = seq.augment_image(np.expand_dims(np.asarray(Image.open(fish).resize((28, 28)))[...,3], axis=2))\n",
    "                # or with other fish\n",
    "                fish1 = np.random.choice(crops)\n",
    "                fish2 = np.random.choice(crops)\n",
    "                x_batch[index, ...] = np.expand_dims(occlude(fish1, fish2), axis=2)\n",
    "                y_batch[index, ...] = get_1_hot(1, classes)\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fish = np.random.choice(crops)\n",
    "# out = seq.augment_image(np.asarray(Image.open(fish).resize((28, 28)))[...,3])\n",
    "# plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = generator(crops, classes, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = g.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(xb[0, ...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(crops, classes, batch_size)\n",
    "val_generator = generator(crops, classes, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "39/39 [==============================] - 31s 799ms/step - loss: 6.5606 - acc: 0.5829 - val_loss: 3.6322 - val_acc: 0.7526\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 18s 451ms/step - loss: 1.0158 - acc: 0.9297 - val_loss: 0.2119 - val_acc: 0.9844\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 12s 316ms/step - loss: 0.3031 - acc: 0.9768 - val_loss: 0.1071 - val_acc: 0.9870\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 12s 297ms/step - loss: 0.1955 - acc: 0.9844 - val_loss: 0.2537 - val_acc: 0.9766\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 11s 278ms/step - loss: 0.1158 - acc: 0.9894 - val_loss: 0.0389 - val_acc: 0.9974\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 11s 277ms/step - loss: 0.0782 - acc: 0.9936 - val_loss: 0.1259 - val_acc: 0.9922\n",
      "Epoch 7/20\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9928"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-05e6f7694ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrops\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                    )\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2245\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = train_generator, \n",
    "                    steps_per_epoch = len(crops)//batch_size,\n",
    "                    epochs = 20,\n",
    "                    verbose = 1,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = len(crops) // (10*batch_size)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = np.random.choice(crops)\n",
    "x = np.expand_dims(np.asarray(Image.open(fish).resize((28, 28)))[...,3], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 4.2359885e-34]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = seq.augment_image(np.expand_dims(np.asarray(Image.open(fish).resize((28, 28)))[...,3], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5a98e9390>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5a9b41a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(occ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(occ, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
