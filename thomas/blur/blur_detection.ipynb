{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import json\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/root/data/data_quality/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #0 Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = '/root/data/aquabyte-images/cocofiles/coco_visibility_2018-10-01.json'\n",
    "# example_coco = COCO(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (image_id, image_data) in tqdm(example_coco.imgs.items()):\n",
    "#     annotation_ids = example_coco.getAnnIds(imgIds=image_data['id']) #, catIds=category_ids, iscrowd=None)\n",
    "#     annotations = example_coco.loadAnns(annotation_ids)\n",
    "#     image = io.imread(image_data['local_path'])\n",
    "#     for annotation in annotations:\n",
    "#         crop_id = '{}_{}.jpg'.format(image_id, annotation['id'])\n",
    "#         bbox = annotation['bbox']\n",
    "#         y1, x1, width, height = [int(b) for b in bbox]\n",
    "#         # print(bbox)\n",
    "#         crop = image[x1:x1+height, y1:y1+width, :]\n",
    "#         io.imsave(os.path.join(data_folder, crop_id), crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = glob.glob(data_folder + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    plt.imshow(io.imread(np.random.choice(crops)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Create a data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import cv2\n",
    "from albumentations import OneOf, MotionBlur, Blur, MedianBlur, Compose, RandomBrightness, RandomGamma, GaussNoise, RandomContrast\n",
    "# import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224, 224, 3]\n",
    "batch_size = 32\n",
    "augmentation = Compose([OneOf([MotionBlur(p=1/3.0), \n",
    "                               Blur(p=1/3.0), \n",
    "                               MedianBlur(p=1/3.0)], p=1.0), \n",
    "                        OneOf([RandomBrightness(limit=1.0, p=1/3.0),\n",
    "                               RandomGamma(gamma_limit=(60, 150), p=1/3.0),\n",
    "                               RandomContrast(limit=1.0, p=1/3.0)\n",
    "                              ], p=1.0),\n",
    "                        GaussNoise(var_limit=(30, 50), p=0.5)],\n",
    "                       p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(42)\n",
    "# image = cv2.imread(crops[0])\n",
    "\n",
    "# light = A.Compose([\n",
    "# #    A.RandomBrightness(limit=3.0, p=1),\n",
    "# #     A.RandomContrast(limit=1.0, p=1),\n",
    "# #     A.RandomGamma(p=1),\n",
    "# #     A.RGBShift(),\n",
    "# #    A.CLAHE(p=1),\n",
    "# #     A.ToGray(),\n",
    "# #     A.HueSaturationValue(),\n",
    "# ], p=1)\n",
    "\n",
    "# medium = A.Compose([\n",
    "#     A.CLAHE(p=1),\n",
    "#     A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=50, val_shift_limit=50, p=1),\n",
    "# ], p=1)\n",
    "\n",
    "\n",
    "# strong = A.Compose([\n",
    "#     A.ChannelShuffle(p=1),\n",
    "# ], p=1)\n",
    "# for _ in range(10):\n",
    "#     aug_img = light(image=image)['image']\n",
    "#     plt.figure(figsize=(10, 20))\n",
    "#     plt.imshow(aug_img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(image_paths, image_size, batch_size, steps_per_epoch, augmentation):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.zeros((batch_size, image_size[0], image_size[1], image_size[2]), dtype=np.uint8)\n",
    "        y_batch = np.zeros((batch_size))\n",
    "        for (ind, j) in enumerate(range(i*batch_size, (i+1)*batch_size)):\n",
    "            path = image_paths[j]\n",
    "            image = io.imread(path)\n",
    "            image = cv2.resize(image, (image_size[0], image_size[1]))\n",
    "            coin = np.random.rand()\n",
    "            if augmentation is not None:\n",
    "                if coin > 0.5:\n",
    "                    image = augmentation(image=image)['image']\n",
    "                    y_batch[ind, ...] += 1\n",
    "            x_batch[ind, ...] = image \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, keras.utils.to_categorical(y_batch, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(crops, image_size, batch_size, 10, augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    plt.imshow(xb[i, ...].squeeze())\n",
    "    k = np.argmax(yb[i, :])\n",
    "    if k == 0:\n",
    "        plt.title('Clear')\n",
    "    else:\n",
    "        plt.title('Blurry')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbnet = MobileNet(input_shape=image_size, dropout=1e-3, include_top=False, weights='imagenet', classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 1, int(1024 * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.GlobalAveragePooling2D()(mbnet.output)\n",
    "x = layers.Reshape(shape, name='reshape_1')(x)\n",
    "x = layers.Dropout(1e-3, name='dropout')(x)\n",
    "x = layers.Conv2D(2, (1, 1),\n",
    "                  padding='same',\n",
    "                  name='conv_preds')(x)\n",
    "x = layers.Activation('softmax', name='act_softmax')(x)\n",
    "x = layers.Reshape((2,), name='reshape_2')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([mbnet.input], [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(18679)\n",
    "random.shuffle(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(len(crops)*0.8)\n",
    "train = crops[:cutoff]\n",
    "val = crops[cutoff:]\n",
    "print(\"Train set: {}\".format(len(train)))\n",
    "print(\"Val set: {}\".format(len(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train) // batch_size\n",
    "steps_per_epoch_val = len(val) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train, image_size, batch_size, steps_per_epoch, augmentation)\n",
    "val_generator = generator(val, image_size, batch_size, steps_per_epoch_val, augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "adam = Adam(lr=lr)\n",
    "model.compile(adam, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training# start \n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        # callbacks=[saveh, lr_scheduler, checkpoint],\n",
    "        validation_data= val_generator,\n",
    "        validation_steps= steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4 Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_on_batch(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    k = np.argmax(y_pred[i, :])\n",
    "    plt.imshow(xb[i, ...])\n",
    "    if k == 0:\n",
    "        plt.title('Clear')\n",
    "    else:\n",
    "        plt.title('Blurry')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = glob.glob('/root/data/data_quality/crops/next/*/input/left_frame.jpg.crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = generator(frames, image_size, batch_size, 10, augmentation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    xb, _ = next(test_generator)\n",
    "    y_pred = model.predict_on_batch(xb)\n",
    "    f, ax = plt.subplots(8, 4, figsize=(10, 40))\n",
    "    for i in range(batch_size):\n",
    "        k = np.argmax(y_pred[i, :])\n",
    "\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        ax[row, col].imshow(xb[i, ...])\n",
    "        if k == 0:\n",
    "            ax[row, col].set_title('Clear')\n",
    "        else:\n",
    "            ax[row, col].set_title('Blurry')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
