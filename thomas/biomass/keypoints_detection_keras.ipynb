{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data and chunk it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_format = json.load(open(\"./keypoints_181017010001_json_format.json\"))\n",
    "example = json_format[1]\n",
    "image_path = \"/root/data/small_pen_data_collection/181017010001/right_small-pen-test-site_1_1539774727592.jpg\"\n",
    "image = io.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmap = {}\n",
    "mapclass = {}\n",
    "k = 1\n",
    "for (i, c) in enumerate(example[\"Label\"].keys()):\n",
    "    if c == \"Salmon\":\n",
    "        continue\n",
    "    classmap[k] = c\n",
    "    mapclass[c] = k\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(image, keypoints, tile):\n",
    "    chunks = []\n",
    "    height, width, _ = image.shape\n",
    "    for i in range(height//tile):\n",
    "        for j in range(width//tile):\n",
    "            one_hot_vector = np.zeros((10)) # 10 classes = 9 kp + other\n",
    "            tile_image = image[i*tile:i*tile+tile, j*tile:j*tile+tile]\n",
    "            tile_keypoints = keypoints[i*tile:i*tile+tile, j*tile:j*tile+tile]\n",
    "            # fish chunk\n",
    "            if np.max(tile_keypoints) == 0:\n",
    "                continue\n",
    "                one_hot_vector[0] = 1\n",
    "            else:\n",
    "                one_hot_vector[int(np.max(tile_keypoints))] = 1\n",
    "            chunks.append({\"gt\": one_hot_vector, \n",
    "                           \"tile\": tile_image, \n",
    "                           \"coordinates\": unravel_index(tile_keypoints.argmax(), tile_keypoints.shape)})\n",
    "                \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = create_chunks(image, keypoints, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for z in range(9):\n",
    "#     plt.imshow(chunks[z][\"tile\"])\n",
    "#     print(chunks[z][\"gt\"])\n",
    "#     print(classmap[np.argmax(chunks[z][\"gt\"])])\n",
    "#     coord = chunks[z][\"coordinates\"]\n",
    "#     plt.scatter(coord[1], coord[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(json_format, batch_size, tile):\n",
    "    while True:\n",
    "        xbatch = np.zeros((batch_size, tile, tile, 3), dtype=np.uint8)\n",
    "        y1 = np.zeros((batch_size, 2))\n",
    "        y2 = np.zeros((batch_size, 10))\n",
    "        ct = 0\n",
    "        while ct < batch_size:\n",
    "            random_sample = np.random.choice(json_format)\n",
    "#              print(random_sample['Labeled Data'])\n",
    "            random_image_path = os.path.join(\"/root/data/small_pen_data_collection/\", \"/\".join(random_sample['Labeled Data'].split(\"/\")[-2:]))\n",
    "            image = io.imread(random_image_path)\n",
    "            \n",
    "            # create keypoints map\n",
    "            k = 1\n",
    "            keypoints = np.zeros((image.shape[0], image.shape[1]))\n",
    "#             plt.imshow(image)\n",
    "            for (i, c) in enumerate(random_sample[\"Label\"].keys()):\n",
    "                if c == \"Salmon\":\n",
    "                    continue\n",
    "                y, x = random_sample[\"Label\"][c][0][\"geometry\"][\"x\"], random_sample[\"Label\"][c][0][\"geometry\"][\"y\"]\n",
    "                keypoints[x, y] = mapclass[c]\n",
    "#                 plt.scatter(y,x,color=\"r\")\n",
    "#             plt.show()\n",
    "\n",
    "            \n",
    "            chunks = create_chunks(image, keypoints, tile)\n",
    "            random.shuffle(chunks)\n",
    "            randlen = np.random.randint(low=1, high=len(chunks)+1)\n",
    "            for c in chunks[:randlen]:\n",
    "                if ct == batch_size:\n",
    "                    continue\n",
    "                xbatch[ct, ...] = c[\"tile\"]\n",
    "                y1[ct, ...] = c[\"coordinates\"]\n",
    "                y2[ct, ...] = c[\"gt\"]\n",
    "                ct += 1\n",
    "        yield (xbatch, {'reg': y1, 'classif': y2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(json_format, 8, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(8):\n",
    "    plt.imshow(xb[z, ...])\n",
    "    plt.scatter(yb[\"reg\"][z][1], yb[\"reg\"][z][0])\n",
    "#     reg, classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    # classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "#     print(chunks[z][\"gt\"])\n",
    "#     print(np.round(classif[0]*1000)/1000.0)\n",
    "#     print(classmap[np.argmax(classif[0])])\n",
    "#     print(reg[0])\n",
    "#     coord = chunks[z][\"coordinates\"]\n",
    "#     reg = reg[0]\n",
    "#     plt.scatter(coord[1], coord[0], color=\"r\")\n",
    "#     plt.scatter(reg[1], reg[0], color=\"b\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from utils import depthwise_conv_block, conv_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "dropout=1e-3\n",
    "classes = 2\n",
    "depth_multiplier = 1\n",
    "shape = (1, 1, int(1024 * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=[tile, tile, 3])\n",
    "x = conv_block(img_input, 32, alpha, strides=(2, 2))\n",
    "x = depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "x = depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=2)\n",
    "x = depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "x = depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=4)\n",
    "x = depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "x = depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=6)\n",
    "\n",
    "# head1 \n",
    "h1 = depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=8)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=9)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=10)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "h1 = depthwise_conv_block(h1, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=12)\n",
    "h1 = depthwise_conv_block(h1, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    \n",
    "h1 = layers.GlobalAveragePooling2D()(h1)\n",
    "h1 = layers.Reshape(shape, name='reshape_1')(h1)\n",
    "h1 = layers.Dropout(dropout, name='dropout1')(h1)\n",
    "h1 = layers.Conv2D(2, (1, 1), padding='same', name='conv_preds1')(h1)\n",
    "h1 = layers.Activation('linear', name='linear')(h1)\n",
    "reg = layers.Reshape((2,), name='reg')(h1)\n",
    "\n",
    "# head2\n",
    "h2 = depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=14)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=15)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=16)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=17)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=18)\n",
    "\n",
    "h2 = depthwise_conv_block(h2, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=19)\n",
    "h2 = depthwise_conv_block(h2, 1024, alpha, depth_multiplier, block_id=20)\n",
    "\n",
    "h2 = layers.GlobalAveragePooling2D()(h2)\n",
    "h2 = layers.Reshape(shape, name='reshape_2')(h2)\n",
    "h2 = layers.Dropout(dropout, name='dropout2')(h2)\n",
    "h2 = layers.Conv2D(10, (1, 1), padding='same', name='conv_preds2')(h2)\n",
    "h2 = layers.Activation('softmax', name='act_softmax')(h2)\n",
    "classif = layers.Reshape((10,), name='classif')(h2)\n",
    "\n",
    "\n",
    "model = Model(inputs=[img_input], outputs=[reg, classif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'reg': 'mean_squared_error', 'classif': 'categorical_crossentropy'}) #, loss_weights={'reg': 0.5, 'classif': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch= len(json_format) // 8, \n",
    "                    epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f:\n",
    "    json.dump(h, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h[\"reg_loss\"])\n",
    "plt.plot(h[\"classif_loss\"])\n",
    "plt.ylim([0, 500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/root/data/models/biomass/key_points_detection.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(9):\n",
    "    plt.imshow(chunks[z][\"tile\"])\n",
    "    reg, classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    # classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    print(chunks[z][\"gt\"])\n",
    "    print(np.round(classif[0]*1000)/1000.0)\n",
    "    print(classmap[np.argmax(classif[0])])\n",
    "    print(reg[0])\n",
    "    coord = chunks[z][\"coordinates\"]\n",
    "    reg = reg[0]\n",
    "    plt.scatter(coord[1], coord[0], color=\"r\")\n",
    "    plt.scatter(reg[1], reg[0], color=\"b\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_polygon = example[\"Label\"][\"Salmon\"][0][\"geometry\"]\n",
    "coordinates = np.array([[k[\"x\"], k[\"y\"]] for k in body_polygon])\n",
    "y1, y2 = np.min(coordinates[:, 0]), np.max(coordinates[:, 0])\n",
    "x1, x2 = np.min(coordinates[:, 1]), np.max(coordinates[:, 1])\n",
    "print(x1, x2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 20))\n",
    "ax.imshow(image[x1:x2, y1:y2])\n",
    "# plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = x2-x1\n",
    "width = y2-y1\n",
    "tile = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = image[x1:x2, y1:y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_crop = list(crop.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_chunks = [flatten_crop[i:i + 3*tile**2] for i in range(0, len(flatten_crop), 3*tile**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f: \n",
    "    json.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
