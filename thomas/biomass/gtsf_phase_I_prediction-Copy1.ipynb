{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTSF phase: biomass prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are forecasting the weights by finding the closest blender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the volumes created with blender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load blender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/thomas/blender/volumes_all.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(np.array(data[\"dimensions\"])[:, 1], data[\"volume\"])\n",
    "# plt.ylabel(\"Volume (cm^3)\")\n",
    "# plt.xlabel(\"Length (mm)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"volume\"])\n",
    "plt.title(\"Blender volume histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pairwise distances from blender data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = data[\"mapping\"]\n",
    "reverse_mapping = data[\"reverse_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_parts = max(list(mapping.values()))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"volume\":[]}\n",
    "dataset_np = []\n",
    "kfactors = []\n",
    "for (coord, vol) in zip(data[\"coordinates\"], data[\"volume\"]):\n",
    "    row = []\n",
    "    for k in range(number_of_parts):\n",
    "        v = coord[reverse_mapping[str(k)]]\n",
    "        for k0 in range(k+1, number_of_parts):\n",
    "            v0 = coord[reverse_mapping[str(k0)]]\n",
    "            dist = np.sqrt((v[2]-v0[2])**2 + (v[1]-v0[1])**2)\n",
    "            cname = \"{}-{}\".format(k, k0)\n",
    "            row.append(dist)\n",
    "            if cname not in dataset:\n",
    "                dataset[cname] = []\n",
    "            dataset[cname].append(dist)\n",
    "    dataset_np.append(row)\n",
    "    dataset[\"volume\"].append(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"2-3\"], \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the gtsf data\n",
    "\n",
    "Loading the gtsf data points and creating the pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfiles = [\"/root/data/gtsf_phase_I/2019-02-26/2019-02-26_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-02-27/2019-02-27_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-01/2019-03-01_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-04/2019-03-04_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-05/2019-03-05_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-06/2019-03-06_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-11/2019-03-11_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-13/2019-03-13_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-14/2019-03-14_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-18/2019-03-18_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-19/2019-03-19_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-21/2019-03-21_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-25/2019-03-25_cogito_annotations.json\",\n",
    "             \"/root/data/gtsf_phase_I/2019-03-27/2019-03-27_cogito_annotations.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for jsonpath in jsonfiles:\n",
    "    with open(jsonpath, \"r\") as f:\n",
    "        jfile = json.load(f)\n",
    "        annotations += jfile\n",
    "print(\"Number of annotations: {}\".format(len(annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the local path for ease and rename the body parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotations:\n",
    "    local_path = os.path.join(\"/root/data/gtsf_phase_I/\", \n",
    "                  \"/\".join(ann[\"Labeled Data\"].split(\"/\")[7:]))\n",
    "    ann[\"local_path\"] = local_path\n",
    "    if not os.path.isfile(local_path):\n",
    "        print(\"missing image!!\")\n",
    "    for body_part in ann[\"Label\"].keys():\n",
    "        new_body_part = \"_\".join(body_part.replace(\":\", \"\").split()).upper()\n",
    "        ann[\"Label\"][new_body_part] = ann[\"Label\"].pop(body_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ground truth weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table, select, func, and_, insert, delete, update, or_\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_credentials = json.load(open(\"/root/thomas/sql_research_credentials.json\"))\n",
    "\n",
    "sql_engine = create_engine(\n",
    "    \"postgresql://{}:{}@{}:{}/{}\".format(sql_credentials[\"user\"], sql_credentials[\"password\"],\n",
    "                                         sql_credentials[\"host\"], sql_credentials[\"port\"],\n",
    "                                         sql_credentials[\"database\"]))\n",
    "\n",
    "metadata = MetaData()\n",
    "gtsf = Table('gtsf_data_collections', metadata, autoload=True, autoload_with=sql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "for ann in annotations:\n",
    "    timestamp = ann[\"local_path\"].split(\"/\")[-3]\n",
    "    ann[\"timestamp\"] = timestamp\n",
    "    timestamps.append(ann[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query over all the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = select([gtsf.c.ground_truth_metadata,\n",
    "                gtsf.c.gtsf_fish_identifier]).select_from(gtsf).where(gtsf.c.gtsf_fish_identifier.in_(timestamps))\n",
    "connection = sql_engine.connect()\n",
    "q = connection.execute(query)\n",
    "results = [(eval(r[0]), r[1]) for r in q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the morphologic information to the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(r[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ann in annotations:\n",
    "    for r in results:\n",
    "        if r[1] == ann[\"timestamp\"]:\n",
    "            ann[\"weight\"] = r[0][\"data\"][\"weight\"]\n",
    "            ann[\"breath\"] = r[0][\"data\"][\"breath\"]\n",
    "            ann[\"length\"] = r[0][\"data\"][\"length\"]\n",
    "            ann[\"width\"] = r[0][\"data\"][\"width\"]\n",
    "            ann[\"kfactor\"] = 10**5*ann[\"weight\"] / ann[\"length\"]**3\n",
    "            ann[\"species\"] = r[0][\"data\"].get(\"species\", \"salmon\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ann for ann in annotations if ann[\"kfactor\"] < 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactor = np.array([ann[\"kfactor\"] for ann in annotations if ann[\"species\"] == \"salmon\"])\n",
    "plt.hist(kfactor)\n",
    "plt.title(\"K factor distribution of GTSF data\")\n",
    "plt.xlabel(\"K factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D to 3D \n",
    "\n",
    "Move from 2d pixel coordinates to 3d world coordinates. First, need to create pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating pairs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs per timestamp\n",
    "pairs = {}\n",
    "for ann in annotations:\n",
    "    if ann[\"species\"] != \"salmon\":\n",
    "        continue\n",
    "    if ann[\"kfactor\"] < 0.3:\n",
    "        continue\n",
    "    timestamp = ann[\"timestamp\"]\n",
    "    side = os.path.basename(ann[\"local_path\"]).split(\"_\")[0]\n",
    "    ann[\"side\"] = side\n",
    "    if timestamp not in pairs:\n",
    "        pairs[timestamp] = {}\n",
    "    pairs[timestamp][side] = ann\n",
    "\n",
    "full_pairs = [k for (k, v)in pairs.items() if \"left\" in v and \"right\" in v]\n",
    "print(\"Number of full pairs: {}\".format(len(full_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1 = {\"version\": 1, \"leftCrop\": [{\"xCrop\": 1808, \"yCrop\": 125, \"xFrame\": 1931, \"yFrame\": 581, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 1686, \"yCrop\": 160, \"xFrame\": 1809, \"yFrame\": 616, \"keypointType\": \"EYE\"}, {\"xCrop\": 1034, \"yCrop\": 62, \"xFrame\": 1157, \"yFrame\": 518, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 474, \"yCrop\": 318, \"xFrame\": 597, \"yFrame\": 774, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 132, \"yCrop\": 582, \"xFrame\": 255, \"yFrame\": 1038, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 632, \"yCrop\": 530, \"xFrame\": 755, \"yFrame\": 986, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 1013, \"yCrop\": 463, \"xFrame\": 1136, \"yFrame\": 919, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 1511, \"yCrop\": 309, \"xFrame\": 1634, \"yFrame\": 765, \"keypointType\": \"PECTORAL_FIN\"}], \"rightCrop\": [{\"xCrop\": 2266, \"yCrop\": 63, \"xFrame\": 2587, \"yFrame\": 717, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 2135, \"yCrop\": 145, \"xFrame\": 2456, \"yFrame\": 799, \"keypointType\": \"EYE\"}, {\"xCrop\": 1315, \"yCrop\": 95, \"xFrame\": 1636, \"yFrame\": 749, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 651, \"yCrop\": 438, \"xFrame\": 972, \"yFrame\": 1092, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 170, \"yCrop\": 816, \"xFrame\": 491, \"yFrame\": 1470, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 888, \"yCrop\": 670, \"xFrame\": 1209, \"yFrame\": 1324, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 1358, \"yCrop\": 585, \"xFrame\": 1679, \"yFrame\": 1239, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 1957, \"yCrop\": 347, \"xFrame\": 2278, \"yFrame\": 1001, \"keypointType\": \"PECTORAL_FIN\"}]}\n",
    "pair2 = {\"version\": 1, \"leftCrop\": [{\"xCrop\": 1148, \"yCrop\": 170, \"xFrame\": 2250, \"yFrame\": 1098, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 1082, \"yCrop\": 157, \"xFrame\": 2184, \"yFrame\": 1085, \"keypointType\": \"EYE\"}, {\"xCrop\": 649, \"yCrop\": 59, \"xFrame\": 1751, \"yFrame\": 987, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 290, \"yCrop\": 162, \"xFrame\": 1392, \"yFrame\": 1090, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 144, \"yCrop\": 244, \"xFrame\": 1246, \"yFrame\": 1172, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 379, \"yCrop\": 339, \"xFrame\": 1481, \"yFrame\": 1267, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 635, \"yCrop\": 345, \"xFrame\": 1737, \"yFrame\": 1273, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 984, \"yCrop\": 239, \"xFrame\": 2086, \"yFrame\": 1167, \"keypointType\": \"PECTORAL_FIN\"}], \"rightCrop\": [{\"xCrop\": 1198, \"yCrop\": 174, \"xFrame\": 2340, \"yFrame\": 897, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 1126, \"yCrop\": 169, \"xFrame\": 2268, \"yFrame\": 892, \"keypointType\": \"EYE\"}, {\"xCrop\": 719, \"yCrop\": 71, \"xFrame\": 1861, \"yFrame\": 794, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 313, \"yCrop\": 181, \"xFrame\": 1455, \"yFrame\": 904, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 103, \"yCrop\": 264, \"xFrame\": 1245, \"yFrame\": 987, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 403, \"yCrop\": 343, \"xFrame\": 1545, \"yFrame\": 1066, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 658, \"yCrop\": 349, \"xFrame\": 1800, \"yFrame\": 1072, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 996, \"yCrop\": 253, \"xFrame\": 2138, \"yFrame\": 976, \"keypointType\": \"PECTORAL_FIN\"}]}\n",
    "pair3 = {\"version\": 1, \"leftCrop\": [{\"xCrop\": 1239, \"yCrop\": 115, \"xFrame\": 2493, \"yFrame\": 1342, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 1167, \"yCrop\": 124, \"xFrame\": 2421, \"yFrame\": 1351, \"keypointType\": \"EYE\"}, {\"xCrop\": 735, \"yCrop\": 77, \"xFrame\": 1989, \"yFrame\": 1304, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 360, \"yCrop\": 222, \"xFrame\": 1614, \"yFrame\": 1449, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 117, \"yCrop\": 356, \"xFrame\": 1371, \"yFrame\": 1583, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 455, \"yCrop\": 395, \"xFrame\": 1709, \"yFrame\": 1622, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 729, \"yCrop\": 368, \"xFrame\": 1983, \"yFrame\": 1595, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 1071, \"yCrop\": 232, \"xFrame\": 2325, \"yFrame\": 1459, \"keypointType\": \"PECTORAL_FIN\"}], \"rightCrop\": [{\"xCrop\": 1180, \"yCrop\": 103, \"xFrame\": 2418, \"yFrame\": 1470, \"keypointType\": \"UPPER_LIP\"}, {\"xCrop\": 1121, \"yCrop\": 111, \"xFrame\": 2359, \"yFrame\": 1478, \"keypointType\": \"EYE\"}, {\"xCrop\": 753, \"yCrop\": 40, \"xFrame\": 1991, \"yFrame\": 1407, \"keypointType\": \"DORSAL_FIN\"}, {\"xCrop\": 349, \"yCrop\": 174, \"xFrame\": 1587, \"yFrame\": 1541, \"keypointType\": \"ADIPOSE_FIN\"}, {\"xCrop\": 160, \"yCrop\": 314, \"xFrame\": 1398, \"yFrame\": 1681, \"keypointType\": \"TAIL_NOTCH\"}, {\"xCrop\": 452, \"yCrop\": 313, \"xFrame\": 1690, \"yFrame\": 1680, \"keypointType\": \"ANAL_FIN\"}, {\"xCrop\": 701, \"yCrop\": 297, \"xFrame\": 1939, \"yFrame\": 1664, \"keypointType\": \"PELVIC_FIN\"}, {\"xCrop\": 1019, \"yCrop\": 205, \"xFrame\": 2257, \"yFrame\": 1572, \"keypointType\": \"PECTORAL_FIN\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[1] = {}\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair1[\"leftCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[1][\"left\"] = ann_tmp\n",
    "\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair1[\"rightCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[1][\"right\"] = ann_tmp\n",
    "\n",
    "pairs[2] = {}\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair2[\"leftCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[2][\"left\"] = ann_tmp\n",
    "\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair2[\"rightCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[2][\"right\"] = ann_tmp\n",
    "\n",
    "pairs[3] = {}\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair3[\"leftCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[3][\"left\"] = ann_tmp\n",
    "\n",
    "ann_tmp = {}\n",
    "label = {}\n",
    "for kp in pair3[\"rightCrop\"]:\n",
    "    label[kp[\"keypointType\"]] = [{\"geometry\": {\"x\": kp[\"xFrame\"], \"y\": kp[\"yFrame\"]}}]\n",
    "ann_tmp[\"Label\"] = label\n",
    "pairs[3][\"right\"] = ann_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair2[\"leftCrop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair2[\"rightCrop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the keypoints and create world coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import depth_from_disp, convert_to_world_point, load_keypoints, euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = False\n",
    "new_shape = (512, 512)\n",
    "height_ratio = new_shape[0] / 3000.0\n",
    "width_ratio = new_shape[1] / 4096.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = {}\n",
    "for ts in full_pairs:\n",
    "    # load annotations\n",
    "    left_ann = pairs[ts][\"left\"]\n",
    "    # print(left_ann)\n",
    "    right_ann = pairs[ts][\"right\"]\n",
    "    # print(right_ann)\n",
    "    \n",
    "    left_keypoints = load_keypoints(left_ann, mapping)\n",
    "    # print(left_keypoints)\n",
    "    right_keypoints = load_keypoints(right_ann, mapping)\n",
    "    # print(right_keypoints)\n",
    "    \n",
    "    if rescale:\n",
    "        left_keypoints = left_keypoints * np.array([width_ratio, height_ratio])\n",
    "        left_keypoints = np.array(left_keypoints, dtype=np.uint8)\n",
    "        right_keypoints = right_keypoints * np.array([width_ratio, height_ratio])\n",
    "        right_keypoints = np.array(right_keypoints, dtype=np.uint8)\n",
    "        \n",
    "    # calculate disparities\n",
    "    disparities = left_keypoints[:, 1] - right_keypoints[:, 1]\n",
    "    # print(disparities)\n",
    "    # compute world key point\n",
    "    world_keypoints = {}\n",
    "    for (i, d) in enumerate(disparities):\n",
    "        depth = depth_from_disp(d)\n",
    "        world_coord = convert_to_world_point(left_keypoints[i, 0], left_keypoints[i, 1], depth)\n",
    "        world_keypoints[list(mapping.keys())[i]] = world_coord\n",
    "    world[ts] = world_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot world coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(left_keypoints[:, 0], left_keypoints[:, 1])\n",
    "# for i in range(number_of_parts):\n",
    "#     plt.text(left_keypoints[i, 0], left_keypoints[i, 1], list(mapping.keys())[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for (k, v) in world[3].items():\n",
    "    plt.scatter(v[0], v[2])\n",
    "    plt.text(v[0]+0.003, v[2]+0.003, k)\n",
    "    plt.axis(\"scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "\n",
    "First, let's calculate the pairwise distances for the gtsf data. Second let's find the closest Blender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions_average = []\n",
    "ground_truth = []\n",
    "\n",
    "for ts in world:\n",
    "    # load keypoints\n",
    "    world_keypoints = world[ts]\n",
    "    # calculate distances\n",
    "    measurements= []\n",
    "    for k in range(number_of_parts):\n",
    "        v = world_keypoints[reverse_mapping[str(k)]]\n",
    "        for k0 in range(k+1, number_of_parts):\n",
    "            v0 = world_keypoints[reverse_mapping[str(k0)]]\n",
    "            dist = euclidean_distance(v, v0)*1000 # mm to m\n",
    "            measurements.append(dist)\n",
    "    print(measurements)\n",
    "    # find closest blender volume\n",
    "    # calculate l1 distance\n",
    "    diff = np.nanmean(np.abs(np.array(df)[:, :-1] - measurements), axis=1)\n",
    "    closest = np.argsort(diff)\n",
    "    idx = 10\n",
    "    closest5 = np.array(df)[closest[:idx], -1]\n",
    "    print(\"closest volumes\", closest5)\n",
    "    print(\"standard dev:\", np.std(closest5))\n",
    "    print(\"estimated length\", measurements[13])\n",
    "    closest_length = np.array(list(df[\"2-3\"].iloc()[closest[:idx]]))\n",
    "    kfactor = 10**5*closest5 / closest_length**3\n",
    "    print(\"closest length\", closest_length)\n",
    "    print(\"closest kfactor\", kfactor)\n",
    "    print(\"closest height\", list(df[\"4-6\"].iloc()[closest[:idx]]))\n",
    "    print(\"#\"*50)\n",
    "    pred_volume = np.array(df)[closest[0], -1]\n",
    "    predictions.append(pred_volume)\n",
    "    predictions_average.append(np.mean(closest5))\n",
    "    \n",
    "    # ground truth\n",
    "#     ground_truth_weight = [ann[\"weight\"] for ann in annotations if ann[\"timestamp\"] == ts][0]\n",
    "#     ground_truth_kfactor = [ann[\"kfactor\"] for ann in annotations if ann[\"timestamp\"] == ts][0]\n",
    "#     ground_truth.append([ground_truth_weight, ground_truth_kfactor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meas= \"\"\"2684.92980358  332.35755178 1184.08141775  495.63520638 1015.34894681\n",
    " 1776.57965705  307.67928677 3010.22300125 2316.7343537  2364.15814777\n",
    " 2021.60372757  969.82654924 2980.75134815 1386.37623863  741.1349069\n",
    " 1276.90865534 2099.10758612   67.69223402  853.26597402  449.11099177\n",
    " 1730.27620946 1321.52302624  585.2457656  1528.41323825  694.6478539\n",
    " 1353.77570118 1221.00570886 2078.11299396\"\"\"\n",
    "tmp_meas = [float(t) for t in tmp_meas.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meas = \"\"\"423.59659438 118.69470273 571.57517227 253.73100651 474.48223513\n",
    " 273.11181083  79.59655751 501.75527985 238.34702309 280.47944047\n",
    " 214.21327857 163.1917898  491.30301233 667.59069335 332.97026956\n",
    " 569.06195017 345.40201862  76.70760669 362.94126826 114.93850252\n",
    " 371.08882481 634.58451829 252.52398985 220.38174009 294.64349748\n",
    " 306.71541616 532.27316335 342.06575775\"\"\"\n",
    "tmp_meas = [float(t) for t in tmp_meas.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.nanmean(np.abs(np.array(data[\"distances\"]) - tmp_meas), axis=1)\n",
    "idx = 10\n",
    "closest5 = np.array(df)[closest[:idx], -1]\n",
    "print(\"closest volumes\", closest5)\n",
    "print(\"standard dev:\", np.std(closest5))\n",
    "print(\"estimated length\", measurements[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions_average = np.array(predictions_average)\n",
    "ground_truth = np.array(ground_truth)\n",
    "gt_weight = ground_truth[:, 0]\n",
    "gt_kfactor = ground_truth[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OLD CODE**\n",
    "\n",
    "Quick OLS. \n",
    "\n",
    "$\\hat{\\beta} = (X^{T}X)^{-1}X^{T}Y$\n",
    "\n",
    "(just for Alok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = ground_truth[:, np.newaxis]\n",
    "# ground_truth.shape\n",
    "# A = np.linalg.inv(np.matmul(ground_truth.transpose(), ground_truth))\n",
    "# B = np.matmul(ground_truth.transpose(), predictions)\n",
    "# coeff = 1 / (A*B)\n",
    "# print(\"Reg coeff: {}\".format(coeff))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot([0, 5000], [0, 5000], \"--\", c=\"r\", linewidth=2)\n",
    "# plt.scatter(ground_truth, predictions*coeff)\n",
    "# #plt.scatter(ground_truth, predictions)\n",
    "# plt.xlabel(\"Ground truth weight\")\n",
    "# plt.ylabel(\"Predicted weight\")\n",
    "# plt.axis(\"scaled\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear reg New code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[:, np.newaxis]\n",
    "reg = LinearRegression().fit(predictions, gt_weight)\n",
    "print(reg.coef_, reg.intercept_)\n",
    "print(\"R2 : {}\".format(reg.score(predictions, gt_weight)))\n",
    "predictions = np.squeeze(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 5000], [0, 5000], \"--\", c=\"r\", linewidth=2)\n",
    "plt.scatter(gt_weight, predictions*reg.coef_ + reg.intercept_, c=gt_kfactor)\n",
    "#plt.scatter(ground_truth, predictions)\n",
    "plt.xlabel(\"Ground truth weight\")\n",
    "plt.ylabel(\"Predicted weight\")\n",
    "plt.colorbar()\n",
    "plt.clim([0.8, 1.6])\n",
    "plt.axis(\"scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_predictions = predictions*reg.coef_ + reg.intercept_\n",
    "error = fitted_predictions-gt_weight\n",
    "print(\"Average absolute error: {}\".format(np.nanmean(np.abs(error))))\n",
    "print(\"Average error: {}\".format(np.nanmean(error)))\n",
    "# error5 = predictions_average-ground_truth\n",
    "#print(\"Average absolute error5: {}\".format(np.nanmean(np.abs(error5))))\n",
    "relative_error = ((fitted_predictions-gt_weight) / gt_weight)*100\n",
    "print(\"Average relative error: {} %\".format(np.nanmean(relative_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.kde import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = gaussian_kde(error)\n",
    "dist_space = np.linspace( min(error), max(error), 100 )\n",
    "plt.hist(error, bins=20, density=True)\n",
    "plt.plot( dist_space, kde(dist_space) )\n",
    "plt.title(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = gaussian_kde(relative_error)\n",
    "dist_space = np.linspace( min(relative_error), max(relative_error), 100 )\n",
    "plt.hist(relative_error, bins=20, density=True)\n",
    "plt.plot( dist_space, kde(dist_space) )\n",
    "plt.title(\"Relative Error (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentile plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.arange(0, 101, 5)\n",
    "percentiles = np.percentile(np.abs(relative_error), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(percentiles, values)\n",
    "plt.yticks(np.arange(0,101,5))\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xlabel(\"Absolute relative error (%)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KS test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = norm.fit(fitted_predictions)\n",
    "print(\"Mean: {}, Standard deviation: {}\".format(mean, std))\n",
    "plt.hist(fitted_predictions, bins=20, normed=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(fitted_predictions, norm(loc=mean, scale=std).cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = np.squeeze(predictions)\n",
    "# all_errors = []\n",
    "# for i in np.arange(0.1, 1.0, 0.1):\n",
    "#     predictions = predictions[:, np.newaxis]\n",
    "#     test_size = i\n",
    "#     print(test_size)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(predictions, ground_truth, test_size=test_size)\n",
    "#     X_test= np.squeeze(X_test)\n",
    "    \n",
    "#     plt.scatter(X_train, y_train)\n",
    "#     plt.scatter(X_test, y_test)\n",
    "#     plt.axis(\"scaled\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     reg = LinearRegression().fit(X_train, y_train)\n",
    "#     print(reg.coef_, reg.intercept_)\n",
    "#     print(\"R2 : {}\".format(reg.score(X_train, y_train)))\n",
    "#     predictions = np.squeeze(predictions)\n",
    "    \n",
    "    \n",
    "#     fitted_X_test = X_test*reg.coef_ + reg.intercept_\n",
    "#     error = fitted_X_test-y_test\n",
    "#     print(\"Average absolute error: {}\".format(np.nanmean(np.abs(error))))\n",
    "#     print(\"Average error: {}\".format(np.nanmean(error)))\n",
    "#     relative_error = ((fitted_X_test-y_test) / y_test)*100\n",
    "#     print(\"Average relative error: {} %\".format(np.nanmean(relative_error)))\n",
    "#     all_errors.append(np.nanmean(relative_error))\n",
    "#     print(\"#\"*50)\n",
    "# plt.plot(np.arange(0.1, 1.0, 0.1)*100 , all_errors)\n",
    "# plt.ylabel(\"Test set average relative error\")\n",
    "# plt.xlabel(\"Test set size (% of total pop)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(predictions)\n",
    "all_errors = []\n",
    "all_relative_errors = []\n",
    "for i in range(1000):\n",
    "    predictions = predictions[:, np.newaxis]\n",
    "    test_size = i\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictions, gt_weight, test_size=0.2)\n",
    "    X_test= np.squeeze(X_test)\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    # print(reg.coef_, reg.intercept_)\n",
    "    # print(\"R2 : {}\".format(reg.score(X_train, y_train)))\n",
    "    predictions = np.squeeze(predictions)\n",
    "    \n",
    "    \n",
    "    fitted_X_test = X_test*reg.coef_ + reg.intercept_\n",
    "    error = fitted_X_test-y_test\n",
    "    relative_error = ((fitted_X_test-y_test) / y_test)*100\n",
    "    all_errors.append(np.nanmean(error))\n",
    "    all_relative_errors.append(np.nanmean(relative_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_errors)\n",
    "plt.xlabel(\"Average error distribution\")\n",
    "plt.show()\n",
    "plt.hist(all_relative_errors)\n",
    "plt.xlabel(\"Average relative error distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
