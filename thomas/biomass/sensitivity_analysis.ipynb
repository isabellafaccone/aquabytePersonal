{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import skimage.io as io\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotation file (gtsf predictions)\n",
    "coco = COCO(\"/root/data/small_pen_data_collection/coco_body_parts_merged_27k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coco.imgs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs list\n",
    "pairs = {}\n",
    "for (imgid, imgdata) in coco.imgs.items():\n",
    "    # file_name = imgdata['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "    # img_path = local_dic[file_name]\n",
    "    img_path = imgdata['local_path']\n",
    "    annotation_ids = coco.getAnnIds(imgIds=[imgid])\n",
    "    if len(annotation_ids) == 0:\n",
    "        continue\n",
    "    if 'rectified' in img_path:\n",
    "        ts = os.path.basename(img_path).split('.')[0].split('_')[-1]\n",
    "        side = os.path.basename(img_path).split('.')[0].split('_')[0]\n",
    "        if ts not in pairs:\n",
    "            pairs[ts] = {}\n",
    "        pairs[ts][side] = imgid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pairs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random timestamps\n",
    "random_timestamp = np.random.choice(list(pairs.keys()))\n",
    "# random_timestamp = '1539347092528'\n",
    "# random_timestamp = '1539339593113'\n",
    "random_timestamp = '1539775997086'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image_data\n",
    "left_image_data = coco.loadImgs([pairs[random_timestamp]['right']])[0]\n",
    "right_image_data = coco.loadImgs([pairs[random_timestamp]['left']])[0]\n",
    "\n",
    "# load images\n",
    "left_image = io.imread(left_image_data['local_path'])\n",
    "right_image = io.imread(right_image_data['local_path'])\n",
    "\n",
    "\n",
    "# load annotations\n",
    "left_annotations = coco.imgToAnns[left_image_data[\"id\"]]\n",
    "right_annotations = coco.imgToAnns[right_image_data[\"id\"]]\n",
    "\n",
    "# plot\n",
    "f ,ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(left_image)\n",
    "for ann in left_annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax[0].add_patch(rec)\n",
    "    seg = ann['segmentation'][0]\n",
    "    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "    c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "    ax[0].add_patch(patches.Polygon(poly, facecolor=c, linewidth=0, alpha=0.4))\n",
    "    ax[0].add_patch(patches.Polygon(poly, facecolor='none', edgecolor=c, linewidth=2))\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "ax[1].imshow(right_image)\n",
    "for ann in right_annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax[1].add_patch(rec)\n",
    "    seg = ann['segmentation'][0]\n",
    "    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "    polygon = patches.Polygon(poly)\n",
    "    c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "    ax[1].add_patch(patches.Polygon(poly, facecolor=c, linewidth=0, alpha=0.4))\n",
    "    ax[1].add_patch(patches.Polygon(poly, facecolor='none', edgecolor=c, linewidth=2))\n",
    "    ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get world coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = 0.0107\n",
    "baseline = 0.135\n",
    "pixel_size_m = 3.45 * 1e-6 \n",
    "focal_length_pixel = focal_length / pixel_size_m\n",
    "image_sensor_width = 0.01412\n",
    "image_sensor_height = 0.01412\n",
    "\n",
    "\n",
    "def depth_from_disp(disp):\n",
    "    depth = focal_length_pixel*baseline / np.array(disp)\n",
    "    return depth\n",
    "\n",
    "\n",
    "def convert_to_world_point(x, y, d):\n",
    "    image_center_x = 3000 / 2.0 #depth_map.shape[1] / 2.0\n",
    "    image_center_y = 4096 / 2.0# depth_map.shape[0] / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (image_sensor_height / 3000)\n",
    "    sensor_z = px_z * (image_sensor_width / 4096)\n",
    "    \n",
    "    # d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "    return np.array((world_x, world_y, world_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids\n",
    "world_coordinates = {}\n",
    "for cat in range(2, 9):\n",
    "    # get the seg\n",
    "    left_seg = [ann for ann in left_annotations if ann['category_id'] == cat][0]['segmentation'][0]\n",
    "    right_seg = [ann for ann in right_annotations if ann['category_id'] == cat][0]['segmentation'][0]\n",
    "    \n",
    "    # get the centroids\n",
    "    poly = np.array(left_seg).reshape((int(len(left_seg)/2), 2))\n",
    "    left_centroid = [np.mean(poly[:, 0]), np.mean(poly[:, 1])]\n",
    "    \n",
    "    poly = np.array(right_seg).reshape((int(len(right_seg)/2), 2))\n",
    "    right_centroid = [np.mean(poly[:, 0]), np.mean(poly[:, 1])]\n",
    "    \n",
    "    # get the world coordinates\n",
    "#     print(left_centroid, right_centroid)\n",
    "    disparity = left_centroid[0] - right_centroid[0]\n",
    "#     print(disparity)\n",
    "    depth = depth_from_disp(disparity)\n",
    "    world_coordinates[str(cat)] = convert_to_world_point(left_centroid[1], left_centroid[0], depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = [str(ids) for ids in range(2, 9) ]\n",
    "pairwise_distances = [c+k for (i, c) in enumerate(category_ids) for k in category_ids[i+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for d in pairwise_distances:\n",
    "    dataset[d] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairwise_distances:\n",
    "    if pair == 'ground_truth' or pair == 'left_image_key':\n",
    "        continue\n",
    "    cat0, cat1 = pair[0], pair[1]\n",
    "    dist = np.linalg.norm(world_coordinates[cat0] - world_coordinates[cat1])\n",
    "    dataset[pair].append(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relax the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from statsmodels.iolib.smpickle import load_pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 5\n",
    "jitter = 20\n",
    "nsimulation = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = np.load(\"/root/data/models/biomass/components_sensitivity.npy\")\n",
    "iqr = json.load(open(\"/root/data/models/biomass/iqr_sensitivity.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pickle(\"/root/data/models/biomass/model_sensitivity.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i in tqdm(range(nsimulation)):\n",
    "    \n",
    "    world_coordinates = {}\n",
    "    for cat in range(2, 9):\n",
    "        # get the seg\n",
    "        left_seg = [ann for ann in left_annotations if ann['category_id'] == cat][0]['segmentation'][0]\n",
    "        right_seg = [ann for ann in right_annotations if ann['category_id'] == cat][0]['segmentation'][0]\n",
    "\n",
    "        # get the centroids\n",
    "        poly = np.array(left_seg).reshape((int(len(left_seg)/2), 2))\n",
    "        left_centroid = [np.mean(poly[:, 0]), np.mean(poly[:, 1])] \n",
    "        coin = np.random.rand()\n",
    "        if i > 0:\n",
    "            if coin > p:\n",
    "                left_centroid += np.random.uniform(low=-jitter, high=jitter, size=2)\n",
    "        \n",
    "        poly = np.array(right_seg).reshape((int(len(right_seg)/2), 2))\n",
    "        right_centroid = [np.mean(poly[:, 0]), np.mean(poly[:, 1])]\n",
    "        if i > 0:\n",
    "            if coin > p:\n",
    "                right_centroid += np.random.uniform(low=-jitter, high=jitter, size=2)\n",
    "            \n",
    "        # get the world coordinates\n",
    "        disparity = left_centroid[0] - right_centroid[0]\n",
    "        depth = depth_from_disp(disparity)\n",
    "        world_coordinates[str(cat)] = convert_to_world_point(left_centroid[1], left_centroid[0], depth)\n",
    "    \n",
    "    dataset = {}\n",
    "    for d in pairwise_distances:\n",
    "        dataset[d] = []\n",
    "    \n",
    "    # stuff\n",
    "    for pair in pairwise_distances:\n",
    "        if pair == 'ground_truth' or pair == 'left_image_key':\n",
    "            continue\n",
    "        cat0, cat1 = pair[0], pair[1]\n",
    "        dist = np.linalg.norm(world_coordinates[cat0] - world_coordinates[cat1])\n",
    "        dataset[pair].append(dist)\n",
    "    \n",
    "    df = pd.DataFrame(dataset)\n",
    "    for pwd in pairwise_distances:\n",
    "        df[pwd] = df[pwd] / iqr[pwd]\n",
    "    \n",
    "    pidx = np.indices((df.shape[1], df.shape[1])).reshape(2, -1)\n",
    "    lcol = pd.MultiIndex.from_product([df.columns, df.columns],  names=[df.columns.name, df.columns.name])\n",
    "    X = pd.DataFrame(df.values[:, pidx[0]] * df.values[:, pidx[1]],  columns=lcol)\n",
    "    \n",
    "    # pick number of parts to jitter\n",
    "    newX = np.dot(X, components.T)\n",
    "    weight = np.squeeze(model.predict(newX))\n",
    "    weights.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weights)\n",
    "plt.plot([weights[0], weights[0]], [0, 2000], color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
