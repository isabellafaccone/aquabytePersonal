{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "source": [
    "# keras_retinanet imports\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "# sys.path.append('/root/amol/product_detection/keras-retinanet/keras_retinanet/preprocessing/')\n",
    "# from csv_generator import CSVGenerator\n",
    "# from ..models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "\n",
    "\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/root/data/lice_detection/lice_dataset_fish_only_train.csv'\n",
    "classes = '/root/data/lice_detection/class_id.csv'\n",
    "batch_size = 4\n",
    "val_annotations = '/root/data/lice_detection/lice_dataset_fish_only_val.csv'"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/root/data/blender_v2/training/free_low_rez/annotations.csv'\n",
    "classes = '/root/data/blender_v2/training/classID.csv'\n",
    "batch_size = 8\n",
    "val_annotations = None"
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create generators"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 6,
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(annotations,classes,batch_size=1,val_annotations=''):\n",
    "    # create random transform generator for augmenting training data\n",
<<<<<<< HEAD
    "    # transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "    \n",
    "    transform_generator = random_transform_generator(\n",
    "    min_rotation=-0.2,\n",
    "    max_rotation=0.2,\n",
    "    min_translation=(-0.3, -0.3),\n",
    "    max_translation=(0.3, 0.3),\n",
    "    min_shear=-0.3,\n",
    "    max_shear=0.3,\n",
    "    min_scaling=(0.5, 0.5),\n",
    "    max_scaling=(1.3, 1.3),\n",
    "    flip_x_chance=0,\n",
    "    flip_y_chance=0.5)\n",
=======
    "    transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "\n",
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "    \n",
    "    \n",
    "    train_generator = CSVGenerator(\n",
    "        annotations,\n",
    "        classes,\n",
    "        transform_generator=transform_generator,\n",
<<<<<<< HEAD
    "        batch_size=batch_size,\n",
    "        image_min_side=800,\n",
    "        image_max_side=1500\n",
=======
    "        batch_size=batch_size\n",
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "    )\n",
    "\n",
    "\n",
    "    if val_annotations:\n",
    "        validation_generator = CSVGenerator(\n",
    "            val_annotations,\n",
    "            classes,\n",
<<<<<<< HEAD
    "            batch_size=batch_size,\n",
    "            image_min_side=800,\n",
    "            image_max_side=1500\n",
=======
    "            batch_size=batch_size\n",
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "        )\n",
    "    else:\n",
    "        validation_generator = None\n",
    "    \n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = create_generators(annotations, classes, batch_size, val_annotations)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.size()"
   ]
  },
  {
=======
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0, freeze_backbone=False):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "backbone = models.backbone('resnet50')\n",
    "weights = backbone.download_imagenet()"
=======
    "weights = download_imagenet('resnet50')"
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "model, training_model, prediction_model = create_models(\n",
    "    backbone_retinanet=backbone.retinanet,\n",
    "    num_classes=train_generator.num_classes(),\n",
    "    weights=weights\n",
    ")"
=======
    "model, training_model, prediction_model = create_models(backbone_retinanet=retinanet,\n",
    "                                                        backbone='resnet50',\n",
    "                                                        num_classes=train_generator.num_classes(),\n",
    "                                                        weights=weights)"
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-5\n",
    "    drop = 0.5\n",
<<<<<<< HEAD
    "    epochs_drop = 20.0\n",
=======
    "    epochs_drop = 10.0\n",
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/retinanet/', 'model_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
=======
   "metadata": {
    "scrolled": true
   },
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
   "outputs": [],
   "source": [
    "# start training\n",
    "history = training_model.fit_generator(\n",
    "        generator=train_generator,\n",
<<<<<<< HEAD
    "        steps_per_epoch=500//batch_size,\n",
    "        epochs=40,\n",
    "        verbose=1,\n",
    "        validation_data= validation_generator,\n",
    "        validation_steps= 50 // batch_size,\n",
    "        callbacks=[lr_scheduler, saveh]\n",
=======
    "        steps_per_epoch=1000//batch_size,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        # callbacks=[checkpoint, lr_scheduler]\n",
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "source": [
    "training_model.save('/root/data/blender_v2/detection_free.h5')"
   ]
>>>>>>> 24fbdf5bb74c2192fc3e12557d427eec454cae70
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
