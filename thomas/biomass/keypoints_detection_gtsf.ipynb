{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data and chunk it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pycocotools/coco.py:49: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ddb6debf7fbb>\", line 3, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "import glob\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data in air\n",
    "jsonfiles = glob.glob(\"/root/data/gtsf_2.0/gtsf_air/labels/*.json\")\n",
    "data = []\n",
    "for jf in jsonfiles: \n",
    "    data += json.load(open(jf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download images\n",
    "for d in data:\n",
    "    url = d['Labeled Data']\n",
    "    path = \"/root/data/gtsf_2.0/gtsf_air/images/{}\".format(d['External ID'])\n",
    "    if os.path.isfile(path):\n",
    "        continue\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(path, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d for d in data if d[\"Label\"] != \"Skip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = ['eye', \n",
    "             'adipose fin', \n",
    "             'dorsal fin', \n",
    "             'pectoral fin', \n",
    "             'upper lip', \n",
    "             'anal fin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "good_data = []\n",
    "for d in data:\n",
    "    if d[\"Label\"] != \"Skip\":\n",
    "        cter = 0\n",
    "        for k in keypoints:\n",
    "            if k in d[\"Label\"].keys():\n",
    "                cter += 1\n",
    "        if cter == len(keypoints):\n",
    "            good_data.append(d)\n",
    "print(len(good_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, batch_size, image_shape=[]):\n",
    "    while True:\n",
    "        xbatch = np.zeros((batch_size, tile, tile, 3), dtype=np.uint8)\n",
    "        ybatch = np.zeros((batch_size, 2*len(keypoints)))\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "        yield (xbatch, ybatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_format = json.load(open(\"./keypoints_181017010001_json_format.json\"))\n",
    "example = json_format[1]\n",
    "image_path = \"/root/data/small_pen_data_collection/181017010001/right_small-pen-test-site_1_1539774727592.jpg\"\n",
    "image = io.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmap = {}\n",
    "mapclass = {}\n",
    "k = 1\n",
    "for (i, c) in enumerate(example[\"Label\"].keys()):\n",
    "    if c == \"Salmon\":\n",
    "        continue\n",
    "    classmap[k] = c\n",
    "    mapclass[c] = k\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(image, keypoints, tile):\n",
    "    chunks = []\n",
    "    height, width, _ = image.shape\n",
    "    for i in range(height//tile):\n",
    "        for j in range(width//tile):\n",
    "            one_hot_vector = np.zeros((10)) # 10 classes = 9 kp + other\n",
    "            tile_image = image[i*tile:i*tile+tile, j*tile:j*tile+tile]\n",
    "            tile_keypoints = keypoints[i*tile:i*tile+tile, j*tile:j*tile+tile]\n",
    "            # fish chunk\n",
    "            if np.max(tile_keypoints) == 0:\n",
    "                continue\n",
    "                one_hot_vector[0] = 1\n",
    "            else:\n",
    "                one_hot_vector[int(np.max(tile_keypoints))] = 1\n",
    "            chunks.append({\"gt\": one_hot_vector, \n",
    "                           \"tile\": tile_image, \n",
    "                           \"coordinates\": unravel_index(tile_keypoints.argmax(), tile_keypoints.shape)})\n",
    "                \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = create_chunks(image, keypoints, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for z in range(9):\n",
    "#     plt.imshow(chunks[z][\"tile\"])\n",
    "#     print(chunks[z][\"gt\"])\n",
    "#     print(classmap[np.argmax(chunks[z][\"gt\"])])\n",
    "#     coord = chunks[z][\"coordinates\"]\n",
    "#     plt.scatter(coord[1], coord[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(json_format, batch_size, tile):\n",
    "    while True:\n",
    "        xbatch = np.zeros((batch_size, tile, tile, 3), dtype=np.uint8)\n",
    "        y1 = np.zeros((batch_size, 2))\n",
    "        y2 = np.zeros((batch_size, 10))\n",
    "        ct = 0\n",
    "        while ct < batch_size:\n",
    "            random_sample = np.random.choice(json_format)\n",
    "#              print(random_sample['Labeled Data'])\n",
    "            random_image_path = os.path.join(\"/root/data/small_pen_data_collection/\", \"/\".join(random_sample['Labeled Data'].split(\"/\")[-2:]))\n",
    "            image = io.imread(random_image_path)\n",
    "            \n",
    "            # create keypoints map\n",
    "            k = 1\n",
    "            keypoints = np.zeros((image.shape[0], image.shape[1]))\n",
    "#             plt.imshow(image)\n",
    "            for (i, c) in enumerate(random_sample[\"Label\"].keys()):\n",
    "                if c == \"Salmon\":\n",
    "                    continue\n",
    "                y, x = random_sample[\"Label\"][c][0][\"geometry\"][\"x\"], random_sample[\"Label\"][c][0][\"geometry\"][\"y\"]\n",
    "                keypoints[x, y] = mapclass[c]\n",
    "#                 plt.scatter(y,x,color=\"r\")\n",
    "#             plt.show()\n",
    "\n",
    "            \n",
    "            chunks = create_chunks(image, keypoints, tile)\n",
    "            random.shuffle(chunks)\n",
    "            randlen = np.random.randint(low=1, high=len(chunks)+1)\n",
    "            for c in chunks[:randlen]:\n",
    "                if ct == batch_size:\n",
    "                    continue\n",
    "                xbatch[ct, ...] = c[\"tile\"]\n",
    "                y1[ct, ...] = c[\"coordinates\"]\n",
    "                y2[ct, ...] = c[\"gt\"]\n",
    "                ct += 1\n",
    "        yield (xbatch, {'reg': y1, 'classif': y2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(json_format, 8, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(8):\n",
    "    plt.imshow(xb[z, ...])\n",
    "    plt.scatter(yb[\"reg\"][z][1], yb[\"reg\"][z][0])\n",
    "#     reg, classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    # classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "#     print(chunks[z][\"gt\"])\n",
    "#     print(np.round(classif[0]*1000)/1000.0)\n",
    "#     print(classmap[np.argmax(classif[0])])\n",
    "#     print(reg[0])\n",
    "#     coord = chunks[z][\"coordinates\"]\n",
    "#     reg = reg[0]\n",
    "#     plt.scatter(coord[1], coord[0], color=\"r\")\n",
    "#     plt.scatter(reg[1], reg[0], color=\"b\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from utils import depthwise_conv_block, conv_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "dropout=1e-3\n",
    "classes = 2\n",
    "depth_multiplier = 1\n",
    "shape = (1, 1, int(1024 * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=[tile, tile, 3])\n",
    "x = conv_block(img_input, 32, alpha, strides=(2, 2))\n",
    "x = depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "x = depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=2)\n",
    "x = depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "x = depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=4)\n",
    "x = depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "x = depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                          strides=(2, 2), block_id=6)\n",
    "\n",
    "# head1 \n",
    "h1 = depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=8)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=9)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=10)\n",
    "h1 = depthwise_conv_block(h1, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "h1 = depthwise_conv_block(h1, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=12)\n",
    "h1 = depthwise_conv_block(h1, 1024, alpha, depth_multiplier, block_id=13)\n",
    "    \n",
    "h1 = layers.GlobalAveragePooling2D()(h1)\n",
    "h1 = layers.Reshape(shape, name='reshape_1')(h1)\n",
    "h1 = layers.Dropout(dropout, name='dropout1')(h1)\n",
    "h1 = layers.Conv2D(2, (1, 1), padding='same', name='conv_preds1')(h1)\n",
    "h1 = layers.Activation('linear', name='linear')(h1)\n",
    "reg = layers.Reshape((2,), name='reg')(h1)\n",
    "\n",
    "# head2\n",
    "h2 = depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=14)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=15)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=16)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=17)\n",
    "h2 = depthwise_conv_block(h2, 512, alpha, depth_multiplier, block_id=18)\n",
    "\n",
    "h2 = depthwise_conv_block(h2, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=19)\n",
    "h2 = depthwise_conv_block(h2, 1024, alpha, depth_multiplier, block_id=20)\n",
    "\n",
    "h2 = layers.GlobalAveragePooling2D()(h2)\n",
    "h2 = layers.Reshape(shape, name='reshape_2')(h2)\n",
    "h2 = layers.Dropout(dropout, name='dropout2')(h2)\n",
    "h2 = layers.Conv2D(10, (1, 1), padding='same', name='conv_preds2')(h2)\n",
    "h2 = layers.Activation('softmax', name='act_softmax')(h2)\n",
    "classif = layers.Reshape((10,), name='classif')(h2)\n",
    "\n",
    "\n",
    "model = Model(inputs=[img_input], outputs=[reg, classif])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'reg': 'mean_squared_error', 'classif': 'categorical_crossentropy'}) #, loss_weights={'reg': 0.5, 'classif': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch= len(json_format) // 8, \n",
    "                    epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f:\n",
    "    json.dump(h, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h[\"reg_loss\"])\n",
    "plt.plot(h[\"classif_loss\"])\n",
    "plt.ylim([0, 500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/root/data/models/biomass/key_points_detection.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(9):\n",
    "    plt.imshow(chunks[z][\"tile\"])\n",
    "    reg, classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    # classif = model.predict_on_batch(np.expand_dims(chunks[z][\"tile\"], axis=0))\n",
    "    print(chunks[z][\"gt\"])\n",
    "    print(np.round(classif[0]*1000)/1000.0)\n",
    "    print(classmap[np.argmax(classif[0])])\n",
    "    print(reg[0])\n",
    "    coord = chunks[z][\"coordinates\"]\n",
    "    reg = reg[0]\n",
    "    plt.scatter(coord[1], coord[0], color=\"r\")\n",
    "    plt.scatter(reg[1], reg[0], color=\"b\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_polygon = example[\"Label\"][\"Salmon\"][0][\"geometry\"]\n",
    "coordinates = np.array([[k[\"x\"], k[\"y\"]] for k in body_polygon])\n",
    "y1, y2 = np.min(coordinates[:, 0]), np.max(coordinates[:, 0])\n",
    "x1, x2 = np.min(coordinates[:, 1]), np.max(coordinates[:, 1])\n",
    "print(x1, x2, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(15, 20))\n",
    "ax.imshow(image[x1:x2, y1:y2])\n",
    "# plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = x2-x1\n",
    "width = y2-y1\n",
    "tile = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = image[x1:x2, y1:y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_crop = list(crop.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_chunks = [flatten_crop[i:i + 3*tile**2] for i in range(0, len(flatten_crop), 3*tile**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f: \n",
    "    json.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./history.json\", \"w\") as f: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
