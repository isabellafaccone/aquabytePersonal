{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download prod data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from aquabyte.data_access_utils import DataAccessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_CREDENTIALS'] = '/root/thomas/aws_credentials.json'\n",
    "os.environ['PROD_SQL_CREDENTIALS'] = '/root/thomas/sqlcredentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacess = DataAccessUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from keypoint_annotations where pen_id=7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = datacess.extract_from_database(query)\n",
    "print(original_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['keypoints'].notnull()]\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aquabyte.optics import convert_to_world_point, depth_from_disp, pixel2world, euclidean_distance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish new columns\n",
    "mask = (original_df.is_skipped == False) & (~original_df.keypoints.isnull())\n",
    "for col in ['left_keypoints', 'right_keypoints', 'world_keypoint_coordinates']:\n",
    "    original_df[col] = np.nan\n",
    "    original_df[col] = original_df[col].astype(object)\n",
    "for col in ['predicted_biomass_linear', 'predicted_biomass_blender', 'max_y_coordinate_deviation']:\n",
    "    original_df[col] = np.nan\n",
    "\n",
    "\n",
    "# modify the dataframe row-by-row\n",
    "for idx, row in original_df[mask].iterrows():\n",
    "    keypoints = row.keypoints\n",
    "    left_keypoints = keypoints['leftCrop']\n",
    "    right_keypoints = keypoints['rightCrop']\n",
    "            \n",
    "    # compute world coordinates\n",
    "    camera_metadata = row.camera_metadata\n",
    "    camera_metadata['pixelCountHeight'] = 3000\n",
    "    camera_metadata['pixelCountWidth'] = 4096\n",
    "    world_keypoint_coordinates = pixel2world(left_keypoints, right_keypoints, camera_metadata)\n",
    "    \n",
    "    # update dataframe with world keypoint coordinates\n",
    "    original_df.at[idx, 'left_keypoints'] = left_keypoints\n",
    "    original_df.at[idx, 'right_keypoints'] = right_keypoints\n",
    "    original_df.at[idx, 'world_keypoint_coordinates'] = world_keypoint_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_df.to_csv('/root/data/bati/bremnes_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('/root/data/alok/biomass_estimation/df.csv')\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_order = [\"TAIL_NOTCH\",\n",
    "                    \"ADIPOSE_FIN\",\n",
    "                    \"UPPER_LIP\",\n",
    "                    \"ANAL_FIN\",\n",
    "                    \"PELVIC_FIN\",\n",
    "                    \"EYE\",\n",
    "                    \"PECTORAL_FIN\",\n",
    "                    \"DORSAL_FIN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for wkp in dataframe['world_keypoints']:\n",
    "    tmp = []\n",
    "    for kp in keypoints_order:\n",
    "        coord = eval(wkp)[kp]\n",
    "        tmp.append(coord)\n",
    "    X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(dataframe['weight'])\n",
    "Y = np.expand_dims(Y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(X[..., 0]), np.max(X[..., 0]), np.median(X[..., 0]))\n",
    "print(np.min(X[..., 1]), np.max(X[..., 1]), np.median(X[..., 1]))\n",
    "print(np.min(X[..., 2]), np.max(X[..., 2]), np.median(X[..., 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Train / Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "cutoff = int(N*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[:cutoff]\n",
    "y_train = Y[:cutoff]\n",
    "x_val = X[cutoff:]\n",
    "y_val = Y[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(X[...,1])\n",
    "# plt.xlim([-2, 10])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(8, 3))\n",
    "x = layers.Flatten()(inp)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dense(1, activation='linear')(x)\n",
    "# x = layers.Dense(100, activation='relu')(x)\n",
    "# x = layers.Dense(100, activation='relu')(x)\n",
    "# x = layers.Dense(50, activation='relu')(x)\n",
    "# x = layers.Dense(50, activation='relu')(x)\n",
    "# x = layers.Dense(1, activation='linear')(x)\n",
    "model = Model(inputs=[inp], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.adam(lr=1e-3),\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.adam(lr=1e-3),\n",
    "#               loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    validation_data=[x_val, y_val], \n",
    "                    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_pred = gaussian_kde(y_pred.squeeze())\n",
    "kde_val = gaussian_kde(y_val.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kde_pred(range(0, 8000, 1)))\n",
    "plt.plot(kde_val(range(0, 8000, 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, y_pred_train, c='r')\n",
    "plt.scatter(y_val, y_pred)\n",
    "plt.plot([0, 8000], [0, 8000], 'k')\n",
    "# plt.ylim([0, 8000])\n",
    "# plt.xlim([0, 8000])\n",
    "# plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(y_pred - y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((np.mean(y_pred) - np.mean(y_val)) / np.mean(y_val))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's retrain without val data - only for 400 epochs though (after that -> overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = layers.Input(shape=(8, 3))\n",
    "x = layers.Flatten()(inp)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(200, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "x = layers.Dense(50, activation='relu')(x)\n",
    "x = layers.Dense(1, activation='linear')(x)\n",
    "# x = layers.Dense(100, activation='relu')(x)\n",
    "# x = layers.Dense(100, activation='relu')(x)\n",
    "# x = layers.Dense(50, activation='relu')(x)\n",
    "# x = layers.Dense(50, activation='relu')(x)\n",
    "# x = layers.Dense(1, activation='linear')(x)\n",
    "model = Model(inputs=[inp], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.adam(lr=1e-3),\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, \n",
    "                    Y, \n",
    "                    epochs=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history\n",
    "plt.plot(h['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now prediction on bremnes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bremnes_df = pd.read_csv('/root/data/bati/bremnes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prod = []\n",
    "for wkp in bremnes_df['world_keypoint_coordinates']:\n",
    "    tmp = []\n",
    "    if str(wkp) == 'nan':\n",
    "        continue\n",
    "    for kp in keypoints_order:\n",
    "        coord = eval(wkp)[kp]\n",
    "        tmp.append(coord[::-1])\n",
    "    X_prod.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prod = model.predict(np.array(X_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array(X_prod)[..., 0].flatten())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array(X)[..., 0].flatten())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_prod, bins=50)\n",
    "plt.xlim([0, 10000])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
