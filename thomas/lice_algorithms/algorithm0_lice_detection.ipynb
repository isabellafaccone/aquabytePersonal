{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open('/root/data/lice_detection/lice_dataset_fish_only.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in reader:\n",
    "        dataset.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randindex = np.random.randint(0, len(dataset))\n",
    "randlice = dataset[randindex]\n",
    "img = Image.open(randlice[0])\n",
    "print(img.size)\n",
    "rectangle = [int(coord) for coord in randlice[1:5]]\n",
    "rec = [rectangle[0], rectangle[1], rectangle[2]-rectangle[0], rectangle[3]-rectangle[1]] \n",
    "ImageDraw.Draw(img).rectangle(rectangle, outline='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, figsize=(20, 10))\n",
    "ax.imshow(np.array(img))\n",
    "\n",
    "# Create a Rectangle patch\n",
    "rect = patches.Rectangle((rec[0], rec[1]), rec[2], rec[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "randindex = np.random.randint(0, len(dataset))\n",
    "randlice = dataset[randindex]\n",
    "rec = [int(coord) for coord in randlice[1:5]] \n",
    "img = Image.open(randlice[0])\n",
    "image = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bboxes\n",
    "bbs = ia.BoundingBoxesOnImage([ia.BoundingBox(x1=rec[0], y1=rec[1], x2=rec[2], y2=rec[3])], shape=image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ia.seed(1)\n",
    "print(image.shape)\n",
    "# image = ia.quokka(size=(256, 256))\n",
    "# bbs = ia.BoundingBoxesOnImage([\n",
    "#     ia.BoundingBox(x1=65, y1=100, x2=200, y2=150),\n",
    "#     ia.BoundingBox(x1=150, y1=80, x2=200, y2=130)\n",
    "# ], shape=image.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Multiply((1.2, 1.5)), # change brightness, doesn't affect BBs\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.7, 1.3), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.5, 0.5), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-20, 20),\n",
    "        shear=(-16, 16)\n",
    "    ) # translate by 40/60px on x/y axis, and scale to 50-70%, affects BBs\n",
    "])\n",
    "\n",
    "# Make our sequence deterministic.\n",
    "# We can now apply it to the image and then to the BBs and it will\n",
    "# lead to the same augmentations.\n",
    "# IMPORTANT: Call this once PER BATCH, otherwise you will always get the\n",
    "# exactly same augmentations for every batch!\n",
    "seq_det = seq.to_deterministic()\n",
    "\n",
    "# Augment BBs and images.\n",
    "# As we only have one image and list of BBs, we use\n",
    "# [image] and [bbs] to turn both into lists (batches) for the\n",
    "# functions and then [0] to reverse that. In a real experiment, your\n",
    "# variables would likely already be lists.\n",
    "image_aug = seq_det.augment_images([image])[0]\n",
    "bbs_aug = seq_det.augment_bounding_boxes([bbs])[0]\n",
    "\n",
    "# print coordinates before/after augmentation (see below)\n",
    "# use .x1_int, .y_int, ... to get integer coordinates\n",
    "for i in range(len(bbs.bounding_boxes)):\n",
    "    before = bbs.bounding_boxes[i]\n",
    "    after = bbs_aug.bounding_boxes[i]\n",
    "    print(\"BB %d: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n",
    "        i,\n",
    "        before.x1, before.y1, before.x2, before.y2,\n",
    "        after.x1, after.y1, after.x2, after.y2)\n",
    "    )\n",
    "\n",
    "# image with BBs before/after augmentation (shown below)\n",
    "image_before = bbs.draw_on_image(image, thickness=3)\n",
    "image_after = bbs_aug.draw_on_image(image_aug, thickness=3, color=[0, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(image_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(image_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW USE RETINANET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_retinanet\n",
    "from keras_retinanet.bin.train import * \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.backbone('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_parameters = {\n",
    "    'batch_size'       : 1,\n",
    "    'image_min_side'   : 3000,\n",
    "    'image_max_side'   : 4000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(args, preprocess_image):\n",
    "    \"\"\" Create generators for training and validation.\n",
    "    Args\n",
    "        args             : parseargs object containing configuration for generators.\n",
    "        preprocess_image : Function that preprocesses an image for the network.\n",
    "    \"\"\"\n",
    "    common_args = {\n",
    "        'batch_size'       : 1,\n",
    "        'image_min_side'   : 4000,\n",
    "        'image_max_side'   : 4000,\n",
    "        'preprocess_image' : preprocess_image,\n",
    "    }\n",
    "    args.dataset_type == 'csv':\n",
    "    train_generator = CSVGenerator(\n",
    "        args.annotations,\n",
    "        args.classes,\n",
    "        transform_generator=transform_generator,\n",
    "        **common_args\n",
    "    )\n",
    "\n",
    "    if args.val_annotations:\n",
    "        validation_generator = CSVGenerator(\n",
    "            args.val_annotations,\n",
    "            args.classes\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = None\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
