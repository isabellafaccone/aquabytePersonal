{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge coco files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [{'id': 1, 'name': 'Head', 'supercategory': 'Head'},\n",
    " # {'id': 2, 'name': 'Eye', 'supercategory': 'Eye'},\n",
    " {'id': 2, 'name': 'Caudal Fin', 'supercategory': 'Caudal Fin'},\n",
    " {'id': 3, 'name': 'Dorsal Fin', 'supercategory': 'Dorsal Fin'},\n",
    " {'id': 4, 'name': 'Adipose Fin', 'supercategory': 'Adipose Fin'},\n",
    " {'id': 5, 'name': 'Anal Fin', 'supercategory': 'Anal Fin'},\n",
    " {'id': 6, 'name': 'Pelvic Fin', 'supercategory': 'Pelvic Fin'},\n",
    " {'id': 7, 'name': 'Pectoral Fin', 'supercategory': 'Pectoral Fin'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco0 = json.load(open('/root/data/small_pen_data_collection/body_parts_detection_part0.json'))\n",
    "coco1 = json.load(open('/root/data/small_pen_data_collection/body_parts_detection_part1.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([ann['category_id'] for ann in coco0['annotations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_merged = copy.copy(coco0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximage_id = np.max([im['id'] for im in coco0['images']])\n",
    "maxann_id = np.max([ann['id'] for ann in coco0['annotations']])\n",
    "for img in coco1['images']:\n",
    "    img['id'] += int(maximage_id)\n",
    "for ann in coco1['annotations']:\n",
    "    ann['image_id'] += int(maximage_id)\n",
    "    ann['id'] += int(maxann_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_merged['images'] += coco1['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_merged['annotations'] += coco1['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_merged['categories'] = cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(coco_merged, open('/root/data/small_pen_data_collection/body_parts_detection_merged.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load coco file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.io as io\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = '/root/data/small_pen_data_collection/body_parts_detection_merged.json'\n",
    "json_path = '/root/data/small_pen_data_collection/body_parts_detection_merged.json'\n",
    "files = json.load(open(json_path))\n",
    "example_coco = COCO(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_path = glob.glob('/root/data/small_pen_data_collection/*_rectified/*.jpg')\n",
    "local_dic = {}\n",
    "for path in all_images_path:\n",
    "    if 'rectified' not in path:\n",
    "        local_dic[os.path.basename(path)] = path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO FIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ann in files['annotations']:\n",
    "#     seg = ann['segmentation']\n",
    "#     seg[0][1::2] = 3000 - np.array(seg)[0][1::2]\n",
    "#     ann['segmentation'] = seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (i, imgdata) in enumerate(files['images']):\n",
    "#     file_name = imgdata['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "#     imgdata['local_path'] = local_dic[file_name]\n",
    "#     annotation_ids = example_coco.getAnnIds(imgIds=[imgdata['id']])\n",
    "#     if len(annotation_ids) == 0:\n",
    "#         del files['images'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(json_path, 'w') as f:\n",
    "#     json.dump(files, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = example_coco.getCatIds()\n",
    "# category_ids = [1, 2, 3, 4, 5, 6, 7,]\n",
    "image_ids = example_coco.getImgIds(catIds=np.random.choice(category_ids))\n",
    "image_data = example_coco.loadImgs([np.random.choice(image_ids)])[0]\n",
    "# image_data = example_coco.loadImgs([0])[0]\n",
    "\n",
    "\n",
    "# load and display instance annotations\n",
    "# file_name = image_data['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "# image = io.imread(local_dic[file_name])\n",
    "image = io.imread(image_data['local_path'])\n",
    "f ,ax = plt.subplots(1, figsize=(20, 20))\n",
    "ax.imshow(image); \n",
    "# ax.axis('off')\n",
    "# plt.axis('off')\n",
    "# pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=[image_data['id']], catIds=category_ids, iscrowd=None)\n",
    "annotations = example_coco.loadAnns(annotation_ids)\n",
    "example_coco.showAnns(annotations)\n",
    "for ann in annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax.add_patch(rec)\n",
    "    ax.text(bbox[1], bbox[0]-10, ann['category_id'], fontsize=16, color='w')\n",
    "plt.show()\n",
    "# plt.savefig('test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs list\n",
    "pairs = {}\n",
    "for (imgid, imgdata) in example_coco.imgs.items():\n",
    "    # file_name = imgdata['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "    # img_path = local_dic[file_name]\n",
    "    img_path = imgdata['local_path']\n",
    "    annotation_ids = example_coco.getAnnIds(imgIds=[imgid])\n",
    "    if len(annotation_ids) == 0:\n",
    "        continue\n",
    "    if 'rectified' in img_path:\n",
    "        ts = os.path.basename(img_path).split('.')[0].split('_')[-1]\n",
    "        side = os.path.basename(img_path).split('.')[0].split('_')[0]\n",
    "        if ts not in pairs:\n",
    "            pairs[ts] = {}\n",
    "        pairs[ts][side] = imgid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random timestamps\n",
    "# random_timestamp = np.random.choice(list(pairs.keys()))\n",
    "random_timestamp = '1538489072394'\n",
    "# print(random_timestamp)\n",
    "# print(pairs[random_timestamp]['right'], pairs[random_timestamp]['left'])\n",
    "\n",
    "# get image_data\n",
    "left_image_data = example_coco.loadImgs([pairs[random_timestamp]['right']])[0]\n",
    "right_image_data = example_coco.loadImgs([pairs[random_timestamp]['left']])[0]\n",
    "\n",
    "# load images\n",
    "# left_file_name = left_image_data['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "# left_image = io.imread(local_dic[left_file_name])\n",
    "# right_file_name = right_image_data['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "# right_image = io.imread(local_dic[right_file_name])\n",
    "left_image = io.imread(left_image_data['local_path'])\n",
    "right_image = io.imread(right_image_data['local_path'])\n",
    "\n",
    "\n",
    "# load annotations\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=[left_image_data['id']]) #, catIds=category_ids, iscrowd=None)\n",
    "left_annotations = example_coco.loadAnns(annotation_ids)\n",
    "   \n",
    "annotation_ids = example_coco.getAnnIds(imgIds=[right_image_data['id']]) #, catIds=category_ids, iscrowd=None)\n",
    "right_annotations = example_coco.loadAnns(annotation_ids)\n",
    "\n",
    "# plot\n",
    "f ,ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "ax[0].imshow(left_image)\n",
    "for ann in left_annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax[0].add_patch(rec)\n",
    "    seg = ann['segmentation'][0]\n",
    "    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "    c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "    ax[0].add_patch(patches.Polygon(poly, facecolor=c, linewidth=0, alpha=0.4))\n",
    "    ax[0].add_patch(patches.Polygon(poly, facecolor='none', edgecolor=c, linewidth=2))\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "ax[1].imshow(right_image)\n",
    "for ann in right_annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[1], bbox[0]), bbox[3]-bbox[1], bbox[2]-bbox[0], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax[1].add_patch(rec)\n",
    "    seg = ann['segmentation'][0]\n",
    "    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "    polygon = patches.Polygon(poly)\n",
    "    c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "    ax[1].add_patch(patches.Polygon(poly, facecolor=c, linewidth=0, alpha=0.4))\n",
    "    ax[1].add_patch(patches.Polygon(poly, facecolor='none', edgecolor=c, linewidth=2))\n",
    "    ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import pandas as pd\n",
    "from utils import convert_to_world_point, depth_from_disp\n",
    "from PIL import Image, ImageDraw\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdata = pd.read_csv('/root/data/small_pen_data_collection/gtsf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_weights = {}\n",
    "for (i,exp) in enumerate(gtdata.iloc[4:, 0]):\n",
    "    ground_truth_weights[exp] = gtdata.iloc[i+4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_lengths = {'181001010001': 0.695,\n",
    " '1810010100010': 0.655,\n",
    " '181001010002': 0.75,\n",
    " '181001010003': 0.585,\n",
    " '181001010004': 0.625,\n",
    " '181001010005': 0.685,\n",
    " '181001010006': 0.645,\n",
    " '181001010007': 0.535,\n",
    " '181001010008': 0.66,\n",
    " '181001010009': 0.56,\n",
    " '181001010010': 0.655}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = [str(ids) for ids in example_coco.getCatIds()]\n",
    "distances = [c+k for (i, c) in enumerate(category_ids) for k in category_ids[i+1:]]\n",
    "# distances =  [example_coco.cats[int(cid)]['name'] for cid in category_ids]\n",
    "dataset = {}\n",
    "for d in distances:\n",
    "    dataset[d] = []\n",
    "dataset['ground_truth'] = []\n",
    "dataset['left_image_key'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for timestamp in ['1538489072394']:\n",
    "for timestamp in tqdm(list(pairs.keys())):\n",
    "    # get the image data\n",
    "    if 'left' not in pairs[timestamp]:\n",
    "        continue\n",
    "    if 'right' not in pairs[timestamp]:\n",
    "        continue\n",
    "    left_image_data = example_coco.loadImgs([pairs[timestamp]['right']])[0]\n",
    "    right_image_data = example_coco.loadImgs([pairs[timestamp]['left']])[0]\n",
    "    experience = left_image_data[\"local_path\"].split('/')[-2].split('_')[0]\n",
    "    if experience not in ground_truth_weights:\n",
    "        continue\n",
    "    \n",
    "    world_coordinates = {}\n",
    "    # calculate the body parts centroids\n",
    "    for cat in range(1, 8):\n",
    "        # get annotations\n",
    "        left_annotation_ids = example_coco.getAnnIds(imgIds=[left_image_data['id']], catIds=[cat])\n",
    "        right_annotation_ids = example_coco.getAnnIds(imgIds=[right_image_data['id']], catIds=[cat])\n",
    "        \n",
    "        if len(left_annotation_ids) == 0 or len(right_annotation_ids) == 0:\n",
    "            # print('Missing body part.....')\n",
    "            world_coordinates[str(cat)] = np.nan\n",
    "            dataset[example_coco.cats[int(cat)]['name']].append(world_coordinates[str(cat)])\n",
    "            continue\n",
    "        \n",
    "        # get centroids\n",
    "        left_annotations = example_coco.loadAnns(left_annotation_ids)[0]\n",
    "        seg = left_annotations['segmentation'][0]\n",
    "        poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "        p = [(r[0], r[1]) for r in poly]\n",
    "        left_mask = Image.new('L', (4096, 3000), 0)\n",
    "        ImageDraw.Draw(left_mask).polygon(p, outline=1, fill=1)\n",
    "        left_mask = np.array(left_mask)\n",
    "        x, y = np.nonzero(left_mask)\n",
    "        left_centroid = [np.mean(x), np.mean(y)]\n",
    "        \n",
    "        right_annotations = example_coco.loadAnns(right_annotation_ids)[0]\n",
    "        seg = right_annotations['segmentation'][0]\n",
    "        poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "        p = [(r[0], r[1]) for r in poly]\n",
    "        right_mask = Image.new('L', (4096, 3000), 0)\n",
    "        ImageDraw.Draw(right_mask).polygon(p, outline=1, fill=1)\n",
    "        right_mask = np.array(right_mask)\n",
    "        x, y = np.nonzero(right_mask)\n",
    "        right_centroid = [np.mean(x), np.mean(y)]\n",
    "        \n",
    "        disparities = left_centroid[1] - right_centroid[1]\n",
    "        print(cat, disparities)\n",
    "        depth = depth_from_disp(disparities)\n",
    "        print(cat, depth)\n",
    "        world_coordinates[str(cat)] = convert_to_world_point(left_centroid[0], left_centroid[1], depth)\n",
    "        dataset[example_coco.cats[int(cat)]['name']].append(world_coordinates[str(cat)].tolist())\n",
    "        \n",
    "    # now calculate the pairwise distances\n",
    "#     for pair in dataset.keys():\n",
    "#         if pair == 'ground_truth' or pair == 'left_image_key':\n",
    "#             continue\n",
    "#         cat0, cat1 = pair[0], pair[1]\n",
    "#         dist = np.linalg.norm(world_coordinates[cat0] - world_coordinates[cat1])\n",
    "#         dataset[pair].append(dist)\n",
    "    dataset['ground_truth'].append(ground_truth_weights[experience])\n",
    "    dataset['left_image_key'].append(pairs[timestamp]['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(world_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dataset.keys():\n",
    "    print(k, len(dataset[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./dataset_predictions_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.io as io\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random timestamps\n",
    "random_timestamp = np.random.choice(list(pairs.keys()))\n",
    "# print(random_timestamp)\n",
    "# print(pairs[random_timestamp]['right'], pairs[random_timestamp]['left'])\n",
    "\n",
    "# get image_data\n",
    "left_image_data = example_coco.loadImgs([pairs[random_timestamp]['right']])[0]\n",
    "right_image_data = example_coco.loadImgs([pairs[timestamp]['left']])[0]\n",
    "\n",
    "# load images\n",
    "left_file_name = left_image_data['coco_url'].split('%2F')[2].split('?alt')[0]\n",
    "left_image = io.imread(local_dic[left_file_name])\n",
    "\n",
    "# load annotations\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=[left_image_data['id']]) #, catIds=category_ids, iscrowd=None)\n",
    "left_annotations = example_coco.loadAnns(annotation_ids)\n",
    "   \n",
    "# plot\n",
    "f ,ax = plt.subplots(1, figsize=(20, 20))\n",
    "\n",
    "ax.imshow(left_image)\n",
    "for ann in left_annotations:\n",
    "    bbox = ann['bbox']\n",
    "    rec = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], \n",
    "                            edgecolor='w', facecolor=None, fill=False, linestyle='--', linewidth=2)\n",
    "    ax.add_patch(rec)\n",
    "    seg = ann['segmentation'][0]\n",
    "    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "    c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "    ax.add_patch(patches.Polygon(poly, facecolor=c, linewidth=0, alpha=0.4))\n",
    "    ax.add_patch(patches.Polygon(poly, facecolor='none', edgecolor=c, linewidth=2))\n",
    "    \n",
    "    # poly stuff\n",
    "    p = [(r[0], r[1]) for r in poly]\n",
    "    mask = Image.new('L', (4096, 3000), 0)\n",
    "    ImageDraw.Draw(mask).polygon(p, outline=1, fill=1)\n",
    "    mask = np.array(mask)\n",
    "    x, y = np.nonzero(mask)\n",
    "    right_centroid = [np.mean(x), np.mean(y)]\n",
    "    ax.scatter(right_centroid[1], right_centroid[0], s=25, color='r')\n",
    "    \n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
