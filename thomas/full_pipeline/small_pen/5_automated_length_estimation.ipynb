{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWO OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #0.1 Load mask rcnn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open('/root/data/headtail/detection_coco_results2.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images: {}\".format(len(results[\"images\"])))\n",
    "print(\"Number of annotations: {}\".format(len(results[\"annotations\"])))\n",
    "print(\"Number of unique annotations: {}\".format(len(list(set([k['image_id'] for k in results[\"annotations\"]])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image dic for faster search\n",
    "image_dic = {}\n",
    "for img in results[\"images\"]:\n",
    "    image_dic[img[\"id\"]] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ann dic for faster search\n",
    "ann_dic = {}\n",
    "for ann in results[\"annotations\"]:\n",
    "    ann_dic[ann[\"image_id\"]] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the images paths with detections\n",
    "paths = []\n",
    "for ann in results['annotations']:\n",
    "    img_path = image_dic[ann['image_id']][\"local_path\"]\n",
    "    paths.append((img_path, ann[\"image_id\"]))\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good pairs manually filtered\n",
    "good_ts = []\n",
    "for image_path in glob.glob('/root/data/headtail/good_pairs/*'):\n",
    "    ts = int(os.path.basename(image_path).split('.')[0].split('_')[-1])\n",
    "    good_ts.append(ts)\n",
    "good_ts = list(set(good_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps dict\n",
    "timestamps = {}\n",
    "for path in paths:\n",
    "    path0 = path[0]\n",
    "    ts = int(os.path.basename(path0).split('.')[0].split('_')[-1])\n",
    "    if ts not in good_ts:\n",
    "        continue\n",
    "    side = os.path.basename(path0).split('.')[0].split('_')[0]\n",
    "    if ts not in timestamps:\n",
    "        timestamps[ts] = {}\n",
    "    timestamps[ts][side] = path0\n",
    "    timestamps[ts][side + \"_id\"] = path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of pairs: {}\".format(len([v for (k, v) in timestamps.items() if \"right\" in v and \"left\" in v])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pairs = [v for (k, v) in timestamps.items() if \"right\" in v and \"left\" in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gp in good_pairs:\n",
    "#     shutil.copy(gp['left'], os.path.join('/root/data/headtail/good_pairs/', os.path.basename(gp['left'])))\n",
    "#     shutil.copy(gp['right'], os.path.join('/root/data/headtail/good_pairs/', os.path.basename(gp['right'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for 406 pairs we have full fish on both side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1 Display some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "import numpy as np\n",
    "from pycocotools.mask import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp = {'left': '/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/181001010007_rectified/left_sotra-small-pen_0_1538488432310.jpg',\n",
    "#   'left_id': 2490,\n",
    "#   'right': '/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/181001010007_rectified/right_sotra-small-pen_0_1538488432310.jpg',\n",
    "#   'right_id': 2763}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_timestamp = np.random.choice(good_pairs)\n",
    "# random_timestamp = gp\n",
    "# left side\n",
    "left_img = Image.open(random_timestamp[\"right\"])\n",
    "left_ann = ann_dic[random_timestamp[\"right_id\"]]\n",
    "left_bbox = left_ann['bbox']\n",
    "left_rec = Rectangle((left_bbox[1], left_bbox[0]), left_bbox[3]-left_bbox[1], left_bbox[2]-left_bbox[0], linewidth=2,edgecolor='w',linestyle=\"--\",facecolor='none')\n",
    "seg = left_ann['segmentation'][0]\n",
    "left_poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "left_mask = Polygon(left_poly)\n",
    "\n",
    "# right_side\n",
    "right_img = Image.open(random_timestamp[\"left\"])\n",
    "right_ann = ann_dic[random_timestamp[\"left_id\"]]\n",
    "right_bbox = right_ann['bbox']\n",
    "right_rec = Rectangle((right_bbox[1], right_bbox[0]), right_bbox[3]-right_bbox[1], right_bbox[2]-right_bbox[0], linewidth=2,edgecolor='w',linestyle=\"--\",facecolor='none')\n",
    "seg = right_ann['segmentation'][0]\n",
    "poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "right_mask = Polygon(poly)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(left_img)\n",
    "ax[0].add_patch(left_rec)\n",
    "ax[0].add_patch(left_mask)\n",
    "\n",
    "ax[1].imshow(right_img)\n",
    "ax[1].add_patch(right_rec)\n",
    "ax[1].add_patch(right_mask)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2 Calculate centroids, depth, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = 0.0107\n",
    "baseline = 0.135\n",
    "pixel_size_m = 3.45 * 1e-6 \n",
    "focal_length_pixel = focal_length / pixel_size_m\n",
    "image_sensor_width = 0.01412\n",
    "image_sensor_height = 0.01412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point(x, y, d):\n",
    "    image_center_x = 3000 / 2.0 #depth_map.shape[1] / 2.0\n",
    "    image_center_y = 4096 / 2.0# depth_map.shape[0] / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (image_sensor_width / 3000)\n",
    "    sensor_z = px_z * (image_sensor_height / 4096)\n",
    "    \n",
    "    # d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "    return (world_x, world_y, world_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {'181001010001': 0.695,\n",
    " '1810010100010': 0.655,\n",
    " '181001010002': 0.75,\n",
    " '181001010003': 0.585,\n",
    " '181001010004': 0.625,\n",
    " '181001010005': 0.685,\n",
    " '181001010006': 0.645,\n",
    " '181001010007': 0.535,\n",
    " '181001010008': 0.66,\n",
    " '181001010009': 0.56,\n",
    " '181001010010': 0.655}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for (i, random_timestamp) in enumerate(good_pairs):\n",
    "    if i % 10 == 0:\n",
    "        print('{}/{}'.format(i, len(good_pairs)))\n",
    "    \n",
    "    experience = random_timestamp[\"right\"].split('/')[-2].split('_')[0]\n",
    "    if experience not in results:\n",
    "        results[experience] = []\n",
    "    # left side\n",
    "    left_img = Image.open(random_timestamp[\"right\"])\n",
    "    left_ann = ann_dic[random_timestamp[\"right_id\"]]\n",
    "    left_bbox = left_ann['bbox']\n",
    "    left_rec = Rectangle((left_bbox[1], left_bbox[0]), left_bbox[3]-left_bbox[1], left_bbox[2]-left_bbox[0], linewidth=2,edgecolor='w',linestyle=\"--\",facecolor='none')\n",
    "\n",
    "    seg = left_ann['segmentation'][0]\n",
    "    left_poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "#     left_X = left_poly\n",
    "    lp = [(r[0], r[1]) for r in left_poly]\n",
    "    left_mask = Image.new('L', (4096, 3000), 0)\n",
    "    ImageDraw.Draw(left_mask).polygon(lp, outline=1, fill=1)\n",
    "    left_mask = np.array(left_mask)\n",
    "    left_X = np.stack([np.nonzero(left_mask)[0], np.nonzero(left_mask)[1]], axis=1)\n",
    "    left_X = left_X[::100, :]\n",
    "    \n",
    "    left_y_pred = KMeans(n_clusters=6, random_state=random_state).fit_predict(left_X)\n",
    "    centroids = []\n",
    "    for label in np.unique(left_y_pred):\n",
    "        x_mean = np.mean(left_X[left_y_pred==label, 0])\n",
    "        y_mean = np.mean(left_X[left_y_pred==label, 1])\n",
    "        centroids.append((x_mean, y_mean))\n",
    "    left_centroids = np.array(centroids)\n",
    "    left_centroids = left_centroids[left_centroids[:,1].argsort()]\n",
    "\n",
    "    # right side\n",
    "    right_img = Image.open(random_timestamp[\"left\"])\n",
    "    right_ann = ann_dic[random_timestamp[\"left_id\"]]\n",
    "    right_bbox = right_ann['bbox']\n",
    "    right_rec = Rectangle((right_bbox[1], right_bbox[0]), right_bbox[3]-right_bbox[1], right_bbox[2]-right_bbox[0], linewidth=2,edgecolor='w',linestyle=\"--\",facecolor='none')\n",
    "\n",
    "    seg = right_ann['segmentation'][0]\n",
    "    right_poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "#     right_X = right_poly\n",
    "    rp = [(r[0], r[1]) for r in right_poly]\n",
    "    right_mask = Image.new('L', (4096, 3000), 0)\n",
    "    ImageDraw.Draw(right_mask).polygon(rp, outline=1, fill=1)\n",
    "    right_mask = np.array(right_mask)\n",
    "    right_X = np.stack([np.nonzero(right_mask)[0], np.nonzero(right_mask)[1]], axis=1)\n",
    "    right_X = right_X[::100, :]\n",
    "    \n",
    "    right_y_pred = KMeans(n_clusters=6, random_state=random_state).fit_predict(right_X)\n",
    "    centroids = []\n",
    "    for label in np.unique(right_y_pred):\n",
    "        x_mean = np.mean(right_X[right_y_pred==label, 0])\n",
    "        y_mean = np.mean(right_X[right_y_pred==label, 1])\n",
    "        centroids.append((x_mean, y_mean))\n",
    "    right_centroids = np.array(centroids)\n",
    "    right_centroids = right_centroids[right_centroids[:,1].argsort()]\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        f, ax = plt.subplots(1,2, figsize=(20, 10))\n",
    "        ax[0].imshow(left_img)\n",
    "        # ax[0].scatter(left_X[:, 0], left_X[:, 1], c=left_y_pred)\n",
    "        ax[0].scatter(left_centroids[[0, -1], 1], left_centroids[[0, -1], 0], c='r')\n",
    "        # ax[0].scatter(left_centroids[:, 1], left_centroids[:, 0], c='r')\n",
    "        \n",
    "        ax[1].imshow(right_img)\n",
    "        # ax[1].scatter(right_X[:, 0], right_X[:, 1], c=right_y_pred)\n",
    "        ax[1].scatter(right_centroids[[0, -1], 1], right_centroids[[0, -1], 0], c='r')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    # estimate disparities\n",
    "    # print(left_centroids)\n",
    "    # print(right_centroids)\n",
    "    disparities = left_centroids[[0, -1], 1] - right_centroids[[0, -1], 1]\n",
    "    # print(disparities)\n",
    "\n",
    "    # estimate depth\n",
    "    depth = focal_length_pixel*baseline / np.array(disparities)\n",
    "    # print(depth)\n",
    "\n",
    "    # calculate world coordinate of point 0 \n",
    "    world0 = convert_to_world_point(left_centroids[0][0], left_centroids[0][1], depth[0])\n",
    "    # print(world0)\n",
    "\n",
    "    # calculate world coordinate of point 1 \n",
    "    world1 = convert_to_world_point(left_centroids[-1][0], left_centroids[-1][1], depth[1])\n",
    "    # print(world1)\n",
    "\n",
    "    # print length\n",
    "    predicted_length = np.linalg.norm(np.array(world0) - np.array(world1))\n",
    "    results[experience].append(predicted_length)\n",
    "    \n",
    "#     print(\"example: {}\".format(i))\n",
    "#     print(\"predicted length: {}\".format(predicted_length))\n",
    "#     print(\"ground truth length: {}\".format(ground_truth[experience]))\n",
    "#     print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, exp) in enumerate(results.keys()):\n",
    "    plt.scatter(np.zeros_like(np.array(results[exp]))+i, np.array(results[exp]))\n",
    "    plt.plot([i-0.3, i+0.3], [ground_truth[exp]]*2, color='k')\n",
    "plt.xticks(range(10), list(results.keys()), rotation=70)\n",
    "plt.ylim([0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = 1e6 # g per cubic meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_weights = {'181001010001':4315,\n",
    "'181001010002':5981,\n",
    "'181001010003':2773,\n",
    "'181001010004':3164,\n",
    "'181001010005':4480,\n",
    "'181001010006':2559,\n",
    "'181001010007':2121,\n",
    "'181001010008':3949,\n",
    "'181001010009':1957,\n",
    "'181001010010':2997}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, exp) in enumerate(results.keys()):\n",
    "    plt.scatter(np.zeros_like(np.array(results[exp]))+i, np.array(results[exp])**3*density/44.0)\n",
    "    plt.plot([i-0.3, i+0.3], [ground_truth_weights[exp]]*2, color='k')\n",
    "plt.xticks(range(10), list(results.keys()), rotation=70)\n",
    "plt.ylim([0,10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "for (i, exp) in enumerate(results.keys()):\n",
    "    median_weight = np.median(np.array(results[exp])**3*density)\n",
    "    true_weights = ground_truth_weights[exp]\n",
    "    ratio = median_weight/true_weights\n",
    "    print(ratio)\n",
    "    ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load ground truth results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = json.load(open('/root/thomas/github/cv_research/thomas/full_pipeline/small_pen/head_tails_segmentation.json'))\n",
    "print(\"total number of images: {}\".format(len(ground_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = []\n",
    "for gt in ground_truth:\n",
    "    label = gt['Label']\n",
    "    if \"Head\" in label and \"Tail\" in label:\n",
    "        if \"sotra\" in gt['External ID']:\n",
    "            full.append(gt)\n",
    "print(\"Total number of full images from small pen: {}\".format(len(full)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the left is not too much on the left so the right one is also full\n",
    "full_pairs = []\n",
    "for ff in full:\n",
    "    label = ff['Label']\n",
    "    total_poly = label['Head'][0]['geometry'] + label['Tail'][0]['geometry']\n",
    "    array = np.array([[k['x'], k['y']] for k in total_poly])\n",
    "    y1, y2 = array[:, 0].min(), array[:, 0].max()\n",
    "    if y1 > 1000:\n",
    "        full_pairs.append(ff)\n",
    "print(\"Total number of full pairs: {}\".format(len(full_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
