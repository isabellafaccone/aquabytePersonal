{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create image dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('/root/data/headtail/frames/*/*.jpg') + ['/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/181001010008_rectified/right_sotra-small-pen_0_1538489067394.jpg']\n",
    "image_dic = {}\n",
    "for image in images: \n",
    "    image_dic[os.path.basename(image)] = image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(3, 512, 512, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "adam = Adam(lr=lr)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and define generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "SEED = 448\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open(\"./head_tails_segmentation.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [ann for ann in annotations if ann['Label'] != 'Skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [ann for ann in annotations if \"erko\" in ann['External ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_json(ann, input_size=(512, 512)):\n",
    "    \"\"\"from json file create the mask and load the image\n",
    "    outputs: \n",
    "    - image: RGB\n",
    "    - mask: (H, W, 2)\"\"\"\n",
    "    img = Image.open(image_dic[ann['External ID']])\n",
    "    width, height = img.size\n",
    "    image = np.array(img.resize(input_size))\n",
    "    \n",
    "    # create head mask\n",
    "    if 'Head' in ann['Label']:\n",
    "        head_labels = ann['Label']['Head']\n",
    "        head_mask_img = Image.new('L', (width, height), 0)\n",
    "        for hl in head_labels:\n",
    "            geometry = hl['geometry']\n",
    "            polygon = [(k['x'], k['y']) for k in geometry]\n",
    "            ImageDraw.Draw(head_mask_img).polygon(polygon, outline=1, fill=1)\n",
    "            head_mask = cv2.resize(np.array(head_mask_img), input_size)\n",
    "    else:\n",
    "        head_mask = np.zeros(input_size)\n",
    "    \n",
    "    # create tail mask\n",
    "    if 'Tail' in ann['Label']:\n",
    "        tail_labels = ann['Label']['Tail']\n",
    "        tail_mask_img = Image.new('L', (width, height), 0)\n",
    "        for tl in tail_labels:\n",
    "            geometry = tl['geometry']\n",
    "            polygon = [(k['x'], k['y']) for k in geometry]\n",
    "            ImageDraw.Draw(tail_mask_img).polygon(polygon, outline=1, fill=1)\n",
    "            tail_mask = cv2.resize(np.array(tail_mask_img), input_size)\n",
    "    else:\n",
    "        tail_mask = np.zeros(input_size)\n",
    "    mask = np.stack([head_mask, tail_mask], axis=2)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = create_mask_from_json(tmp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the generator now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1356)\n",
    "random.shuffle(annotations)\n",
    "cutoff = int(len(annotations)*0.8)\n",
    "trainset = annotations[:cutoff]\n",
    "valset = annotations[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "input_size = (512, 512, 3)\n",
    "steps_per_epoch = len(trainset) // batch_size\n",
    "steps_per_epoch_val = len(valset) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dataset, steps_per_epoch, BATCH_SIZE, input_shape):\n",
    "    i = 0\n",
    "    img_size = input_shape[0]\n",
    "    aug = Compose([HorizontalFlip(p=0.5), \n",
    "              VerticalFlip(p=0.5),\n",
    "              RandomRotate90(p=0.5),\n",
    "              RandomSizedCrop(p=0.3, min_max_height=(400, 512), height=512, width=512),\n",
    "              Transpose(p=0.5)])\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], input_shape[2]), dtype=np.uint8)\n",
    "        y_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], 2), dtype=np.uint8)\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            image, mask = create_mask_from_json(dataset[j], (input_shape[0], input_shape[1]))\n",
    "            augmented = aug(image=image, mask=mask)\n",
    "            x_batch[ind, ...] = np.expand_dims(augmented['image'], axis=0)\n",
    "            y_batch[ind, ...] = np.expand_dims(augmented['mask'], axis=0)\n",
    "        \n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(trainset, steps_per_epoch, batch_size, input_size)\n",
    "val_generator = generator(valset, steps_per_epoch_val, batch_size, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some viz to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.imshow(xb[i,...])\n",
    "    plt.imshow(yb[i,...,0], alpha=0.3)\n",
    "    plt.imshow(yb[i,...,1], alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = lr\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20.0\n",
    "    fake_epoch = epoch\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "    print('lr {}'.format(lrate))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/headtail/', '1004_model_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_jaccard_coef_int', \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "saveh = SaveHistory('./headtail_history2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training# start \n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[saveh, lr_scheduler, checkpoint],\n",
    "        validation_data= val_generator,\n",
    "        validation_steps= steps_per_epoch_val, initial_epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD PASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pycocotools.mask import encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/root/data/models/headtail/1004_model_62.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/root/data/rnd/small_pen_data_collection/sotra-small-pen/pen-1/2018-10-01/'\n",
    "experiences = os.listdir(base_dir)\n",
    "all_image_path = []\n",
    "for experience in experiences:\n",
    "    folder_path = os.path.join(base_dir, experience)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    if \"rectified\" not in folder_path:\n",
    "        continue\n",
    "    if \"reference\" in folder_path:\n",
    "        continue\n",
    "    print(folder_path)\n",
    "    all_image_path += glob.glob(folder_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for path in all_image_path[:6]:\n",
    "    image = np.expand_dims(np.array(Image.open(path).resize((512, 512))), axis=0)\n",
    "    predictions = model.predict(image).squeeze()\n",
    "    predictions = np.array(predictions, dtype=np.uint8)\n",
    "    tmp = {'image_path': path, 'mask': encode(np.asfortranarray(predictions))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze())\n",
    "plt.imshow(predictions[...,1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
