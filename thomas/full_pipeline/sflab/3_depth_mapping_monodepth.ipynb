{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# only keep warnings and errors\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='1'\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from monodepth_model import *\n",
    "from monodepth_dataloader import *\n",
    "from average_gradients import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_files = sorted(glob.glob('/root/data/sflab_ground_truth/v2_071218/raw_images/left*'))[:250]\n",
    "right_files = sorted(glob.glob('/root/data/sflab_ground_truth/v2_071218/raw_images/right*'))[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/sflab_ground_truth/v2_071218/depth_map_files.txt', 'w') as f:\n",
    "    for (left, right) in zip(left_files, right_files):\n",
    "        f.write(left + ' ' + right + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [int(os.path.basename(left).split('.')[0].split('_')[-1]) for left in left_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(left_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10): \n",
    "    ind = np.random.randint(low=0, high=len(left_files))\n",
    "    print(ind)\n",
    "    f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax[0].imshow(np.array(Image.open(left_files[ind]).resize((400, 300))))\n",
    "    ax[1].imshow(np.array(Image.open(right_files[ind]).resize((400, 300))))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_disparity(disp):\n",
    "    if len(disp) == 1:\n",
    "        _, h, w = disp.shape\n",
    "        l_disp = disp[0,:,:]\n",
    "        r_disp = np.fliplr(disp[1,:,:])\n",
    "        m_disp = 0.5 * (l_disp + r_disp)\n",
    "        l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "        l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "        r_mask = np.fliplr(l_mask)\n",
    "        return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
    "    else:\n",
    "        h, w = disp[0].squeeze().shape\n",
    "        l_disp = disp[0].squeeze().astype(np.float32)\n",
    "        r_disp = disp[1].squeeze().astype(np.float32)\n",
    "        m_disp = 0.5 * (l_disp + r_disp)\n",
    "        l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "        l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "        r_mask = np.fliplr(l_mask)\n",
    "        return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
    "\n",
    "def count_text_lines(file_path):\n",
    "    f = open(file_path, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    return len(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = namedtuple('parameters', \n",
    "                        'encoder, '\n",
    "                        'height, width, '\n",
    "                        'batch_size, '\n",
    "                        'num_threads, '\n",
    "                        'num_epochs, '\n",
    "                        'do_stereo, '\n",
    "                        'wrap_mode, '\n",
    "                        'use_deconv, '\n",
    "                        'alpha_image_loss, '\n",
    "                        'disp_gradient_loss_weight, '\n",
    "                        'lr_loss_weight, '\n",
    "                        'full_summary, '\n",
    "                       'filenames_file, '\n",
    "                        'learning_rate, '\n",
    "                         'data_path,'\n",
    "                         'dataset,'\n",
    "                         'mode, '\n",
    "                         'num_gpus, '\n",
    "                         'log_directory, '\n",
    "                         'model_name, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parameters(encoder='vgg',\n",
    "                  height=256,\n",
    "                  width=512,\n",
    "                  batch_size=16,\n",
    "                  num_threads=8,\n",
    "                  num_epochs=500,\n",
    "                  do_stereo=True,\n",
    "                  wrap_mode='border',\n",
    "                  use_deconv='True',\n",
    "                  alpha_image_loss=0.85,\n",
    "                  disp_gradient_loss_weight=0.1,\n",
    "                  lr_loss_weight=1.0,\n",
    "                  full_summary=True,\n",
    "                  filenames_file='/root/data/sflab_ground_truth/v2_071218/depth_map_files.txt',\n",
    "                  learning_rate=1e-4,\n",
    "                  data_path='',\n",
    "                  dataset='sflab',\n",
    "                  mode='train',\n",
    "                  num_gpus=2,\n",
    "                  log_directory='/root/data/models/sflab/depthmap/',\n",
    "                  model_name='sflab_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(params.filenames_file, 'r')\n",
    "left_image_path, right_image_path = f.readline().split()\n",
    "print('Left image path: {}'.format(left_image_path))\n",
    "print('Right image path: {}'.format(right_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training loop.\"\"\"\n",
    "# LOAD IMAGES\n",
    "left_input = scipy.misc.imread(left_image_path, mode=\"RGB\")\n",
    "original_height, original_width, num_channels = left_input.shape\n",
    "left_input = scipy.misc.imresize(left_input, [params.height, params.width], interp='lanczos')\n",
    "left_input_disp = copy.copy(left_input)\n",
    "print(left_input.shape)\n",
    "left_input = left_input.astype(np.float32) / 255\n",
    "left_input = np.expand_dims(left_input, 0)\n",
    "\n",
    "# input_images = np.stack((input_image, np.fliplr(input_image)), 0)\n",
    "right_input = scipy.misc.imread(right_image_path, mode=\"RGB\")\n",
    "original_height, original_width, num_channels = right_input.shape\n",
    "right_input = scipy.misc.imresize(right_input, [params.height, params.width], interp='lanczos')\n",
    "right_input_disp = copy.copy(right_input)\n",
    "right_input = right_input.astype(np.float32) / 255\n",
    "right_input = np.expand_dims(right_input, 0)\n",
    "\n",
    "# PLOTS\n",
    "f, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax[0].imshow(left_input_disp)\n",
    "ax[1].imshow(right_input_disp)\n",
    "plt.show()\n",
    "\n",
    "with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    # OPTIMIZER\n",
    "    num_training_samples = count_text_lines(params.filenames_file)\n",
    "\n",
    "    steps_per_epoch = np.ceil(num_training_samples / params.batch_size).astype(np.int32)\n",
    "    num_total_steps = params.num_epochs * steps_per_epoch\n",
    "    print(steps_per_epoch)\n",
    "    print(num_total_steps)\n",
    "    start_learning_rate = params.learning_rate\n",
    "\n",
    "    boundaries = [np.int32((3/5) * num_total_steps), np.int32((4/5) * num_total_steps)]\n",
    "    values = [params.learning_rate, params.learning_rate / 2, params.learning_rate / 4]\n",
    "    learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "\n",
    "    opt_step = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "    print(\"total number of samples: {}\".format(num_training_samples))\n",
    "    print(\"total number of steps: {}\".format(num_total_steps))\n",
    "\n",
    "    dataloader = MonodepthDataloader(params.data_path, params.filenames_file, params, params.dataset, \n",
    "                                     params.mode)\n",
    "    left  = dataloader.left_image_batch\n",
    "    right = dataloader.right_image_batch\n",
    "#         print(left)\n",
    "#         print(right)\n",
    "    # split for each gpu\n",
    "    left_splits  = tf.split(left,  params.num_gpus, 0)\n",
    "    right_splits = tf.split(right, params.num_gpus, 0)\n",
    "\n",
    "    tower_grads  = []\n",
    "    tower_losses = []\n",
    "    reuse_variables = None\n",
    "    \n",
    "    print('loading model.....')\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        for i in range(params.num_gpus):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "\n",
    "                model = MonodepthModel(params, params.mode, left_splits[i], right_splits[i], reuse_variables, i)\n",
    "\n",
    "                loss = model.total_loss\n",
    "                tower_losses.append(loss)\n",
    "\n",
    "                reuse_variables = True\n",
    "\n",
    "                grads = opt_step.compute_gradients(loss)\n",
    "\n",
    "                tower_grads.append(grads)\n",
    "\n",
    "    grads = average_gradients(tower_grads)\n",
    "\n",
    "    apply_gradient_op = opt_step.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    total_loss = tf.reduce_mean(tower_losses)\n",
    "\n",
    "    tf.summary.scalar('learning_rate', learning_rate, ['model_0'])\n",
    "    tf.summary.scalar('total_loss', total_loss, ['model_0'])\n",
    "    summary_op = tf.summary.merge_all('model_0')\n",
    "\n",
    "    # SESSION\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # SAVER\n",
    "    summary_writer = tf.summary.FileWriter(params.log_directory + '/' + params.model_name, sess.graph)\n",
    "    train_saver = tf.train.Saver()\n",
    "\n",
    "    # COUNT PARAMS\n",
    "    total_num_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        total_num_parameters += np.array(variable.get_shape().as_list()).prod()\n",
    "    print(\"number of trainable parameters: {}\".format(total_num_parameters))\n",
    "\n",
    "    # INIT\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global variables initialized')\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    print('local variables initialized')\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "    print('threads created')\n",
    "\n",
    "#         # LOAD CHECKPOINT IF SET\n",
    "#         if args.checkpoint_path != '':\n",
    "#             train_saver.restore(sess, args.checkpoint_path.split(\".\")[0])\n",
    "\n",
    "#             if args.retrain:\n",
    "#                 sess.run(global_step.assign(0))\n",
    "\n",
    "    # GO!\n",
    "    print('go!')\n",
    "    start_step = global_step.eval(session=sess)\n",
    "    start_time = time.time()\n",
    "    for step in range(start_step, num_total_steps):\n",
    "        # print(step)\n",
    "        before_op_time = time.time()\n",
    "        _, loss_value = sess.run([apply_gradient_op, total_loss])\n",
    "        duration = time.time() - before_op_time\n",
    "        if step and step % 50 == 0:\n",
    "            # some plot\n",
    "#             disp = sess.run([model.disp_left_est[0], model.disp_right_est[0]], \n",
    "#             feed_dict={left: left_input, right: right_input})\n",
    "#             disp_pp = post_process_disparity(disp)\n",
    "#             plt.imshow(disp_pp, cmap='plasma')\n",
    "#             plt.show()\n",
    "\n",
    "            examples_per_sec = params.batch_size / duration\n",
    "            time_sofar = (time.time() - start_time) / 3600\n",
    "            training_time_left = (num_total_steps / step - 1.0) * time_sofar\n",
    "            print_string = 'batch {:>6} | examples/s: {:4.2f} | loss: {:.5f} | time elapsed: {:.2f}h | time left: {:.2f}h'\n",
    "            print(print_string.format(step, examples_per_sec, loss_value, time_sofar, training_time_left))\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, global_step=step)\n",
    "        if step and step % 500 == 0:\n",
    "            train_saver.save(sess, params.log_directory + '/' + params.model_name + '/model', global_step=step)\n",
    "\n",
    "    train_saver.save(sess, params.log_directory + '/' + params.model_name + '/model', global_step=num_total_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# only keep warnings and errors\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from monodepth_model import *\n",
    "from monodepth_dataloader import *\n",
    "from average_gradients import *\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_disparity(disp):\n",
    "    if len(disp) == 1:\n",
    "        _, h, w = disp.shape\n",
    "        l_disp = disp[0,:,:]\n",
    "        r_disp = np.fliplr(disp[1,:,:])\n",
    "        m_disp = 0.5 * (l_disp + r_disp)\n",
    "        l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "        l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "        r_mask = np.fliplr(l_mask)\n",
    "        return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
    "    else:\n",
    "        h, w = disp[0].squeeze().shape\n",
    "        l_disp = disp[0].squeeze().astype(np.float32)\n",
    "        r_disp = disp[1].squeeze().astype(np.float32)\n",
    "        m_disp = 0.5 * (l_disp + r_disp)\n",
    "        l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "        l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "        r_mask = np.fliplr(l_mask)\n",
    "        return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = namedtuple('parameters', \n",
    "                        'encoder, '\n",
    "                        'height, width, '\n",
    "                        'batch_size, '\n",
    "                        'num_threads, '\n",
    "                        'num_epochs, '\n",
    "                        'do_stereo, '\n",
    "                        'wrap_mode, '\n",
    "                        'use_deconv, '\n",
    "                        'alpha_image_loss, '\n",
    "                        'disp_gradient_loss_weight, '\n",
    "                        'lr_loss_weight, '\n",
    "                        'full_summary, '\n",
    "                       'filenames_file, '\n",
    "                        'learning_rate, '\n",
    "                         'data_path,'\n",
    "                         'dataset,'\n",
    "                         'mode, '\n",
    "                         'num_gpus, '\n",
    "                         'log_directory, '\n",
    "                         'model_name, '\n",
    "                         'checkpoint_path,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parameters(encoder='vgg',\n",
    "                  height=256,\n",
    "                  width=512,\n",
    "                  batch_size=1,\n",
    "                  num_threads=8,\n",
    "                  num_epochs=10000,\n",
    "                  do_stereo=True,\n",
    "                  wrap_mode='border',\n",
    "                  use_deconv='True',\n",
    "                  alpha_image_loss=0.85,\n",
    "                  disp_gradient_loss_weight=0.1,\n",
    "                  lr_loss_weight=1.0,\n",
    "                  full_summary=False,\n",
    "                  filenames_file='/root/data/sflab_ground_truth/v2_071218/depth_map_files.txt',\n",
    "                  learning_rate=1e-4,\n",
    "                  data_path='',\n",
    "                  dataset='kitti',\n",
    "                  mode='test',\n",
    "                  num_gpus=1,\n",
    "                  log_directory='./logs',\n",
    "                  model_name='overfit',\n",
    "                  checkpoint_path='/root/data/models/sflab/depthmap/sflab_0/model-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(params.filenames_file, 'r')\n",
    "\n",
    "for (i, line) in enumerate(f):\n",
    "    if i == 0:\n",
    "        print(\"loading model\")\n",
    "        left  = tf.placeholder(tf.float32, [1, params.height, params.width, 3])\n",
    "        right  = tf.placeholder(tf.float32, [1, params.height, params.width, 3])\n",
    "        model = MonodepthModel(params, \"test\", left, right)\n",
    "\n",
    "        # SESSION\n",
    "        config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        # SAVER\n",
    "        train_saver = tf.train.Saver()\n",
    "\n",
    "        # INIT\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        coordinator = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "        # RESTORE\n",
    "        print(params.checkpoint_path)\n",
    "        restore_path = params.checkpoint_path # .split(\".\")[0]\n",
    "        print(restore_path)\n",
    "        train_saver.restore(sess, restore_path)\n",
    "    \n",
    "    left_image_path, right_image_path = line.split()\n",
    "       \n",
    "    # input_image = scipy.misc.imread(params.image_path, mode=\"RGB\")\n",
    "    # original_height, original_width, num_channels = input_image.shape\n",
    "    # input_image = scipy.misc.imresize(input_image, [params.height, params.width], interp='lanczos')\n",
    "    # input_image = input_image.astype(np.float32) / 255\n",
    "    # input_images = np.stack((input_image, np.fliplr(input_image)), 0)\n",
    "    left_input = scipy.misc.imread(left_image_path, mode=\"RGB\")\n",
    "    original_height, original_width, num_channels = left_input.shape\n",
    "    left_input = scipy.misc.imresize(left_input, [params.height, params.width], interp='lanczos')\n",
    "    left_input = left_input.astype(np.float32) / 255\n",
    "    left_input = np.expand_dims(left_input, 0)\n",
    "    # input_images = np.stack((input_image, np.fliplr(input_image)), 0)\n",
    "    right_input = scipy.misc.imread(right_image_path, mode=\"RGB\")\n",
    "    original_height, original_width, num_channels = right_input.shape\n",
    "    right_input = scipy.misc.imresize(right_input, [params.height, params.width], interp='lanczos')\n",
    "    right_input = right_input.astype(np.float32) / 255\n",
    "    right_input = np.expand_dims(right_input, 0)\n",
    "    \n",
    "    # disp = sess.run(model.disp_left_est[0], feed_dict={left: input_images})\n",
    "    disp = sess.run([model.disp_left_est[0], model.disp_right_est[0]], feed_dict={left: left_input, right: right_input})\n",
    "    print(len(disp))\n",
    "    print('display')\n",
    "    # disp_pp = post_process_disparity(disp.squeeze().astype(np.float32))\n",
    "    disp_pp = post_process_disparity(disp)\n",
    "\n",
    "    # output_directory = os.path.dirname(left_image_path)\n",
    "    # output_name = os.path.splitext(os.path.basename(left_image_path))[0]\n",
    "\n",
    "    # np.save(os.path.join(output_directory, \"{}_disp.npy\".format(output_name)), disp_pp)\n",
    "    disp_to_img = scipy.misc.imresize(disp_pp.squeeze(), [original_height, original_width])\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(disp_to_img, cmap='plasma')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(disp_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
