{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from keras import backend as K\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import csv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_MODEL_PATH = '/root/data/models/sflab/detection/detection_45.h5'\n",
    "SEGMENTATION_MODEL_PATH = '/root/data/models/sflab/segmentation/segmentation_49.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #0 Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = glob.glob('/root/data/sflab_ground_truth/v2_071218/trunc_images/*')\n",
    "print(len(raw_images))\n",
    "# RANDOM_IMAGE_PATH = np.random.choice(raw_images)\n",
    "RANDOM_IMAGE_PATH = '/root/data/sflab_ground_truth/v2_071218/trunc_images/left_1531438106696.jpg'\n",
    "plt.imshow(np.array(Image.open(RANDOM_IMAGE_PATH).resize((400, 300))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1 Run detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(DETECTION_MODEL_PATH, backbone_name='resnet50', convert=True)\n",
    "labels_to_names = {0: 'fish'}\n",
    "print('model loaded........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = read_image_bgr(RANDOM_IMAGE_PATH)\n",
    "\n",
    "# copy to draw on\n",
    "draw = image.copy()\n",
    "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess image for network\n",
    "image = preprocess_image(image)\n",
    "image, scale = resize_image(image)\n",
    "\n",
    "# process image\n",
    "start = time.time()\n",
    "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "print(\"processing time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct for image scale\n",
    "boxes /= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize detections\n",
    "fig,ax = plt.subplots(1, figsize=(15, 15))\n",
    "im = np.array(Image.open(RANDOM_IMAGE_PATH), dtype=np.uint8)\n",
    "ax.imshow(im)\n",
    "for (i, (box, score, label)) in enumerate(zip(boxes[0], scores[0], labels[0])):\n",
    "    # scores are sorted so we can break\n",
    "    if score < 0.3:\n",
    "        break\n",
    "    color = label_color(label)\n",
    "    b = box.astype(int)\n",
    "    # draw_box(draw, b, color=color)\n",
    "    if i == 0:\n",
    "        rect = patches.Rectangle((b[0],b[1]),b[2]-b[0],b[3]-b[1],\n",
    "                                 linewidth=1,edgecolor='b',facecolor='none', label='prediction')\n",
    "    else:\n",
    "        rect = patches.Rectangle((b[0],b[1]),b[2]-b[0],b[3]-b[1],\n",
    "                         linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    # caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "    # draw_caption(draw, b, caption)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(draw)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 Run segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.backend import binary_crossentropy\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-12\n",
    "\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(SEGMENTATION_MODEL_PATH, custom_objects={'jaccard_coef_loss': jaccard_coef_loss,\n",
    "                                                            'jaccard_coef_int': jaccard_coef_int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in raw_images:\n",
    "    image = np.array(Image.open(image_path).resize((512, 512)))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    preds = model.predict(image)\n",
    "    mask_name = os.path.basename(image_path).split('.')[0] + '.npy'\n",
    "    np.save('/root/data/sflab_ground_truth/v2_071218/segmentation_prediction/{}'.format(mask_name), preds.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(image.squeeze())\n",
    "plt.imshow(preds.squeeze(), alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3 Run depth mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from main_monodepth_pytorch import Model\n",
    "import shutil\n",
    "import tempfile\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('/root/data/sflab_ground_truth/v2_071218/raw_images_pytorch/stupid/*/left*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = tempfile.mkdtemp()\n",
    "left_dir =  os.path.join(tmpdir, 'left')\n",
    "os.makedirs(left_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_parameters_test = edict({'data_dir':tmpdir,\n",
    "                              'model_path':'/root/data/models/test_model_cpt.pth',\n",
    "                              'output_directory':'/root/data/sflab_ground_truth/v2_071218/depth_map_predictions/',\n",
    "                              'input_height':256,\n",
    "                              'input_width':512,\n",
    "                              'model':'resnet18_md',\n",
    "                              'mode':'test',\n",
    "                              'tensor_type':'torch.cuda.FloatTensor'})  # torch.FloatTensor' for cpu mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,image_path) in enumerate(images):\n",
    "    print(\"{}/{}\".format(i, len(images)))\n",
    "    results_name = os.path.basename(image_path).split('.')[0] + '.npy'\n",
    "    shutil.copy(image_path, os.path.join(left_dir, os.path.basename(image_path)))\n",
    "    model_test = Model(dict_parameters_test)\n",
    "    model_test.test()\n",
    "    os.rename('/root/data/sflab_ground_truth/v2_071218/depth_map_predictions/disparities_pp.npy',\n",
    "              '/root/data/sflab_ground_truth/v2_071218/depth_map_predictions/{}' + results_name)\n",
    "    # shutil.rmtree(os.path.join(left_dir, os.path.basename(image_path)))\n",
    "    os.remove(os.path.join(left_dir, os.path.basename(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = np.load('./disparities_pp.npy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(disp.squeeze(), cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_to_img = skimage.transform.resize(disp[0].squeeze(), [512, 512], mode='constant')\n",
    "plt.imshow(disp_to_img, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length_m = 0.008\n",
    "pixel_size_m = 3.45 * 1e-6 \n",
    "focal_length_pixel = focal_length_m / pixel_size_m\n",
    "baseline = 0.135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = focal_length_pixel*baseline / (disp_to_img*4096)\n",
    "# depth *= 100 # meters to cm\n",
    "# depth /= 2.54 # cm to inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(tmpdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #4 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth*preds.squeeze())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #5 Biomass Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
