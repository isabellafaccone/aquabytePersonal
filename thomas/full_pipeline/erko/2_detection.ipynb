{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations\n",
    "crops = glob.glob('/root/data/erko/thomas_detection/fish_crop_lice_couting/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for crop in crops:\n",
    "    ts, xmin, ymin = os.path.basename(crop).split('_')[0:3]\n",
    "    img_path = '/root/data/erko/labeled_frames/' + ts\n",
    "    if not os.path.isfile(img_path):\n",
    "        continue\n",
    "    height, width, _ = np.array(Image.open(crop)).shape\n",
    "    dataset.append([img_path, int(ymin), int(xmin), int(ymin)+width, int(xmin)+height, '1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(Image.open('/root/data/erko/labeled_frames/1533133023365'))[0:296, 166:1025 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sorted(dataset, key=lambda k:k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/erko/thomas_detection/train.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    for ts in dataset[:675]:\n",
    "        writer.writerow(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/data/erko/thomas_detection/val.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    for ts in dataset[675:]:\n",
    "        writer.writerow(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 23 23:35:21 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 37%   63C    P0    63W / 250W |      0MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   42C    P8     9W / 250W |  10787MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 27%   49C    P0    59W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   41C    P0    57W / 250W |      0MiB / 11172MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "# keras_retinanet imports\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "# sys.path.append('/root/amol/product_detection/keras-retinanet/keras_retinanet/preprocessing/')\n",
    "# from csv_generator import CSVGenerator\n",
    "# from ..models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "\n",
    "\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from eval_modified import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/root/data/erko/thomas_detection/train.csv'\n",
    "classes = '/root/data/erko/thomas_detection/classid.csv'\n",
    "batch_size = 4\n",
    "val_annotations = '/root/data/erko/thomas_detection/val.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(annotations,classes,batch_size=1,val_annotations=''):\n",
    "    # create random transform generator for augmenting training data\n",
    "    transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "    \n",
    "    transform_generator = random_transform_generator(\n",
    "    min_rotation=-0.2,\n",
    "    max_rotation=0.2,\n",
    "    min_translation=(-0.3, -0.3),\n",
    "    max_translation=(0.3, 0.3),\n",
    "    min_shear=-0.3,\n",
    "    max_shear=0.3,\n",
    "    min_scaling=(0.5, 0.5),\n",
    "    max_scaling=(1.3, 1.3),\n",
    "    flip_x_chance=0,\n",
    "    flip_y_chance=0.5)\n",
    "    \n",
    "    \n",
    "    train_generator = CSVGenerator(\n",
    "        annotations,\n",
    "        classes,\n",
    "        transform_generator=transform_generator,\n",
    "        batch_size=batch_size,\n",
    "        image_min_side=800,\n",
    "        image_max_side=1500\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_annotations:\n",
    "        validation_generator = CSVGenerator(\n",
    "            val_annotations,\n",
    "            classes,\n",
    "            batch_size=batch_size,\n",
    "            image_min_side=800,\n",
    "            image_max_side=1500\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = None\n",
    "    \n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = create_generators(annotations, classes, batch_size, val_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0, freeze_backbone=False):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = models.backbone('resnet50')\n",
    "weights = backbone.download_imagenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_model, prediction_model = create_models(\n",
    "    backbone_retinanet=backbone.retinanet,\n",
    "    num_classes=train_generator.num_classes(),\n",
    "    weights=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-5\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/erko/detection/', 'model_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "        \n",
    "saveh = SaveHistory('./history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "65/65 [==============================] - 106s 2s/step - loss: 3.1132 - regression_loss: 2.5282 - classification_loss: 0.5850 - val_loss: 2.8501 - val_regression_loss: 2.3576 - val_classification_loss: 0.4925\n",
      "Epoch 2/40\n",
      "65/65 [==============================] - 96s 1s/step - loss: 2.9295 - regression_loss: 2.4003 - classification_loss: 0.5292 - val_loss: 2.7058 - val_regression_loss: 2.1777 - val_classification_loss: 0.5281\n",
      "Epoch 3/40\n",
      "65/65 [==============================] - 94s 1s/step - loss: 2.7663 - regression_loss: 2.2703 - classification_loss: 0.4959 - val_loss: 2.4214 - val_regression_loss: 1.9968 - val_classification_loss: 0.4246\n",
      "Epoch 4/40\n",
      "65/65 [==============================] - 98s 2s/step - loss: 2.5954 - regression_loss: 2.1282 - classification_loss: 0.4672 - val_loss: 2.3818 - val_regression_loss: 1.9756 - val_classification_loss: 0.4062\n",
      "Epoch 5/40\n",
      "65/65 [==============================] - 98s 2s/step - loss: 2.4794 - regression_loss: 2.0286 - classification_loss: 0.4507 - val_loss: 2.2288 - val_regression_loss: 1.8398 - val_classification_loss: 0.3890\n",
      "Epoch 6/40\n",
      "65/65 [==============================] - 95s 1s/step - loss: 2.4245 - regression_loss: 1.9894 - classification_loss: 0.4352 - val_loss: 2.2496 - val_regression_loss: 1.8702 - val_classification_loss: 0.3794\n",
      "Epoch 7/40\n",
      "65/65 [==============================] - 90s 1s/step - loss: 2.3096 - regression_loss: 1.9030 - classification_loss: 0.4066 - val_loss: 2.1331 - val_regression_loss: 1.7565 - val_classification_loss: 0.3766\n",
      "Epoch 8/40\n",
      "65/65 [==============================] - 98s 2s/step - loss: 2.3097 - regression_loss: 1.8899 - classification_loss: 0.4199 - val_loss: 2.1835 - val_regression_loss: 1.7528 - val_classification_loss: 0.4307\n",
      "Epoch 9/40\n",
      "65/65 [==============================] - 94s 1s/step - loss: 2.2106 - regression_loss: 1.8226 - classification_loss: 0.3880 - val_loss: 2.1491 - val_regression_loss: 1.8116 - val_classification_loss: 0.3375\n",
      "Epoch 10/40\n",
      "65/65 [==============================] - 95s 1s/step - loss: 2.1669 - regression_loss: 1.7879 - classification_loss: 0.3791 - val_loss: 2.0526 - val_regression_loss: 1.7150 - val_classification_loss: 0.3376\n",
      "Epoch 11/40\n",
      "65/65 [==============================] - 90s 1s/step - loss: 2.0680 - regression_loss: 1.7052 - classification_loss: 0.3629 - val_loss: 2.2343 - val_regression_loss: 1.8938 - val_classification_loss: 0.3406\n",
      "Epoch 12/40\n",
      "65/65 [==============================] - 90s 1s/step - loss: 2.0662 - regression_loss: 1.6948 - classification_loss: 0.3714 - val_loss: 1.9493 - val_regression_loss: 1.6274 - val_classification_loss: 0.3219\n",
      "Epoch 13/40\n",
      "65/65 [==============================] - 92s 1s/step - loss: 1.9973 - regression_loss: 1.6474 - classification_loss: 0.3498 - val_loss: 1.9564 - val_regression_loss: 1.6188 - val_classification_loss: 0.3376\n",
      "Epoch 14/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.9951 - regression_loss: 1.6414 - classification_loss: 0.3537 - val_loss: 2.0287 - val_regression_loss: 1.7063 - val_classification_loss: 0.3224\n",
      "Epoch 15/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.8902 - regression_loss: 1.5529 - classification_loss: 0.3373 - val_loss: 2.0091 - val_regression_loss: 1.6869 - val_classification_loss: 0.3222\n",
      "Epoch 16/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.9011 - regression_loss: 1.5636 - classification_loss: 0.3376 - val_loss: 2.1623 - val_regression_loss: 1.8281 - val_classification_loss: 0.3343\n",
      "Epoch 17/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.8740 - regression_loss: 1.5471 - classification_loss: 0.3269 - val_loss: 2.0673 - val_regression_loss: 1.7566 - val_classification_loss: 0.3107\n",
      "Epoch 18/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.8750 - regression_loss: 1.5481 - classification_loss: 0.3269 - val_loss: 1.9534 - val_regression_loss: 1.6463 - val_classification_loss: 0.3072\n",
      "Epoch 19/40\n",
      "65/65 [==============================] - 95s 1s/step - loss: 1.8555 - regression_loss: 1.5226 - classification_loss: 0.3329 - val_loss: 2.2161 - val_regression_loss: 1.8836 - val_classification_loss: 0.3325\n",
      "Epoch 20/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.7577 - regression_loss: 1.4476 - classification_loss: 0.3101 - val_loss: 1.8762 - val_regression_loss: 1.5860 - val_classification_loss: 0.2902\n",
      "Epoch 21/40\n",
      "65/65 [==============================] - 92s 1s/step - loss: 1.7936 - regression_loss: 1.4686 - classification_loss: 0.3251 - val_loss: 2.0126 - val_regression_loss: 1.7045 - val_classification_loss: 0.3081\n",
      "Epoch 22/40\n",
      "65/65 [==============================] - 92s 1s/step - loss: 1.7591 - regression_loss: 1.4364 - classification_loss: 0.3227 - val_loss: 1.9630 - val_regression_loss: 1.6656 - val_classification_loss: 0.2973\n",
      "Epoch 23/40\n",
      "65/65 [==============================] - 94s 1s/step - loss: 1.7242 - regression_loss: 1.4256 - classification_loss: 0.2987 - val_loss: 2.1939 - val_regression_loss: 1.8976 - val_classification_loss: 0.2962\n",
      "Epoch 24/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.7461 - regression_loss: 1.4358 - classification_loss: 0.3103 - val_loss: 2.1636 - val_regression_loss: 1.8330 - val_classification_loss: 0.3306\n",
      "Epoch 25/40\n",
      "65/65 [==============================] - 93s 1s/step - loss: 1.7397 - regression_loss: 1.4329 - classification_loss: 0.3069 - val_loss: 2.0469 - val_regression_loss: 1.7415 - val_classification_loss: 0.3054\n",
      "Epoch 26/40\n",
      "65/65 [==============================] - 95s 1s/step - loss: 1.6648 - regression_loss: 1.3688 - classification_loss: 0.2959 - val_loss: 2.0360 - val_regression_loss: 1.7219 - val_classification_loss: 0.3142\n",
      "Epoch 27/40\n",
      "65/65 [==============================] - 97s 1s/step - loss: 1.7107 - regression_loss: 1.3968 - classification_loss: 0.3139 - val_loss: 2.0739 - val_regression_loss: 1.7640 - val_classification_loss: 0.3099\n",
      "Epoch 28/40\n",
      "59/65 [==========================>...] - ETA: 5s - loss: 1.6954 - regression_loss: 1.3893 - classification_loss: 0.3062"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "history = training_model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=train_generator.size()//batch_size,\n",
    "        epochs=40,\n",
    "        verbose=1,\n",
    "        validation_data= validation_generator,\n",
    "        validation_steps= validation_generator.size() // batch_size,\n",
    "        callbacks=[lr_scheduler, saveh, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec, prec, average_precisions = evaluate(validation_generator, prediction_model, score_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rec, prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
