{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep  5 22:13:59 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 41%   71C    P2    78W / 250W |  10755MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 29%   52C    P0    61W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 27%   48C    P0    59W / 250W |      0MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 23%   41C    P0    57W / 250W |      0MiB / 11172MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(3, 512, 512, classes=1)\n",
    "# tmp = glob.glob('/root/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# model.load_weights('/root/data/models/erko/segmentation/0904_oneclass_fg_17.h5')\n",
    "# preds = model.predict(np.expand_dims(np.array(Image.open('/root/data/gopro/frames/553265761/553265761_13518.png').resize((512, 512))), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(Image.open('/root/data/gopro/frames/553265761/553265761_13518.png').resize((512, 512)))\n",
    "# plt.imshow(preds[...,1].squeeze(), alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "adam = Adam(lr=lr)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and define generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "SEED = 448\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import shutil\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob.glob('/root/data/aquabyte-images/erko/raw/*/*.semantic.jpg') + glob.glob('/root/data/aquabyte-images/erko/raw/*/*.semantic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2375\n",
      "50/2375\n",
      "100/2375\n",
      "150/2375\n",
      "200/2375\n",
      "250/2375\n",
      "300/2375\n",
      "350/2375\n",
      "400/2375\n",
      "450/2375\n",
      "500/2375\n",
      "550/2375\n",
      "600/2375\n",
      "650/2375\n",
      "700/2375\n",
      "750/2375\n",
      "800/2375\n",
      "850/2375\n",
      "900/2375\n",
      "950/2375\n",
      "1000/2375\n",
      "1050/2375\n",
      "1100/2375\n",
      "1150/2375\n",
      "1200/2375\n",
      "1250/2375\n",
      "1300/2375\n",
      "1350/2375\n",
      "1400/2375\n",
      "1450/2375\n",
      "1500/2375\n",
      "1550/2375\n",
      "1600/2375\n",
      "1650/2375\n",
      "1700/2375\n",
      "1750/2375\n",
      "1800/2375\n",
      "1850/2375\n",
      "1900/2375\n",
      "1950/2375\n",
      "2000/2375\n",
      "2050/2375\n",
      "2100/2375\n",
      "2150/2375\n",
      "2200/2375\n",
      "2250/2375\n",
      "2300/2375\n",
      "2350/2375\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for (i, mask_path) in enumerate(all_images):\n",
    "    if i % 50 == 0:\n",
    "        print('{}/{}'.format(i, len(all_images)))\n",
    "    mask_img = np.array(Image.open(mask_path)) # .resize((input_shape[0], input_shape[1])))           \n",
    "    red, green, blue = mask_img[:,:,0], mask_img[:,:,1], mask_img[:,:,2]\n",
    "    if mask_path.endswith('png'):\n",
    "        pink_mask = (red == 255) & (green == 105) & (blue == 180)\n",
    "    elif mask_path.endswith('jpg'):\n",
    "        pink_mask = (red == 255) & (green == 105) & (blue == 179)\n",
    "    if np.count_nonzero(pink_mask) > 0:\n",
    "        images.append(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(images, open('./balanced_images.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "random.shuffle(images)\n",
    "cutoff = int(len(images)*0.8)\n",
    "train = images[:cutoff]\n",
    "val = images[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "steps_per_epoch = len(train) // batch_size\n",
    "steps_per_epoch_val = len(val) // batch_size\n",
    "input_shape = (512, 512, 3)\n",
    "kernel = np.ones((5,5),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(images, steps_per_epoch, BATCH_SIZE, input_shape):\n",
    "    i = 0\n",
    "    seq = iaa.Sequential([iaa.Sometimes(0.7, iaa.GaussianBlur(sigma=(0, 2.0))),\n",
    "                  iaa.Sharpen(alpha=(0, 0.1), lightness=(0.7, 1.3)),\n",
    "                  iaa.ContrastNormalization((0.5, 1.2))],\n",
    "                 random_order=True)\n",
    "    img_size = input_shape[0]\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], input_shape[2]), dtype=np.uint8)\n",
    "        y_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], 1), dtype=np.uint8)\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            # img_path = images[j]\n",
    "            # img_name = os.path.basename(img_path)\n",
    "            # mask_path = '/root/data/erko/labels/{}.semantic.png'.format(img_name)\n",
    "            mask_path = images[j]\n",
    "            img_path = mask_path.replace('.semantic.png', '')\n",
    "            img_path = img_path.replace('.semantic.jpg', '')\n",
    "            \n",
    "            xb = np.array(Image.open(img_path).resize((input_shape[0], input_shape[1])))\n",
    "                        \n",
    "            mask_img = np.array(Image.open(mask_path).resize((input_shape[0], input_shape[1])))\n",
    "            \n",
    "            mask0 = np.zeros((input_shape[0], input_shape[1]))\n",
    "            \n",
    "            red, green, blue = mask_img[:,:,0], mask_img[:,:,1], mask_img[:,:,2]\n",
    "            if mask_path.endswith('png'):\n",
    "                pink_mask = (red == 255) & (green == 105) & (blue == 180)\n",
    "            elif mask_path.endswith('jpg'):\n",
    "                pink_mask = (red == 255) & (green == 105) & (blue == 179)\n",
    "            \n",
    "            mask0[pink_mask] = 1\n",
    "            \n",
    "            y0 = mask0\n",
    "            \n",
    "            if np.random.random() > 0.5:\n",
    "                xb = flip_axis(xb, 1)\n",
    "                y0 = flip_axis(y0, 1)\n",
    "                \n",
    "            x_batch[ind,...] = xb\n",
    "            y_batch[ind,...,0] = y0\n",
    "            \n",
    "        x_batch = seq.augment_images(x_batch)\n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train, steps_per_epoch, batch_size, input_shape)\n",
    "val_generator = generator(val, steps_per_epoch_val, batch_size, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(X[1,...])\n",
    "# # plt.imshow(Y[0,...,0], alpha=0.3)\n",
    "# # plt.imshow(Y[0,...,1], alpha=0.3)\n",
    "# plt.imshow(Y[1,...,0], alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = lr\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    fake_epoch = epoch\n",
    "#     lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "    # if epoch >= 30:\n",
    "        #fake_epoch = epoch - 20 \n",
    "#         lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "#     else:\n",
    "#         lrate = initial_lrate\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "    print('lr {}'.format(lrate))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./erko_0905_balanced_oneclass_fg_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/erko/segmentation/', '0905_balanced_oneclass_fg_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_jaccard_coef_int', \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 786s 5s/step - loss: 5.7698 - binary_crossentropy: 1.5435 - jaccard_coef_int: 0.0963 - val_loss: 12.0625 - val_binary_crossentropy: 9.0312 - val_jaccard_coef_int: 0.0704\n",
      "Epoch 2/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 726s 5s/step - loss: 2.6912 - binary_crossentropy: 0.6798 - jaccard_coef_int: 0.2696 - val_loss: 3.3559 - val_binary_crossentropy: 0.4881 - val_jaccard_coef_int: 0.2060\n",
      "Epoch 3/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 718s 5s/step - loss: 1.9852 - binary_crossentropy: 0.5135 - jaccard_coef_int: 0.3571 - val_loss: 2.0118 - val_binary_crossentropy: 0.4034 - val_jaccard_coef_int: 0.3510\n",
      "Epoch 4/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 713s 5s/step - loss: 1.7419 - binary_crossentropy: 0.4648 - jaccard_coef_int: 0.3984 - val_loss: 1.8084 - val_binary_crossentropy: 0.4300 - val_jaccard_coef_int: 0.3807\n",
      "Epoch 5/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 708s 4s/step - loss: 1.6287 - binary_crossentropy: 0.4505 - jaccard_coef_int: 0.4196 - val_loss: 1.7309 - val_binary_crossentropy: 0.4604 - val_jaccard_coef_int: 0.4133\n",
      "Epoch 6/100\n",
      "lr 0.001\n",
      "158/158 [==============================] - 708s 4s/step - loss: 1.5726 - binary_crossentropy: 0.4488 - jaccard_coef_int: 0.4288 - val_loss: 1.6127 - val_binary_crossentropy: 0.4164 - val_jaccard_coef_int: 0.4432\n",
      "Epoch 7/100\n",
      "lr 0.001\n",
      " 93/158 [================>.............] - ETA: 3:51 - loss: 1.5143 - binary_crossentropy: 0.4380 - jaccard_coef_int: 0.4492"
     ]
    }
   ],
   "source": [
    "# start training# start \n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        callbacks=[saveh, lr_scheduler, checkpoint],\n",
    "        validation_data= val_generator,\n",
    "        validation_steps= steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = json.load(open('./erko_0904_oneclass_fg_history.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(history['val_jaccard_coef_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['jaccard_coef_int'], label='jaccard_coef_int')\n",
    "plt.plot(history['val_jaccard_coef_int'], label='val_jaccard_coef_int')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = val_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = model.predict_on_batch(X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    ax[0].imshow(X[i,...])\n",
    "    ax[0].set_title(\"Raw image\")\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(X[i,...])\n",
    "    ax[1].imshow(Ypred[i,...], alpha=0.3)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title(\"predictions\")\n",
    "    \n",
    "#     ax[1].imshow(X[i,...])\n",
    "#     ax[1].imshow(Ypred[i,...,1], alpha=0.3)\n",
    "#     ax[1].axis('off')\n",
    "#     ax[1].set_title(\"foreground\")\n",
    "    \n",
    "#     ax[2].imshow(X[i,...])\n",
    "#     ax[2].imshow(Y[i,...,2], alpha=0.5)\n",
    "#     ax[2].set_title(\"contours\")\n",
    "#     ax[2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # img = cv2.imread('coins.png')\n",
    "# img = Y[-1,...,2]\n",
    "# test = np.zeros((512, 512, 3))\n",
    "# test[...,0] = img\n",
    "# test[...,1] = img\n",
    "# test[...,2] = img\n",
    "# img0 = np.zeros_like(img)\n",
    "# img0[img==0] = 1\n",
    "# gray = img0\n",
    "# # img = copy.copy(X[-1,...])\n",
    "# # img[Y[-1,...,0]==1] = 0\n",
    "# test = X[-1,...]\n",
    "# gray = cv2.cvtColor(test,cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.zeros([512,512,3],dtype=np.uint8)\n",
    "blue = img[...,2]\n",
    "blue += Y[0,...,1]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(Y[-1,...,2],cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    " \n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    " \n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.2*dist_transform.max(),255,0)\n",
    "  \n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sure_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    " \n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros([512,512,3],dtype=np.uint8)\n",
    "blue = img[...,2]\n",
    "blue += Y[0,...,1]*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and perform pyramid mean shift filtering\n",
    "# to aid the thresholding step\n",
    "# image = cv2.imread(args[\"image\"])\n",
    "image = img\n",
    "shifted = cv2.pyrMeanShiftFiltering(image, 21, 51)\n",
    "# cv2.imshow(\"Input\", image)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the mean shift image to grayscale, then apply\n",
    "# Otsu's thresholding\n",
    "gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "# cv2.imshow(\"Thresh\", thresh)\n",
    "plt.imshow(thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the exact Euclidean distance from every binary\n",
    "# pixel to the nearest zero pixel, then find peaks in this\n",
    "# distance map\n",
    "D = ndimage.distance_transform_edt(thresh)\n",
    "localMax = peak_local_max(D, indices=False, min_distance=30, labels=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " modified_recall = true_positives[-1] / float(num_annotations)\n",
    "        modified_precision = true_positives[-1] / float(true_positives[-1] + false_positives[-1])def merge_close_markers(markers, thresh=10):\n",
    "    x, y = np.where(markers!=0)\n",
    "    dist = scipy.spatial.distance_matrix(zip(x,y), zip(x,y))\n",
    "    dist = np.triu(dist)\n",
    "    xclose, yclose = np.where(np.logical_and(dist> 0, dist<=10))\n",
    "    for (i,j) in zip(xclose, yclose):\n",
    "        markers[x[i], y[i]] = 0\n",
    "    return markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a connected component analysis on the local peaks,\n",
    "# using 8-connectivity, then appy the Watershed algorithm\n",
    "markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]\n",
    "markers = merge_close_markers(markers)\n",
    "labels = watershed(-D, markers, mask=thresh)\n",
    "print(\"[INFO] {} unique segments found\".format(len(np.unique(labels)) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512 / 4096.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lab in sorted(np.unique(labels))[1:]:\n",
    "    print lab\n",
    "    plt.imshow(labels==lab)\n",
    "    plt.show()\n",
    "    x, y = np.where(labels==lab)\n",
    "    bbox = [np.min(x), np.min(y), np.max(x), np.max(y)]\n",
    "    print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labels==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test[int(377*1080/512.0):int(508*1080/512.0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(377*1080/512.0), int(508*1080/512.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(val[0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(Image.open(val[0]))[int(377*1080/512.0):int(508*1080/512.0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(markers!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = copy.copy(X[-1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for label in np.unique(labels): \n",
    "    # if the label is zero, we are examining the 'background'\n",
    "    # so simply ignore it\n",
    "    if label == 0:\n",
    "        continue\n",
    " \n",
    "    # otherwise, allocate memory for the label region and draw\n",
    "    # it on the mask\n",
    "    mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "    mask[labels == label] = 255\n",
    " \n",
    "    # detect contours in the mask and grab the largest one\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "    cv2.drawContours(truc, cnts,-1,(255,255,0),3)\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    cv2.putText(truc, \"#{}\".format(label), (int(x) - 10, int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "#     # draw a circle enclosing the object\n",
    "#     \n",
    "#     cv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "#     \n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(truc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write code to merge labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
