{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# keras_retinanet imports\n",
    "import keras.backend as K\n",
    "\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.preprocessing.pascal_voc import PascalVocGenerator\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "# sys.path.append('/root/amol/product_detection/keras-retinanet/keras_retinanet/preprocessing/')\n",
    "# from csv_generator import CSVGenerator\n",
    "# from ..models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "\n",
    "\n",
    "from keras_retinanet.utils.transform import random_transform_generator\n",
    "from keras_retinanet.utils.keras_version import check_keras_version\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from keras_retinanet.utils.eval import _compute_ap, _get_annotations, _get_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/root/data/blender_v4/annotations/annotations_train.csv'\n",
    "classes = '/root/data/blender_v4/annotations/classID.csv'\n",
    "batch_size = 4\n",
    "val_annotations = '/root/data/blender_v4/annotations/annotations_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators(annotations,classes,batch_size=1,val_annotations=''):\n",
    "    # create random transform generator for augmenting training data\n",
    "    transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
    "       \n",
    "    train_generator = CSVGenerator(\n",
    "        annotations,\n",
    "        classes,\n",
    "        transform_generator=transform_generator,\n",
    "        batch_size=batch_size,\n",
    "        image_min_side=800,\n",
    "        image_max_side=1500\n",
    "    )\n",
    "\n",
    "\n",
    "    if val_annotations:\n",
    "        validation_generator = CSVGenerator(\n",
    "            val_annotations,\n",
    "            classes,\n",
    "            batch_size=batch_size,\n",
    "            image_min_side=800,\n",
    "            image_max_side=1500\n",
    "        )\n",
    "    else:\n",
    "        validation_generator = None\n",
    "    \n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = create_generators(annotations, classes, batch_size, val_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '/root/data/models/blender/detection/detection_04.h5'\n",
    "backbone = models.backbone('mobilenet128_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0, freeze_backbone=False):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "\n",
    "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
    "    # optionally wrap in a parallel model\n",
    "    if multi_gpu > 1:\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "    else:\n",
    "        model          = model_with_weights(backbone_retinanet(num_classes, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "        training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-4, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "    return model, training_model, prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_weights(model, weights, skip_mismatch):\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, training_model, prediction_model = create_models(\n",
    "    backbone_retinanet=backbone.retinanet,\n",
    "    num_classes=train_generator.num_classes(),\n",
    "    weights=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(a, b):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    a: (N, 4) ndarray of float\n",
    "    b: (K, 4) ndarray of float\n",
    "    Returns\n",
    "    -------\n",
    "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
    "    \"\"\"\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
    "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    return intersection / ua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    generator,\n",
    "    model,\n",
    "    iou_threshold=0.5,\n",
    "    score_threshold=0.05,\n",
    "    max_detections=100,\n",
    "    save_path=None\n",
    "):\n",
    "    \"\"\" Evaluate a given dataset using a given model.\n",
    "\n",
    "    # Arguments\n",
    "        generator       : The generator that represents the dataset to evaluate.\n",
    "        model           : The model to evaluate.\n",
    "        iou_threshold   : The threshold used to consider when a detection is positive or negative.\n",
    "        score_threshold : The score confidence threshold to use for detections.\n",
    "        max_detections  : The maximum number of detections to use per image.\n",
    "        save_path       : The path to save images with visualized detections to.\n",
    "    # Returns\n",
    "        A dict mapping class names to mAP scores.\n",
    "    \"\"\"\n",
    "    # gather all detections and annotations\n",
    "    all_detections     = _get_detections(generator, model, score_threshold=score_threshold, max_detections=max_detections, save_path=save_path)\n",
    "    all_annotations    = _get_annotations(generator)\n",
    "    average_precisions = {}\n",
    "\n",
    "    # all_detections = pickle.load(open('all_detections.pkl', 'rb'))\n",
    "    # all_annotations = pickle.load(open('all_annotations.pkl', 'rb'))\n",
    "    # pickle.dump(all_detections, open('all_detections.pkl', 'wb'))\n",
    "    # pickle.dump(all_annotations, open('all_annotations.pkl', 'wb'))\n",
    "\n",
    "    # process detections and annotations\n",
    "    for label in range(generator.num_classes()):\n",
    "        false_positives = np.zeros((0,))\n",
    "        true_positives  = np.zeros((0,))\n",
    "        scores          = np.zeros((0,))\n",
    "        num_annotations = 0.0\n",
    "\n",
    "        for i in range(generator.size()):\n",
    "            detections           = all_detections[i][label]\n",
    "            annotations          = all_annotations[i][label]\n",
    "            num_annotations     += annotations.shape[0]\n",
    "            detected_annotations = []\n",
    "\n",
    "            for d in detections:\n",
    "                scores = np.append(scores, d[4])\n",
    "\n",
    "                if annotations.shape[0] == 0:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "                    continue\n",
    "\n",
    "                overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
    "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                max_overlap         = overlaps[0, assigned_annotation]\n",
    "\n",
    "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                    false_positives = np.append(false_positives, 0)\n",
    "                    true_positives  = np.append(true_positives, 1)\n",
    "                    detected_annotations.append(assigned_annotation)\n",
    "                else:\n",
    "                    false_positives = np.append(false_positives, 1)\n",
    "                    true_positives  = np.append(true_positives, 0)\n",
    "\n",
    "        # no annotations -> AP for this class is 0 (is this correct?)\n",
    "        if num_annotations == 0:\n",
    "            average_precisions[label] = 0\n",
    "            continue\n",
    "\n",
    "        # sort by score\n",
    "        indices         = np.argsort(-scores)\n",
    "        false_positives = false_positives[indices]\n",
    "        true_positives  = true_positives[indices]\n",
    "\n",
    "        # compute false positives and true positives\n",
    "        false_positives = np.cumsum(false_positives)\n",
    "        true_positives  = np.cumsum(true_positives)\n",
    "\n",
    "        # compute recall and precision\n",
    "        recall    = true_positives / num_annotations\n",
    "        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "        # compute average precision\n",
    "        average_precision  = _compute_ap(recall, precision)\n",
    "        average_precisions[label] = average_precision\n",
    "\n",
    "    return average_precisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(validation_generator, prediction_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
