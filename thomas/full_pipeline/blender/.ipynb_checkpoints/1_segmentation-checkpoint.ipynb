{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(3, 512, 512, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_error(y_true, y_pred):\n",
    "    return K.mean(K.not_equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int, binary_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore labels load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.mask import decode\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open('/root/data/blender_v4/training/training_low_rez/labels.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(labels[0]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mask = np.sum(decode(labels[0]['masks']), axis=2)\n",
    "sum_mask[sum_mask>0]=1\n",
    "plt.imshow(sum_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and define generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "SEED = 448\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = json.load(open('/root/data/blender_v4/training/training_low_rez/labels.json'))\n",
    "test_labels = json.load(open('/root/data/blender_v4/training/test_low_rez/labels.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "batch_size = 8\n",
    "steps_per_epoch = len(train_labels) // batch_size\n",
    "steps_per_epoch_val = len(test_labels) // batch_size\n",
    "input_shape = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(labels, steps_per_epoch, BATCH_SIZE, input_shape):\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], input_shape[2]), dtype=np.uint8)\n",
    "        y_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], 1), dtype=np.uint8)\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            x_batch[ind,...] = np.array(Image.open(labels[j]['path']).resize((input_shape[0], input_shape[1])))\n",
    "            sum_mask = np.sum(decode(labels[j]['masks']), axis=2)\n",
    "            sum_mask[sum_mask>0]=1\n",
    "            y_batch[ind,...,0] = cv2.resize(np.array(sum_mask, dtype=np.uint8), (input_shape[0], input_shape[1]))\n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_labels, steps_per_epoch, batch_size, input_shape)\n",
    "val_generator = generator(test_labels, steps_per_epoch_val, batch_size, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Image.open(labels[0]['path'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0,...])\n",
    "plt.imshow(Y[0,...].squeeze(), alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-3\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    if epoch >= 30:\n",
    "        fake_epoch = epoch - 20 \n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "    else:\n",
    "        lrate = initial_lrate\n",
    "    print('lr {}'.format(lrate))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./segmentation_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/blender/segmentation/', 'segmentation_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_jaccard_coef_int', \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training# start \n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        callbacks=[saveh, lr_scheduler, checkpoint],\n",
    "        validation_data= val_generator,\n",
    "        validation_steps= steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = json.load(open('segmentation_history.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(history['val_jaccard_coef_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['jaccard_coef_int'], label='jaccard_coef_int')\n",
    "plt.plot(history['val_jaccard_coef_int'], label='val_jaccard_coef_int')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = val_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = model.predict_on_batch(X).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax[0].imshow(X[i,...])\n",
    "    ax[0].imshow(Y[i,...,0], alpha=0.5)\n",
    "    ax[0].set_title(\"background\")\n",
    "    \n",
    "    ax[1].imshow(X[i,...])\n",
    "    ax[1].imshow(Y[i,...,1], alpha=0.5)\n",
    "    ax[1].set_title(\"foreground\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
