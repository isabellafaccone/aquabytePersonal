{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_path = '/root/data/blender_test/Image0028_L.png'\n",
    "right_path = '/root/data/blender_test/Image0028_R.png'\n",
    "ground_truth_depth_path = '/root/data/blender_test/true_depth.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(3, 512, 512, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_error(y_true, y_pred):\n",
    "    return K.mean(K.not_equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int, binary_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/root/data/models/blender/segmentation/raw_segmentation_03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on left image\n",
    "prediction = model.predict_on_batch(np.expand_dims(np.array(Image.open(left_path).convert('RGB').resize((512, 512))), axis=0))\n",
    "prediction = np.round(prediction)\n",
    "rprediction = cv2.resize(prediction.squeeze(), (1024, 512))\n",
    "rprediction[rprediction<1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3, 3))\n",
    "rprediction = cv2.erode(rprediction, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# plt.imshow(np.array(Image.open(left_path).convert('RGB')))\n",
    "plt.imshow(rprediction, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick hack until segmentation is fixed\n",
    "# original = copy.deepcopy(rprediction)\n",
    "# prediction = np.zeros((512, 1024))\n",
    "# prediction[200:350, 300:700] = original[200:350, 300:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(rprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.nonzero(rprediction)\n",
    "xmin, xmax = x.min()-delta, x.max()+delta\n",
    "ymin, ymax = y.min()-delta, y.max()+delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xmin, xmax)\n",
    "print(ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rprediction[xmin:xmax, ymin:ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3, 3))\n",
    "mask= cv2.erode(mask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 Depthmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_crop = cv2.imread(left_path)[xmin:xmax, ymin:ymax]\n",
    "right_crop = cv2.imread(right_path)[xmin:xmax, ymin:ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(left_crop)\n",
    "ax[1].imshow(right_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'p2': 864, 'p1': 216, 'speckle_window_size': 32, 'speckle_range': 6, 'min_disparity': 0, 'max_disparity': 20, 'uniqueness': 13, 'num_disp': 32, 'full_dp': False, 'sad_window_size': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_matcher = cv2.StereoSGBM(minDisparity=params['min_disparity'],\n",
    "                        numDisparities=params['num_disp'],\n",
    "                        SADWindowSize=params['sad_window_size'],\n",
    "                        uniquenessRatio=params['uniqueness'],\n",
    "                        speckleWindowSize=params['speckle_window_size'],\n",
    "                        speckleRange=params['speckle_range'],\n",
    "                        disp12MaxDiff=params['max_disparity'],\n",
    "                        P1=params['p1'],\n",
    "                        P2=params['p2'],\n",
    "                        fullDP=params['full_dp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = block_matcher.compute(left_crop, right_crop).astype(np.float32) / 16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(disp*mask)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meters\n",
    "focal_length = 10.0*1e-3\n",
    "baseline = 65.0*1e-3\n",
    "image_sensor_width = 32.0*1e-3\n",
    "image_sensor_height = 18.0*1e-3\n",
    "pixel_size = image_sensor_width / 1024\n",
    "print(pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length_pixel = focal_length / pixel_size\n",
    "depth = focal_length_pixel*baseline / (disp*mask)\n",
    "depth[depth == np.inf] = 0\n",
    "depth[depth == -np.inf] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth[depth>12] = 0\n",
    "# depth[depth ==0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import , g\n",
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth) #[50:100, 250:300])\n",
    "plt.colorbar()\n",
    "plt.clim([0, 12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.nonzero(depth)\n",
    "z = [depth[i,j] for (i,j) in zip(x,y)]\n",
    "A = np.c_[x, y, np.ones((len(x)))]\n",
    "C, _, _, _ = lstsq(A, z)\n",
    "vert_params = C[0], C[1], -1., C[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.arange(0, 128.0, 10), np.arange(0, 309, 10))\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "def Z(X, Y, params):\n",
    "    a, b, c, d = params\n",
    "    return -(a*X + b*Y + d)/c\n",
    "\n",
    "ax.plot_surface(Z(X, Y, vert_params), Y, X, alpha=0.5) #, rstride=1, cstride=1, alpha=0.2, color='yellow')\n",
    "ax.scatter(z, y, x, c='r', s=50)\n",
    "ax.invert_zaxis()\n",
    "ax.invert_xaxis()\n",
    "# plt.xlabel('Y')\n",
    "# plt.ylabel('Z')\n",
    "ax.set_zlabel('Z')\n",
    "# ax.axis('equal')\n",
    "ax.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(np.arange(0, 128.0, 1), np.arange(0, 309, 1))\n",
    "Zfit = Z(X, Y, vert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Zfit.transpose()*mask)\n",
    "plt.colorbar()\n",
    "plt.clim([0, 12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = Zfit.transpose()*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = np.load(ground_truth_depth_path)\n",
    "td[td>12]=0\n",
    "td = td[xmin:xmax, ymin:ymax]*mask\n",
    "plt.imshow(td)\n",
    "plt.colorbar()\n",
    "plt.clim([0, 12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4 Biomass estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obb import OBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_map = np.zeros((512, 1024))\n",
    "# depth_map[200:350, 300:700] = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point(x, y, depth_map):\n",
    "    image_center_x = 1024 / 2.0 #depth_map.shape[1] / 2.0\n",
    "    image_center_y = 512 / 2.0 # depth_map.shape[0] / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (image_sensor_width / 1024)\n",
    "    sensor_z = px_z * (image_sensor_height / 512)\n",
    "    \n",
    "    d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "#     return world_y\n",
    "    return (world_x, world_y, world_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true coordinates\n",
    "world_left = convert_to_world_point(35, 75, td)\n",
    "world_right = convert_to_world_point(280, 70, td)\n",
    "print(world_left)\n",
    "print(world_right)\n",
    "true_length = np.linalg.norm(np.array(world_left) - np.array(world_right))\n",
    "print(true_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted coordinates\n",
    "world_left = convert_to_world_point(35, 75, depth)\n",
    "world_right = convert_to_world_point(280, 70, depth)\n",
    "print(world_left)\n",
    "print(world_right)\n",
    "pred_length = np.linalg.norm(np.array(world_left) - np.array(world_right))\n",
    "print(pred_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True bbox\n",
    "i, j = np.nonzero(td)\n",
    "cloud = []\n",
    "for (i0, j0) in zip(i, j):\n",
    "    cloud.append([i0, j0, td[i0, j0]])\n",
    "obb, eigen_vectors = OBB.build_from_points([(p[0], p[1], p[2]) for p in cloud])\n",
    "true_obb_points = np.array(obb.points)\n",
    "length = np.linalg.norm(true_obb_points[0] - true_obb_points[1])\n",
    "width = np.linalg.norm(true_obb_points[0] - true_obb_points[3])\n",
    "height = np.linalg.norm(true_obb_points[0] - true_obb_points[5])\n",
    "true_volume = length * width * height\n",
    "\n",
    "print('True length: {}'.format(length))\n",
    "print('True width: {}'.format(width))\n",
    "print('True height: {}'.format(height))\n",
    "print('True volume: {}'.format(true_volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td[td !=0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth[depth!=0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted bbox\n",
    "i, j = np.nonzero(depth)\n",
    "cloud = []\n",
    "for (i0, j0) in zip(i, j):\n",
    "    cloud.append([i0, j0, depth[i0, j0]])\n",
    "obb, eigen_vectors = OBB.build_from_points([(p[0], p[1], p[2]) for p in cloud])\n",
    "obb_points = np.array(obb.points)\n",
    "length = np.linalg.norm(obb_points[0] - obb_points[1])\n",
    "width = np.linalg.norm(obb_points[0] - obb_points[3])\n",
    "height = np.linalg.norm(obb_points[0] - obb_points[5])\n",
    "volume = length * width * height\n",
    "\n",
    "print('Pred length: {}'.format(length))\n",
    "print('Pred width: {}'.format(width))\n",
    "print('Pred height: {}'.format(height))\n",
    "print('Pred volume: {}'.format(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative error\n",
    "error = np.abs(volume - true_volume)*100 / true_volume\n",
    "print('Relative error: {}'.format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from scipy.spatial import ConvexHull\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_world_point_vector(x, y, depth_map):\n",
    "    image_center_x = 1024 / 2.0 #depth_map.shape[1] / 2.0\n",
    "    image_center_y = 512 / 2.0 # depth_map.shape[0] / 2.0\n",
    "    px_x = x - image_center_x\n",
    "    px_z = image_center_y - y\n",
    "\n",
    "    sensor_x = px_x * (image_sensor_width / 1024)\n",
    "    sensor_z = px_z * (image_sensor_height / 512)\n",
    "    \n",
    "    d = depth_map[y, x]\n",
    "    world_y = d\n",
    "    world_x = (world_y * sensor_x) / focal_length\n",
    "    world_z = (world_y * sensor_z) / focal_length\n",
    "#     return world_y\n",
    "    return (world_x, world_y, world_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = np.nonzero(td)\n",
    "wx, wy, wz = convert_to_world_point_vector(x, y, td)\n",
    "verts = [zip(wx, wy,wz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate convex hull\n",
    "hull = ConvexHull(np.stack([wx, wy, wz]).transpose())\n",
    "print(hull.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obb, eigen_vectors = OBB.build_from_points([(x, y, z) for (x,z,y) in zip(wx, wy, wz)])\n",
    "# true_obb_points = np.array(obb.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(wx, wy, wz)\n",
    "plt.xlabel('X', fontsize=18)\n",
    "plt.ylabel('Y', fontsize=16)\n",
    "# plt.zlabel('Z', fontsize=16)\n",
    "\n",
    "# ax.add_collection3d(Poly3DCollection(verts))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = np.nonzero(depth)\n",
    "wx, wy, wz = convert_to_world_point_vector(x, y, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate convex hull\n",
    "hull = ConvexHull(np.stack([wx, wy, wz]).transpose())\n",
    "print(hull.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(wx, wy, wz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [-1, 1]\n",
    "for s, e in combinations(np.array(list(product(r, r, r))), 2):\n",
    "    if np.sum(np.abs(s-e)) == r[1]-r[0]:\n",
    "        print(zip(s, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = zip(s,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from skimage.measure import label\n",
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = sorted(glob.glob('/root/data/blender_v5/stereo_images/left*'), key=lambda k:int(os.path.basename(k).split('.')[0].split('_')[-1]))\n",
    "right = sorted(glob.glob('/root/data/blender_v5/stereo_images/right*'), key=lambda k:int(os.path.basename(k).split('.')[0].split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGMENTATION SET UP\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "model = get_unet(3, 512, 512, classes=1)\n",
    "def binary_error(y_true, y_pred):\n",
    "    return K.mean(K.not_equal(y_true, K.round(y_pred)), axis=-1)\n",
    "adam = Adam(lr=1e-3)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int, binary_error])\n",
    "model.load_weights('/root/data/models/blender/segmentation/raw_segmentation_03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPTH MAP SET UP\n",
    "params = {'p2': 864, 'p1': 216, 'speckle_window_size': 32, 'speckle_range': 6, 'min_disparity': 0, 'max_disparity': 20, 'uniqueness': 13, 'num_disp': 32, 'full_dp': False, 'sad_window_size': 7}\n",
    "block_matcher = cv2.StereoSGBM(minDisparity=params['min_disparity'],\n",
    "                        numDisparities=params['num_disp'],\n",
    "                        SADWindowSize=params['sad_window_size'],\n",
    "                        uniquenessRatio=params['uniqueness'],\n",
    "                        speckleWindowSize=params['speckle_window_size'],\n",
    "                        speckleRange=params['speckle_range'],\n",
    "                        disp12MaxDiff=params['max_disparity'],\n",
    "                        P1=params['p1'],\n",
    "                        P2=params['p2'],\n",
    "                        fullDP=params['full_dp'])\n",
    "\n",
    "# meters\n",
    "focal_length = 10.0*1e-3\n",
    "baseline = 65.0*1e-3\n",
    "image_sensor_width = 32.0*1e-3\n",
    "image_sensor_height = 18.0*1e-3\n",
    "pixel_size = image_sensor_width / 1024\n",
    "focal_length_pixel = focal_length / pixel_size\n",
    "\n",
    "\n",
    "def Z(X, Y, params):\n",
    "    a, b, c, d = params\n",
    "    return -(a*X + b*Y + d)/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = left[:1]\n",
    "right = right[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_errors = []\n",
    "length_errors = []\n",
    "\n",
    "\n",
    "for (i, (left_path, right_path)) in enumerate(zip(left, right)):\n",
    "    # fancy trick\n",
    "    ground_truth_depth_path = '/root/data/blender_v5/depth_map/depth_map_{}.npy'.format(i)\n",
    "    \n",
    "    \n",
    "    # 1 SEGMENTATION\n",
    "    # predict on left image\n",
    "    prediction = model.predict_on_batch(np.expand_dims(np.array(Image.open(left_path).convert('RGB').resize((512, 512))), axis=0))\n",
    "    prediction = np.round(prediction)\n",
    "    rprediction = cv2.resize(prediction.squeeze(), (1024, 512))\n",
    "    rprediction[rprediction<1] = 0\n",
    "    \n",
    "    labels = label(rprediction)\n",
    "    for l in np.unique(labels):\n",
    "        tmp = labels == l\n",
    "        if l == 0:\n",
    "            continue\n",
    "        if np.count_nonzero(tmp) < 1000:\n",
    "            continue\n",
    "        pred = tmp\n",
    "        break\n",
    "    \n",
    "    if display:\n",
    "        plt.imshow(pred)\n",
    "        plt.title('Segmentation prediction')\n",
    "        plt.show()\n",
    "        \n",
    "    # 2 IDENTIFICATION\n",
    "    delta = 20\n",
    "    x,y = np.nonzero(pred)\n",
    "    xmin, xmax = x.min()-delta, x.max()+delta\n",
    "    ymin, ymax = y.min()-delta, y.max()+delta\n",
    "    mask = rprediction[xmin:xmax, ymin:ymax]\n",
    "    \n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.title('Mask')\n",
    "        plt.show()\n",
    "    \n",
    "    # 3 DEPTH MAP\n",
    "    left_crop = cv2.imread(left_path)[xmin:xmax, ymin:ymax]\n",
    "    right_crop = cv2.imread(right_path)[xmin:xmax, ymin:ymax]\n",
    "    disp = block_matcher.compute(left_crop, right_crop).astype(np.float32) / 16.0\n",
    "    \n",
    "    depth = focal_length_pixel*baseline / (disp*mask)\n",
    "    depth[depth == np.inf] = 0\n",
    "    depth[depth == -np.inf] = 0\n",
    "     \n",
    "    x,y = np.nonzero(depth)\n",
    "    z = [depth[i,j] for (i,j) in zip(x,y)]\n",
    "    A = np.c_[x, y, np.ones((len(x)))]\n",
    "    C, _, _, _ = lstsq(A, z)\n",
    "    vert_params = C[0], C[1], -1., C[2]\n",
    "\n",
    "    X, Y = np.meshgrid(np.arange(0,mask.shape[0], 1), np.arange(0, mask.shape[1], 1))\n",
    "    Zfit = Z(X, Y, vert_params)\n",
    "    depth = np.abs(Zfit.transpose()*mask)\n",
    "    true_depth = np.load(ground_truth_depth_path)[xmin:xmax, ymin:ymax]*mask\n",
    "    \n",
    "    if display:\n",
    "        f, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(depth)\n",
    "        ax[1].imshow(true_depth)\n",
    "        plt.show()\n",
    "        \n",
    "    depth_relative_error= np.nanmean(np.abs(depth-true_depth) / true_depth)\n",
    "    print('Depth relative error {}'.format(depth_relative_error))\n",
    "    depth_errors.append(depth_relative_error)\n",
    "    \n",
    "    \n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
