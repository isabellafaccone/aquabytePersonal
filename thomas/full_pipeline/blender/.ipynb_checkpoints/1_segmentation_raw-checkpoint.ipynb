{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "\n",
    "from unet import get_unet, jaccard_coef_int, jaccard_coef_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(3, 512, 512, classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_error(y_true, y_pred):\n",
    "    return K.mean(K.not_equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-3)\n",
    "model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int, binary_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "SEED = 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('/root/data/blender_v3/stereo_images/left*.png')\n",
    "random.shuffle(images)\n",
    "print(len(images))\n",
    "cutoff = int(len(images)*0.8)\n",
    "train = images[:cutoff]\n",
    "print(len(train))\n",
    "test = images[cutoff:]\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "batch_size = 8\n",
    "steps_per_epoch = len(train) // batch_size\n",
    "steps_per_epoch_val = len(test) // batch_size\n",
    "input_shape = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN_RANGE_MIN_HSV = (100, 20, 20)\n",
    "GREEN_RANGE_MAX_HSV = (185, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(r, g, b):\n",
    "    maxc = max(r, g, b)\n",
    "    minc = min(r, g, b)\n",
    "    v = maxc\n",
    "    if minc == maxc:\n",
    "        return 0.0, 0.0, v\n",
    "    s = (maxc-minc) / maxc\n",
    "    rc = (maxc-r) / (maxc-minc)\n",
    "    gc = (maxc-g) / (maxc-minc)\n",
    "    bc = (maxc-b) / (maxc-minc)\n",
    "    if r == maxc:\n",
    "        h = bc-gc\n",
    "    elif g == maxc:\n",
    "        h = 2.0+rc-bc\n",
    "    else:\n",
    "        h = 4.0+gc-rc\n",
    "    h = (h/6.0) % 1.0\n",
    "    return h, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_mask(im, min_hsv=GREEN_RANGE_MIN_HSV, max_hsv=GREEN_RANGE_MAX_HSV):\n",
    "    \"\"\"remove green pixels\"\"\"\n",
    "    # im = Image.open(image_path)\n",
    "    # im = im.convert('RGBA')\n",
    "    pix = im.load()\n",
    "    width, height = im.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            r, g, b = pix[x, y]\n",
    "            h_ratio, s_ratio, v_ratio = rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)\n",
    "            h, s, v = (h_ratio * 360, s_ratio * 255, v_ratio * 255)\n",
    "\n",
    "            min_h, min_s, min_v = min_hsv\n",
    "            max_h, max_s, max_v = max_hsv\n",
    "            if min_h <= h <= max_h and min_s <= s <= max_s and min_v <= v <= max_v:\n",
    "                pix[x, y] = (0, 0, 0, 0)\n",
    "\n",
    "    # save the mask\n",
    "    mask = np.asarray(im)[...,0]\n",
    "    mask.flags.writeable = True\n",
    "    mask[mask > 0] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dataset, steps_per_epoch, BATCH_SIZE, input_shape):\n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], input_shape[2]), dtype=np.uint8)\n",
    "        y_batch = np.empty((BATCH_SIZE, input_shape[0], input_shape[1], 1), dtype=np.uint8)\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            img = Image.open(dataset[j]).convert('RGB').resize((input_shape[0], input_shape[1]))\n",
    "            x_batch[ind,...] = np.array(img)\n",
    "            y_batch[ind,...,0] = crop_and_mask(img)\n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train, steps_per_epoch, batch_size, input_shape)\n",
    "val_generator = generator(test, steps_per_epoch_val, batch_size, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-3\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    if epoch >= 30:\n",
    "        fake_epoch = epoch - 20 \n",
    "        lrate = initial_lrate * math.pow(drop, math.floor((1+fake_epoch)/epochs_drop))\n",
    "    else:\n",
    "        lrate = initial_lrate\n",
    "    print('lr {}'.format(lrate))\n",
    "    return lrate\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history callback\n",
    "class SaveHistory(Callback):\n",
    "    \n",
    "    def __init__(self, json_path):\n",
    "        self.json_path = json_path\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        with open(self.json_path, 'w') as f:\n",
    "            json.dump(self.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveh = SaveHistory('./raw_segmentation_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filepath = os.path.join('/root/data/models/blender/segmentation/', 'raw_segmentation_{epoch:02d}.h5')\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_jaccard_coef_int', \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training# start \n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[saveh, lr_scheduler, checkpoint],\n",
    "        validation_data= val_generator,\n",
    "        validation_steps= steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
