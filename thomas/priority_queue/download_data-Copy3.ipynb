{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table, select, func, and_, insert, delete, update, or_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "sql_credentials = json.load(open(\"/root/thomas/sqlcredentials.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_credentials = json.load(open(\"/root/thomas/aws_credentials.json\"))\n",
    "s3_client = boto3.client('s3', aws_access_key_id=aws_credentials[\"aws_access_key_id\"],\n",
    "                         aws_secret_access_key=aws_credentials[\"aws_secret_access_key\"],\n",
    "                         region_name=\"eu-west-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "sql_engine = create_engine(\n",
    "    \"postgresql://{}:{}@{}:{}/{}\".format(sql_credentials[\"user\"], sql_credentials[\"password\"],\n",
    "                                         sql_credentials[\"host\"], sql_credentials[\"port\"],\n",
    "                                         sql_credentials[\"database\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = MetaData()\n",
    "# # step 1 - download crops + json\n",
    "# fish_crops = Table('lati_fish_detections', metadata, autoload=True, autoload_with=sql_engine)\n",
    "# lice_crops = Table('lati_fish_detections_lice_annotations', metadata, autoload=True,\n",
    "#                    autoload_with=sql_engine)\n",
    "\n",
    "# # inner join on fish crop id\n",
    "# query = select([fish_crops.c.image_key, \n",
    "#                 lice_crops.c.is_blurry,\n",
    "#                 lice_crops.c.is_too_dark,\n",
    "#                 lice_crops.c.is_obstructed,\n",
    "#                 lice_crops.c.is_bad_crop,\n",
    "#                 ]) \\\n",
    "#     .select_from(lice_crops.join(fish_crops, lice_crops.c.lati_fish_detections_id == fish_crops.c.id)) \\\n",
    "#     .where(and_(fish_crops.c.site_id == 23,\n",
    "#                 lice_crops.c.is_skipped == True,\n",
    "#                 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sqlalchemy/dialects/postgresql/base.py:2950: SAWarning: Skipped unsupported reflection of expression-based index lati_fish_detections_detected_at_date\n",
      "  % idx_name)\n"
     ]
    }
   ],
   "source": [
    "metadata = MetaData()\n",
    "# step 1 - download crops + json\n",
    "fish_crops = Table('lati_fish_detections', metadata, autoload=True, autoload_with=sql_engine)\n",
    "lice_crops = Table('lati_fish_detections_lice_annotations', metadata, autoload=True,\n",
    "                   autoload_with=sql_engine)\n",
    "\n",
    "# inner join on fish crop id\n",
    "query = select([fish_crops.c.image_key, \n",
    "                lice_crops.c.is_blurry,\n",
    "                lice_crops.c.is_too_dark,\n",
    "                lice_crops.c.is_obstructed,\n",
    "                lice_crops.c.is_bad_crop,\n",
    "                ]) \\\n",
    "    .select_from(lice_crops.join(fish_crops, lice_crops.c.lati_fish_detections_id == fish_crops.c.id)) \\\n",
    "    .where(and_(fish_crops.c.site_id == 23,\n",
    "                lice_crops.c.is_skipped == True,\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sql_engine.connect()\n",
    "q = connection.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713651\n"
     ]
    }
   ],
   "source": [
    "results = [{\"key\": r[0], \n",
    "            \"blurry\": r[1], \n",
    "            \"dark\": r[2], \n",
    "            \"obstructed\": r[3], \n",
    "            \"bad\": r[4], \n",
    "            \"year\": r[0].split(\"/\")[3].split(\"-\")[0]} for r in q]\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop dictionnary stuff\n",
    "(for each crop, write down the associated classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# key_results = {}\n",
    "# for r in results:\n",
    "#     key_results[os.path.basename(r[\"key\"])] = [r[\"blurry\"], r[\"dark\"], r[\"obstructed\"], r[\"bad\"]]\n",
    "    \n",
    "# import json\n",
    "# with open(\"/root/data/priority_queue/images/image_classes.json\", \"w\") as f:\n",
    "#     json.dump(key_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame dictionnary stuff\n",
    "(for each frame, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# frame_classes = {}\n",
    "# for r in results:\n",
    "#     typ, farm, penid, date, crop_name = r[\"key\"].split(\"/\")\n",
    "#     frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "#     if frame_name not in frame_classes:\n",
    "#         frame_classes[frame_name] = np.zeros((4))\n",
    "#     if r[\"blurry\"]:\n",
    "#         frame_classes[frame_name][0] += 1\n",
    "#     if r[\"dark\"]:\n",
    "#         frame_classes[frame_name][1] += 1\n",
    "# #     if r[\"obstructed\"]:\n",
    "# #         frame_classes[frame_name][2] += 1\n",
    "# #     if r[\"bad\"]:\n",
    "# #         frame_classes[frame_name][3] += 1\n",
    "# no_consensus = 0\n",
    "# for (k,v) in frame_classes.items():\n",
    "#     if v[0] > 1 and v[0] != v[1]:\n",
    "#         no_consensus += 1\n",
    "        \n",
    "# print(no_consensus / len(list(frame_classes.keys())))\n",
    "\n",
    "# to_json = {}\n",
    "# for (k,v) in frame_classes.items():\n",
    "#     to_json[k] = [int(k) for k in (v[:2] > 0)]\n",
    "    \n",
    "# with open(\"/root/data/priority_queue/frames/image_classes.json\", \"w\") as f:\n",
    "#     json.dump(to_json, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532422\n"
     ]
    }
   ],
   "source": [
    "results = [r for r in results if r[\"year\"] == \"2019\"]\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blurry images: 352261\n"
     ]
    }
   ],
   "source": [
    "blurry = [r for r in results if r[\"blurry\"]]\n",
    "print(\"Number of blurry images: {}\".format(len(blurry)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dark images: 298976\n"
     ]
    }
   ],
   "source": [
    "dark = [r for r in results if r[\"dark\"]]\n",
    "print(\"Number of dark images: {}\".format(len(dark)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad images: 99608\n"
     ]
    }
   ],
   "source": [
    "bad = [r for r in results if r[\"bad\"]]\n",
    "print(\"Number of bad images: {}\".format(len(bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obstructed images: 10187\n"
     ]
    }
   ],
   "source": [
    "obstructed = [r for r in results if r[\"obstructed\"]]\n",
    "print(\"Number of obstructed images: {}\".format(len(obstructed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's download a few k images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's download ~5k images for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = True\n",
    "if frame:\n",
    "    bucket = \"aquabyte-images-raw-resized\"\n",
    "    destination_folder = \"frames-resized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = np.random.choice(blurry)\n",
    "# typ, farm, penid, date, crop_name = T[\"key\"].split(\"/\")\n",
    "# frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "# key = \"/\".join([typ, farm, penid, date, frame_name])\n",
    "# print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # download blurry image\n",
    "# blurry_subset = np.random.choice(blurry, 10000)\n",
    "# for img in tqdm(blurry_subset):\n",
    "#     key = img[\"key\"]\n",
    "#     if frame:\n",
    "#         typ, farm, penid, date, crop_name = key.split(\"/\")\n",
    "#         frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "#         key = \"/\".join([typ, farm, penid, date, frame_name])\n",
    "#     destination = os.path.join(\"/root/data/priority_queue/{}/blurry/\".format(destination_folder), \n",
    "#                                os.path.basename(key))\n",
    "#     try:\n",
    "#         s3_client.download_file(bucket, key, destination)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download dark image\n",
    "# dark_subset = np.random.choice(dark, 10000)\n",
    "# for img in tqdm(dark_subset):\n",
    "#     key = img[\"key\"]\n",
    "#     if frame:\n",
    "#         typ, farm, penid, date, crop_name = key.split(\"/\")\n",
    "#         frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "#         key = \"/\".join([typ, farm, penid, date, frame_name])\n",
    "#     destination = os.path.join(\"/root/data/priority_queue/{}/dark/\".format(destination_folder), \n",
    "#                                os.path.basename(key))\n",
    "#     try:\n",
    "#         s3_client.download_file(bucket, key, destination)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download bad image\n",
    "# bad_subset = np.random.choice(bad, 10000)\n",
    "# for img in tqdm(bad_subset):\n",
    "#     key = img[\"key\"]\n",
    "#     if frame:\n",
    "#         typ, farm, penid, date, crop_name = key.split(\"/\")\n",
    "#         frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "#         key = \"/\".join([typ, farm, penid, date, frame_name])\n",
    "#     destination = os.path.join(\"/root/data/priority_queue/{}/bad/\".format(destination_folder), \n",
    "#                                os.path.basename(key))\n",
    "#     try:\n",
    "#         s3_client.download_file(bucket, key, destination)\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [52:07<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# download obstructed image\n",
    "obstructed_subset = np.random.choice(obstructed, 10000)\n",
    "for img in tqdm(obstructed_subset):\n",
    "    key = img[\"key\"]\n",
    "    if frame:\n",
    "        typ, farm, penid, date, crop_name = key.split(\"/\")\n",
    "        frame_name = \"_\".join(crop_name.split(\"_\")[:4]) + \".jpg\"\n",
    "        key = \"/\".join([typ, farm, penid, date, frame_name])\n",
    "    destination = os.path.join(\"/root/data/priority_queue/{}/obstructed/\".format(destination_folder),\n",
    "                               os.path.basename(key))\n",
    "    try:\n",
    "        s3_client.download_file(bucket, key, destination)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.utcfromtimestamp(1545914338476/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from time import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "image = Image.open(\"/root/data/priority_queue/frames/good/left_blom-kjeppevikholmen_2_1543143094624.jpg\")\n",
    "# image = image.resize((224, 224))\n",
    "# image.save(\"/tmp/test.jpg\")\n",
    "end = time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "image = cv2.imread(\"/root/data/priority_queue/frames/good/left_blom-kjeppevikholmen_2_1543143094624.jpg\")\n",
    "# image = cv2.resize(image, (224, 224))\n",
    "# cv2.imwrite(\"/tmp/test.jpg/\", image)\n",
    "end = time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
