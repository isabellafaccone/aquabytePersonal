{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_images = glob.glob(\"/root/data/priority_queue/frames-resized/good/*.jpg\")\n",
    "print(\"Number of good images {}\".format(len(good_images)))\n",
    "bad_images = glob.glob(\"/root/data/priority_queue/frames-resized/blurry/*.jpg\")\n",
    "bad_images += glob.glob(\"/root/data/priority_queue/frames-resized/dark/*.jpg\")\n",
    "print(\"Number of bad images {}\".format(len(bad_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consensus crops -> frames\n",
    "image_classes = json.load(open(\"/root/data/priority_queue/frames/image_classes.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (k,v) in image_classes.items():\n",
    "#     print(v)\n",
    "#     print([int(k) for k in v])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in bad_images:\n",
    "    name = os.path.basename(img)\n",
    "    if name not in image_classes:\n",
    "        print(\"red alert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiences:\n",
    "* BW classifier\n",
    "* RGB classifer: overfitting done / \n",
    "* split per class with sigmoid head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(124)\n",
    "random.shuffle(bad_images)\n",
    "random.shuffle(good_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_good = int(len(good_images)*0.8)\n",
    "cutoff_bad = int(len(bad_images)*0.8)\n",
    "\n",
    "train_good = good_images[:cutoff_good]\n",
    "val_good = good_images[cutoff_good:]\n",
    "\n",
    "train_bad = bad_images[:cutoff_bad]\n",
    "val_bad = bad_images[cutoff_bad:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpus = 2\n",
    "new_shape = (224, 224)\n",
    "batch_size = 32*ngpus\n",
    "classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenters = {1: iaa.GaussianBlur((0.0, 3.0), name=\"GaussianBlur\"),\n",
    "              2: iaa.Add((-100, 0))}\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, good_images, bad_images, batch_size=batch_size, dim=(224, 224, 3)):\n",
    "        'Initialization'\n",
    "        self.good_images = good_images\n",
    "        self.batch_size = batch_size\n",
    "        self.bad_images = bad_images\n",
    "        self.dim = dim\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "#         return int((len(self.good_images) + len(self.bad_images)) / self.batch_size)\n",
    "        return (np.min([len(self.good_images), len(self.bad_images)])) // (self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        xbatch = []\n",
    "        ybatch = []\n",
    "        start = index * self.batch_size\n",
    "        end = (index+1)*self.batch_size\n",
    "#         print(start, end)\n",
    "        for i in range(start, end, 1):\n",
    "            auglist = [iaa.Fliplr(0.5)]\n",
    "            k = i // 2\n",
    "            if i % 2 == 0:\n",
    "                path = self.good_images[k]\n",
    "                label = [1, 0, 0]\n",
    "            else:\n",
    "                k = i // 2 # - 1\n",
    "                path = self.bad_images[k]\n",
    "                label = [0] + image_classes[os.path.basename(path)]\n",
    "#                 auglist += [sometimes(iaa.GaussianBlur((0.0, 3.0))), \n",
    "#                             sometimes(iaa.Add((-100, 0)))]\n",
    "                \n",
    "            seq = iaa.Sequential(auglist)    \n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.resize(image, new_shape)\n",
    "            image = seq.augment_image(image)\n",
    "            xbatch.append(image)\n",
    "            ybatch.append(label)\n",
    "\n",
    "        return np.array(xbatch), np.array(ybatch)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.good_images)\n",
    "        random.shuffle(self.bad_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = DataGenerator(train_good, train_bad)\n",
    "valgen = DataGenerator(val_good, val_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = traingen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(batch_size):\n",
    "#     plt.imshow(xb[i, ...])\n",
    "#     plt.show()\n",
    "#     print(yb[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models:\n",
    "* resnet50 = overfit\n",
    "* mobilenet \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body = ResNet50(include_top=False, \n",
    "#                  weights='imagenet',\n",
    "#                  input_shape=(256, 256, 3),\n",
    "#                  pooling=\"avg\")\n",
    "# x = body.output\n",
    "# x = layers.Dense(1, activation='sigmoid', name='fc1000')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "#     alpha=1.0\n",
    "#     shape = (1, 1, int(1024 * alpha))\n",
    "#     dropout=1e-3\n",
    "#     body = MobileNet(include_top=False,\n",
    "#                      weights='imagenet',\n",
    "#                      input_shape=(224, 224, 3),\n",
    "#                      pooling=None\n",
    "#                     )\n",
    "    \n",
    "#     x = layers.GlobalAveragePooling2D()(body.output)\n",
    "#     x = layers.Reshape(shape, name='reshape_1')(x)\n",
    "#     x = layers.Dropout(dropout, name='dropout')(x)\n",
    "#     x = layers.Conv2D(classes, (1, 1),\n",
    "#                       padding='same',\n",
    "#                       name='conv_preds')(x)\n",
    "#     x = layers.Activation('sigmoid', name='act_sigmoid')(x)\n",
    "#     x = layers.Reshape((classes,), name='reshape_2')(x)\n",
    "    \n",
    "#     single_model = Model([body.input], [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "#     alpha = 1.0\n",
    "#     dropout = 1e-2\n",
    "#     body = MobileNetV2(include_top=False,\n",
    "#                      weights='imagenet',\n",
    "#                      input_shape=(224, 224, 3),\n",
    "#                      pooling=None\n",
    "#                     )\n",
    "    \n",
    "#     x = layers.GlobalAveragePooling2D()(body.output)\n",
    "#     x = layers.Dense(classes, activation='sigmoid',\n",
    "#                      use_bias=True, name='Logits')(x)\n",
    "    \n",
    "#     single_model = Model([body.input], [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
    "    in_channels = K.int_shape(inputs)[-1]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "\n",
    "    if block_id:\n",
    "        # Expand\n",
    "        x = layers.Conv2D(expansion * in_channels,\n",
    "                          kernel_size=1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          activation=None,\n",
    "                          name=prefix + 'expand')(x)\n",
    "        x = layers.BatchNormalization(epsilon=1e-3,\n",
    "                                      momentum=0.999,\n",
    "                                      name=prefix + 'expand_BN')(x)\n",
    "        x = layers.ReLU(6., name=prefix + 'expand_relu')(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "\n",
    "    # Depthwise\n",
    "    if stride == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(K, x, 3),\n",
    "                                 name=prefix + 'pad')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3,\n",
    "                               strides=stride,\n",
    "                               activation=None,\n",
    "                               use_bias=False,\n",
    "                               padding='same' if stride == 1 else 'valid',\n",
    "                               name=prefix + 'depthwise')(x)\n",
    "    x = layers.BatchNormalization(epsilon=1e-3,\n",
    "                                  momentum=0.999,\n",
    "                                  name=prefix + 'depthwise_BN')(x)\n",
    "\n",
    "    x = layers.ReLU(6., name=prefix + 'depthwise_relu')(x)\n",
    "\n",
    "    # Project\n",
    "    x = layers.Conv2D(pointwise_filters,\n",
    "                      kernel_size=1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      activation=None,\n",
    "                      name=prefix + 'project')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        epsilon=1e-3, momentum=0.999, name=prefix + 'project_BN')(x)\n",
    "\n",
    "    if in_channels == pointwise_filters and stride == 1:\n",
    "        return layers.Add(name=prefix + 'add')([inputs, x])\n",
    "    return x\n",
    "\n",
    "def correct_pad(backend, inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
    "    # Arguments\n",
    "        input_size: An integer or tuple/list of 2 integers.\n",
    "        kernel_size: An integer or tuple/list of 2 integers.\n",
    "    # Returns\n",
    "        A tuple.\n",
    "    \"\"\"\n",
    "    img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
    "\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    alpha=1.0\n",
    "    dropout=5e-3\n",
    "    depth_multiplier=1.0\n",
    "\n",
    "    img_input = layers.Input(shape=(224, 224, 3))\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(K, img_input, 3),\n",
    "                             name='Conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(first_block_filters,\n",
    "                      kernel_size=3,\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      name='Conv1')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        epsilon=1e-3, momentum=0.999, name='bn_Conv1')(x)\n",
    "    x = layers.ReLU(6., name='Conv1_relu')(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=6)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=7)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=8)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=9)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=10)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=11)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=12)\n",
    "\n",
    "#     x = _inverted_res_block(x, filters=160, alpha=alpha, stride=2,\n",
    "#                             expansion=6, block_id=13)\n",
    "#     x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
    "#                             expansion=6, block_id=14)\n",
    "#     x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
    "#                             expansion=6, block_id=15)\n",
    "\n",
    "#     x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1,\n",
    "#                             expansion=6, block_id=16)\n",
    "    \n",
    "    last_block_filters = 1280\n",
    "    x = layers.Conv2D(last_block_filters,\n",
    "                      kernel_size=1,\n",
    "                      use_bias=False,\n",
    "                      name='Conv_1')(x)\n",
    "    x = layers.BatchNormalization(epsilon=1e-3,\n",
    "                                  momentum=0.999,\n",
    "                                  name='Conv_1_bn')(x)\n",
    "    x = layers.ReLU(6., name='out_relu')(x)\n",
    "    \n",
    "    # top\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(classes, activation='sigmoid',\n",
    "                     use_bias=True, name='Logits')(x)\n",
    "    \n",
    "    single_model = Model([img_input], [x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(single_model, gpus=ngpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lrate = 1e-3\n",
    "adam = Adam(lr=initial_lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_pred[:, 0]), y_true[:, 0]), axis=0)\n",
    "def blurry_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_pred[:, 1]), y_true[:, 1]), axis=0)\n",
    "def dark_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_pred[:, 2]), y_true[:, 2]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def class_accuracy(y_true, y_pred):\n",
    "#     return np.mean(np.equal(np.round(y_pred), y_true), axis=0)\n",
    "\n",
    "# y_true = np.round(np.random.rand(16, 3))\n",
    "# y_pred = np.random.rand(16, 3)\n",
    "# class_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(adam, \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=[\"binary_accuracy\", good_accuracy, blurry_accuracy, dark_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    drop = 0.5\n",
    "    epochs_drop = 15.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"/root/data/priority_queue/models/frames_{epoch:02d}.h5\", \n",
    "#                              monitor='val_loss', \n",
    "#                              verbose=0, \n",
    "#                              save_best_only=False, \n",
    "#                              save_weights_only=False, \n",
    "#                              mode='min', \n",
    "#                              period=1)\n",
    "class CheckpointSingleModel(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        single_model.save(\"/root/data/priority_queue/models/frames_{}.h5\".format(epoch))\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slowdown = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator = traingen, \n",
    "                              steps_per_epoch=(np.min([len(train_good), len(train_bad)])) // (batch_size*slowdown),\n",
    "                              workers=10,\n",
    "                              max_queue_size=20,\n",
    "                              use_multiprocessing=False,\n",
    "                              validation_data=valgen,\n",
    "                              validation_steps = (np.min([len(val_good), len(val_bad)])) // (batch_size*slowdown),\n",
    "                              callbacks=[lrate, CheckpointSingleModel()],\n",
    "                              epochs=30*slowdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h[\"loss\"])\n",
    "plt.plot(h[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.max(h[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(h[\"good_accuracy\"])\n",
    "# plt.plot(h[\"blurry_accuracy\"])\n",
    "# plt.plot(h[\"dark_accuracy\"])\n",
    "plt.plot(h[\"val_good_accuracy\"])\n",
    "plt.plot(h[\"val_blurry_accuracy\"])\n",
    "plt.plot(h[\"val_dark_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_model.save(\"/root/data/priority_queue/models/draft_frames_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(h[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "stuff = {}\n",
    "stuff[\"description\"] = \"binary classification good / bad for filtering\"\n",
    "stuff[\"input_size\"] = (224, 224, 3)\n",
    "stuff[\"output_size\"] = (3,)\n",
    "stuff[\"probability\"] = {\"is_good\": 0, \"is_dark\":2, \"is_blurry\": 1}\n",
    "stuff[\"model\"] = \"Mobilenet\"\n",
    "with open(\"/root/data/priority_queue/models/blom-kjeppevikholmen_filtration_2019-03-08.json\", \"w\") as f:\n",
    "    json.dump(stuff, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
